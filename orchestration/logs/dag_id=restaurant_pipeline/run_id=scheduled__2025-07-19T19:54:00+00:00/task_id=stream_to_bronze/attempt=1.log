[2025-07-19T19:57:07.708+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T19:54:00+00:00 [queued]>
[2025-07-19T19:57:07.712+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T19:54:00+00:00 [queued]>
[2025-07-19T19:57:07.712+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2025-07-19T19:57:07.717+0000] {taskinstance.py:1382} INFO - Executing <Task(BashOperator): stream_to_bronze> on 2025-07-19 19:54:00+00:00
[2025-07-19T19:57:07.719+0000] {standard_task_runner.py:57} INFO - Started process 2873 to run task
[2025-07-19T19:57:07.721+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'restaurant_pipeline', 'stream_to_bronze', 'scheduled__2025-07-19T19:54:00+00:00', '--job-id', '1147', '--raw', '--subdir', 'DAGS_FOLDER/restaurant_pipeline.py', '--cfg-path', '/tmp/tmpjzf47neh']
[2025-07-19T19:57:07.722+0000] {standard_task_runner.py:85} INFO - Job 1147: Subtask stream_to_bronze
[2025-07-19T19:57:07.743+0000] {task_command.py:416} INFO - Running <TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T19:54:00+00:00 [running]> on host e3f5d8fc4eef
[2025-07-19T19:57:07.780+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='moran' AIRFLOW_CTX_DAG_ID='restaurant_pipeline' AIRFLOW_CTX_TASK_ID='stream_to_bronze' AIRFLOW_CTX_EXECUTION_DATE='2025-07-19T19:54:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T19:54:00+00:00'
[2025-07-19T19:57:07.780+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-07-19T19:57:07.780+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', "docker exec -e AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T19:54:00+00:00' spark-iceberg spark-submit /home/iceberg/spark/stream_to_bronze.py"]
[2025-07-19T19:57:07.784+0000] {subprocess.py:86} INFO - Output:
[2025-07-19T19:57:09.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SparkContext: Running Spark version 3.5.6
[2025-07-19T19:57:09.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T19:57:09.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SparkContext: Java version 17.0.15
[2025-07-19T19:57:09.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO ResourceUtils: ==============================================================
[2025-07-19T19:57:09.391+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-19T19:57:09.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO ResourceUtils: ==============================================================
[2025-07-19T19:57:09.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SparkContext: Submitted application: StreamToBronze
[2025-07-19T19:57:09.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-19T19:57:09.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO ResourceProfile: Limiting resource is cpu
[2025-07-19T19:57:09.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-19T19:57:09.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SecurityManager: Changing view acls to: root,spark
[2025-07-19T19:57:09.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SecurityManager: Changing modify acls to: root,spark
[2025-07-19T19:57:09.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SecurityManager: Changing view acls groups to:
[2025-07-19T19:57:09.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SecurityManager: Changing modify acls groups to:
[2025-07-19T19:57:09.448+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
[2025-07-19T19:57:09.480+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-19T19:57:09.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO Utils: Successfully started service 'sparkDriver' on port 44501.
[2025-07-19T19:57:09.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SparkEnv: Registering MapOutputTracker
[2025-07-19T19:57:09.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-19T19:57:09.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-19T19:57:09.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-19T19:57:09.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-19T19:57:09.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7bb8128c-1676-4df4-97a2-f0da978d5057
[2025-07-19T19:57:09.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-19T19:57:09.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-19T19:57:09.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-19T19:57:09.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-07-19T19:57:09.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-07-19T19:57:09.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO Executor: Starting executor ID driver on host 8b44f3d35cfa
[2025-07-19T19:57:09.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T19:57:09.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO Executor: Java version 17.0.15
[2025-07-19T19:57:09.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-19T19:57:09.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5a01fd7 for default.
[2025-07-19T19:57:09.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44249.
[2025-07-19T19:57:09.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO NettyBlockTransferService: Server created on 8b44f3d35cfa:44249
[2025-07-19T19:57:09.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-19T19:57:09.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 8b44f3d35cfa, 44249, None)
[2025-07-19T19:57:09.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO BlockManagerMasterEndpoint: Registering block manager 8b44f3d35cfa:44249 with 434.4 MiB RAM, BlockManagerId(driver, 8b44f3d35cfa, 44249, None)
[2025-07-19T19:57:09.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 8b44f3d35cfa, 44249, None)
[2025-07-19T19:57:09.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 8b44f3d35cfa, 44249, None)
[2025-07-19T19:57:10.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:10 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-19T19:57:10.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:10 INFO SharedState: Warehouse path is 'file:/app/spark-warehouse'.
[2025-07-19T19:57:11.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-07-19T19:57:11.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-07-19T19:57:11.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-07-19T19:57:11.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:11.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-07-19T19:57:11.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00 resolved to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00.
[2025-07-19T19:57:11.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T19:57:11.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/metadata using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/.metadata.91fe1f0e-c110-4818-9989-24924abaeeaa.tmp
[2025-07-19T19:57:11.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/.metadata.91fe1f0e-c110-4818-9989-24924abaeeaa.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/metadata
[2025-07-19T19:57:11.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO MicroBatchExecution: Starting [id = 5253d98e-255c-4533-9785-660d38a21faf, runId = 8d7b6976-38a8-4337-af61-4ae74f3cdde4]. Use file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00 to store the query checkpoint.
[2025-07-19T19:57:11.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@48879b0d] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@39505960]
[2025-07-19T19:57:11.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T19:57:11.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T19:57:11.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T19:57:11.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:11 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T19:57:12.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:12.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00 resolved to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00.
[2025-07-19T19:57:12.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T19:57:12.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/metadata using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/.metadata.e29de9ef-b4c2-4eb5-93a4-156ee4243695.tmp
[2025-07-19T19:57:12.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/.metadata.e29de9ef-b4c2-4eb5-93a4-156ee4243695.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/metadata
[2025-07-19T19:57:12.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Starting [id = 609fc205-5186-4889-9ac4-e96d359c0199, runId = bba1078e-cb27-476b-a4e5-d0c62f2a2c75]. Use file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00 to store the query checkpoint.
[2025-07-19T19:57:12.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@1ea583d9] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@10627fa5]
[2025-07-19T19:57:12.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T19:57:12.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T19:57:12.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T19:57:12.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T19:57:12.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:12.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00 resolved to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00.
[2025-07-19T19:57:12.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T19:57:12.195+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/metadata using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/.metadata.e168df58-ce5d-47f9-8852-b286277b2375.tmp
[2025-07-19T19:57:12.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T19:57:12.199+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T19:57:12.199+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T19:57:12.200+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T19:57:12.200+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T19:57:12.200+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T19:57:12.200+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T19:57:12.200+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T19:57:12.200+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T19:57:12.200+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T19:57:12.201+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T19:57:12.201+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T19:57:12.201+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T19:57:12.201+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T19:57:12.202+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T19:57:12.202+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T19:57:12.202+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T19:57:12.203+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T19:57:12.203+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T19:57:12.203+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T19:57:12.203+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T19:57:12.204+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T19:57:12.204+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T19:57:12.204+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T19:57:12.204+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T19:57:12.204+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T19:57:12.204+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T19:57:12.204+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T19:57:12.205+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T19:57:12.205+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T19:57:12.205+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T19:57:12.205+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T19:57:12.205+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T19:57:12.205+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T19:57:12.206+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T19:57:12.206+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T19:57:12.206+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T19:57:12.206+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T19:57:12.206+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T19:57:12.206+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T19:57:12.207+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T19:57:12.207+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T19:57:12.207+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T19:57:12.207+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T19:57:12.207+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T19:57:12.208+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T19:57:12.208+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T19:57:12.209+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T19:57:12.209+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T19:57:12.209+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T19:57:12.210+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T19:57:12.210+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T19:57:12.210+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T19:57:12.210+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T19:57:12.211+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T19:57:12.211+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T19:57:12.212+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T19:57:12.212+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T19:57:12.212+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T19:57:12.212+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T19:57:12.213+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T19:57:12.213+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T19:57:12.213+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T19:57:12.213+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T19:57:12.213+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T19:57:12.214+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T19:57:12.214+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T19:57:12.215+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T19:57:12.215+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T19:57:12.216+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T19:57:12.216+0000] {subprocess.py:93} INFO - 
[2025-07-19T19:57:12.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T19:57:12.216+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T19:57:12.217+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T19:57:12.217+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T19:57:12.218+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T19:57:12.218+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T19:57:12.219+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T19:57:12.219+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T19:57:12.219+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T19:57:12.220+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T19:57:12.220+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T19:57:12.220+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T19:57:12.221+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T19:57:12.221+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T19:57:12.222+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T19:57:12.222+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T19:57:12.223+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T19:57:12.223+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T19:57:12.223+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T19:57:12.224+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T19:57:12.224+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T19:57:12.224+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T19:57:12.224+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T19:57:12.224+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T19:57:12.225+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T19:57:12.225+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T19:57:12.225+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T19:57:12.225+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T19:57:12.225+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T19:57:12.225+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T19:57:12.225+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T19:57:12.225+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T19:57:12.225+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T19:57:12.226+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T19:57:12.226+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T19:57:12.226+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T19:57:12.226+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T19:57:12.226+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T19:57:12.226+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T19:57:12.226+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T19:57:12.227+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T19:57:12.228+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T19:57:12.228+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T19:57:12.228+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T19:57:12.228+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T19:57:12.228+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T19:57:12.228+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T19:57:12.228+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T19:57:12.228+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T19:57:12.228+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 
[2025-07-19T19:57:12.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/.metadata.e168df58-ce5d-47f9-8852-b286277b2375.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/metadata
[2025-07-19T19:57:12.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Starting [id = e64be3f7-c229-4a3a-b3cc-de24eff1ecd3, runId = b5fdfb25-db44-4f9a-8656-6e80fbb359f7]. Use file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00 to store the query checkpoint.
[2025-07-19T19:57:12.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@14980772] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@1a5ffa49]
[2025-07-19T19:57:12.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T19:57:12.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T19:57:12.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T19:57:12.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T19:57:12.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T19:57:12.230+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T19:57:12.230+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T19:57:12.231+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T19:57:12.232+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T19:57:12.232+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T19:57:12.232+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T19:57:12.232+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T19:57:12.232+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T19:57:12.232+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T19:57:12.232+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T19:57:12.232+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T19:57:12.232+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T19:57:12.233+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T19:57:12.234+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T19:57:12.235+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T19:57:12.236+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T19:57:12.236+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T19:57:12.236+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T19:57:12.236+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T19:57:12.236+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T19:57:12.236+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T19:57:12.236+0000] {subprocess.py:93} INFO - 
[2025-07-19T19:57:12.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T19:57:12.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T19:57:12.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T19:57:12.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T19:57:12.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T19:57:12.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AppInfoParser: Kafka startTimeMs: 1752955032253
[2025-07-19T19:57:12.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T19:57:12.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T19:57:12.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AppInfoParser: Kafka startTimeMs: 1752955032253
[2025-07-19T19:57:12.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T19:57:12.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T19:57:12.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO AppInfoParser: Kafka startTimeMs: 1752955032253
[2025-07-19T19:57:12.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/sources/0/.0.aca262a2-888f-42ed-bbb6-d9e76c2a8ff1.tmp
[2025-07-19T19:57:12.471+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/sources/0/.0.0cad1883-0aee-4bae-b422-084958bb1d6a.tmp
[2025-07-19T19:57:12.471+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/sources/0/.0.f18158cd-e7f1-4fde-9038-978a1b97b73f.tmp
[2025-07-19T19:57:12.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/sources/0/.0.0cad1883-0aee-4bae-b422-084958bb1d6a.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/sources/0/0
[2025-07-19T19:57:12.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/sources/0/.0.f18158cd-e7f1-4fde-9038-978a1b97b73f.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/sources/0/0
[2025-07-19T19:57:12.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO KafkaMicroBatchStream: Initial offsets: {"checkins":{"0":0}}
[2025-07-19T19:57:12.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO KafkaMicroBatchStream: Initial offsets: {"reservations":{"0":0}}
[2025-07-19T19:57:12.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/sources/0/.0.aca262a2-888f-42ed-bbb6-d9e76c2a8ff1.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/sources/0/0
[2025-07-19T19:57:12.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO KafkaMicroBatchStream: Initial offsets: {"feedback":{"0":0}}
[2025-07-19T19:57:12.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/offsets/.0.f921238a-a9ae-4ca1-ab41-60e7ad54be7e.tmp
[2025-07-19T19:57:12.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/offsets/.0.d32ddee6-6a03-47fb-a139-486e87e669f2.tmp
[2025-07-19T19:57:12.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/offsets/.0.87ec7981-a693-43e3-b612-21cf4a32158e.tmp
[2025-07-19T19:57:12.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/offsets/.0.87ec7981-a693-43e3-b612-21cf4a32158e.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/offsets/0
[2025-07-19T19:57:12.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/offsets/.0.d32ddee6-6a03-47fb-a139-486e87e669f2.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/offsets/0
[2025-07-19T19:57:12.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752955032492,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T19:57:12.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752955032492,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T19:57:12.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/offsets/.0.f921238a-a9ae-4ca1-ab41-60e7ad54be7e.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/offsets/0
[2025-07-19T19:57:12.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752955032492,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T19:57:12.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:12.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:12.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:12.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:12.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:12.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:12.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:12.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:12.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:12.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:12 INFO CodeGenerator: Code generated in 121.833875 ms
[2025-07-19T19:57:13.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:13.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:13.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:13.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:13.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:13.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:13.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:13.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:13.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:13.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.096+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.096+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:13.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:13.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:13.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:13.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:13.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:13.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:13.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:13.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:13.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T19:57:13.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 27.118959 ms
[2025-07-19T19:57:13.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 26.936042 ms
[2025-07-19T19:57:13.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 46.510917 ms
[2025-07-19T19:57:13.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T19:57:13.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T19:57:13.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T19:57:13.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T19:57:13.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T19:57:13.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T19:57:13.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 8b44f3d35cfa:44249 (size: 35.4 KiB, free: 434.4 MiB)
[2025-07-19T19:57:13.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 8b44f3d35cfa:44249 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T19:57:13.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 8b44f3d35cfa:44249 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T19:57:13.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Created broadcast 0 from start at <unknown>:0
[2025-07-19T19:57:13.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Created broadcast 1 from start at <unknown>:0
[2025-07-19T19:57:13.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Created broadcast 2 from start at <unknown>:0
[2025-07-19T19:57:13.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T19:57:13.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T19:57:13.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T19:57:13.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.6 MiB)
[2025-07-19T19:57:13.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.5 MiB)
[2025-07-19T19:57:13.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.5 MiB)
[2025-07-19T19:57:13.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 8b44f3d35cfa:44249 (size: 29.6 KiB, free: 434.3 MiB)
[2025-07-19T19:57:13.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 8b44f3d35cfa:44249 (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T19:57:13.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Created broadcast 5 from start at <unknown>:0
[2025-07-19T19:57:13.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 8b44f3d35cfa:44249 (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T19:57:13.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Created broadcast 4 from start at <unknown>:0
[2025-07-19T19:57:13.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Created broadcast 3 from start at <unknown>:0
[2025-07-19T19:57:13.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T19:57:13.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T19:57:13.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T19:57:13.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T19:57:13.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T19:57:13.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T19:57:13.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Registering RDD 17 (start at <unknown>:0) as input to shuffle 2
[2025-07-19T19:57:13.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Got job 2 (start at <unknown>:0) with 200 output partitions
[2025-07-19T19:57:13.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Final stage: ResultStage 1 (start at <unknown>:0)
[2025-07-19T19:57:13.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
[2025-07-19T19:57:13.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
[2025-07-19T19:57:13.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[17] at start at <unknown>:0), which has no missing parents
[2025-07-19T19:57:13.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 35.8 KiB, free 433.5 MiB)
[2025-07-19T19:57:13.674+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.5 MiB)
[2025-07-19T19:57:13.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 8b44f3d35cfa:44249 (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T19:57:13.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-07-19T19:57:13.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[17] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T19:57:13.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-07-19T19:57:13.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Registering RDD 16 (start at <unknown>:0) as input to shuffle 1
[2025-07-19T19:57:13.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 200 output partitions
[2025-07-19T19:57:13.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Final stage: ResultStage 3 (start at <unknown>:0)
[2025-07-19T19:57:13.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-07-19T19:57:13.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
[2025-07-19T19:57:13.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at start at <unknown>:0), which has no missing parents
[2025-07-19T19:57:13.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.8 KiB, free 433.4 MiB)
[2025-07-19T19:57:13.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 433.4 MiB)
[2025-07-19T19:57:13.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 8b44f3d35cfa:44249 (size: 14.7 KiB, free: 434.2 MiB)
[2025-07-19T19:57:13.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-07-19T19:57:13.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T19:57:13.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-07-19T19:57:13.760+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9925 bytes)
[2025-07-19T19:57:13.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Registering RDD 15 (start at <unknown>:0) as input to shuffle 0
[2025-07-19T19:57:13.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Got job 1 (start at <unknown>:0) with 200 output partitions
[2025-07-19T19:57:13.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Final stage: ResultStage 5 (start at <unknown>:0)
[2025-07-19T19:57:13.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-07-19T19:57:13.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
[2025-07-19T19:57:13.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0), which has no missing parents
[2025-07-19T19:57:13.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 32.3 KiB, free 433.4 MiB)
[2025-07-19T19:57:13.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9928 bytes)
[2025-07-19T19:57:13.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 433.4 MiB)
[2025-07-19T19:57:13.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 8b44f3d35cfa:44249 (size: 14.0 KiB, free: 434.2 MiB)
[2025-07-19T19:57:13.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-07-19T19:57:13.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T19:57:13.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-19T19:57:13.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
[2025-07-19T19:57:13.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9923 bytes)
[2025-07-19T19:57:13.778+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-19T19:57:13.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)
[2025-07-19T19:57:13.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 18.7785 ms
[2025-07-19T19:57:13.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 21.18525 ms
[2025-07-19T19:57:13.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 20.74175 ms
[2025-07-19T19:57:13.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 15.0305 ms
[2025-07-19T19:57:13.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 17.67625 ms
[2025-07-19T19:57:13.913+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 6.285417 ms
[2025-07-19T19:57:13.916+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 26.076333 ms
[2025-07-19T19:57:13.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 8.704208 ms
[2025-07-19T19:57:13.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 13.877709 ms
[2025-07-19T19:57:13.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 8.207917 ms
[2025-07-19T19:57:13.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reservations-0 fromOffset=0 untilOffset=174, for query queryId=5253d98e-255c-4533-9785-660d38a21faf batchId=0 taskId=1 partitionId=0
[2025-07-19T19:57:13.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=feedback-0 fromOffset=0 untilOffset=174, for query queryId=e64be3f7-c229-4a3a-b3cc-de24eff1ecd3 batchId=0 taskId=2 partitionId=0
[2025-07-19T19:57:13.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=checkins-0 fromOffset=0 untilOffset=174, for query queryId=609fc205-5186-4889-9ac4-e96d359c0199 batchId=0 taskId=0 partitionId=0
[2025-07-19T19:57:13.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 7.656625 ms
[2025-07-19T19:57:13.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:13 INFO CodeGenerator: Code generated in 7.813958 ms
[2025-07-19T19:57:14.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T19:57:14.014+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T19:57:14.014+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T19:57:14.014+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T19:57:14.014+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T19:57:14.014+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T19:57:14.014+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T19:57:14.014+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T19:57:14.015+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1
[2025-07-19T19:57:14.015+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T19:57:14.015+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T19:57:14.015+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T19:57:14.015+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T19:57:14.015+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T19:57:14.015+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T19:57:14.015+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T19:57:14.015+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T19:57:14.016+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T19:57:14.017+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T19:57:14.017+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T19:57:14.017+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T19:57:14.017+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T19:57:14.017+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T19:57:14.017+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T19:57:14.017+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T19:57:14.017+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T19:57:14.018+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T19:57:14.018+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T19:57:14.018+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T19:57:14.019+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T19:57:14.020+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T19:57:14.021+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T19:57:14.022+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 
[2025-07-19T19:57:14.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T19:57:14.024+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T19:57:14.026+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T19:57:14.026+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T19:57:14.026+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T19:57:14.026+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T19:57:14.026+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T19:57:14.026+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T19:57:14.027+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor
[2025-07-19T19:57:14.028+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T19:57:14.028+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T19:57:14.028+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T19:57:14.028+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T19:57:14.028+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T19:57:14.028+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T19:57:14.028+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T19:57:14.029+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T19:57:14.029+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T19:57:14.029+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T19:57:14.029+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T19:57:14.029+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T19:57:14.029+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T19:57:14.029+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T19:57:14.029+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T19:57:14.029+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T19:57:14.030+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T19:57:14.031+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T19:57:14.032+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T19:57:14.032+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T19:57:14.032+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T19:57:14.032+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T19:57:14.032+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T19:57:14.032+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T19:57:14.032+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T19:57:14.032+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T19:57:14.032+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T19:57:14.033+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T19:57:14.034+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T19:57:14.034+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T19:57:14.034+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T19:57:14.034+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T19:57:14.034+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T19:57:14.034+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T19:57:14.035+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T19:57:14.035+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T19:57:14.035+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T19:57:14.035+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T19:57:14.036+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T19:57:14.036+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T19:57:14.036+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T19:57:14.036+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T19:57:14.037+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T19:57:14.037+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T19:57:14.037+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T19:57:14.037+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T19:57:14.037+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T19:57:14.038+0000] {subprocess.py:93} INFO - 
[2025-07-19T19:57:14.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T19:57:14.038+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T19:57:14.038+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T19:57:14.038+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T19:57:14.039+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T19:57:14.039+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T19:57:14.039+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T19:57:14.039+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T19:57:14.039+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3
[2025-07-19T19:57:14.040+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T19:57:14.040+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T19:57:14.040+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T19:57:14.041+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T19:57:14.041+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T19:57:14.041+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T19:57:14.042+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T19:57:14.042+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T19:57:14.043+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor
[2025-07-19T19:57:14.043+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T19:57:14.043+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T19:57:14.044+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T19:57:14.044+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T19:57:14.045+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T19:57:14.045+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T19:57:14.046+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T19:57:14.047+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T19:57:14.048+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T19:57:14.048+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T19:57:14.048+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T19:57:14.049+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T19:57:14.049+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T19:57:14.050+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T19:57:14.050+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T19:57:14.050+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T19:57:14.050+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T19:57:14.051+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T19:57:14.051+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T19:57:14.051+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T19:57:14.051+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T19:57:14.053+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T19:57:14.053+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T19:57:14.053+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T19:57:14.053+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T19:57:14.053+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T19:57:14.054+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T19:57:14.054+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T19:57:14.054+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T19:57:14.054+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T19:57:14.054+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T19:57:14.054+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T19:57:14.054+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T19:57:14.055+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T19:57:14.055+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T19:57:14.055+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T19:57:14.055+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T19:57:14.055+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T19:57:14.056+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T19:57:14.056+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T19:57:14.056+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T19:57:14.057+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T19:57:14.057+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T19:57:14.057+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T19:57:14.058+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T19:57:14.058+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T19:57:14.058+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T19:57:14.058+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T19:57:14.058+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T19:57:14.059+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T19:57:14.059+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T19:57:14.059+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T19:57:14.059+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T19:57:14.059+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T19:57:14.059+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T19:57:14.059+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T19:57:14.060+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T19:57:14.060+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T19:57:14.060+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T19:57:14.060+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T19:57:14.060+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T19:57:14.060+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T19:57:14.060+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T19:57:14.060+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T19:57:14.060+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T19:57:14.061+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T19:57:14.061+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T19:57:14.061+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T19:57:14.061+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T19:57:14.062+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T19:57:14.065+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T19:57:14.065+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T19:57:14.066+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T19:57:14.066+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T19:57:14.066+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T19:57:14.066+0000] {subprocess.py:93} INFO - 
[2025-07-19T19:57:14.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T19:57:14.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T19:57:14.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO AppInfoParser: Kafka startTimeMs: 1752955034062
[2025-07-19T19:57:14.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T19:57:14.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3, groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor] Assigned to partition(s): reservations-0
[2025-07-19T19:57:14.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T19:57:14.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO AppInfoParser: Kafka startTimeMs: 1752955034064
[2025-07-19T19:57:14.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2, groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor] Assigned to partition(s): feedback-0
[2025-07-19T19:57:14.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T19:57:14.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T19:57:14.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO AppInfoParser: Kafka startTimeMs: 1752955034062
[2025-07-19T19:57:14.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1, groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor] Assigned to partition(s): checkins-0
[2025-07-19T19:57:14.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1, groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor] Seeking to offset 0 for partition checkins-0
[2025-07-19T19:57:14.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3, groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor] Seeking to offset 0 for partition reservations-0
[2025-07-19T19:57:14.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2, groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor] Seeking to offset 0 for partition feedback-0
[2025-07-19T19:57:14.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3, groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T19:57:14.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2, groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T19:57:14.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1, groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T19:57:14.150+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3, groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor] Seeking to earliest offset of partition reservations-0
[2025-07-19T19:57:14.150+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2, groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor] Seeking to earliest offset of partition feedback-0
[2025-07-19T19:57:14.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1, groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor] Seeking to earliest offset of partition checkins-0
[2025-07-19T19:57:14.661+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2, groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T19:57:14.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3, groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T19:57:14.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1, groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T19:57:14.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2, groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor] Seeking to latest offset of partition feedback-0
[2025-07-19T19:57:14.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3, groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor] Seeking to latest offset of partition reservations-0
[2025-07-19T19:57:14.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1, groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor] Seeking to latest offset of partition checkins-0
[2025-07-19T19:57:14.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1, groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=174, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T19:57:14.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3, groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=174, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T19:57:14.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2, groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=174, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T19:57:14.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO KafkaDataConsumer: From Kafka topicPartition=feedback-0 groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor read 174 records through 1 polls (polled  out 174 records), taking 588109000 nanos, during time span of 791778167 nanos.
[2025-07-19T19:57:14.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO KafkaDataConsumer: From Kafka topicPartition=checkins-0 groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor read 174 records through 1 polls (polled  out 174 records), taking 588173000 nanos, during time span of 791777208 nanos.
[2025-07-19T19:57:14.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO KafkaDataConsumer: From Kafka topicPartition=reservations-0 groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor read 174 records through 1 polls (polled  out 174 records), taking 588403958 nanos, during time span of 791836209 nanos.
[2025-07-19T19:57:14.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 2642 bytes result sent to driver
[2025-07-19T19:57:14.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2642 bytes result sent to driver
[2025-07-19T19:57:14.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 2642 bytes result sent to driver
[2025-07-19T19:57:14.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1130 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T19:57:14.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-19T19:57:14.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 1106 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T19:57:14.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-19T19:57:14.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 1113 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T19:57:14.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-07-19T19:57:14.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: ShuffleMapStage 0 (start at <unknown>:0) finished in 1.220 s
[2025-07-19T19:57:14.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T19:57:14.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: running: Set(ShuffleMapStage 2, ShuffleMapStage 4)
[2025-07-19T19:57:14.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 5, ResultStage 3)
[2025-07-19T19:57:14.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: failed: Set()
[2025-07-19T19:57:14.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: Submitting ResultStage 1 (StateStoreRDD[22] at start at <unknown>:0), which has no missing parents
[2025-07-19T19:57:14.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 40.1 KiB, free 433.3 MiB)
[2025-07-19T19:57:14.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 433.3 MiB)
[2025-07-19T19:57:14.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 8b44f3d35cfa:44249 (size: 19.9 KiB, free: 434.1 MiB)
[2025-07-19T19:57:14.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-07-19T19:57:14.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 1 (StateStoreRDD[22] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T19:57:14.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 200 tasks resource profile 0
[2025-07-19T19:57:14.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: ShuffleMapStage 4 (start at <unknown>:0) finished in 1.179 s
[2025-07-19T19:57:14.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T19:57:14.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: running: Set(ResultStage 1, ShuffleMapStage 2)
[2025-07-19T19:57:14.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: waiting: Set(ResultStage 5, ResultStage 3)
[2025-07-19T19:57:14.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: failed: Set()
[2025-07-19T19:57:14.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO DAGScheduler: Submitting ResultStage 5 (StateStoreRDD[21] at start at <unknown>:0), which has no missing parents
[2025-07-19T19:57:14.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:14.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 4) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:14.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 5) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:14.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 6) (8b44f3d35cfa, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:14.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 7) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:14.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 8) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:14.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 9) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:14.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 10) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:14.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
[2025-07-19T19:57:14.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Running task 7.0 in stage 1.0 (TID 5)
[2025-07-19T19:57:14.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Running task 5.0 in stage 1.0 (TID 4)
[2025-07-19T19:57:14.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Running task 10.0 in stage 1.0 (TID 7)
[2025-07-19T19:57:14.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Running task 8.0 in stage 1.0 (TID 6)
[2025-07-19T19:57:14.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Running task 12.0 in stage 1.0 (TID 9)
[2025-07-19T19:57:14.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Running task 11.0 in stage 1.0 (TID 8)
[2025-07-19T19:57:14.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:14 INFO Executor: Running task 14.0 in stage 1.0 (TID 10)
[2025-07-19T19:57:15.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.014+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.014+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T19:57:15.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T19:57:15.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T19:57:15.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T19:57:15.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T19:57:15.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
[2025-07-19T19:57:15.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
[2025-07-19T19:57:15.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
[2025-07-19T19:57:15.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 38.8 KiB, free 433.3 MiB)
[2025-07-19T19:57:15.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: State Store maintenance task started
[2025-07-19T19:57:15.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 433.2 MiB)
[2025-07-19T19:57:15.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 8b44f3d35cfa:44249 (size: 19.3 KiB, free: 434.1 MiB)
[2025-07-19T19:57:15.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-07-19T19:57:15.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 5 (StateStoreRDD[21] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T19:57:15.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSchedulerImpl: Adding task set 5.0 with 200 tasks resource profile 0
[2025-07-19T19:57:15.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DAGScheduler: ShuffleMapStage 2 (start at <unknown>:0) finished in 1.304 s
[2025-07-19T19:57:15.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T19:57:15.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DAGScheduler: running: Set(ResultStage 1, ResultStage 5)
[2025-07-19T19:57:15.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DAGScheduler: waiting: Set(ResultStage 3)
[2025-07-19T19:57:15.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DAGScheduler: failed: Set()
[2025-07-19T19:57:15.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DAGScheduler: Submitting ResultStage 3 (StateStoreRDD[23] at start at <unknown>:0), which has no missing parents
[2025-07-19T19:57:15.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7efe253c
[2025-07-19T19:57:15.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:15.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5] for update
[2025-07-19T19:57:15.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e3c91ed
[2025-07-19T19:57:15.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:15.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14] for update
[2025-07-19T19:57:15.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodeGenerator: Code generated in 6.083917 ms
[2025-07-19T19:57:15.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2030705
[2025-07-19T19:57:15.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:15.052+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8] for update
[2025-07-19T19:57:15.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40014322
[2025-07-19T19:57:15.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:15.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11] for update
[2025-07-19T19:57:15.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@728affd9
[2025-07-19T19:57:15.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:15.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10] for update
[2025-07-19T19:57:15.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodeGenerator: Code generated in 8.609 ms
[2025-07-19T19:57:15.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@152c56c0
[2025-07-19T19:57:15.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:15.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7] for update
[2025-07-19T19:57:15.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c34964b
[2025-07-19T19:57:15.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:15.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12] for update
[2025-07-19T19:57:15.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a4fa155
[2025-07-19T19:57:15.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:15.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2] for update
[2025-07-19T19:57:15.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 39.6 KiB, free 433.2 MiB)
[2025-07-19T19:57:15.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 433.2 MiB)
[2025-07-19T19:57:15.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 8b44f3d35cfa:44249 (size: 19.7 KiB, free: 434.1 MiB)
[2025-07-19T19:57:15.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1611
[2025-07-19T19:57:15.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 3 (StateStoreRDD[23] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T19:57:15.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 200 tasks resource profile 0
[2025-07-19T19:57:15.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 8b44f3d35cfa:44249 in memory (size: 14.0 KiB, free: 434.1 MiB)
[2025-07-19T19:57:15.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.158+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 8b44f3d35cfa:44249 in memory (size: 14.7 KiB, free: 434.1 MiB)
[2025-07-19T19:57:15.379+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.1.delta.5fa8b504-6166-44de-b973-b72ba8f59ede.TID6.tmp
[2025-07-19T19:57:15.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.1.delta.dd32eeb2-4ae6-4a99-884b-1758a6a23b71.TID3.tmp
[2025-07-19T19:57:15.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.1.delta.26581db3-4cf4-4a66-9192-f62339c2acb7.TID8.tmp
[2025-07-19T19:57:15.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.1.delta.ddc43dcf-44bd-4a8d-b07e-f13641143069.TID7.tmp
[2025-07-19T19:57:15.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.1.delta.20cf34a8-fc48-41da-8f66-f506a57de68a.TID4.tmp
[2025-07-19T19:57:15.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.1.delta.840a232c-1e94-445c-8b77-a914395f1699.TID5.tmp
[2025-07-19T19:57:15.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.1.delta.865dfeea-789a-4aa5-870d-a7cb68ccb3e5.TID9.tmp
[2025-07-19T19:57:15.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.1.delta.90b78d60-b9e0-4246-9e21-9044b20527e6.TID10.tmp
[2025-07-19T19:57:15.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodeGenerator: Code generated in 5.723625 ms
[2025-07-19T19:57:15.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.1.delta.5fa8b504-6166-44de-b973-b72ba8f59ede.TID6.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/1.delta
[2025-07-19T19:57:15.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/1.delta
[2025-07-19T19:57:15.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.1.delta.ddc43dcf-44bd-4a8d-b07e-f13641143069.TID7.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/1.delta
[2025-07-19T19:57:15.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/1.delta
[2025-07-19T19:57:15.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.1.delta.90b78d60-b9e0-4246-9e21-9044b20527e6.TID10.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/1.delta
[2025-07-19T19:57:15.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/1.delta
[2025-07-19T19:57:15.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.1.delta.26581db3-4cf4-4a66-9192-f62339c2acb7.TID8.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/1.delta
[2025-07-19T19:57:15.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.1.delta.dd32eeb2-4ae6-4a99-884b-1758a6a23b71.TID3.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/1.delta
[2025-07-19T19:57:15.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/1.delta
[2025-07-19T19:57:15.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/1.delta
[2025-07-19T19:57:15.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.1.delta.865dfeea-789a-4aa5-870d-a7cb68ccb3e5.TID9.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/1.delta
[2025-07-19T19:57:15.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/1.delta
[2025-07-19T19:57:15.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 6, attempt 0, stage 1.0)
[2025-07-19T19:57:15.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 10, attempt 0, stage 1.0)
[2025-07-19T19:57:15.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 3, attempt 0, stage 1.0)
[2025-07-19T19:57:15.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 7, attempt 0, stage 1.0)
[2025-07-19T19:57:15.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.1.delta.20cf34a8-fc48-41da-8f66-f506a57de68a.TID4.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/1.delta
[2025-07-19T19:57:15.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/1.delta
[2025-07-19T19:57:15.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 9, attempt 0, stage 1.0)
[2025-07-19T19:57:15.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 8, attempt 0, stage 1.0)
[2025-07-19T19:57:15.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.1.delta.840a232c-1e94-445c-8b77-a914395f1699.TID5.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/1.delta
[2025-07-19T19:57:15.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/1.delta
[2025-07-19T19:57:15.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 5, attempt 0, stage 1.0)
[2025-07-19T19:57:15.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 4, attempt 0, stage 1.0)
[2025-07-19T19:57:15.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Committed partition 14 (task 10, attempt 0, stage 1.0)
[2025-07-19T19:57:15.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Committed partition 5 (task 4, attempt 0, stage 1.0)
[2025-07-19T19:57:15.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Committed partition 2 (task 3, attempt 0, stage 1.0)
[2025-07-19T19:57:15.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Committed partition 8 (task 6, attempt 0, stage 1.0)
[2025-07-19T19:57:15.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Committed partition 10 (task 7, attempt 0, stage 1.0)
[2025-07-19T19:57:15.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Committed partition 12 (task 9, attempt 0, stage 1.0)
[2025-07-19T19:57:15.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Committed partition 7 (task 5, attempt 0, stage 1.0)
[2025-07-19T19:57:15.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Finished task 12.0 in stage 1.0 (TID 9). 9339 bytes result sent to driver
[2025-07-19T19:57:15.758+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Finished task 7.0 in stage 1.0 (TID 5). 9343 bytes result sent to driver
[2025-07-19T19:57:15.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:15.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Finished task 5.0 in stage 1.0 (TID 4). 9319 bytes result sent to driver
[2025-07-19T19:57:15.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Committed partition 11 (task 8, attempt 0, stage 1.0)
[2025-07-19T19:57:15.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Running task 1.0 in stage 3.0 (TID 11)
[2025-07-19T19:57:15.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 9344 bytes result sent to driver
[2025-07-19T19:57:15.761+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Finished task 8.0 in stage 1.0 (TID 6). 9334 bytes result sent to driver
[2025-07-19T19:57:15.762+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 12) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:15.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Finished task 14.0 in stage 1.0 (TID 10). 9335 bytes result sent to driver
[2025-07-19T19:57:15.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 13) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:15.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Finished task 11.0 in stage 1.0 (TID 8). 9291 bytes result sent to driver
[2025-07-19T19:57:15.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 14) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:15.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Running task 3.0 in stage 3.0 (TID 12)
[2025-07-19T19:57:15.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Running task 4.0 in stage 3.0 (TID 13)
[2025-07-19T19:57:15.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Finished task 10.0 in stage 1.0 (TID 7). 9330 bytes result sent to driver
[2025-07-19T19:57:15.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 15) (8b44f3d35cfa, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:15.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 16) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:15.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 17) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:15.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Running task 7.0 in stage 3.0 (TID 16)
[2025-07-19T19:57:15.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 18) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:15.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 9) in 824 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T19:57:15.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Running task 6.0 in stage 3.0 (TID 15)
[2025-07-19T19:57:15.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 6) in 825 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T19:57:15.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 5) in 825 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T19:57:15.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Running task 9.0 in stage 3.0 (TID 17)
[2025-07-19T19:57:15.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Running task 5.0 in stage 3.0 (TID 14)
[2025-07-19T19:57:15.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 10) in 827 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T19:57:15.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 7) in 829 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T19:57:15.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO Executor: Running task 11.0 in stage 3.0 (TID 18)
[2025-07-19T19:57:15.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 834 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T19:57:15.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 4) in 831 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T19:57:15.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 8) in 830 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T19:57:15.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:15.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:15.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:15.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:15.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:15.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:15.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:15.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:15.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:15.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33ce99a1
[2025-07-19T19:57:15.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:15.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/3] for update
[2025-07-19T19:57:15.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e7da2ae
[2025-07-19T19:57:15.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:15.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/6] for update
[2025-07-19T19:57:15.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodeGenerator: Code generated in 11.945416 ms
[2025-07-19T19:57:15.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@675ea4b3
[2025-07-19T19:57:15.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:15.843+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/11] for update
[2025-07-19T19:57:15.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodeGenerator: Code generated in 3.353292 ms
[2025-07-19T19:57:15.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22e801c7
[2025-07-19T19:57:15.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:15.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/7] for update
[2025-07-19T19:57:15.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44bb68cd
[2025-07-19T19:57:15.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:15.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/5] for update
[2025-07-19T19:57:15.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7eba7d2c
[2025-07-19T19:57:15.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:15.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/9] for update
[2025-07-19T19:57:15.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d13305d
[2025-07-19T19:57:15.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:15.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/4] for update
[2025-07-19T19:57:15.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b49e697
[2025-07-19T19:57:15.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:15.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/1] for update
[2025-07-19T19:57:15.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:15.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.1.delta.1340d052-ad94-4733-95e1-3dd909b2594b.TID15.tmp
[2025-07-19T19:57:15.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.1.delta.9a669d92-3582-4982-ad3f-9f1212335e41.TID12.tmp
[2025-07-19T19:57:15.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.1.delta.0525fa9f-27e1-4462-afae-ef429eb02b28.TID16.tmp
[2025-07-19T19:57:15.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.1.delta.2ac2ed52-3d8d-4c15-b8ea-55f74f3e8eb2.TID17.tmp
[2025-07-19T19:57:15.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.1.delta.6c24b221-a299-47f9-b9e5-74fd810d0c0a.TID11.tmp
[2025-07-19T19:57:15.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.1.delta.5bb53279-e87c-42ac-94db-4b2679644326.TID13.tmp
[2025-07-19T19:57:15.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.1.delta.a00d873f-b836-4042-8a79-54c8755ea2a9.TID18.tmp
[2025-07-19T19:57:15.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.1.delta.ba66e5a4-ca64-4fcb-9daa-cf29ee04714b.TID14.tmp
[2025-07-19T19:57:15.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 8b44f3d35cfa:44249 in memory (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T19:57:15.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.1.delta.ba66e5a4-ca64-4fcb-9daa-cf29ee04714b.TID14.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/5/1.delta
[2025-07-19T19:57:15.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/5] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/5/1.delta
[2025-07-19T19:57:15.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.1.delta.a00d873f-b836-4042-8a79-54c8755ea2a9.TID18.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/11/1.delta
[2025-07-19T19:57:15.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/11] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/11/1.delta
[2025-07-19T19:57:15.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 18, attempt 0, stage 3.0)
[2025-07-19T19:57:15.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 14, attempt 0, stage 3.0)
[2025-07-19T19:57:15.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.1.delta.9a669d92-3582-4982-ad3f-9f1212335e41.TID12.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/3/1.delta
[2025-07-19T19:57:15.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/3] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/3/1.delta
[2025-07-19T19:57:15.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.1.delta.2ac2ed52-3d8d-4c15-b8ea-55f74f3e8eb2.TID17.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/9/1.delta
[2025-07-19T19:57:15.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 12, attempt 0, stage 3.0)
[2025-07-19T19:57:15.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.1.delta.0525fa9f-27e1-4462-afae-ef429eb02b28.TID16.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/7/1.delta
[2025-07-19T19:57:15.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/7] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/7/1.delta
[2025-07-19T19:57:16.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/9] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/9/1.delta
[2025-07-19T19:57:16.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 17, attempt 0, stage 3.0)
[2025-07-19T19:57:16.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 16, attempt 0, stage 3.0)
[2025-07-19T19:57:16.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.1.delta.6c24b221-a299-47f9-b9e5-74fd810d0c0a.TID11.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/1/1.delta
[2025-07-19T19:57:16.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/1] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/1/1.delta
[2025-07-19T19:57:16.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 11, attempt 0, stage 3.0)
[2025-07-19T19:57:16.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.1.delta.1340d052-ad94-4733-95e1-3dd909b2594b.TID15.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/6/1.delta
[2025-07-19T19:57:16.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.1.delta.5bb53279-e87c-42ac-94db-4b2679644326.TID13.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/4/1.delta
[2025-07-19T19:57:16.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/6] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/6/1.delta
[2025-07-19T19:57:16.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/4] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/4/1.delta
[2025-07-19T19:57:16.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 13, attempt 0, stage 3.0)
[2025-07-19T19:57:16.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 15, attempt 0, stage 3.0)
[2025-07-19T19:57:16.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 5 (task 14, attempt 0, stage 3.0)
[2025-07-19T19:57:16.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 11 (task 18, attempt 0, stage 3.0)
[2025-07-19T19:57:16.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 9 (task 17, attempt 0, stage 3.0)
[2025-07-19T19:57:16.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 4 (task 13, attempt 0, stage 3.0)
[2025-07-19T19:57:16.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 9.0 in stage 3.0 (TID 17). 9128 bytes result sent to driver
[2025-07-19T19:57:16.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 5.0 in stage 3.0 (TID 14). 9118 bytes result sent to driver
[2025-07-19T19:57:16.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 4.0 in stage 3.0 (TID 13). 9091 bytes result sent to driver
[2025-07-19T19:57:16.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 7 (task 16, attempt 0, stage 3.0)
[2025-07-19T19:57:16.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 19) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 11.0 in stage 3.0 (TID 18). 9103 bytes result sent to driver
[2025-07-19T19:57:16.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 1 (task 11, attempt 0, stage 3.0)
[2025-07-19T19:57:16.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 14) in 272 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T19:57:16.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 20) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 7.0 in stage 3.0 (TID 16). 9076 bytes result sent to driver
[2025-07-19T19:57:16.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 17) in 266 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T19:57:16.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 14.0 in stage 3.0 (TID 20)
[2025-07-19T19:57:16.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 1.0 in stage 3.0 (TID 11). 9116 bytes result sent to driver
[2025-07-19T19:57:16.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 21) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 12.0 in stage 3.0 (TID 19)
[2025-07-19T19:57:16.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 20.0 in stage 3.0 (TID 21)
[2025-07-19T19:57:16.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 22) (8b44f3d35cfa, executor driver, partition 21, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 21.0 in stage 3.0 (TID 22)
[2025-07-19T19:57:16.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 3 (task 12, attempt 0, stage 3.0)
[2025-07-19T19:57:16.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 3.0 in stage 3.0 (TID 12). 9077 bytes result sent to driver
[2025-07-19T19:57:16.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 6 (task 15, attempt 0, stage 3.0)
[2025-07-19T19:57:16.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 6.0 in stage 3.0 (TID 15). 9077 bytes result sent to driver
[2025-07-19T19:57:16.052+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:16.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 23) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 24) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 25) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 23.0 in stage 3.0 (TID 24)
[2025-07-19T19:57:16.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 26) (8b44f3d35cfa, executor driver, partition 25, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 18) in 281 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T19:57:16.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T19:57:16.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 25.0 in stage 3.0 (TID 26)
[2025-07-19T19:57:16.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 24.0 in stage 3.0 (TID 25)
[2025-07-19T19:57:16.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 12) in 292 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T19:57:16.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 13) in 293 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T19:57:16.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 302 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T19:57:16.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eab4bed
[2025-07-19T19:57:16.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 15) in 287 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T19:57:16.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 16) in 289 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T19:57:16.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 22.0 in stage 3.0 (TID 23)
[2025-07-19T19:57:16.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/14] for update
[2025-07-19T19:57:16.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T19:57:16.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ff28d50
[2025-07-19T19:57:16.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/21] for update
[2025-07-19T19:57:16.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@263bc30a
[2025-07-19T19:57:16.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/20] for update
[2025-07-19T19:57:16.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.1.delta.0af3444c-7e03-4f9d-8038-35a69a6c2011.TID22.tmp
[2025-07-19T19:57:16.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.1.delta.120a6e1e-f7cc-456b-832d-c53c3a2ab92f.TID20.tmp
[2025-07-19T19:57:16.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39fa8292
[2025-07-19T19:57:16.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/12] for update
[2025-07-19T19:57:16.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b396d7e
[2025-07-19T19:57:16.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/24] for update
[2025-07-19T19:57:16.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.1.delta.818939d5-2be3-482b-b83b-22efa0e9abcc.TID21.tmp
[2025-07-19T19:57:16.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.1.delta.07fa6060-9df0-4d34-9e2d-bb6a6385428e.TID19.tmp
[2025-07-19T19:57:16.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ed8147a
[2025-07-19T19:57:16.114+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.114+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/22] for update
[2025-07-19T19:57:16.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@349ae2ce
[2025-07-19T19:57:16.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/25] for update
[2025-07-19T19:57:16.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.1.delta.c6cdeca8-6f37-43c6-82e8-e8c93f7d7b86.TID25.tmp
[2025-07-19T19:57:16.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e53ca12
[2025-07-19T19:57:16.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/23] for update
[2025-07-19T19:57:16.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.1.delta.b8843f76-5557-4edf-a264-eba59c6600e3.TID23.tmp
[2025-07-19T19:57:16.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.1.delta.f652d2ed-68c8-4104-bfde-894055c708c2.TID26.tmp
[2025-07-19T19:57:16.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.1.delta.0af3444c-7e03-4f9d-8038-35a69a6c2011.TID22.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/21/1.delta
[2025-07-19T19:57:16.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/21] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/21/1.delta
[2025-07-19T19:57:16.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 22, attempt 0, stage 3.0)
[2025-07-19T19:57:16.156+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.1.delta.dd6d7748-ae67-4fc8-a467-2661dc639755.TID24.tmp
[2025-07-19T19:57:16.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.1.delta.120a6e1e-f7cc-456b-832d-c53c3a2ab92f.TID20.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/14/1.delta
[2025-07-19T19:57:16.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/14] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/14/1.delta
[2025-07-19T19:57:16.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 20, attempt 0, stage 3.0)
[2025-07-19T19:57:16.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.1.delta.07fa6060-9df0-4d34-9e2d-bb6a6385428e.TID19.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/12/1.delta
[2025-07-19T19:57:16.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/12] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/12/1.delta
[2025-07-19T19:57:16.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 19, attempt 0, stage 3.0)
[2025-07-19T19:57:16.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.1.delta.818939d5-2be3-482b-b83b-22efa0e9abcc.TID21.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/20/1.delta
[2025-07-19T19:57:16.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/20] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/20/1.delta
[2025-07-19T19:57:16.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 21, attempt 0, stage 3.0)
[2025-07-19T19:57:16.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.1.delta.c6cdeca8-6f37-43c6-82e8-e8c93f7d7b86.TID25.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/24/1.delta
[2025-07-19T19:57:16.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.1.delta.f652d2ed-68c8-4104-bfde-894055c708c2.TID26.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/25/1.delta
[2025-07-19T19:57:16.187+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/25] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/25/1.delta
[2025-07-19T19:57:16.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 26, attempt 0, stage 3.0)
[2025-07-19T19:57:16.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.1.delta.dd6d7748-ae67-4fc8-a467-2661dc639755.TID24.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/23/1.delta
[2025-07-19T19:57:16.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/23] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/23/1.delta
[2025-07-19T19:57:16.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/24] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/24/1.delta
[2025-07-19T19:57:16.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.1.delta.b8843f76-5557-4edf-a264-eba59c6600e3.TID23.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/22/1.delta
[2025-07-19T19:57:16.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/22] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/22/1.delta
[2025-07-19T19:57:16.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 21 (task 22, attempt 0, stage 3.0)
[2025-07-19T19:57:16.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 23, attempt 0, stage 3.0)
[2025-07-19T19:57:16.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 25, attempt 0, stage 3.0)
[2025-07-19T19:57:16.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 24, attempt 0, stage 3.0)
[2025-07-19T19:57:16.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 21.0 in stage 3.0 (TID 22). 9039 bytes result sent to driver
[2025-07-19T19:57:16.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 27) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 22) in 164 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T19:57:16.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 26.0 in stage 3.0 (TID 27)
[2025-07-19T19:57:16.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 14 (task 20, attempt 0, stage 3.0)
[2025-07-19T19:57:16.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 14.0 in stage 3.0 (TID 20). 9054 bytes result sent to driver
[2025-07-19T19:57:16.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 28) (8b44f3d35cfa, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 20) in 181 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T19:57:16.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 29.0 in stage 3.0 (TID 28)
[2025-07-19T19:57:16.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 12 (task 19, attempt 0, stage 3.0)
[2025-07-19T19:57:16.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a5a4234
[2025-07-19T19:57:16.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/26] for update
[2025-07-19T19:57:16.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 12.0 in stage 3.0 (TID 19). 9098 bytes result sent to driver
[2025-07-19T19:57:16.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 29) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 19) in 197 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T19:57:16.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 30.0 in stage 3.0 (TID 29)
[2025-07-19T19:57:16.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 22 (task 23, attempt 0, stage 3.0)
[2025-07-19T19:57:16.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 20 (task 21, attempt 0, stage 3.0)
[2025-07-19T19:57:16.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47d8648f
[2025-07-19T19:57:16.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/29] for update
[2025-07-19T19:57:16.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 20.0 in stage 3.0 (TID 21). 9043 bytes result sent to driver
[2025-07-19T19:57:16.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 22.0 in stage 3.0 (TID 23). 9042 bytes result sent to driver
[2025-07-19T19:57:16.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 30) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 21) in 210 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T19:57:16.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 32.0 in stage 3.0 (TID 30)
[2025-07-19T19:57:16.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@585b55f
[2025-07-19T19:57:16.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/30] for update
[2025-07-19T19:57:16.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.1.delta.8c8c9221-32f5-4047-9556-14f560f4e2cd.TID28.tmp
[2025-07-19T19:57:16.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 31) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 35.0 in stage 3.0 (TID 31)
[2025-07-19T19:57:16.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 23) in 215 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T19:57:16.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.1.delta.f9a53d1a-1023-47a2-90e7-92628b01fe70.TID27.tmp
[2025-07-19T19:57:16.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 23 (task 24, attempt 0, stage 3.0)
[2025-07-19T19:57:16.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T19:57:16.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 24 (task 25, attempt 0, stage 3.0)
[2025-07-19T19:57:16.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 24.0 in stage 3.0 (TID 25). 9040 bytes result sent to driver
[2025-07-19T19:57:16.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 32) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 37.0 in stage 3.0 (TID 32)
[2025-07-19T19:57:16.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 25) in 217 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T19:57:16.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18c8b45d
[2025-07-19T19:57:16.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/32] for update
[2025-07-19T19:57:16.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 23.0 in stage 3.0 (TID 24). 9081 bytes result sent to driver
[2025-07-19T19:57:16.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 33) (8b44f3d35cfa, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:16.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.1.delta.67fe85e9-1f7c-4f4f-8c46-cc56836e6ddc.TID29.tmp
[2025-07-19T19:57:16.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 24) in 223 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T19:57:16.277+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.277+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 38.0 in stage 3.0 (TID 33)
[2025-07-19T19:57:16.277+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e6669f3
[2025-07-19T19:57:16.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/35] for update
[2025-07-19T19:57:16.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 25 (task 26, attempt 0, stage 3.0)
[2025-07-19T19:57:16.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 25.0 in stage 3.0 (TID 26). 9036 bytes result sent to driver
[2025-07-19T19:57:16.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 34) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 26) in 231 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T19:57:16.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 39.0 in stage 3.0 (TID 34)
[2025-07-19T19:57:16.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@629e8a74
[2025-07-19T19:57:16.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/37] for update
[2025-07-19T19:57:16.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.1.delta.f9c82caf-659e-4646-b193-55f643bc85d8.TID30.tmp
[2025-07-19T19:57:16.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:16.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:16.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.1.delta.f8460864-ee0e-471d-bf88-38180a44fd1e.TID31.tmp
[2025-07-19T19:57:16.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.1.delta.f9a53d1a-1023-47a2-90e7-92628b01fe70.TID27.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/26/1.delta
[2025-07-19T19:57:16.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/26] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/26/1.delta
[2025-07-19T19:57:16.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 27, attempt 0, stage 3.0)
[2025-07-19T19:57:16.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b95e85c
[2025-07-19T19:57:16.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/39] for update
[2025-07-19T19:57:16.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.1.delta.8c8c9221-32f5-4047-9556-14f560f4e2cd.TID28.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/29/1.delta
[2025-07-19T19:57:16.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/29] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/29/1.delta
[2025-07-19T19:57:16.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 28, attempt 0, stage 3.0)
[2025-07-19T19:57:16.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.1.delta.aed0e18a-2173-4d91-baf9-22adb8fabf19.TID32.tmp
[2025-07-19T19:57:16.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7967c79e
[2025-07-19T19:57:16.321+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/38] for update
[2025-07-19T19:57:16.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.1.delta.67fe85e9-1f7c-4f4f-8c46-cc56836e6ddc.TID29.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/30/1.delta
[2025-07-19T19:57:16.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/30] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/30/1.delta
[2025-07-19T19:57:16.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 29, attempt 0, stage 3.0)
[2025-07-19T19:57:16.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.1.delta.2a4fe223-bedd-46ab-ab4b-b4c74eaa137d.TID34.tmp
[2025-07-19T19:57:16.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.1.delta.354e3f58-906e-40e4-86e5-aa39f478c759.TID33.tmp
[2025-07-19T19:57:16.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 29 (task 28, attempt 0, stage 3.0)
[2025-07-19T19:57:16.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 26 (task 27, attempt 0, stage 3.0)
[2025-07-19T19:57:16.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 29.0 in stage 3.0 (TID 28). 9067 bytes result sent to driver
[2025-07-19T19:57:16.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 35) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 26.0 in stage 3.0 (TID 27). 9072 bytes result sent to driver
[2025-07-19T19:57:16.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 28) in 134 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T19:57:16.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 36) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.1.delta.f8460864-ee0e-471d-bf88-38180a44fd1e.TID31.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/35/1.delta
[2025-07-19T19:57:16.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/35] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/35/1.delta
[2025-07-19T19:57:16.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 41.0 in stage 3.0 (TID 35)
[2025-07-19T19:57:16.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 31, attempt 0, stage 3.0)
[2025-07-19T19:57:16.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.1.delta.f9c82caf-659e-4646-b193-55f643bc85d8.TID30.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/32/1.delta
[2025-07-19T19:57:16.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/32] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/32/1.delta
[2025-07-19T19:57:16.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 43.0 in stage 3.0 (TID 36)
[2025-07-19T19:57:16.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 30, attempt 0, stage 3.0)
[2025-07-19T19:57:16.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 27) in 152 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T19:57:16.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 30 (task 29, attempt 0, stage 3.0)
[2025-07-19T19:57:16.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T19:57:16.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 30.0 in stage 3.0 (TID 29). 9077 bytes result sent to driver
[2025-07-19T19:57:16.379+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 37) (8b44f3d35cfa, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 45.0 in stage 3.0 (TID 37)
[2025-07-19T19:57:16.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 29) in 149 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T19:57:16.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42810ca
[2025-07-19T19:57:16.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/41] for update
[2025-07-19T19:57:16.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.1.delta.aed0e18a-2173-4d91-baf9-22adb8fabf19.TID32.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/37/1.delta
[2025-07-19T19:57:16.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/37] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/37/1.delta
[2025-07-19T19:57:16.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 32, attempt 0, stage 3.0)
[2025-07-19T19:57:16.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49ed2873
[2025-07-19T19:57:16.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.391+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/43] for update
[2025-07-19T19:57:16.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 35 (task 31, attempt 0, stage 3.0)
[2025-07-19T19:57:16.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 35.0 in stage 3.0 (TID 31). 9088 bytes result sent to driver
[2025-07-19T19:57:16.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 38) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 31) in 145 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T19:57:16.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 32 (task 30, attempt 0, stage 3.0)
[2025-07-19T19:57:16.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.1.delta.91cb7029-3b4e-4064-aa71-c2a211791ce5.TID35.tmp
[2025-07-19T19:57:16.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 46.0 in stage 3.0 (TID 38)
[2025-07-19T19:57:16.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.1.delta.354e3f58-906e-40e4-86e5-aa39f478c759.TID33.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/38/1.delta
[2025-07-19T19:57:16.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.1.delta.2a4fe223-bedd-46ab-ab4b-b4c74eaa137d.TID34.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/39/1.delta
[2025-07-19T19:57:16.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/39] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/39/1.delta
[2025-07-19T19:57:16.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/38] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/38/1.delta
[2025-07-19T19:57:16.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 33, attempt 0, stage 3.0)
[2025-07-19T19:57:16.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 34, attempt 0, stage 3.0)
[2025-07-19T19:57:16.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cbf3627
[2025-07-19T19:57:16.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/45] for update
[2025-07-19T19:57:16.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 32.0 in stage 3.0 (TID 30). 9081 bytes result sent to driver
[2025-07-19T19:57:16.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 39) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 47.0 in stage 3.0 (TID 39)
[2025-07-19T19:57:16.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 30) in 166 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T19:57:16.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.1.delta.ba189df9-1552-4b45-acee-9ad6fd07517b.TID36.tmp
[2025-07-19T19:57:16.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:16.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.1.delta.52dd1876-48be-426c-9d95-f3c40b0f0c4d.TID37.tmp
[2025-07-19T19:57:16.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 37 (task 32, attempt 0, stage 3.0)
[2025-07-19T19:57:16.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:16.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 37.0 in stage 3.0 (TID 32). 9120 bytes result sent to driver
[2025-07-19T19:57:16.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 32) in 160 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T19:57:16.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27bfef0
[2025-07-19T19:57:16.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 40) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 48.0 in stage 3.0 (TID 40)
[2025-07-19T19:57:16.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/46] for update
[2025-07-19T19:57:16.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.1.delta.63a28058-1777-4ff8-8c34-c729ab6d31c0.TID38.tmp
[2025-07-19T19:57:16.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c31d4de
[2025-07-19T19:57:16.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 39 (task 34, attempt 0, stage 3.0)
[2025-07-19T19:57:16.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/47] for update
[2025-07-19T19:57:16.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 39.0 in stage 3.0 (TID 34). 9067 bytes result sent to driver
[2025-07-19T19:57:16.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 51.0 in stage 3.0 (TID 41) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 51.0 in stage 3.0 (TID 41)
[2025-07-19T19:57:16.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.1.delta.91cb7029-3b4e-4064-aa71-c2a211791ce5.TID35.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/41/1.delta
[2025-07-19T19:57:16.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/41] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/41/1.delta
[2025-07-19T19:57:16.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 35, attempt 0, stage 3.0)
[2025-07-19T19:57:16.465+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@299d5447
[2025-07-19T19:57:16.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 34) in 184 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T19:57:16.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/48] for update
[2025-07-19T19:57:16.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:16.480+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 38 (task 33, attempt 0, stage 3.0)
[2025-07-19T19:57:16.488+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.1.delta.ba189df9-1552-4b45-acee-9ad6fd07517b.TID36.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/43/1.delta
[2025-07-19T19:57:16.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/43] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/43/1.delta
[2025-07-19T19:57:16.492+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 38.0 in stage 3.0 (TID 33). 9116 bytes result sent to driver
[2025-07-19T19:57:16.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 36, attempt 0, stage 3.0)
[2025-07-19T19:57:16.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@547b3643
[2025-07-19T19:57:16.515+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.516+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/51] for update
[2025-07-19T19:57:16.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 52.0 in stage 3.0 (TID 42) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 52.0 in stage 3.0 (TID 42)
[2025-07-19T19:57:16.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 33) in 238 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T19:57:16.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.1.delta.52dd1876-48be-426c-9d95-f3c40b0f0c4d.TID37.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/45/1.delta
[2025-07-19T19:57:16.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/45] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/45/1.delta
[2025-07-19T19:57:16.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.1.delta.f314ad1b-0cc7-449e-8878-2d02d79ad5ac.TID40.tmp
[2025-07-19T19:57:16.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.1.delta.88d9c01b-4ff2-46ee-a774-5502d7c4c593.TID39.tmp
[2025-07-19T19:57:16.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 37, attempt 0, stage 3.0)
[2025-07-19T19:57:16.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22390901
[2025-07-19T19:57:16.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 41 (task 35, attempt 0, stage 3.0)
[2025-07-19T19:57:16.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/52] for update
[2025-07-19T19:57:16.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 41.0 in stage 3.0 (TID 35). 9075 bytes result sent to driver
[2025-07-19T19:57:16.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 53.0 in stage 3.0 (TID 43) (8b44f3d35cfa, executor driver, partition 53, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 53.0 in stage 3.0 (TID 43)
[2025-07-19T19:57:16.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 35) in 191 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T19:57:16.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.1.delta.63a28058-1777-4ff8-8c34-c729ab6d31c0.TID38.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/46/1.delta
[2025-07-19T19:57:16.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/46] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/46/1.delta
[2025-07-19T19:57:16.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 38, attempt 0, stage 3.0)
[2025-07-19T19:57:16.546+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.1.delta.4f1d2133-f648-4506-8470-212e43994ea3.TID41.tmp
[2025-07-19T19:57:16.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 43 (task 36, attempt 0, stage 3.0)
[2025-07-19T19:57:16.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 43.0 in stage 3.0 (TID 36). 9075 bytes result sent to driver
[2025-07-19T19:57:16.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 45 (task 37, attempt 0, stage 3.0)
[2025-07-19T19:57:16.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 45.0 in stage 3.0 (TID 37). 9085 bytes result sent to driver
[2025-07-19T19:57:16.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 56.0 in stage 3.0 (TID 44) (8b44f3d35cfa, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 57.0 in stage 3.0 (TID 45) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 36) in 202 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T19:57:16.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 37) in 177 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T19:57:16.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 57.0 in stage 3.0 (TID 45)
[2025-07-19T19:57:16.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.1.delta.88d9c01b-4ff2-46ee-a774-5502d7c4c593.TID39.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/47/1.delta
[2025-07-19T19:57:16.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 56.0 in stage 3.0 (TID 44)
[2025-07-19T19:57:16.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/47] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/47/1.delta
[2025-07-19T19:57:16.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 39, attempt 0, stage 3.0)
[2025-07-19T19:57:16.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:16.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:16.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@319a5fcc
[2025-07-19T19:57:16.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/57] for update
[2025-07-19T19:57:16.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 46 (task 38, attempt 0, stage 3.0)
[2025-07-19T19:57:16.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25f89952
[2025-07-19T19:57:16.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/56] for update
[2025-07-19T19:57:16.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.1.delta.bd2c4691-3067-4fdb-9f41-f48a2da9f75f.TID45.tmp
[2025-07-19T19:57:16.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.1.delta.0a77842e-a691-45c8-a28d-e44636478569.TID42.tmp
[2025-07-19T19:57:16.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 47 (task 39, attempt 0, stage 3.0)
[2025-07-19T19:57:16.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.1.delta.f314ad1b-0cc7-449e-8878-2d02d79ad5ac.TID40.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/48/1.delta
[2025-07-19T19:57:16.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/48] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/48/1.delta
[2025-07-19T19:57:16.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 40, attempt 0, stage 3.0)
[2025-07-19T19:57:16.582+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 46.0 in stage 3.0 (TID 38). 9092 bytes result sent to driver
[2025-07-19T19:57:16.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 58.0 in stage 3.0 (TID 46) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 47.0 in stage 3.0 (TID 39). 9084 bytes result sent to driver
[2025-07-19T19:57:16.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 58.0 in stage 3.0 (TID 46)
[2025-07-19T19:57:16.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 38) in 183 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T19:57:16.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 59.0 in stage 3.0 (TID 47) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 59.0 in stage 3.0 (TID 47)
[2025-07-19T19:57:16.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 39) in 178 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T19:57:16.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65587182
[2025-07-19T19:57:16.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/53] for update
[2025-07-19T19:57:16.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.1.delta.91a0692c-d774-486b-b232-18c23efad3f5.TID44.tmp
[2025-07-19T19:57:16.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66d2476b
[2025-07-19T19:57:16.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.1.delta.4f1d2133-f648-4506-8470-212e43994ea3.TID41.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/51/1.delta
[2025-07-19T19:57:16.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/51] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/51/1.delta
[2025-07-19T19:57:16.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/58] for update
[2025-07-19T19:57:16.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 41, attempt 0, stage 3.0)
[2025-07-19T19:57:16.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 48 (task 40, attempt 0, stage 3.0)
[2025-07-19T19:57:16.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 48.0 in stage 3.0 (TID 40). 9077 bytes result sent to driver
[2025-07-19T19:57:16.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.1.delta.6293809e-c3f2-4d8e-90e0-cef7735ae3ec.TID43.tmp
[2025-07-19T19:57:16.600+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37ea8de2
[2025-07-19T19:57:16.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 60.0 in stage 3.0 (TID 48) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/59] for update
[2025-07-19T19:57:16.606+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 40) in 175 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T19:57:16.608+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 60.0 in stage 3.0 (TID 48)
[2025-07-19T19:57:16.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:16.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.1.delta.bd2c4691-3067-4fdb-9f41-f48a2da9f75f.TID45.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/57/1.delta
[2025-07-19T19:57:16.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/57] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/57/1.delta
[2025-07-19T19:57:16.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 45, attempt 0, stage 3.0)
[2025-07-19T19:57:16.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e86cfce
[2025-07-19T19:57:16.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/60] for update
[2025-07-19T19:57:16.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.1.delta.a49d5714-b046-4778-9b54-1b0be1320ac2.TID47.tmp
[2025-07-19T19:57:16.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.1.delta.0a77842e-a691-45c8-a28d-e44636478569.TID42.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/52/1.delta
[2025-07-19T19:57:16.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/52] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/52/1.delta
[2025-07-19T19:57:16.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.1.delta.2e94ffca-0565-426f-b6b9-c019ac196e13.TID46.tmp
[2025-07-19T19:57:16.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 42, attempt 0, stage 3.0)
[2025-07-19T19:57:16.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 51 (task 41, attempt 0, stage 3.0)
[2025-07-19T19:57:16.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.1.delta.c90b9c2d-cb58-4d3b-a3c6-5ddeb05467e5.TID48.tmp
[2025-07-19T19:57:16.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 51.0 in stage 3.0 (TID 41). 9042 bytes result sent to driver
[2025-07-19T19:57:16.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 63.0 in stage 3.0 (TID 49) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 63.0 in stage 3.0 (TID 49)
[2025-07-19T19:57:16.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 57 (task 45, attempt 0, stage 3.0)
[2025-07-19T19:57:16.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 51.0 in stage 3.0 (TID 41) in 179 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T19:57:16.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 57.0 in stage 3.0 (TID 45). 9040 bytes result sent to driver
[2025-07-19T19:57:16.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 64.0 in stage 3.0 (TID 50) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3067e9f3
[2025-07-19T19:57:16.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 57.0 in stage 3.0 (TID 45) in 90 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T19:57:16.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 64.0 in stage 3.0 (TID 50)
[2025-07-19T19:57:16.647+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.647+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/63] for update
[2025-07-19T19:57:16.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 52 (task 42, attempt 0, stage 3.0)
[2025-07-19T19:57:16.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 52.0 in stage 3.0 (TID 42). 9026 bytes result sent to driver
[2025-07-19T19:57:16.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 65.0 in stage 3.0 (TID 51) (8b44f3d35cfa, executor driver, partition 65, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.1.delta.91a0692c-d774-486b-b232-18c23efad3f5.TID44.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/56/1.delta
[2025-07-19T19:57:16.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 52.0 in stage 3.0 (TID 42) in 156 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T19:57:16.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/56] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/56/1.delta
[2025-07-19T19:57:16.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 65.0 in stage 3.0 (TID 51)
[2025-07-19T19:57:16.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 44, attempt 0, stage 3.0)
[2025-07-19T19:57:16.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.1.delta.6293809e-c3f2-4d8e-90e0-cef7735ae3ec.TID43.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/53/1.delta
[2025-07-19T19:57:16.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/53] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/53/1.delta
[2025-07-19T19:57:16.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 43, attempt 0, stage 3.0)
[2025-07-19T19:57:16.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fd46f3f
[2025-07-19T19:57:16.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/64] for update
[2025-07-19T19:57:16.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.1.delta.a49d5714-b046-4778-9b54-1b0be1320ac2.TID47.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/59/1.delta
[2025-07-19T19:57:16.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/59] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/59/1.delta
[2025-07-19T19:57:16.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 47, attempt 0, stage 3.0)
[2025-07-19T19:57:16.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a46e2b4
[2025-07-19T19:57:16.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.1.delta.2e94ffca-0565-426f-b6b9-c019ac196e13.TID46.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/58/1.delta
[2025-07-19T19:57:16.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/65] for update
[2025-07-19T19:57:16.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/58] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/58/1.delta
[2025-07-19T19:57:16.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.1.delta.190261e2-2d5d-4b67-b5ee-408f5e61b3b0.TID49.tmp
[2025-07-19T19:57:16.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 46, attempt 0, stage 3.0)
[2025-07-19T19:57:16.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.1.delta.c90b9c2d-cb58-4d3b-a3c6-5ddeb05467e5.TID48.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/60/1.delta
[2025-07-19T19:57:16.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/60] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/60/1.delta
[2025-07-19T19:57:16.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 48, attempt 0, stage 3.0)
[2025-07-19T19:57:16.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.1.delta.1be29eac-733f-45de-913c-4346383a1b3b.TID50.tmp
[2025-07-19T19:57:16.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.1.delta.fa648f94-de7a-4195-8d57-2fb095988742.TID51.tmp
[2025-07-19T19:57:16.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 59 (task 47, attempt 0, stage 3.0)
[2025-07-19T19:57:16.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 53 (task 43, attempt 0, stage 3.0)
[2025-07-19T19:57:16.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 59.0 in stage 3.0 (TID 47). 9081 bytes result sent to driver
[2025-07-19T19:57:16.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 66.0 in stage 3.0 (TID 52) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 53.0 in stage 3.0 (TID 43). 9090 bytes result sent to driver
[2025-07-19T19:57:16.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 66.0 in stage 3.0 (TID 52)
[2025-07-19T19:57:16.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 60 (task 48, attempt 0, stage 3.0)
[2025-07-19T19:57:16.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 60.0 in stage 3.0 (TID 48). 9036 bytes result sent to driver
[2025-07-19T19:57:16.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 59.0 in stage 3.0 (TID 47) in 112 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T19:57:16.710+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 68.0 in stage 3.0 (TID 53) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 69.0 in stage 3.0 (TID 54) (8b44f3d35cfa, executor driver, partition 69, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 60.0 in stage 3.0 (TID 48) in 108 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T19:57:16.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 69.0 in stage 3.0 (TID 54)
[2025-07-19T19:57:16.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 53.0 in stage 3.0 (TID 43) in 177 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T19:57:16.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 68.0 in stage 3.0 (TID 53)
[2025-07-19T19:57:16.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.1.delta.1be29eac-733f-45de-913c-4346383a1b3b.TID50.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/64/1.delta
[2025-07-19T19:57:16.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/64] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/64/1.delta
[2025-07-19T19:57:16.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 50, attempt 0, stage 3.0)
[2025-07-19T19:57:16.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:16.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6782b65a
[2025-07-19T19:57:16.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.1.delta.190261e2-2d5d-4b67-b5ee-408f5e61b3b0.TID49.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/63/1.delta
[2025-07-19T19:57:16.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/63] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/63/1.delta
[2025-07-19T19:57:16.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 58 (task 46, attempt 0, stage 3.0)
[2025-07-19T19:57:16.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 58.0 in stage 3.0 (TID 46). 9081 bytes result sent to driver
[2025-07-19T19:57:16.729+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 49, attempt 0, stage 3.0)
[2025-07-19T19:57:16.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/66] for update
[2025-07-19T19:57:16.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 71.0 in stage 3.0 (TID 55) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 58.0 in stage 3.0 (TID 46) in 150 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T19:57:16.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 71.0 in stage 3.0 (TID 55)
[2025-07-19T19:57:16.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25c39f7e
[2025-07-19T19:57:16.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/69] for update
[2025-07-19T19:57:16.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.1.delta.fa648f94-de7a-4195-8d57-2fb095988742.TID51.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/65/1.delta
[2025-07-19T19:57:16.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/65] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/65/1.delta
[2025-07-19T19:57:16.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 51, attempt 0, stage 3.0)
[2025-07-19T19:57:16.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 64 (task 50, attempt 0, stage 3.0)
[2025-07-19T19:57:16.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 64.0 in stage 3.0 (TID 50). 9092 bytes result sent to driver
[2025-07-19T19:57:16.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T19:57:16.749+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30816b5
[2025-07-19T19:57:16.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.1.delta.083dafd7-10df-42d9-b051-bc650a37da34.TID52.tmp
[2025-07-19T19:57:16.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/68] for update
[2025-07-19T19:57:16.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 72.0 in stage 3.0 (TID 56) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 64.0 in stage 3.0 (TID 50) in 109 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T19:57:16.754+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 72.0 in stage 3.0 (TID 56)
[2025-07-19T19:57:16.754+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 56 (task 44, attempt 0, stage 3.0)
[2025-07-19T19:57:16.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 56.0 in stage 3.0 (TID 44). 9077 bytes result sent to driver
[2025-07-19T19:57:16.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 73.0 in stage 3.0 (TID 57) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 73.0 in stage 3.0 (TID 57)
[2025-07-19T19:57:16.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 56.0 in stage 3.0 (TID 44) in 205 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T19:57:16.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.1.delta.91268372-704e-42ca-a3a5-702e90f49c1c.TID54.tmp
[2025-07-19T19:57:16.762+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 63 (task 49, attempt 0, stage 3.0)
[2025-07-19T19:57:16.763+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 63.0 in stage 3.0 (TID 49). 9075 bytes result sent to driver
[2025-07-19T19:57:16.764+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 75.0 in stage 3.0 (TID 58) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 63.0 in stage 3.0 (TID 49) in 132 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T19:57:16.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e09528e
[2025-07-19T19:57:16.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/71] for update
[2025-07-19T19:57:16.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 75.0 in stage 3.0 (TID 58)
[2025-07-19T19:57:16.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.1.delta.30d7252e-f308-4742-aa5c-03150388c89f.TID53.tmp
[2025-07-19T19:57:16.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 65 (task 51, attempt 0, stage 3.0)
[2025-07-19T19:57:16.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 65.0 in stage 3.0 (TID 51). 9085 bytes result sent to driver
[2025-07-19T19:57:16.778+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 77.0 in stage 3.0 (TID 59) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.778+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e55fe79
[2025-07-19T19:57:16.780+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.782+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/73] for update
[2025-07-19T19:57:16.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 65.0 in stage 3.0 (TID 51) in 134 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T19:57:16.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 77.0 in stage 3.0 (TID 59)
[2025-07-19T19:57:16.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.1.delta.4017c61d-2062-48d4-ac09-0cd5551a7d9b.TID55.tmp
[2025-07-19T19:57:16.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59a8cdba
[2025-07-19T19:57:16.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/72] for update
[2025-07-19T19:57:16.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b3ebad7
[2025-07-19T19:57:16.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/75] for update
[2025-07-19T19:57:16.803+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.1.delta.722f00f2-f2a5-4c3c-94f4-870a63274781.TID57.tmp
[2025-07-19T19:57:16.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d673f9b
[2025-07-19T19:57:16.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/77] for update
[2025-07-19T19:57:16.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.1.delta.77b18ca0-a838-4dd4-bad9-b03ad4aae7e8.TID56.tmp
[2025-07-19T19:57:16.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.1.delta.083dafd7-10df-42d9-b051-bc650a37da34.TID52.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/66/1.delta
[2025-07-19T19:57:16.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/66] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/66/1.delta
[2025-07-19T19:57:16.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 52, attempt 0, stage 3.0)
[2025-07-19T19:57:16.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.1.delta.91268372-704e-42ca-a3a5-702e90f49c1c.TID54.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/69/1.delta
[2025-07-19T19:57:16.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/69] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/69/1.delta
[2025-07-19T19:57:16.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 54, attempt 0, stage 3.0)
[2025-07-19T19:57:16.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.1.delta.f519c19d-3ad7-443f-aa91-35f4bbe6deb2.TID58.tmp
[2025-07-19T19:57:16.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.1.delta.6efd8a93-41b1-4b12-9445-e72680a5ddd9.TID59.tmp
[2025-07-19T19:57:16.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.1.delta.30d7252e-f308-4742-aa5c-03150388c89f.TID53.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/68/1.delta
[2025-07-19T19:57:16.824+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/68] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/68/1.delta
[2025-07-19T19:57:16.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 53, attempt 0, stage 3.0)
[2025-07-19T19:57:16.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.1.delta.4017c61d-2062-48d4-ac09-0cd5551a7d9b.TID55.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/71/1.delta
[2025-07-19T19:57:16.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/71] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/71/1.delta
[2025-07-19T19:57:16.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 55, attempt 0, stage 3.0)
[2025-07-19T19:57:16.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.1.delta.77b18ca0-a838-4dd4-bad9-b03ad4aae7e8.TID56.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/72/1.delta
[2025-07-19T19:57:16.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/72] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/72/1.delta
[2025-07-19T19:57:16.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.1.delta.722f00f2-f2a5-4c3c-94f4-870a63274781.TID57.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/73/1.delta
[2025-07-19T19:57:16.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/73] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/73/1.delta
[2025-07-19T19:57:16.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 56, attempt 0, stage 3.0)
[2025-07-19T19:57:16.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 69 (task 54, attempt 0, stage 3.0)
[2025-07-19T19:57:16.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 57, attempt 0, stage 3.0)
[2025-07-19T19:57:16.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 69.0 in stage 3.0 (TID 54). 9065 bytes result sent to driver
[2025-07-19T19:57:16.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 68 (task 53, attempt 0, stage 3.0)
[2025-07-19T19:57:16.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 66 (task 52, attempt 0, stage 3.0)
[2025-07-19T19:57:16.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 68.0 in stage 3.0 (TID 53). 9071 bytes result sent to driver
[2025-07-19T19:57:16.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 66.0 in stage 3.0 (TID 52). 9084 bytes result sent to driver
[2025-07-19T19:57:16.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 78.0 in stage 3.0 (TID 60) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 79.0 in stage 3.0 (TID 61) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 82.0 in stage 3.0 (TID 62) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 79.0 in stage 3.0 (TID 61)
[2025-07-19T19:57:16.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 66.0 in stage 3.0 (TID 52) in 164 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T19:57:16.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 68.0 in stage 3.0 (TID 53) in 158 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T19:57:16.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 78.0 in stage 3.0 (TID 60)
[2025-07-19T19:57:16.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.1.delta.f519c19d-3ad7-443f-aa91-35f4bbe6deb2.TID58.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/75/1.delta
[2025-07-19T19:57:16.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/75] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/75/1.delta
[2025-07-19T19:57:16.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 69.0 in stage 3.0 (TID 54) in 152 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T19:57:16.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 82.0 in stage 3.0 (TID 62)
[2025-07-19T19:57:16.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 58, attempt 0, stage 3.0)
[2025-07-19T19:57:16.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.1.delta.6efd8a93-41b1-4b12-9445-e72680a5ddd9.TID59.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/77/1.delta
[2025-07-19T19:57:16.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:16.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/77] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/77/1.delta
[2025-07-19T19:57:16.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:16.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6483170
[2025-07-19T19:57:16.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 59, attempt 0, stage 3.0)
[2025-07-19T19:57:16.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/79] for update
[2025-07-19T19:57:16.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 72 (task 56, attempt 0, stage 3.0)
[2025-07-19T19:57:16.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 73 (task 57, attempt 0, stage 3.0)
[2025-07-19T19:57:16.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68e54ad9
[2025-07-19T19:57:16.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 73.0 in stage 3.0 (TID 57). 9137 bytes result sent to driver
[2025-07-19T19:57:16.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/82] for update
[2025-07-19T19:57:16.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.1.delta.7a37955d-98c2-4fe8-a08e-50cb9ca13604.TID61.tmp
[2025-07-19T19:57:16.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 83.0 in stage 3.0 (TID 63) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 72.0 in stage 3.0 (TID 56). 9069 bytes result sent to driver
[2025-07-19T19:57:16.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 83.0 in stage 3.0 (TID 63)
[2025-07-19T19:57:16.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 85.0 in stage 3.0 (TID 64) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 72.0 in stage 3.0 (TID 56) in 141 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T19:57:16.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 73.0 in stage 3.0 (TID 57) in 136 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T19:57:16.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.902+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 85.0 in stage 3.0 (TID 64)
[2025-07-19T19:57:16.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7de33b75
[2025-07-19T19:57:16.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:16.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 71 (task 55, attempt 0, stage 3.0)
[2025-07-19T19:57:16.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 71.0 in stage 3.0 (TID 55). 9116 bytes result sent to driver
[2025-07-19T19:57:16.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 86.0 in stage 3.0 (TID 65) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.1.delta.aae26afd-bf81-44ec-81d0-c123bd84b187.TID62.tmp
[2025-07-19T19:57:16.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/78] for update
[2025-07-19T19:57:16.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 86.0 in stage 3.0 (TID 65)
[2025-07-19T19:57:16.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:16.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 77 (task 59, attempt 0, stage 3.0)
[2025-07-19T19:57:16.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 71.0 in stage 3.0 (TID 55) in 211 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T19:57:16.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 77.0 in stage 3.0 (TID 59). 9079 bytes result sent to driver
[2025-07-19T19:57:16.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 87.0 in stage 3.0 (TID 66) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b98c4b7
[2025-07-19T19:57:16.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 87.0 in stage 3.0 (TID 66)
[2025-07-19T19:57:16.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO DataWritingSparkTask: Committed partition 75 (task 58, attempt 0, stage 3.0)
[2025-07-19T19:57:16.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 77.0 in stage 3.0 (TID 59) in 163 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T19:57:16.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/83] for update
[2025-07-19T19:57:16.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Finished task 75.0 in stage 3.0 (TID 58). 9118 bytes result sent to driver
[2025-07-19T19:57:16.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Starting task 89.0 in stage 3.0 (TID 67) (8b44f3d35cfa, executor driver, partition 89, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:16.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c86ffeb
[2025-07-19T19:57:16.959+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/85] for update
[2025-07-19T19:57:16.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:16.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO Executor: Running task 89.0 in stage 3.0 (TID 67)
[2025-07-19T19:57:16.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO TaskSetManager: Finished task 75.0 in stage 3.0 (TID 58) in 191 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T19:57:16.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:16.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:16.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f5d5839
[2025-07-19T19:57:16.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/87] for update
[2025-07-19T19:57:16.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.1.delta.c0975996-c436-48ad-833c-eaf2d482e59c.TID60.tmp
[2025-07-19T19:57:16.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.1.delta.9c942acb-77d6-43f7-a074-03779d7a3c82.TID63.tmp
[2025-07-19T19:57:16.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.1.delta.4feb12e4-d769-4142-add9-2fdee43719d1.TID64.tmp
[2025-07-19T19:57:16.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6694180e
[2025-07-19T19:57:16.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:16.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/86] for update
[2025-07-19T19:57:16.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:16.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@502f33c8
[2025-07-19T19:57:16.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/89] for update
[2025-07-19T19:57:17.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.1.delta.69a4b030-e9a6-4bdd-be70-315561d4075c.TID66.tmp
[2025-07-19T19:57:17.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.1.delta.7a37955d-98c2-4fe8-a08e-50cb9ca13604.TID61.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/79/1.delta
[2025-07-19T19:57:17.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/79] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/79/1.delta
[2025-07-19T19:57:17.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 61, attempt 0, stage 3.0)
[2025-07-19T19:57:17.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.1.delta.ab68501e-d130-47a1-be6c-ad3f0146e5fc.TID65.tmp
[2025-07-19T19:57:17.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.1.delta.aae26afd-bf81-44ec-81d0-c123bd84b187.TID62.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/82/1.delta
[2025-07-19T19:57:17.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/82] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/82/1.delta
[2025-07-19T19:57:17.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 62, attempt 0, stage 3.0)
[2025-07-19T19:57:17.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.1.delta.99be9b17-2dfa-424a-a2bb-1f079e804c4f.TID67.tmp
[2025-07-19T19:57:17.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.1.delta.c0975996-c436-48ad-833c-eaf2d482e59c.TID60.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/78/1.delta
[2025-07-19T19:57:17.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/78] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/78/1.delta
[2025-07-19T19:57:17.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 60, attempt 0, stage 3.0)
[2025-07-19T19:57:17.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.1.delta.4feb12e4-d769-4142-add9-2fdee43719d1.TID64.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/85/1.delta
[2025-07-19T19:57:17.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/85] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/85/1.delta
[2025-07-19T19:57:17.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 64, attempt 0, stage 3.0)
[2025-07-19T19:57:17.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 79 (task 61, attempt 0, stage 3.0)
[2025-07-19T19:57:17.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 79.0 in stage 3.0 (TID 61). 9081 bytes result sent to driver
[2025-07-19T19:57:17.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.1.delta.9c942acb-77d6-43f7-a074-03779d7a3c82.TID63.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/83/1.delta
[2025-07-19T19:57:17.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/83] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/83/1.delta
[2025-07-19T19:57:17.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 63, attempt 0, stage 3.0)
[2025-07-19T19:57:17.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 92.0 in stage 3.0 (TID 68) (8b44f3d35cfa, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 79.0 in stage 3.0 (TID 61) in 191 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T19:57:17.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 92.0 in stage 3.0 (TID 68)
[2025-07-19T19:57:17.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 82 (task 62, attempt 0, stage 3.0)
[2025-07-19T19:57:17.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:17.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 78 (task 60, attempt 0, stage 3.0)
[2025-07-19T19:57:17.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 82.0 in stage 3.0 (TID 62). 9081 bytes result sent to driver
[2025-07-19T19:57:17.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 94.0 in stage 3.0 (TID 69) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 82.0 in stage 3.0 (TID 62) in 203 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T19:57:17.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 94.0 in stage 3.0 (TID 69)
[2025-07-19T19:57:17.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 78.0 in stage 3.0 (TID 60). 9088 bytes result sent to driver
[2025-07-19T19:57:17.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.1.delta.69a4b030-e9a6-4bdd-be70-315561d4075c.TID66.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/87/1.delta
[2025-07-19T19:57:17.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 95.0 in stage 3.0 (TID 70) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/87] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/87/1.delta
[2025-07-19T19:57:17.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@384ecd97
[2025-07-19T19:57:17.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 78.0 in stage 3.0 (TID 60) in 210 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T19:57:17.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 85 (task 64, attempt 0, stage 3.0)
[2025-07-19T19:57:17.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 66, attempt 0, stage 3.0)
[2025-07-19T19:57:17.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 95.0 in stage 3.0 (TID 70)
[2025-07-19T19:57:17.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/92] for update
[2025-07-19T19:57:17.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 85.0 in stage 3.0 (TID 64). 9090 bytes result sent to driver
[2025-07-19T19:57:17.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 83 (task 63, attempt 0, stage 3.0)
[2025-07-19T19:57:17.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 96.0 in stage 3.0 (TID 71) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.1.delta.99be9b17-2dfa-424a-a2bb-1f079e804c4f.TID67.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/89/1.delta
[2025-07-19T19:57:17.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.1.delta.ab68501e-d130-47a1-be6c-ad3f0146e5fc.TID65.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/86/1.delta
[2025-07-19T19:57:17.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/86] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/86/1.delta
[2025-07-19T19:57:17.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/89] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/89/1.delta
[2025-07-19T19:57:17.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:17.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 65, attempt 0, stage 3.0)
[2025-07-19T19:57:17.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b86f1f3
[2025-07-19T19:57:17.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 83.0 in stage 3.0 (TID 63). 9080 bytes result sent to driver
[2025-07-19T19:57:17.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 85.0 in stage 3.0 (TID 64) in 189 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T19:57:17.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 67, attempt 0, stage 3.0)
[2025-07-19T19:57:17.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 97.0 in stage 3.0 (TID 72) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 96.0 in stage 3.0 (TID 71)
[2025-07-19T19:57:17.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 83.0 in stage 3.0 (TID 63) in 192 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T19:57:17.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 97.0 in stage 3.0 (TID 72)
[2025-07-19T19:57:17.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/94] for update
[2025-07-19T19:57:17.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68ac4e03
[2025-07-19T19:57:17.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/95] for update
[2025-07-19T19:57:17.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:17.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:17.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.1.delta.3353f95f-2d41-49ec-bdb5-345ffedc2896.TID68.tmp
[2025-07-19T19:57:17.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 87 (task 66, attempt 0, stage 3.0)
[2025-07-19T19:57:17.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c39fd69
[2025-07-19T19:57:17.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/97] for update
[2025-07-19T19:57:17.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 87.0 in stage 3.0 (TID 66). 9032 bytes result sent to driver
[2025-07-19T19:57:17.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 99.0 in stage 3.0 (TID 73) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.1.delta.84a29038-8c7c-4701-aaca-8070299ea073.TID69.tmp
[2025-07-19T19:57:17.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 99.0 in stage 3.0 (TID 73)
[2025-07-19T19:57:17.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 86 (task 65, attempt 0, stage 3.0)
[2025-07-19T19:57:17.114+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.114+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.115+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 87.0 in stage 3.0 (TID 66) in 170 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T19:57:17.115+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 86.0 in stage 3.0 (TID 65). 9050 bytes result sent to driver
[2025-07-19T19:57:17.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 100.0 in stage 3.0 (TID 74) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d8e2351
[2025-07-19T19:57:17.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 100.0 in stage 3.0 (TID 74)
[2025-07-19T19:57:17.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 89 (task 67, attempt 0, stage 3.0)
[2025-07-19T19:57:17.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/96] for update
[2025-07-19T19:57:17.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 86.0 in stage 3.0 (TID 65) in 195 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T19:57:17.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 89.0 in stage 3.0 (TID 67). 9034 bytes result sent to driver
[2025-07-19T19:57:17.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 102.0 in stage 3.0 (TID 75) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 102.0 in stage 3.0 (TID 75)
[2025-07-19T19:57:17.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 89.0 in stage 3.0 (TID 67) in 167 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T19:57:17.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e9dbfb7
[2025-07-19T19:57:17.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/99] for update
[2025-07-19T19:57:17.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.1.delta.5c041502-67c8-42b3-b67e-e9cff68fe51e.TID70.tmp
[2025-07-19T19:57:17.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.1.delta.0912eea1-c0c9-4d28-b3b6-469939723918.TID72.tmp
[2025-07-19T19:57:17.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@86af229
[2025-07-19T19:57:17.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/100] for update
[2025-07-19T19:57:17.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.1.delta.696213a6-d5e3-456b-84f6-3c286f1d531c.TID73.tmp
[2025-07-19T19:57:17.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.1.delta.c4cf9adc-2d6e-49ef-ba8c-dab67f6286f7.TID71.tmp
[2025-07-19T19:57:17.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6891ed54
[2025-07-19T19:57:17.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/102] for update
[2025-07-19T19:57:17.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.1.delta.9d2c1356-88b8-4d39-bac5-6f6f48f20cbf.TID74.tmp
[2025-07-19T19:57:17.150+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.1.delta.9d18c0f2-cd4c-46df-a8f2-ab7acc1714dc.TID75.tmp
[2025-07-19T19:57:17.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.1.delta.84a29038-8c7c-4701-aaca-8070299ea073.TID69.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/94/1.delta
[2025-07-19T19:57:17.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/94] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/94/1.delta
[2025-07-19T19:57:17.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.1.delta.3353f95f-2d41-49ec-bdb5-345ffedc2896.TID68.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/92/1.delta
[2025-07-19T19:57:17.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 69, attempt 0, stage 3.0)
[2025-07-19T19:57:17.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/92] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/92/1.delta
[2025-07-19T19:57:17.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 68, attempt 0, stage 3.0)
[2025-07-19T19:57:17.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.1.delta.5c041502-67c8-42b3-b67e-e9cff68fe51e.TID70.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/95/1.delta
[2025-07-19T19:57:17.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.1.delta.696213a6-d5e3-456b-84f6-3c286f1d531c.TID73.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/99/1.delta
[2025-07-19T19:57:17.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/99] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/99/1.delta
[2025-07-19T19:57:17.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/95] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/95/1.delta
[2025-07-19T19:57:17.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 70, attempt 0, stage 3.0)
[2025-07-19T19:57:17.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 73, attempt 0, stage 3.0)
[2025-07-19T19:57:17.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.1.delta.c4cf9adc-2d6e-49ef-ba8c-dab67f6286f7.TID71.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/96/1.delta
[2025-07-19T19:57:17.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/96] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/96/1.delta
[2025-07-19T19:57:17.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 92 (task 68, attempt 0, stage 3.0)
[2025-07-19T19:57:17.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 71, attempt 0, stage 3.0)
[2025-07-19T19:57:17.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 92.0 in stage 3.0 (TID 68). 9034 bytes result sent to driver
[2025-07-19T19:57:17.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 94 (task 69, attempt 0, stage 3.0)
[2025-07-19T19:57:17.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 94.0 in stage 3.0 (TID 69). 9051 bytes result sent to driver
[2025-07-19T19:57:17.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.1.delta.0912eea1-c0c9-4d28-b3b6-469939723918.TID72.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/97/1.delta
[2025-07-19T19:57:17.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/97] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/97/1.delta
[2025-07-19T19:57:17.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 72, attempt 0, stage 3.0)
[2025-07-19T19:57:17.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 104.0 in stage 3.0 (TID 76) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 92.0 in stage 3.0 (TID 68) in 139 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T19:57:17.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 104.0 in stage 3.0 (TID 76)
[2025-07-19T19:57:17.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 105.0 in stage 3.0 (TID 77) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 94.0 in stage 3.0 (TID 69) in 127 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T19:57:17.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 105.0 in stage 3.0 (TID 77)
[2025-07-19T19:57:17.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 95 (task 70, attempt 0, stage 3.0)
[2025-07-19T19:57:17.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 99 (task 73, attempt 0, stage 3.0)
[2025-07-19T19:57:17.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 95.0 in stage 3.0 (TID 70). 9079 bytes result sent to driver
[2025-07-19T19:57:17.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 99.0 in stage 3.0 (TID 73). 9036 bytes result sent to driver
[2025-07-19T19:57:17.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.1.delta.9d18c0f2-cd4c-46df-a8f2-ab7acc1714dc.TID75.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/102/1.delta
[2025-07-19T19:57:17.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/102] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/102/1.delta
[2025-07-19T19:57:17.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14a9a915
[2025-07-19T19:57:17.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 75, attempt 0, stage 3.0)
[2025-07-19T19:57:17.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/105] for update
[2025-07-19T19:57:17.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.1.delta.9d2c1356-88b8-4d39-bac5-6f6f48f20cbf.TID74.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/100/1.delta
[2025-07-19T19:57:17.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/100] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/100/1.delta
[2025-07-19T19:57:17.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 106.0 in stage 3.0 (TID 78) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 74, attempt 0, stage 3.0)
[2025-07-19T19:57:17.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 106.0 in stage 3.0 (TID 78)
[2025-07-19T19:57:17.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 107.0 in stage 3.0 (TID 79) (8b44f3d35cfa, executor driver, partition 107, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 107.0 in stage 3.0 (TID 79)
[2025-07-19T19:57:17.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 95.0 in stage 3.0 (TID 70) in 142 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T19:57:17.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 99.0 in stage 3.0 (TID 73) in 104 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T19:57:17.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 96 (task 71, attempt 0, stage 3.0)
[2025-07-19T19:57:17.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 96.0 in stage 3.0 (TID 71). 9031 bytes result sent to driver
[2025-07-19T19:57:17.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@936d65
[2025-07-19T19:57:17.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/104] for update
[2025-07-19T19:57:17.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 110.0 in stage 3.0 (TID 80) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.1.delta.4e0193a3-4942-43c7-8c1e-b7fcb5625f57.TID77.tmp
[2025-07-19T19:57:17.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 97 (task 72, attempt 0, stage 3.0)
[2025-07-19T19:57:17.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 110.0 in stage 3.0 (TID 80)
[2025-07-19T19:57:17.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 96.0 in stage 3.0 (TID 71) in 141 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T19:57:17.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e33bbe5
[2025-07-19T19:57:17.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/107] for update
[2025-07-19T19:57:17.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 97.0 in stage 3.0 (TID 72). 9079 bytes result sent to driver
[2025-07-19T19:57:17.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 111.0 in stage 3.0 (TID 81) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 97.0 in stage 3.0 (TID 72) in 146 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T19:57:17.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 111.0 in stage 3.0 (TID 81)
[2025-07-19T19:57:17.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f4b5f77
[2025-07-19T19:57:17.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/106] for update
[2025-07-19T19:57:17.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.1.delta.f039347f-546a-466e-86e2-2f60dc370d50.TID76.tmp
[2025-07-19T19:57:17.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62e22b67
[2025-07-19T19:57:17.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.1.delta.0bde167f-6401-4eb7-8f18-39211003141f.TID79.tmp
[2025-07-19T19:57:17.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/111] for update
[2025-07-19T19:57:17.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.1.delta.56622801-d0c5-4c57-b439-91969f7229f9.TID78.tmp
[2025-07-19T19:57:17.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 100 (task 74, attempt 0, stage 3.0)
[2025-07-19T19:57:17.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 100.0 in stage 3.0 (TID 74). 9044 bytes result sent to driver
[2025-07-19T19:57:17.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 113.0 in stage 3.0 (TID 82) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 100.0 in stage 3.0 (TID 74) in 130 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T19:57:17.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 113.0 in stage 3.0 (TID 82)
[2025-07-19T19:57:17.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c0f292d
[2025-07-19T19:57:17.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/110] for update
[2025-07-19T19:57:17.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@134b23b
[2025-07-19T19:57:17.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/113] for update
[2025-07-19T19:57:17.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.1.delta.4e0193a3-4942-43c7-8c1e-b7fcb5625f57.TID77.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/105/1.delta
[2025-07-19T19:57:17.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/105] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/105/1.delta
[2025-07-19T19:57:17.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 77, attempt 0, stage 3.0)
[2025-07-19T19:57:17.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 102 (task 75, attempt 0, stage 3.0)
[2025-07-19T19:57:17.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 102.0 in stage 3.0 (TID 75). 9036 bytes result sent to driver
[2025-07-19T19:57:17.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 117.0 in stage 3.0 (TID 83) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 117.0 in stage 3.0 (TID 83)
[2025-07-19T19:57:17.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 102.0 in stage 3.0 (TID 75) in 151 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T19:57:17.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.1.delta.f039347f-546a-466e-86e2-2f60dc370d50.TID76.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/104/1.delta
[2025-07-19T19:57:17.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/104] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/104/1.delta
[2025-07-19T19:57:17.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 76, attempt 0, stage 3.0)
[2025-07-19T19:57:17.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.1.delta.e4ecb23b-7113-4609-87da-db5ef5a9301a.TID80.tmp
[2025-07-19T19:57:17.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.1.delta.c2ee09d4-e0e8-4260-8699-bcc6a72759bf.TID81.tmp
[2025-07-19T19:57:17.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66358ec5
[2025-07-19T19:57:17.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/117] for update
[2025-07-19T19:57:17.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 105 (task 77, attempt 0, stage 3.0)
[2025-07-19T19:57:17.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.1.delta.727b386d-8b31-441c-b9a7-a349fa2fbad2.TID82.tmp
[2025-07-19T19:57:17.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 105.0 in stage 3.0 (TID 77). 9042 bytes result sent to driver
[2025-07-19T19:57:17.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 118.0 in stage 3.0 (TID 84) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 118.0 in stage 3.0 (TID 84)
[2025-07-19T19:57:17.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 105.0 in stage 3.0 (TID 77) in 107 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T19:57:17.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.1.delta.366e4aa1-be62-4e98-b71b-341726a5a00f.TID83.tmp
[2025-07-19T19:57:17.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.1.delta.56622801-d0c5-4c57-b439-91969f7229f9.TID78.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/106/1.delta
[2025-07-19T19:57:17.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/106] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/106/1.delta
[2025-07-19T19:57:17.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.1.delta.0bde167f-6401-4eb7-8f18-39211003141f.TID79.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/107/1.delta
[2025-07-19T19:57:17.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/107] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/107/1.delta
[2025-07-19T19:57:17.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e05ec4e
[2025-07-19T19:57:17.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 78, attempt 0, stage 3.0)
[2025-07-19T19:57:17.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 79, attempt 0, stage 3.0)
[2025-07-19T19:57:17.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/118] for update
[2025-07-19T19:57:17.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 104 (task 76, attempt 0, stage 3.0)
[2025-07-19T19:57:17.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 104.0 in stage 3.0 (TID 76). 9040 bytes result sent to driver
[2025-07-19T19:57:17.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 119.0 in stage 3.0 (TID 85) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 119.0 in stage 3.0 (TID 85)
[2025-07-19T19:57:17.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 104.0 in stage 3.0 (TID 76) in 133 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T19:57:17.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.1.delta.e4ecb23b-7113-4609-87da-db5ef5a9301a.TID80.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/110/1.delta
[2025-07-19T19:57:17.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/110] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/110/1.delta
[2025-07-19T19:57:17.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 80, attempt 0, stage 3.0)
[2025-07-19T19:57:17.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.1.delta.df2d5d0d-93eb-4670-bff3-45ec78101798.TID84.tmp
[2025-07-19T19:57:17.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c2a620d
[2025-07-19T19:57:17.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/119] for update
[2025-07-19T19:57:17.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.1.delta.c2ee09d4-e0e8-4260-8699-bcc6a72759bf.TID81.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/111/1.delta
[2025-07-19T19:57:17.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/111] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/111/1.delta
[2025-07-19T19:57:17.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 81, attempt 0, stage 3.0)
[2025-07-19T19:57:17.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 107 (task 79, attempt 0, stage 3.0)
[2025-07-19T19:57:17.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 106 (task 78, attempt 0, stage 3.0)
[2025-07-19T19:57:17.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 107.0 in stage 3.0 (TID 79). 9040 bytes result sent to driver
[2025-07-19T19:57:17.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 106.0 in stage 3.0 (TID 78). 9034 bytes result sent to driver
[2025-07-19T19:57:17.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 120.0 in stage 3.0 (TID 86) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 121.0 in stage 3.0 (TID 87) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 121.0 in stage 3.0 (TID 87)
[2025-07-19T19:57:17.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 120.0 in stage 3.0 (TID 86)
[2025-07-19T19:57:17.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 106.0 in stage 3.0 (TID 78) in 147 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T19:57:17.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.1.delta.727b386d-8b31-441c-b9a7-a349fa2fbad2.TID82.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/113/1.delta
[2025-07-19T19:57:17.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/113] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/113/1.delta
[2025-07-19T19:57:17.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 82, attempt 0, stage 3.0)
[2025-07-19T19:57:17.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 107.0 in stage 3.0 (TID 79) in 146 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T19:57:17.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24e10ce3
[2025-07-19T19:57:17.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.1.delta.0dfef2b2-132c-4be4-acc3-d6350634812f.TID85.tmp
[2025-07-19T19:57:17.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/121] for update
[2025-07-19T19:57:17.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 110 (task 80, attempt 0, stage 3.0)
[2025-07-19T19:57:17.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.1.delta.366e4aa1-be62-4e98-b71b-341726a5a00f.TID83.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/117/1.delta
[2025-07-19T19:57:17.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/117] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/117/1.delta
[2025-07-19T19:57:17.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 83, attempt 0, stage 3.0)
[2025-07-19T19:57:17.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 110.0 in stage 3.0 (TID 80). 9017 bytes result sent to driver
[2025-07-19T19:57:17.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 122.0 in stage 3.0 (TID 88) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 110.0 in stage 3.0 (TID 80) in 155 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T19:57:17.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 122.0 in stage 3.0 (TID 88)
[2025-07-19T19:57:17.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 111 (task 81, attempt 0, stage 3.0)
[2025-07-19T19:57:17.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 111.0 in stage 3.0 (TID 81). 9033 bytes result sent to driver
[2025-07-19T19:57:17.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.1.delta.df2d5d0d-93eb-4670-bff3-45ec78101798.TID84.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/118/1.delta
[2025-07-19T19:57:17.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.1.delta.9f6e5cea-cd0b-4fdd-acef-494b0fbf6b58.TID87.tmp
[2025-07-19T19:57:17.379+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 113 (task 82, attempt 0, stage 3.0)
[2025-07-19T19:57:17.379+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 123.0 in stage 3.0 (TID 89) (8b44f3d35cfa, executor driver, partition 123, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 123.0 in stage 3.0 (TID 89)
[2025-07-19T19:57:17.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 111.0 in stage 3.0 (TID 81) in 155 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T19:57:17.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:17.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@403e1e1b
[2025-07-19T19:57:17.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/118] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/118/1.delta
[2025-07-19T19:57:17.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 113.0 in stage 3.0 (TID 82). 9051 bytes result sent to driver
[2025-07-19T19:57:17.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 84, attempt 0, stage 3.0)
[2025-07-19T19:57:17.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/120] for update
[2025-07-19T19:57:17.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 128.0 in stage 3.0 (TID 90) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 128.0 in stage 3.0 (TID 90)
[2025-07-19T19:57:17.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.391+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 113.0 in stage 3.0 (TID 82) in 145 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T19:57:17.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31c2a60e
[2025-07-19T19:57:17.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/122] for update
[2025-07-19T19:57:17.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.1.delta.6ec3da2e-657f-4aa6-8a1e-26397ac48a3d.TID86.tmp
[2025-07-19T19:57:17.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 117 (task 83, attempt 0, stage 3.0)
[2025-07-19T19:57:17.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 117.0 in stage 3.0 (TID 83). 9034 bytes result sent to driver
[2025-07-19T19:57:17.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.1.delta.0dfef2b2-132c-4be4-acc3-d6350634812f.TID85.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/119/1.delta
[2025-07-19T19:57:17.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/119] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/119/1.delta
[2025-07-19T19:57:17.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 85, attempt 0, stage 3.0)
[2025-07-19T19:57:17.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64fd477e
[2025-07-19T19:57:17.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 129.0 in stage 3.0 (TID 91) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/128] for update
[2025-07-19T19:57:17.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 117.0 in stage 3.0 (TID 83) in 145 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T19:57:17.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 129.0 in stage 3.0 (TID 91)
[2025-07-19T19:57:17.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.1.delta.a490e232-bc53-43c2-b417-9db9149942ba.TID88.tmp
[2025-07-19T19:57:17.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a4d1f24
[2025-07-19T19:57:17.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 118 (task 84, attempt 0, stage 3.0)
[2025-07-19T19:57:17.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/123] for update
[2025-07-19T19:57:17.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 118.0 in stage 3.0 (TID 84). 9034 bytes result sent to driver
[2025-07-19T19:57:17.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 130.0 in stage 3.0 (TID 92) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 130.0 in stage 3.0 (TID 92)
[2025-07-19T19:57:17.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 118.0 in stage 3.0 (TID 84) in 138 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T19:57:17.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.1.delta.9c632bc1-ce3f-4820-8f01-7bada546f315.TID90.tmp
[2025-07-19T19:57:17.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.1.delta.9f6e5cea-cd0b-4fdd-acef-494b0fbf6b58.TID87.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/121/1.delta
[2025-07-19T19:57:17.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/121] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/121/1.delta
[2025-07-19T19:57:17.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 87, attempt 0, stage 3.0)
[2025-07-19T19:57:17.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d80ee9e
[2025-07-19T19:57:17.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.438+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/129] for update
[2025-07-19T19:57:17.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 119 (task 85, attempt 0, stage 3.0)
[2025-07-19T19:57:17.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.1.delta.6328afef-f2a9-4185-8a6e-9079205f9b2d.TID89.tmp
[2025-07-19T19:57:17.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 119.0 in stage 3.0 (TID 85). 9079 bytes result sent to driver
[2025-07-19T19:57:17.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 131.0 in stage 3.0 (TID 93) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 119.0 in stage 3.0 (TID 85) in 135 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T19:57:17.446+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 131.0 in stage 3.0 (TID 93)
[2025-07-19T19:57:17.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c368603
[2025-07-19T19:57:17.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.1.delta.6ec3da2e-657f-4aa6-8a1e-26397ac48a3d.TID86.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/120/1.delta
[2025-07-19T19:57:17.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/120] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/120/1.delta
[2025-07-19T19:57:17.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/130] for update
[2025-07-19T19:57:17.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 86, attempt 0, stage 3.0)
[2025-07-19T19:57:17.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f42ff18
[2025-07-19T19:57:17.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/131] for update
[2025-07-19T19:57:17.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.1.delta.95a4e88f-ce12-4807-86cb-e1a476f2fcc8.TID91.tmp
[2025-07-19T19:57:17.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.1.delta.a490e232-bc53-43c2-b417-9db9149942ba.TID88.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/122/1.delta
[2025-07-19T19:57:17.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/122] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/122/1.delta
[2025-07-19T19:57:17.471+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 88, attempt 0, stage 3.0)
[2025-07-19T19:57:17.472+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 121 (task 87, attempt 0, stage 3.0)
[2025-07-19T19:57:17.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.1.delta.e8b87bc3-5d6c-4406-851a-36a15af4391a.TID92.tmp
[2025-07-19T19:57:17.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 121.0 in stage 3.0 (TID 87). 9077 bytes result sent to driver
[2025-07-19T19:57:17.476+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 136.0 in stage 3.0 (TID 94) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 136.0 in stage 3.0 (TID 94)
[2025-07-19T19:57:17.478+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 121.0 in stage 3.0 (TID 87) in 133 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T19:57:17.481+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:17.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.1.delta.9c632bc1-ce3f-4820-8f01-7bada546f315.TID90.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/128/1.delta
[2025-07-19T19:57:17.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/128] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/128/1.delta
[2025-07-19T19:57:17.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 90, attempt 0, stage 3.0)
[2025-07-19T19:57:17.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 120 (task 86, attempt 0, stage 3.0)
[2025-07-19T19:57:17.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 122 (task 88, attempt 0, stage 3.0)
[2025-07-19T19:57:17.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79aec5b2
[2025-07-19T19:57:17.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/136] for update
[2025-07-19T19:57:17.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.1.delta.91e0f488-84a2-4c3c-988c-39d2273b7246.TID93.tmp
[2025-07-19T19:57:17.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 122.0 in stage 3.0 (TID 88). 9060 bytes result sent to driver
[2025-07-19T19:57:17.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 137.0 in stage 3.0 (TID 95) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 120.0 in stage 3.0 (TID 86). 9077 bytes result sent to driver
[2025-07-19T19:57:17.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.1.delta.6328afef-f2a9-4185-8a6e-9079205f9b2d.TID89.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/123/1.delta
[2025-07-19T19:57:17.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/123] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/123/1.delta
[2025-07-19T19:57:17.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 122.0 in stage 3.0 (TID 88) in 137 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T19:57:17.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 137.0 in stage 3.0 (TID 95)
[2025-07-19T19:57:17.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 138.0 in stage 3.0 (TID 96) (8b44f3d35cfa, executor driver, partition 138, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 89, attempt 0, stage 3.0)
[2025-07-19T19:57:17.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 138.0 in stage 3.0 (TID 96)
[2025-07-19T19:57:17.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 120.0 in stage 3.0 (TID 86) in 168 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T19:57:17.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.1.delta.95a4e88f-ce12-4807-86cb-e1a476f2fcc8.TID91.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/129/1.delta
[2025-07-19T19:57:17.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/129] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/129/1.delta
[2025-07-19T19:57:17.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 91, attempt 0, stage 3.0)
[2025-07-19T19:57:17.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T19:57:17.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T19:57:17.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@723cfadd
[2025-07-19T19:57:17.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/138] for update
[2025-07-19T19:57:17.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.1.delta.f3a6fab4-472a-4b8c-a48c-4dc27413e405.TID94.tmp
[2025-07-19T19:57:17.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.1.delta.e8b87bc3-5d6c-4406-851a-36a15af4391a.TID92.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/130/1.delta
[2025-07-19T19:57:17.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/130] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/130/1.delta
[2025-07-19T19:57:17.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1129c4f9
[2025-07-19T19:57:17.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/137] for update
[2025-07-19T19:57:17.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 123 (task 89, attempt 0, stage 3.0)
[2025-07-19T19:57:17.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 123.0 in stage 3.0 (TID 89). 9071 bytes result sent to driver
[2025-07-19T19:57:17.546+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 140.0 in stage 3.0 (TID 97) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 123.0 in stage 3.0 (TID 89) in 167 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T19:57:17.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.1.delta.91e0f488-84a2-4c3c-988c-39d2273b7246.TID93.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/131/1.delta
[2025-07-19T19:57:17.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/131] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/131/1.delta
[2025-07-19T19:57:17.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 92, attempt 0, stage 3.0)
[2025-07-19T19:57:17.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 140.0 in stage 3.0 (TID 97)
[2025-07-19T19:57:17.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 93, attempt 0, stage 3.0)
[2025-07-19T19:57:17.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 128 (task 90, attempt 0, stage 3.0)
[2025-07-19T19:57:17.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.569+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 128.0 in stage 3.0 (TID 90). 9067 bytes result sent to driver
[2025-07-19T19:57:17.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 144.0 in stage 3.0 (TID 98) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 128.0 in stage 3.0 (TID 90) in 184 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T19:57:17.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.1.delta.df3f2dc2-fb0e-48c1-ac0e-5357cd954822.TID96.tmp
[2025-07-19T19:57:17.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 144.0 in stage 3.0 (TID 98)
[2025-07-19T19:57:17.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ceaaf07
[2025-07-19T19:57:17.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/140] for update
[2025-07-19T19:57:17.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.1.delta.6dd237cf-0016-4bb0-8155-1fa3f2fa5118.TID95.tmp
[2025-07-19T19:57:17.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 129 (task 91, attempt 0, stage 3.0)
[2025-07-19T19:57:17.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 129.0 in stage 3.0 (TID 91). 9081 bytes result sent to driver
[2025-07-19T19:57:17.585+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 145.0 in stage 3.0 (TID 99) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 130 (task 92, attempt 0, stage 3.0)
[2025-07-19T19:57:17.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 129.0 in stage 3.0 (TID 91) in 178 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T19:57:17.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 131 (task 93, attempt 0, stage 3.0)
[2025-07-19T19:57:17.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.1.delta.c3a39944-788d-443a-b947-77b93d15d8c1.TID97.tmp
[2025-07-19T19:57:17.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 131.0 in stage 3.0 (TID 93). 9088 bytes result sent to driver
[2025-07-19T19:57:17.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 145.0 in stage 3.0 (TID 99)
[2025-07-19T19:57:17.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 149.0 in stage 3.0 (TID 100) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 131.0 in stage 3.0 (TID 93) in 143 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T19:57:17.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 149.0 in stage 3.0 (TID 100)
[2025-07-19T19:57:17.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.597+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.597+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 130.0 in stage 3.0 (TID 92). 9091 bytes result sent to driver
[2025-07-19T19:57:17.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 150.0 in stage 3.0 (TID 101) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 150.0 in stage 3.0 (TID 101)
[2025-07-19T19:57:17.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 130.0 in stage 3.0 (TID 92) in 170 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T19:57:17.600+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.600+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.600+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.1.delta.f3a6fab4-472a-4b8c-a48c-4dc27413e405.TID94.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/136/1.delta
[2025-07-19T19:57:17.601+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/136] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/136/1.delta
[2025-07-19T19:57:17.601+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 94, attempt 0, stage 3.0)
[2025-07-19T19:57:17.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a155727
[2025-07-19T19:57:17.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/144] for update
[2025-07-19T19:57:17.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a46b770
[2025-07-19T19:57:17.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/150] for update
[2025-07-19T19:57:17.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.1.delta.c3a39944-788d-443a-b947-77b93d15d8c1.TID97.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/140/1.delta
[2025-07-19T19:57:17.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/140] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/140/1.delta
[2025-07-19T19:57:17.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 97, attempt 0, stage 3.0)
[2025-07-19T19:57:17.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.1.delta.df3f2dc2-fb0e-48c1-ac0e-5357cd954822.TID96.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/138/1.delta
[2025-07-19T19:57:17.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/138] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/138/1.delta
[2025-07-19T19:57:17.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 96, attempt 0, stage 3.0)
[2025-07-19T19:57:17.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 136 (task 94, attempt 0, stage 3.0)
[2025-07-19T19:57:17.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 136.0 in stage 3.0 (TID 94). 9077 bytes result sent to driver
[2025-07-19T19:57:17.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 153.0 in stage 3.0 (TID 102) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.1.delta.9a935277-ef50-4334-84a0-a08f74d40ccd.TID98.tmp
[2025-07-19T19:57:17.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37af0c2e
[2025-07-19T19:57:17.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/149] for update
[2025-07-19T19:57:17.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 153.0 in stage 3.0 (TID 102)
[2025-07-19T19:57:17.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 136.0 in stage 3.0 (TID 94) in 151 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T19:57:17.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.1.delta.6dd237cf-0016-4bb0-8155-1fa3f2fa5118.TID95.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/137/1.delta
[2025-07-19T19:57:17.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/137] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/137/1.delta
[2025-07-19T19:57:17.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.1.delta.c1cc07e2-882a-4275-941e-a7ea6822df67.TID101.tmp
[2025-07-19T19:57:17.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 95, attempt 0, stage 3.0)
[2025-07-19T19:57:17.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.1.delta.3d523b4f-b018-4d31-83f0-20d5ae19a24b.TID100.tmp
[2025-07-19T19:57:17.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@492bcd7a
[2025-07-19T19:57:17.647+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/145] for update
[2025-07-19T19:57:17.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 140 (task 97, attempt 0, stage 3.0)
[2025-07-19T19:57:17.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 140.0 in stage 3.0 (TID 97). 9081 bytes result sent to driver
[2025-07-19T19:57:17.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 154.0 in stage 3.0 (TID 103) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1baa9f49
[2025-07-19T19:57:17.661+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 138 (task 96, attempt 0, stage 3.0)
[2025-07-19T19:57:17.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/153] for update
[2025-07-19T19:57:17.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 154.0 in stage 3.0 (TID 103)
[2025-07-19T19:57:17.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 138.0 in stage 3.0 (TID 96). 9079 bytes result sent to driver
[2025-07-19T19:57:17.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.1.delta.5b36744e-36a9-435d-8aff-05fa5d52f314.TID99.tmp
[2025-07-19T19:57:17.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 155.0 in stage 3.0 (TID 104) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 140.0 in stage 3.0 (TID 97) in 131 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T19:57:17.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 138.0 in stage 3.0 (TID 96) in 166 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T19:57:17.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 155.0 in stage 3.0 (TID 104)
[2025-07-19T19:57:17.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bce3b6
[2025-07-19T19:57:17.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/154] for update
[2025-07-19T19:57:17.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.1.delta.9ccbffa9-9e86-40c6-bead-9b5d0b39d697.TID102.tmp
[2025-07-19T19:57:17.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 137 (task 95, attempt 0, stage 3.0)
[2025-07-19T19:57:17.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 137.0 in stage 3.0 (TID 95). 9094 bytes result sent to driver
[2025-07-19T19:57:17.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 158.0 in stage 3.0 (TID 105) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 158.0 in stage 3.0 (TID 105)
[2025-07-19T19:57:17.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 137.0 in stage 3.0 (TID 95) in 191 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T19:57:17.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.1.delta.c1cc07e2-882a-4275-941e-a7ea6822df67.TID101.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/150/1.delta
[2025-07-19T19:57:17.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/150] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/150/1.delta
[2025-07-19T19:57:17.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 101, attempt 0, stage 3.0)
[2025-07-19T19:57:17.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.1.delta.9a935277-ef50-4334-84a0-a08f74d40ccd.TID98.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/144/1.delta
[2025-07-19T19:57:17.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/144] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/144/1.delta
[2025-07-19T19:57:17.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 98, attempt 0, stage 3.0)
[2025-07-19T19:57:17.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.1.delta.3d523b4f-b018-4d31-83f0-20d5ae19a24b.TID100.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/149/1.delta
[2025-07-19T19:57:17.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/149] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/149/1.delta
[2025-07-19T19:57:17.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 100, attempt 0, stage 3.0)
[2025-07-19T19:57:17.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8305b27
[2025-07-19T19:57:17.704+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.704+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/155] for update
[2025-07-19T19:57:17.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.710+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.1.delta.b3058fa0-cadb-43e4-a2ab-13774d6f3ffc.TID103.tmp
[2025-07-19T19:57:17.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@534f4198
[2025-07-19T19:57:17.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.1.delta.650e72a6-da19-41d0-af1a-6f5c9c22cf04.TID104.tmp
[2025-07-19T19:57:17.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.1.delta.5b36744e-36a9-435d-8aff-05fa5d52f314.TID99.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/145/1.delta
[2025-07-19T19:57:17.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/145] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/145/1.delta
[2025-07-19T19:57:17.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/158] for update
[2025-07-19T19:57:17.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 144 (task 98, attempt 0, stage 3.0)
[2025-07-19T19:57:17.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 144.0 in stage 3.0 (TID 98). 9030 bytes result sent to driver
[2025-07-19T19:57:17.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 99, attempt 0, stage 3.0)
[2025-07-19T19:57:17.729+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 159.0 in stage 3.0 (TID 106) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 159.0 in stage 3.0 (TID 106)
[2025-07-19T19:57:17.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.1.delta.9ccbffa9-9e86-40c6-bead-9b5d0b39d697.TID102.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/153/1.delta
[2025-07-19T19:57:17.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 144.0 in stage 3.0 (TID 98) in 169 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T19:57:17.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/153] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/153/1.delta
[2025-07-19T19:57:17.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 102, attempt 0, stage 3.0)
[2025-07-19T19:57:17.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 149 (task 100, attempt 0, stage 3.0)
[2025-07-19T19:57:17.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 149.0 in stage 3.0 (TID 100). 9056 bytes result sent to driver
[2025-07-19T19:57:17.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 150 (task 101, attempt 0, stage 3.0)
[2025-07-19T19:57:17.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 160.0 in stage 3.0 (TID 107) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 149.0 in stage 3.0 (TID 100) in 157 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T19:57:17.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:17.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 160.0 in stage 3.0 (TID 107)
[2025-07-19T19:57:17.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 150.0 in stage 3.0 (TID 101). 9040 bytes result sent to driver
[2025-07-19T19:57:17.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.1.delta.b3058fa0-cadb-43e4-a2ab-13774d6f3ffc.TID103.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/154/1.delta
[2025-07-19T19:57:17.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 161.0 in stage 3.0 (TID 108) (8b44f3d35cfa, executor driver, partition 161, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 150.0 in stage 3.0 (TID 101) in 154 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T19:57:17.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/154] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/154/1.delta
[2025-07-19T19:57:17.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 161.0 in stage 3.0 (TID 108)
[2025-07-19T19:57:17.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b6eb59
[2025-07-19T19:57:17.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 103, attempt 0, stage 3.0)
[2025-07-19T19:57:17.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.758+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/159] for update
[2025-07-19T19:57:17.758+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c24efe6
[2025-07-19T19:57:17.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/160] for update
[2025-07-19T19:57:17.764+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.1.delta.3c1b9a49-2dd4-4585-9ecf-65e3d74bebf3.TID105.tmp
[2025-07-19T19:57:17.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.1.delta.650e72a6-da19-41d0-af1a-6f5c9c22cf04.TID104.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/155/1.delta
[2025-07-19T19:57:17.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/155] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/155/1.delta
[2025-07-19T19:57:17.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 104, attempt 0, stage 3.0)
[2025-07-19T19:57:17.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T19:57:17.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 145 (task 99, attempt 0, stage 3.0)
[2025-07-19T19:57:17.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 145.0 in stage 3.0 (TID 99). 9047 bytes result sent to driver
[2025-07-19T19:57:17.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 163.0 in stage 3.0 (TID 109) (8b44f3d35cfa, executor driver, partition 163, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 145.0 in stage 3.0 (TID 99) in 193 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T19:57:17.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.1.delta.12d07f6c-a2b6-4f6f-b159-9fffa4f704a8.TID107.tmp
[2025-07-19T19:57:17.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 163.0 in stage 3.0 (TID 109)
[2025-07-19T19:57:17.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 155 (task 104, attempt 0, stage 3.0)
[2025-07-19T19:57:17.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34228625
[2025-07-19T19:57:17.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/161] for update
[2025-07-19T19:57:17.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 153 (task 102, attempt 0, stage 3.0)
[2025-07-19T19:57:17.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 154 (task 103, attempt 0, stage 3.0)
[2025-07-19T19:57:17.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 155.0 in stage 3.0 (TID 104). 9050 bytes result sent to driver
[2025-07-19T19:57:17.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 153.0 in stage 3.0 (TID 102). 9039 bytes result sent to driver
[2025-07-19T19:57:17.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 154.0 in stage 3.0 (TID 103). 9039 bytes result sent to driver
[2025-07-19T19:57:17.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 165.0 in stage 3.0 (TID 110) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 155.0 in stage 3.0 (TID 104) in 115 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T19:57:17.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 154.0 in stage 3.0 (TID 103) in 129 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T19:57:17.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 169.0 in stage 3.0 (TID 111) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 165.0 in stage 3.0 (TID 110)
[2025-07-19T19:57:17.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 170.0 in stage 3.0 (TID 112) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 169.0 in stage 3.0 (TID 111)
[2025-07-19T19:57:17.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 170.0 in stage 3.0 (TID 112)
[2025-07-19T19:57:17.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.1.delta.b5d6da87-26b0-4495-8586-c9049fbb642f.TID106.tmp
[2025-07-19T19:57:17.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fb3003c
[2025-07-19T19:57:17.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/165] for update
[2025-07-19T19:57:17.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 153.0 in stage 3.0 (TID 102) in 179 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T19:57:17.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@339fbb4b
[2025-07-19T19:57:17.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/163] for update
[2025-07-19T19:57:17.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.1.delta.3c1b9a49-2dd4-4585-9ecf-65e3d74bebf3.TID105.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/158/1.delta
[2025-07-19T19:57:17.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/158] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/158/1.delta
[2025-07-19T19:57:17.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 105, attempt 0, stage 3.0)
[2025-07-19T19:57:17.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.1.delta.c6b594ff-cd01-47dc-93a6-3b0c56c223a6.TID110.tmp
[2025-07-19T19:57:17.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.1.delta.20126957-9fdd-412c-9000-a4f1bfc2252b.TID108.tmp
[2025-07-19T19:57:17.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@389ea254
[2025-07-19T19:57:17.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/170] for update
[2025-07-19T19:57:17.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.1.delta.bcdf0bcf-f54a-45df-a827-deb4d0bcecd3.TID109.tmp
[2025-07-19T19:57:17.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e754406
[2025-07-19T19:57:17.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/169] for update
[2025-07-19T19:57:17.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.1.delta.102006a9-caa5-4521-8185-d771c39da8eb.TID112.tmp
[2025-07-19T19:57:17.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.1.delta.12d07f6c-a2b6-4f6f-b159-9fffa4f704a8.TID107.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/160/1.delta
[2025-07-19T19:57:17.827+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/160] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/160/1.delta
[2025-07-19T19:57:17.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 107, attempt 0, stage 3.0)
[2025-07-19T19:57:17.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 158 (task 105, attempt 0, stage 3.0)
[2025-07-19T19:57:17.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 158.0 in stage 3.0 (TID 105). 9085 bytes result sent to driver
[2025-07-19T19:57:17.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 172.0 in stage 3.0 (TID 113) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 172.0 in stage 3.0 (TID 113)
[2025-07-19T19:57:17.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.1.delta.20126957-9fdd-412c-9000-a4f1bfc2252b.TID108.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/161/1.delta
[2025-07-19T19:57:17.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/161] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/161/1.delta
[2025-07-19T19:57:17.843+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 158.0 in stage 3.0 (TID 105) in 156 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T19:57:17.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 108, attempt 0, stage 3.0)
[2025-07-19T19:57:17.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.1.delta.83c4ad10-9b53-4082-b6b5-c0f89660d0b0.TID111.tmp
[2025-07-19T19:57:17.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.1.delta.b5d6da87-26b0-4495-8586-c9049fbb642f.TID106.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/159/1.delta
[2025-07-19T19:57:17.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/159] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/159/1.delta
[2025-07-19T19:57:17.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 106, attempt 0, stage 3.0)
[2025-07-19T19:57:17.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T19:57:17.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 160 (task 107, attempt 0, stage 3.0)
[2025-07-19T19:57:17.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 160.0 in stage 3.0 (TID 107). 9033 bytes result sent to driver
[2025-07-19T19:57:17.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 174.0 in stage 3.0 (TID 114) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.858+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 174.0 in stage 3.0 (TID 114)
[2025-07-19T19:57:17.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 160.0 in stage 3.0 (TID 107) in 116 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T19:57:17.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 161 (task 108, attempt 0, stage 3.0)
[2025-07-19T19:57:17.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 161.0 in stage 3.0 (TID 108). 9035 bytes result sent to driver
[2025-07-19T19:57:17.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 161.0 in stage 3.0 (TID 108) in 123 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T19:57:17.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.1.delta.c6b594ff-cd01-47dc-93a6-3b0c56c223a6.TID110.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/165/1.delta
[2025-07-19T19:57:17.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/165] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/165/1.delta
[2025-07-19T19:57:17.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 177.0 in stage 3.0 (TID 115) (8b44f3d35cfa, executor driver, partition 177, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 177.0 in stage 3.0 (TID 115)
[2025-07-19T19:57:17.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 110, attempt 0, stage 3.0)
[2025-07-19T19:57:17.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 159 (task 106, attempt 0, stage 3.0)
[2025-07-19T19:57:17.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 159.0 in stage 3.0 (TID 106). 9037 bytes result sent to driver
[2025-07-19T19:57:17.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e8fadb5
[2025-07-19T19:57:17.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 159.0 in stage 3.0 (TID 106) in 147 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T19:57:17.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.1.delta.102006a9-caa5-4521-8185-d771c39da8eb.TID112.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/170/1.delta
[2025-07-19T19:57:17.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/170] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/170/1.delta
[2025-07-19T19:57:17.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 178.0 in stage 3.0 (TID 116) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 178.0 in stage 3.0 (TID 116)
[2025-07-19T19:57:17.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 112, attempt 0, stage 3.0)
[2025-07-19T19:57:17.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/172] for update
[2025-07-19T19:57:17.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.1.delta.bcdf0bcf-f54a-45df-a827-deb4d0bcecd3.TID109.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/163/1.delta
[2025-07-19T19:57:17.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/163] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/163/1.delta
[2025-07-19T19:57:17.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 109, attempt 0, stage 3.0)
[2025-07-19T19:57:17.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66bc28ca
[2025-07-19T19:57:17.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/177] for update
[2025-07-19T19:57:17.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.1.delta.83c4ad10-9b53-4082-b6b5-c0f89660d0b0.TID111.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/169/1.delta
[2025-07-19T19:57:17.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/169] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/169/1.delta
[2025-07-19T19:57:17.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29041d74
[2025-07-19T19:57:17.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/174] for update
[2025-07-19T19:57:17.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 111, attempt 0, stage 3.0)
[2025-07-19T19:57:17.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 165 (task 110, attempt 0, stage 3.0)
[2025-07-19T19:57:17.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 165.0 in stage 3.0 (TID 110). 9030 bytes result sent to driver
[2025-07-19T19:57:17.901+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 179.0 in stage 3.0 (TID 117) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.1.delta.d108dafe-4a15-432f-8a4d-092fe635e0da.TID113.tmp
[2025-07-19T19:57:17.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 165.0 in stage 3.0 (TID 110) in 116 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T19:57:17.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 179.0 in stage 3.0 (TID 117)
[2025-07-19T19:57:17.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@574ce92b
[2025-07-19T19:57:17.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.910+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/178] for update
[2025-07-19T19:57:17.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.1.delta.bfcd893c-d995-44fc-ba15-6026d57cdcac.TID114.tmp
[2025-07-19T19:57:17.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.1.delta.defb2604-9be4-489a-a057-ef9d975258b3.TID115.tmp
[2025-07-19T19:57:17.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 163 (task 109, attempt 0, stage 3.0)
[2025-07-19T19:57:17.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 170 (task 112, attempt 0, stage 3.0)
[2025-07-19T19:57:17.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 163.0 in stage 3.0 (TID 109). 9050 bytes result sent to driver
[2025-07-19T19:57:17.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 180.0 in stage 3.0 (TID 118) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 180.0 in stage 3.0 (TID 118)
[2025-07-19T19:57:17.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 163.0 in stage 3.0 (TID 109) in 149 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T19:57:17.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 170.0 in stage 3.0 (TID 112). 9082 bytes result sent to driver
[2025-07-19T19:57:17.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 181.0 in stage 3.0 (TID 119) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 170.0 in stage 3.0 (TID 112) in 140 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T19:57:17.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a92fe38
[2025-07-19T19:57:17.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 181.0 in stage 3.0 (TID 119)
[2025-07-19T19:57:17.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/179] for update
[2025-07-19T19:57:17.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.1.delta.91a6b940-51cd-4cbd-9abc-3665dfe78986.TID116.tmp
[2025-07-19T19:57:17.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:17.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 169 (task 111, attempt 0, stage 3.0)
[2025-07-19T19:57:17.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 169.0 in stage 3.0 (TID 111). 9010 bytes result sent to driver
[2025-07-19T19:57:17.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 182.0 in stage 3.0 (TID 120) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 182.0 in stage 3.0 (TID 120)
[2025-07-19T19:57:17.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 169.0 in stage 3.0 (TID 111) in 153 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T19:57:17.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.1.delta.3e33e024-80a1-4f50-b4bc-83c37d2cb0cc.TID117.tmp
[2025-07-19T19:57:17.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:17.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:17.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b854059
[2025-07-19T19:57:17.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.1.delta.d108dafe-4a15-432f-8a4d-092fe635e0da.TID113.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/172/1.delta
[2025-07-19T19:57:17.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/172] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/172/1.delta
[2025-07-19T19:57:17.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 113, attempt 0, stage 3.0)
[2025-07-19T19:57:17.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/181] for update
[2025-07-19T19:57:17.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.1.delta.defb2604-9be4-489a-a057-ef9d975258b3.TID115.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/177/1.delta
[2025-07-19T19:57:17.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/177] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/177/1.delta
[2025-07-19T19:57:17.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 115, attempt 0, stage 3.0)
[2025-07-19T19:57:17.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.1.delta.a9ac4b23-a281-48d5-af42-761f71eef00e.TID119.tmp
[2025-07-19T19:57:17.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37d774c8
[2025-07-19T19:57:17.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/182] for update
[2025-07-19T19:57:17.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.1.delta.91a6b940-51cd-4cbd-9abc-3665dfe78986.TID116.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/178/1.delta
[2025-07-19T19:57:17.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/178] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/178/1.delta
[2025-07-19T19:57:17.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.1.delta.bfcd893c-d995-44fc-ba15-6026d57cdcac.TID114.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/174/1.delta
[2025-07-19T19:57:17.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 116, attempt 0, stage 3.0)
[2025-07-19T19:57:17.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:17.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.1.delta.3e33e024-80a1-4f50-b4bc-83c37d2cb0cc.TID117.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/179/1.delta
[2025-07-19T19:57:17.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/179] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/179/1.delta
[2025-07-19T19:57:17.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 117, attempt 0, stage 3.0)
[2025-07-19T19:57:17.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/174] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/174/1.delta
[2025-07-19T19:57:17.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e3f61a5
[2025-07-19T19:57:17.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 114, attempt 0, stage 3.0)
[2025-07-19T19:57:17.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:17.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.1.delta.8dd546ed-9a03-45a4-9f94-527029172680.TID120.tmp
[2025-07-19T19:57:17.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/180] for update
[2025-07-19T19:57:17.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 172 (task 113, attempt 0, stage 3.0)
[2025-07-19T19:57:17.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 172.0 in stage 3.0 (TID 113). 9043 bytes result sent to driver
[2025-07-19T19:57:17.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 183.0 in stage 3.0 (TID 121) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:17.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Committed partition 177 (task 115, attempt 0, stage 3.0)
[2025-07-19T19:57:18.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Finished task 172.0 in stage 3.0 (TID 113) in 158 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T19:57:18.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.1.delta.a9ac4b23-a281-48d5-af42-761f71eef00e.TID119.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/181/1.delta
[2025-07-19T19:57:18.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Running task 183.0 in stage 3.0 (TID 121)
[2025-07-19T19:57:18.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/181] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/181/1.delta
[2025-07-19T19:57:18.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO Executor: Finished task 177.0 in stage 3.0 (TID 115). 9033 bytes result sent to driver
[2025-07-19T19:57:18.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 119, attempt 0, stage 3.0)
[2025-07-19T19:57:18.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO TaskSetManager: Starting task 188.0 in stage 3.0 (TID 122) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 177.0 in stage 3.0 (TID 115) in 134 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T19:57:18.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 188.0 in stage 3.0 (TID 122)
[2025-07-19T19:57:18.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a5297a4
[2025-07-19T19:57:18.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/183] for update
[2025-07-19T19:57:18.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 178 (task 116, attempt 0, stage 3.0)
[2025-07-19T19:57:18.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 178.0 in stage 3.0 (TID 116). 9029 bytes result sent to driver
[2025-07-19T19:57:18.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 179 (task 117, attempt 0, stage 3.0)
[2025-07-19T19:57:18.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.1.delta.5308272b-1320-4844-ad1f-a13db5e7a0cb.TID118.tmp
[2025-07-19T19:57:18.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 179.0 in stage 3.0 (TID 117). 9053 bytes result sent to driver
[2025-07-19T19:57:18.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 190.0 in stage 3.0 (TID 123) (8b44f3d35cfa, executor driver, partition 190, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 178.0 in stage 3.0 (TID 116) in 142 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T19:57:18.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 192.0 in stage 3.0 (TID 124) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 192.0 in stage 3.0 (TID 124)
[2025-07-19T19:57:18.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.1.delta.474ff7f1-12cb-4417-8724-d6b844338598.TID121.tmp
[2025-07-19T19:57:18.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 190.0 in stage 3.0 (TID 123)
[2025-07-19T19:57:18.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 181 (task 119, attempt 0, stage 3.0)
[2025-07-19T19:57:18.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 179.0 in stage 3.0 (TID 117) in 129 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T19:57:18.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b3df860
[2025-07-19T19:57:18.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/188] for update
[2025-07-19T19:57:18.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 181.0 in stage 3.0 (TID 119). 9037 bytes result sent to driver
[2025-07-19T19:57:18.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 174 (task 114, attempt 0, stage 3.0)
[2025-07-19T19:57:18.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.1.delta.8dd546ed-9a03-45a4-9f94-527029172680.TID120.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/182/1.delta
[2025-07-19T19:57:18.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/182] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/182/1.delta
[2025-07-19T19:57:18.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 195.0 in stage 3.0 (TID 125) (8b44f3d35cfa, executor driver, partition 195, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 120, attempt 0, stage 3.0)
[2025-07-19T19:57:18.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 174.0 in stage 3.0 (TID 114). 9029 bytes result sent to driver
[2025-07-19T19:57:18.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 195.0 in stage 3.0 (TID 125)
[2025-07-19T19:57:18.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 126) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 0.0 in stage 3.0 (TID 126)
[2025-07-19T19:57:18.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 174.0 in stage 3.0 (TID 114) in 183 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T19:57:18.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d45adfd
[2025-07-19T19:57:18.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 181.0 in stage 3.0 (TID 119) in 113 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T19:57:18.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/192] for update
[2025-07-19T19:57:18.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.1.delta.46b72781-04ff-4f7b-ace2-52eabd7ea605.TID122.tmp
[2025-07-19T19:57:18.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.052+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.1.delta.474ff7f1-12cb-4417-8724-d6b844338598.TID121.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/183/1.delta
[2025-07-19T19:57:18.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/183] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/183/1.delta
[2025-07-19T19:57:18.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 121, attempt 0, stage 3.0)
[2025-07-19T19:57:18.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 182 (task 120, attempt 0, stage 3.0)
[2025-07-19T19:57:18.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 182.0 in stage 3.0 (TID 120). 9021 bytes result sent to driver
[2025-07-19T19:57:18.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 127) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 2.0 in stage 3.0 (TID 127)
[2025-07-19T19:57:18.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 182.0 in stage 3.0 (TID 120) in 125 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T19:57:18.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.1.delta.d98311b0-4572-4f87-89b5-eeb229a99c33.TID124.tmp
[2025-07-19T19:57:18.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.1.delta.5308272b-1320-4844-ad1f-a13db5e7a0cb.TID118.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/180/1.delta
[2025-07-19T19:57:18.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/180] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/180/1.delta
[2025-07-19T19:57:18.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/.schema.76f38c48-1fdc-4bda-b717-0d40b61777bd.TID126.tmp
[2025-07-19T19:57:18.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 118, attempt 0, stage 3.0)
[2025-07-19T19:57:18.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:18.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.1.delta.46b72781-04ff-4f7b-ace2-52eabd7ea605.TID122.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/188/1.delta
[2025-07-19T19:57:18.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/188] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/188/1.delta
[2025-07-19T19:57:18.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 122, attempt 0, stage 3.0)
[2025-07-19T19:57:18.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 183 (task 121, attempt 0, stage 3.0)
[2025-07-19T19:57:18.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 183.0 in stage 3.0 (TID 121). 9049 bytes result sent to driver
[2025-07-19T19:57:18.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 128) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 180 (task 118, attempt 0, stage 3.0)
[2025-07-19T19:57:18.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 8.0 in stage 3.0 (TID 128)
[2025-07-19T19:57:18.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 180.0 in stage 3.0 (TID 118). 9057 bytes result sent to driver
[2025-07-19T19:57:18.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 129) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 10.0 in stage 3.0 (TID 129)
[2025-07-19T19:57:18.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 183.0 in stage 3.0 (TID 121) in 97 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T19:57:18.096+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.096+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 180.0 in stage 3.0 (TID 118) in 172 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T19:57:18.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.1.delta.d98311b0-4572-4f87-89b5-eeb229a99c33.TID124.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/192/1.delta
[2025-07-19T19:57:18.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/192] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/192/1.delta
[2025-07-19T19:57:18.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 124, attempt 0, stage 3.0)
[2025-07-19T19:57:18.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 188 (task 122, attempt 0, stage 3.0)
[2025-07-19T19:57:18.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 188.0 in stage 3.0 (TID 122). 9123 bytes result sent to driver
[2025-07-19T19:57:18.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 130) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 13.0 in stage 3.0 (TID 130)
[2025-07-19T19:57:18.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 188.0 in stage 3.0 (TID 122) in 106 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T19:57:18.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/.schema.76f38c48-1fdc-4bda-b717-0d40b61777bd.TID126.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/schema
[2025-07-19T19:57:18.112+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64b49462
[2025-07-19T19:57:18.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.115+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0] for update
[2025-07-19T19:57:18.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f710375
[2025-07-19T19:57:18.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/13] for update
[2025-07-19T19:57:18.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 192 (task 124, attempt 0, stage 3.0)
[2025-07-19T19:57:18.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 192.0 in stage 3.0 (TID 124). 9130 bytes result sent to driver
[2025-07-19T19:57:18.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6085faf4
[2025-07-19T19:57:18.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 131) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/10] for update
[2025-07-19T19:57:18.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 15.0 in stage 3.0 (TID 131)
[2025-07-19T19:57:18.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 192.0 in stage 3.0 (TID 124) in 106 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T19:57:18.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@455f2789
[2025-07-19T19:57:18.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/8] for update
[2025-07-19T19:57:18.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c8d5cf7
[2025-07-19T19:57:18.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/15] for update
[2025-07-19T19:57:18.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.1.delta.8718d8ac-b6b5-4299-9d34-95cd30bbe75d.TID126.tmp
[2025-07-19T19:57:18.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.1.delta.63757a39-3531-46b5-aaee-a9d31058ae55.TID128.tmp
[2025-07-19T19:57:18.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.1.delta.ddc0304a-59f3-46ee-8091-b84896dcd5e5.TID130.tmp
[2025-07-19T19:57:18.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33cff470
[2025-07-19T19:57:18.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/2] for update
[2025-07-19T19:57:18.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.1.delta.56d03515-5fdc-4a42-a931-ac32c77c4e49.TID129.tmp
[2025-07-19T19:57:18.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f60e26b
[2025-07-19T19:57:18.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/195] for update
[2025-07-19T19:57:18.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.1.delta.d2e057a5-1593-4216-8890-777ffec5b7d1.TID131.tmp
[2025-07-19T19:57:18.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@758866c8
[2025-07-19T19:57:18.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/190] for update
[2025-07-19T19:57:18.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.1.delta.63757a39-3531-46b5-aaee-a9d31058ae55.TID128.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/8/1.delta
[2025-07-19T19:57:18.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/8] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/8/1.delta
[2025-07-19T19:57:18.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 128, attempt 0, stage 3.0)
[2025-07-19T19:57:18.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.1.delta.e582dceb-e418-4977-81ba-533f3c8c6d94.TID127.tmp
[2025-07-19T19:57:18.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 8 (task 128, attempt 0, stage 3.0)
[2025-07-19T19:57:18.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 8.0 in stage 3.0 (TID 128). 6243 bytes result sent to driver
[2025-07-19T19:57:18.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 132) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 16.0 in stage 3.0 (TID 132)
[2025-07-19T19:57:18.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 128) in 94 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T19:57:18.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.1.delta.ddc0304a-59f3-46ee-8091-b84896dcd5e5.TID130.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/13/1.delta
[2025-07-19T19:57:18.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/13] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/13/1.delta
[2025-07-19T19:57:18.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 130, attempt 0, stage 3.0)
[2025-07-19T19:57:18.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.1.delta.68cb5843-aef7-45ef-9dcf-6f1bf39737c6.TID125.tmp
[2025-07-19T19:57:18.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 13 (task 130, attempt 0, stage 3.0)
[2025-07-19T19:57:18.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.1.delta.8718d8ac-b6b5-4299-9d34-95cd30bbe75d.TID126.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0/1.delta
[2025-07-19T19:57:18.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.1.delta.77f7a413-e2df-45ee-ba8f-e2de0e1548ed.TID123.tmp
[2025-07-19T19:57:18.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/0/1.delta
[2025-07-19T19:57:18.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 126, attempt 0, stage 3.0)
[2025-07-19T19:57:18.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68b73cf9
[2025-07-19T19:57:18.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 13.0 in stage 3.0 (TID 130). 6243 bytes result sent to driver
[2025-07-19T19:57:18.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.1.delta.56d03515-5fdc-4a42-a931-ac32c77c4e49.TID129.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/10/1.delta
[2025-07-19T19:57:18.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/10] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/10/1.delta
[2025-07-19T19:57:18.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/16] for update
[2025-07-19T19:57:18.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 0 (task 126, attempt 0, stage 3.0)
[2025-07-19T19:57:18.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 129, attempt 0, stage 3.0)
[2025-07-19T19:57:18.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 0.0 in stage 3.0 (TID 126). 6243 bytes result sent to driver
[2025-07-19T19:57:18.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 133) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 130) in 105 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T19:57:18.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 17.0 in stage 3.0 (TID 133)
[2025-07-19T19:57:18.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 10 (task 129, attempt 0, stage 3.0)
[2025-07-19T19:57:18.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 134) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 126) in 174 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T19:57:18.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 18.0 in stage 3.0 (TID 134)
[2025-07-19T19:57:18.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.1.delta.d2e057a5-1593-4216-8890-777ffec5b7d1.TID131.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/15/1.delta
[2025-07-19T19:57:18.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/15] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/15/1.delta
[2025-07-19T19:57:18.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 131, attempt 0, stage 3.0)
[2025-07-19T19:57:18.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 10.0 in stage 3.0 (TID 129). 6243 bytes result sent to driver
[2025-07-19T19:57:18.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 135) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 19.0 in stage 3.0 (TID 135)
[2025-07-19T19:57:18.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:18.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 15 (task 131, attempt 0, stage 3.0)
[2025-07-19T19:57:18.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 129) in 130 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T19:57:18.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44814480
[2025-07-19T19:57:18.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/18] for update
[2025-07-19T19:57:18.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 15.0 in stage 3.0 (TID 131). 6243 bytes result sent to driver
[2025-07-19T19:57:18.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 136) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 27.0 in stage 3.0 (TID 136)
[2025-07-19T19:57:18.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@158de88a
[2025-07-19T19:57:18.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/19] for update
[2025-07-19T19:57:18.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 131) in 101 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T19:57:18.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f620f9f
[2025-07-19T19:57:18.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.1.delta.e582dceb-e418-4977-81ba-533f3c8c6d94.TID127.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/2/1.delta
[2025-07-19T19:57:18.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/2] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/2/1.delta
[2025-07-19T19:57:18.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.1.delta.68cb5843-aef7-45ef-9dcf-6f1bf39737c6.TID125.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/195/1.delta
[2025-07-19T19:57:18.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/195] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/195/1.delta
[2025-07-19T19:57:18.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/17] for update
[2025-07-19T19:57:18.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 125, attempt 0, stage 3.0)
[2025-07-19T19:57:18.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 127, attempt 0, stage 3.0)
[2025-07-19T19:57:18.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.1.delta.af30a140-afdf-4da6-b609-398a47af92d3.TID132.tmp
[2025-07-19T19:57:18.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 2 (task 127, attempt 0, stage 3.0)
[2025-07-19T19:57:18.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.1.delta.b79cdedb-3f6e-4da5-9140-36228b67df48.TID134.tmp
[2025-07-19T19:57:18.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.1.delta.77f7a413-e2df-45ee-ba8f-e2de0e1548ed.TID123.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/190/1.delta
[2025-07-19T19:57:18.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/190] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/190/1.delta
[2025-07-19T19:57:18.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.1.delta.9fa484ce-b312-4ed2-a133-299287e10a65.TID135.tmp
[2025-07-19T19:57:18.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10106be8
[2025-07-19T19:57:18.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 123, attempt 0, stage 3.0)
[2025-07-19T19:57:18.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/27] for update
[2025-07-19T19:57:18.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 2.0 in stage 3.0 (TID 127). 6243 bytes result sent to driver
[2025-07-19T19:57:18.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.1.delta.4f16323b-00ad-41b6-96b6-e3a8353ae4d1.TID133.tmp
[2025-07-19T19:57:18.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 137) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 28.0 in stage 3.0 (TID 137)
[2025-07-19T19:57:18.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 127) in 194 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T19:57:18.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:18.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.1.delta.6baebeca-4d80-42b2-8b70-33a6087c806e.TID136.tmp
[2025-07-19T19:57:18.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 195 (task 125, attempt 0, stage 3.0)
[2025-07-19T19:57:18.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 190 (task 123, attempt 0, stage 3.0)
[2025-07-19T19:57:18.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 195.0 in stage 3.0 (TID 125). 9080 bytes result sent to driver
[2025-07-19T19:57:18.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 190.0 in stage 3.0 (TID 123). 9084 bytes result sent to driver
[2025-07-19T19:57:18.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 138) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 195.0 in stage 3.0 (TID 125) in 238 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T19:57:18.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 31.0 in stage 3.0 (TID 138)
[2025-07-19T19:57:18.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 139) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.1.delta.b79cdedb-3f6e-4da5-9140-36228b67df48.TID134.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/18/1.delta
[2025-07-19T19:57:18.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@142c4dba
[2025-07-19T19:57:18.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.1.delta.9fa484ce-b312-4ed2-a133-299287e10a65.TID135.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/19/1.delta
[2025-07-19T19:57:18.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/19] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/19/1.delta
[2025-07-19T19:57:18.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/28] for update
[2025-07-19T19:57:18.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 190.0 in stage 3.0 (TID 123) in 259 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T19:57:18.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 33.0 in stage 3.0 (TID 139)
[2025-07-19T19:57:18.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/18] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/18/1.delta
[2025-07-19T19:57:18.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 134, attempt 0, stage 3.0)
[2025-07-19T19:57:18.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.1.delta.af30a140-afdf-4da6-b609-398a47af92d3.TID132.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/16/1.delta
[2025-07-19T19:57:18.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/16] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/16/1.delta
[2025-07-19T19:57:18.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 132, attempt 0, stage 3.0)
[2025-07-19T19:57:18.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 135, attempt 0, stage 3.0)
[2025-07-19T19:57:18.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@499a654d
[2025-07-19T19:57:18.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/31] for update
[2025-07-19T19:57:18.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 18 (task 134, attempt 0, stage 3.0)
[2025-07-19T19:57:18.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 19 (task 135, attempt 0, stage 3.0)
[2025-07-19T19:57:18.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 16 (task 132, attempt 0, stage 3.0)
[2025-07-19T19:57:18.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 19.0 in stage 3.0 (TID 135). 6200 bytes result sent to driver
[2025-07-19T19:57:18.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 16.0 in stage 3.0 (TID 132). 6200 bytes result sent to driver
[2025-07-19T19:57:18.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 18.0 in stage 3.0 (TID 134). 6200 bytes result sent to driver
[2025-07-19T19:57:18.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 140) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@336fbc99
[2025-07-19T19:57:18.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 141) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/33] for update
[2025-07-19T19:57:18.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 142) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 36.0 in stage 3.0 (TID 141)
[2025-07-19T19:57:18.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 40.0 in stage 3.0 (TID 142)
[2025-07-19T19:57:18.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 134) in 82 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T19:57:18.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 34.0 in stage 3.0 (TID 140)
[2025-07-19T19:57:18.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 135) in 78 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T19:57:18.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.1.delta.76160554-1ff8-49b0-b111-331c9ff55272.TID137.tmp
[2025-07-19T19:57:18.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.1.delta.4f16323b-00ad-41b6-96b6-e3a8353ae4d1.TID133.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/17/1.delta
[2025-07-19T19:57:18.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/17] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/17/1.delta
[2025-07-19T19:57:18.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 133, attempt 0, stage 3.0)
[2025-07-19T19:57:18.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 132) in 116 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T19:57:18.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.1.delta.db775d1c-3f1a-46b4-a1d8-391132fc804b.TID138.tmp
[2025-07-19T19:57:18.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:18.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 17 (task 133, attempt 0, stage 3.0)
[2025-07-19T19:57:18.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d0b4d51
[2025-07-19T19:57:18.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 17.0 in stage 3.0 (TID 133). 6200 bytes result sent to driver
[2025-07-19T19:57:18.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 143) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.1.delta.d263bf7f-4048-43eb-b41a-d99893aed94a.TID139.tmp
[2025-07-19T19:57:18.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 42.0 in stage 3.0 (TID 143)
[2025-07-19T19:57:18.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/36] for update
[2025-07-19T19:57:18.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 133) in 111 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T19:57:18.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@615e1ca4
[2025-07-19T19:57:18.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/40] for update
[2025-07-19T19:57:18.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.1.delta.5b06877a-acab-4f32-aeed-f98f9e836b57.TID141.tmp
[2025-07-19T19:57:18.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45e6040a
[2025-07-19T19:57:18.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.1.delta.6baebeca-4d80-42b2-8b70-33a6087c806e.TID136.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/27/1.delta
[2025-07-19T19:57:18.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/27] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/27/1.delta
[2025-07-19T19:57:18.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/42] for update
[2025-07-19T19:57:18.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 136, attempt 0, stage 3.0)
[2025-07-19T19:57:18.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 27 (task 136, attempt 0, stage 3.0)
[2025-07-19T19:57:18.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.1.delta.084d367a-96bb-466b-95bb-113e7522156c.TID142.tmp
[2025-07-19T19:57:18.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 27.0 in stage 3.0 (TID 136). 6200 bytes result sent to driver
[2025-07-19T19:57:18.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 136) in 106 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T19:57:18.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 144) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 44.0 in stage 3.0 (TID 144)
[2025-07-19T19:57:18.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.1.delta.76160554-1ff8-49b0-b111-331c9ff55272.TID137.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/28/1.delta
[2025-07-19T19:57:18.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/28] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/28/1.delta
[2025-07-19T19:57:18.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 137, attempt 0, stage 3.0)
[2025-07-19T19:57:18.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.1.delta.2614adbd-97ed-41c2-bd30-6a8487372b6a.TID143.tmp
[2025-07-19T19:57:18.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.1.delta.d263bf7f-4048-43eb-b41a-d99893aed94a.TID139.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/33/1.delta
[2025-07-19T19:57:18.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/33] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/33/1.delta
[2025-07-19T19:57:18.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70020d3
[2025-07-19T19:57:18.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 28 (task 137, attempt 0, stage 3.0)
[2025-07-19T19:57:18.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 28.0 in stage 3.0 (TID 137). 6200 bytes result sent to driver
[2025-07-19T19:57:18.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/34] for update
[2025-07-19T19:57:18.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.1.delta.db775d1c-3f1a-46b4-a1d8-391132fc804b.TID138.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/31/1.delta
[2025-07-19T19:57:18.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/31] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/31/1.delta
[2025-07-19T19:57:18.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 145) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 138, attempt 0, stage 3.0)
[2025-07-19T19:57:18.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 139, attempt 0, stage 3.0)
[2025-07-19T19:57:18.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 137) in 98 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T19:57:18.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 49.0 in stage 3.0 (TID 145)
[2025-07-19T19:57:18.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 31 (task 138, attempt 0, stage 3.0)
[2025-07-19T19:57:18.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 33 (task 139, attempt 0, stage 3.0)
[2025-07-19T19:57:18.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 31.0 in stage 3.0 (TID 138). 6200 bytes result sent to driver
[2025-07-19T19:57:18.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 33.0 in stage 3.0 (TID 139). 6200 bytes result sent to driver
[2025-07-19T19:57:18.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 50.0 in stage 3.0 (TID 146) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 50.0 in stage 3.0 (TID 146)
[2025-07-19T19:57:18.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 54.0 in stage 3.0 (TID 147) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 138) in 86 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T19:57:18.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 54.0 in stage 3.0 (TID 147)
[2025-07-19T19:57:18.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.1.delta.084d367a-96bb-466b-95bb-113e7522156c.TID142.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/40/1.delta
[2025-07-19T19:57:18.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/40] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/40/1.delta
[2025-07-19T19:57:18.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 142, attempt 0, stage 3.0)
[2025-07-19T19:57:18.362+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.1.delta.5b06877a-acab-4f32-aeed-f98f9e836b57.TID141.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/36/1.delta
[2025-07-19T19:57:18.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/36] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/36/1.delta
[2025-07-19T19:57:18.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 141, attempt 0, stage 3.0)
[2025-07-19T19:57:18.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 139) in 86 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T19:57:18.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@321b57fe
[2025-07-19T19:57:18.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T19:57:18.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.1.delta.0b89d3c0-bb36-4c74-a78d-693c377f995f.TID140.tmp
[2025-07-19T19:57:18.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/44] for update
[2025-07-19T19:57:18.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 40 (task 142, attempt 0, stage 3.0)
[2025-07-19T19:57:18.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 36 (task 141, attempt 0, stage 3.0)
[2025-07-19T19:57:18.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 40.0 in stage 3.0 (TID 142). 6200 bytes result sent to driver
[2025-07-19T19:57:18.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 55.0 in stage 3.0 (TID 148) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 55.0 in stage 3.0 (TID 148)
[2025-07-19T19:57:18.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 142) in 76 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T19:57:18.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 36.0 in stage 3.0 (TID 141). 6200 bytes result sent to driver
[2025-07-19T19:57:18.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 61.0 in stage 3.0 (TID 149) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74c6703a
[2025-07-19T19:57:18.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 61.0 in stage 3.0 (TID 149)
[2025-07-19T19:57:18.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 141) in 78 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T19:57:18.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/49] for update
[2025-07-19T19:57:18.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.1.delta.abee3ba0-8570-43e5-9865-fec06ee40a81.TID144.tmp
[2025-07-19T19:57:18.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23f7934a
[2025-07-19T19:57:18.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.1.delta.2614adbd-97ed-41c2-bd30-6a8487372b6a.TID143.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/42/1.delta
[2025-07-19T19:57:18.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/42] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/42/1.delta
[2025-07-19T19:57:18.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/54] for update
[2025-07-19T19:57:18.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 143, attempt 0, stage 3.0)
[2025-07-19T19:57:18.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 42 (task 143, attempt 0, stage 3.0)
[2025-07-19T19:57:18.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 42.0 in stage 3.0 (TID 143). 6200 bytes result sent to driver
[2025-07-19T19:57:18.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 62.0 in stage 3.0 (TID 150) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 143) in 82 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T19:57:18.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38093d1b
[2025-07-19T19:57:18.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/50] for update
[2025-07-19T19:57:18.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 62.0 in stage 3.0 (TID 150)
[2025-07-19T19:57:18.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.1.delta.8796c0ee-4be7-411a-b943-79f91742f54d.TID145.tmp
[2025-07-19T19:57:18.391+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.1.delta.3d004e75-c730-4813-b466-d1d9520d1e8d.TID147.tmp
[2025-07-19T19:57:18.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@787dda7a
[2025-07-19T19:57:18.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.1.delta.0b89d3c0-bb36-4c74-a78d-693c377f995f.TID140.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/34/1.delta
[2025-07-19T19:57:18.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/34] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/34/1.delta
[2025-07-19T19:57:18.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.1.delta.429ff3ef-2ffc-40d0-8608-561b0ba60ccc.TID146.tmp
[2025-07-19T19:57:18.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 140, attempt 0, stage 3.0)
[2025-07-19T19:57:18.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/61] for update
[2025-07-19T19:57:18.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 34 (task 140, attempt 0, stage 3.0)
[2025-07-19T19:57:18.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@531ff47
[2025-07-19T19:57:18.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/55] for update
[2025-07-19T19:57:18.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 34.0 in stage 3.0 (TID 140). 6200 bytes result sent to driver
[2025-07-19T19:57:18.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 67.0 in stage 3.0 (TID 151) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 140) in 124 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T19:57:18.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 67.0 in stage 3.0 (TID 151)
[2025-07-19T19:57:18.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7156e8e5
[2025-07-19T19:57:18.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/62] for update
[2025-07-19T19:57:18.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.1.delta.abee3ba0-8570-43e5-9865-fec06ee40a81.TID144.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/44/1.delta
[2025-07-19T19:57:18.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/44] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/44/1.delta
[2025-07-19T19:57:18.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.1.delta.80099a17-0ea2-4f3a-89df-7b3d45249ad8.TID149.tmp
[2025-07-19T19:57:18.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 144, attempt 0, stage 3.0)
[2025-07-19T19:57:18.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1be27b08
[2025-07-19T19:57:18.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/67] for update
[2025-07-19T19:57:18.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.1.delta.3d004e75-c730-4813-b466-d1d9520d1e8d.TID147.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/54/1.delta
[2025-07-19T19:57:18.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/54] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/54/1.delta
[2025-07-19T19:57:18.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.1.delta.200afad0-ccf6-478b-b1ad-b8c32ee60fbe.TID148.tmp
[2025-07-19T19:57:18.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.1.delta.8796c0ee-4be7-411a-b943-79f91742f54d.TID145.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/49/1.delta
[2025-07-19T19:57:18.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 147, attempt 0, stage 3.0)
[2025-07-19T19:57:18.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.1.delta.a7207e9a-154c-4b87-8fa0-cce5bb22d3c4.TID150.tmp
[2025-07-19T19:57:18.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 44 (task 144, attempt 0, stage 3.0)
[2025-07-19T19:57:18.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 44.0 in stage 3.0 (TID 144). 6200 bytes result sent to driver
[2025-07-19T19:57:18.448+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/49] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/49/1.delta
[2025-07-19T19:57:18.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 145, attempt 0, stage 3.0)
[2025-07-19T19:57:18.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 70.0 in stage 3.0 (TID 152) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 144) in 111 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T19:57:18.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 54 (task 147, attempt 0, stage 3.0)
[2025-07-19T19:57:18.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 54.0 in stage 3.0 (TID 147). 6157 bytes result sent to driver
[2025-07-19T19:57:18.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.1.delta.429ff3ef-2ffc-40d0-8608-561b0ba60ccc.TID146.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/50/1.delta
[2025-07-19T19:57:18.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/50] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/50/1.delta
[2025-07-19T19:57:18.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 146, attempt 0, stage 3.0)
[2025-07-19T19:57:18.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 74.0 in stage 3.0 (TID 153) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 54.0 in stage 3.0 (TID 147) in 92 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T19:57:18.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 49 (task 145, attempt 0, stage 3.0)
[2025-07-19T19:57:18.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 74.0 in stage 3.0 (TID 153)
[2025-07-19T19:57:18.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 70.0 in stage 3.0 (TID 152)
[2025-07-19T19:57:18.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 49.0 in stage 3.0 (TID 145). 6200 bytes result sent to driver
[2025-07-19T19:57:18.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 76.0 in stage 3.0 (TID 154) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 76.0 in stage 3.0 (TID 154)
[2025-07-19T19:57:18.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 50 (task 146, attempt 0, stage 3.0)
[2025-07-19T19:57:18.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 50.0 in stage 3.0 (TID 146). 6200 bytes result sent to driver
[2025-07-19T19:57:18.464+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 145) in 105 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T19:57:18.465+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 50.0 in stage 3.0 (TID 146) in 97 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T19:57:18.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.1.delta.80099a17-0ea2-4f3a-89df-7b3d45249ad8.TID149.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/61/1.delta
[2025-07-19T19:57:18.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 80.0 in stage 3.0 (TID 155) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/61] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/61/1.delta
[2025-07-19T19:57:18.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 80.0 in stage 3.0 (TID 155)
[2025-07-19T19:57:18.471+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.476+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 149, attempt 0, stage 3.0)
[2025-07-19T19:57:18.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.1.delta.ce202525-267e-4d3d-979e-5621ea8ecd0a.TID151.tmp
[2025-07-19T19:57:18.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:18.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c825a3f
[2025-07-19T19:57:18.478+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.478+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/74] for update
[2025-07-19T19:57:18.478+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 61 (task 149, attempt 0, stage 3.0)
[2025-07-19T19:57:18.479+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 61.0 in stage 3.0 (TID 149). 6200 bytes result sent to driver
[2025-07-19T19:57:18.479+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 81.0 in stage 3.0 (TID 156) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.480+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 81.0 in stage 3.0 (TID 156)
[2025-07-19T19:57:18.480+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.481+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63bd0b80
[2025-07-19T19:57:18.481+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/80] for update
[2025-07-19T19:57:18.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 61.0 in stage 3.0 (TID 149) in 96 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T19:57:18.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52515881
[2025-07-19T19:57:18.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/76] for update
[2025-07-19T19:57:18.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.488+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cccab65
[2025-07-19T19:57:18.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/70] for update
[2025-07-19T19:57:18.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.1.delta.bcde6e70-ae11-49c4-b48e-bba17e8db59e.TID153.tmp
[2025-07-19T19:57:18.490+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.490+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.1.delta.200afad0-ccf6-478b-b1ad-b8c32ee60fbe.TID148.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/55/1.delta
[2025-07-19T19:57:18.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/55] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/55/1.delta
[2025-07-19T19:57:18.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.1.delta.a7207e9a-154c-4b87-8fa0-cce5bb22d3c4.TID150.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/62/1.delta
[2025-07-19T19:57:18.492+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/62] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/62/1.delta
[2025-07-19T19:57:18.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23e2eabc
[2025-07-19T19:57:18.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 150, attempt 0, stage 3.0)
[2025-07-19T19:57:18.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 148, attempt 0, stage 3.0)
[2025-07-19T19:57:18.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/81] for update
[2025-07-19T19:57:18.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.1.delta.d7176512-83e1-424d-a66b-9a03ab26c5af.TID155.tmp
[2025-07-19T19:57:18.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.1.delta.ce202525-267e-4d3d-979e-5621ea8ecd0a.TID151.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/67/1.delta
[2025-07-19T19:57:18.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/67] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/67/1.delta
[2025-07-19T19:57:18.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 151, attempt 0, stage 3.0)
[2025-07-19T19:57:18.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.1.delta.78c7de8f-0dad-4338-aae6-1a65274ad54d.TID154.tmp
[2025-07-19T19:57:18.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 62 (task 150, attempt 0, stage 3.0)
[2025-07-19T19:57:18.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 67 (task 151, attempt 0, stage 3.0)
[2025-07-19T19:57:18.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 55 (task 148, attempt 0, stage 3.0)
[2025-07-19T19:57:18.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 55.0 in stage 3.0 (TID 148). 6200 bytes result sent to driver
[2025-07-19T19:57:18.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 67.0 in stage 3.0 (TID 151). 6200 bytes result sent to driver
[2025-07-19T19:57:18.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 84.0 in stage 3.0 (TID 157) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 88.0 in stage 3.0 (TID 158) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 67.0 in stage 3.0 (TID 151) in 81 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T19:57:18.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 55.0 in stage 3.0 (TID 148) in 131 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T19:57:18.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 62.0 in stage 3.0 (TID 150). 6200 bytes result sent to driver
[2025-07-19T19:57:18.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 88.0 in stage 3.0 (TID 158)
[2025-07-19T19:57:18.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 90.0 in stage 3.0 (TID 159) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 90.0 in stage 3.0 (TID 159)
[2025-07-19T19:57:18.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 84.0 in stage 3.0 (TID 157)
[2025-07-19T19:57:18.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.1.delta.e5c1b2fc-ea46-47e0-a303-f441e0a6d84a.TID152.tmp
[2025-07-19T19:57:18.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 62.0 in stage 3.0 (TID 150) in 114 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T19:57:18.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.1.delta.2924efbb-d435-4c92-bbb9-770e17f54774.TID156.tmp
[2025-07-19T19:57:18.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a5097c1
[2025-07-19T19:57:18.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/90] for update
[2025-07-19T19:57:18.514+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.516+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c829827
[2025-07-19T19:57:18.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/88] for update
[2025-07-19T19:57:18.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.1.delta.bcde6e70-ae11-49c4-b48e-bba17e8db59e.TID153.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/74/1.delta
[2025-07-19T19:57:18.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/74] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/74/1.delta
[2025-07-19T19:57:18.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 153, attempt 0, stage 3.0)
[2025-07-19T19:57:18.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.1.delta.d7176512-83e1-424d-a66b-9a03ab26c5af.TID155.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/80/1.delta
[2025-07-19T19:57:18.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/80] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/80/1.delta
[2025-07-19T19:57:18.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 155, attempt 0, stage 3.0)
[2025-07-19T19:57:18.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72e244d5
[2025-07-19T19:57:18.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/84] for update
[2025-07-19T19:57:18.526+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.1.delta.1ec9accd-c40e-4de7-ab7c-c960326ad51b.TID159.tmp
[2025-07-19T19:57:18.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 80 (task 155, attempt 0, stage 3.0)
[2025-07-19T19:57:18.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.1.delta.59d02f5c-13bd-489f-86da-74698a7a5a01.TID158.tmp
[2025-07-19T19:57:18.532+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 74 (task 153, attempt 0, stage 3.0)
[2025-07-19T19:57:18.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 74.0 in stage 3.0 (TID 153). 6200 bytes result sent to driver
[2025-07-19T19:57:18.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 91.0 in stage 3.0 (TID 160) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 80.0 in stage 3.0 (TID 155). 6200 bytes result sent to driver
[2025-07-19T19:57:18.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 93.0 in stage 3.0 (TID 161) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 91.0 in stage 3.0 (TID 160)
[2025-07-19T19:57:18.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 74.0 in stage 3.0 (TID 153) in 91 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T19:57:18.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 80.0 in stage 3.0 (TID 155) in 84 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T19:57:18.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 93.0 in stage 3.0 (TID 161)
[2025-07-19T19:57:18.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.1.delta.7c84bac5-9f2d-45a4-a9d8-e478f6c07f7d.TID157.tmp
[2025-07-19T19:57:18.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.547+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.548+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.1.delta.2924efbb-d435-4c92-bbb9-770e17f54774.TID156.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/81/1.delta
[2025-07-19T19:57:18.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/81] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/81/1.delta
[2025-07-19T19:57:18.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 156, attempt 0, stage 3.0)
[2025-07-19T19:57:18.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.1.delta.78c7de8f-0dad-4338-aae6-1a65274ad54d.TID154.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/76/1.delta
[2025-07-19T19:57:18.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/76] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/76/1.delta
[2025-07-19T19:57:18.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 154, attempt 0, stage 3.0)
[2025-07-19T19:57:18.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42595fee
[2025-07-19T19:57:18.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/91] for update
[2025-07-19T19:57:18.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 76 (task 154, attempt 0, stage 3.0)
[2025-07-19T19:57:18.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 76.0 in stage 3.0 (TID 154). 6200 bytes result sent to driver
[2025-07-19T19:57:18.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.1.delta.e5c1b2fc-ea46-47e0-a303-f441e0a6d84a.TID152.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/70/1.delta
[2025-07-19T19:57:18.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 81 (task 156, attempt 0, stage 3.0)
[2025-07-19T19:57:18.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/70] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/70/1.delta
[2025-07-19T19:57:18.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 152, attempt 0, stage 3.0)
[2025-07-19T19:57:18.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f6461ef
[2025-07-19T19:57:18.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 98.0 in stage 3.0 (TID 162) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/93] for update
[2025-07-19T19:57:18.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 76.0 in stage 3.0 (TID 154) in 113 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T19:57:18.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 98.0 in stage 3.0 (TID 162)
[2025-07-19T19:57:18.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.1.delta.00f54d24-38d2-4c99-9f1b-6ac6177d8683.TID160.tmp
[2025-07-19T19:57:18.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 70 (task 152, attempt 0, stage 3.0)
[2025-07-19T19:57:18.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.1.delta.59d02f5c-13bd-489f-86da-74698a7a5a01.TID158.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/88/1.delta
[2025-07-19T19:57:18.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/88] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/88/1.delta
[2025-07-19T19:57:18.585+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 81.0 in stage 3.0 (TID 156). 6286 bytes result sent to driver
[2025-07-19T19:57:18.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 158, attempt 0, stage 3.0)
[2025-07-19T19:57:18.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 81.0 in stage 3.0 (TID 156) in 123 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T19:57:18.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11382072
[2025-07-19T19:57:18.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 101.0 in stage 3.0 (TID 163) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/98] for update
[2025-07-19T19:57:18.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 101.0 in stage 3.0 (TID 163)
[2025-07-19T19:57:18.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.1.delta.1ec9accd-c40e-4de7-ab7c-c960326ad51b.TID159.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/90/1.delta
[2025-07-19T19:57:18.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/90] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/90/1.delta
[2025-07-19T19:57:18.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 70.0 in stage 3.0 (TID 152). 6286 bytes result sent to driver
[2025-07-19T19:57:18.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.601+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@122822fb
[2025-07-19T19:57:18.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 159, attempt 0, stage 3.0)
[2025-07-19T19:57:18.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.1.delta.459d7b9f-d2c8-41ce-a58b-dd296573d2a0.TID162.tmp
[2025-07-19T19:57:18.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/101] for update
[2025-07-19T19:57:18.606+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 103.0 in stage 3.0 (TID 164) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 70.0 in stage 3.0 (TID 152) in 161 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T19:57:18.608+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 103.0 in stage 3.0 (TID 164)
[2025-07-19T19:57:18.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 88 (task 158, attempt 0, stage 3.0)
[2025-07-19T19:57:18.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.1.delta.7c84bac5-9f2d-45a4-a9d8-e478f6c07f7d.TID157.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/84/1.delta
[2025-07-19T19:57:18.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/84] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/84/1.delta
[2025-07-19T19:57:18.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 157, attempt 0, stage 3.0)
[2025-07-19T19:57:18.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 90 (task 159, attempt 0, stage 3.0)
[2025-07-19T19:57:18.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 90.0 in stage 3.0 (TID 159). 6243 bytes result sent to driver
[2025-07-19T19:57:18.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 108.0 in stage 3.0 (TID 165) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 90.0 in stage 3.0 (TID 159) in 115 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T19:57:18.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 88.0 in stage 3.0 (TID 158). 6243 bytes result sent to driver
[2025-07-19T19:57:18.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 108.0 in stage 3.0 (TID 165)
[2025-07-19T19:57:18.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@356d9cce
[2025-07-19T19:57:18.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/103] for update
[2025-07-19T19:57:18.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.1.delta.eac2ffe0-fc8e-4002-81ad-b393b64bbdf6.TID161.tmp
[2025-07-19T19:57:18.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 109.0 in stage 3.0 (TID 166) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 109.0 in stage 3.0 (TID 166)
[2025-07-19T19:57:18.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 88.0 in stage 3.0 (TID 158) in 121 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T19:57:18.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 84 (task 157, attempt 0, stage 3.0)
[2025-07-19T19:57:18.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 84.0 in stage 3.0 (TID 157). 6243 bytes result sent to driver
[2025-07-19T19:57:18.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.1.delta.00f54d24-38d2-4c99-9f1b-6ac6177d8683.TID160.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/91/1.delta
[2025-07-19T19:57:18.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/91] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/91/1.delta
[2025-07-19T19:57:18.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 160, attempt 0, stage 3.0)
[2025-07-19T19:57:18.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.1.delta.d27fbdfc-5f3f-497e-9f24-631afd361c1e.TID163.tmp
[2025-07-19T19:57:18.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.1.delta.7d12b338-e497-4df2-84a8-44fed8027ec6.TID164.tmp
[2025-07-19T19:57:18.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55a80935
[2025-07-19T19:57:18.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/109] for update
[2025-07-19T19:57:18.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 91 (task 160, attempt 0, stage 3.0)
[2025-07-19T19:57:18.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 91.0 in stage 3.0 (TID 160). 6243 bytes result sent to driver
[2025-07-19T19:57:18.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 112.0 in stage 3.0 (TID 167) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 114.0 in stage 3.0 (TID 168) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 84.0 in stage 3.0 (TID 157) in 137 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T19:57:18.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 112.0 in stage 3.0 (TID 167)
[2025-07-19T19:57:18.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 91.0 in stage 3.0 (TID 160) in 102 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T19:57:18.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 114.0 in stage 3.0 (TID 168)
[2025-07-19T19:57:18.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31035a35
[2025-07-19T19:57:18.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/108] for update
[2025-07-19T19:57:18.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.1.delta.459d7b9f-d2c8-41ce-a58b-dd296573d2a0.TID162.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/98/1.delta
[2025-07-19T19:57:18.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/98] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/98/1.delta
[2025-07-19T19:57:18.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.1.delta.2acc23e7-db81-4313-a3fd-0bbed647bf26.TID166.tmp
[2025-07-19T19:57:18.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 162, attempt 0, stage 3.0)
[2025-07-19T19:57:18.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24df37c9
[2025-07-19T19:57:18.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 98 (task 162, attempt 0, stage 3.0)
[2025-07-19T19:57:18.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 98.0 in stage 3.0 (TID 162). 6243 bytes result sent to driver
[2025-07-19T19:57:18.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/112] for update
[2025-07-19T19:57:18.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 115.0 in stage 3.0 (TID 169) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 98.0 in stage 3.0 (TID 162) in 98 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T19:57:18.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 115.0 in stage 3.0 (TID 169)
[2025-07-19T19:57:18.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.661+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.1.delta.750cad68-6dc0-43f9-b6cd-3df1a7ff976f.TID165.tmp
[2025-07-19T19:57:18.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.1.delta.eac2ffe0-fc8e-4002-81ad-b393b64bbdf6.TID161.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/93/1.delta
[2025-07-19T19:57:18.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/93] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/93/1.delta
[2025-07-19T19:57:18.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 161, attempt 0, stage 3.0)
[2025-07-19T19:57:18.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33836489
[2025-07-19T19:57:18.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/114] for update
[2025-07-19T19:57:18.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.1.delta.d27fbdfc-5f3f-497e-9f24-631afd361c1e.TID163.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/101/1.delta
[2025-07-19T19:57:18.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/101] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/101/1.delta
[2025-07-19T19:57:18.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 163, attempt 0, stage 3.0)
[2025-07-19T19:57:18.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 93 (task 161, attempt 0, stage 3.0)
[2025-07-19T19:57:18.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 93.0 in stage 3.0 (TID 161). 6243 bytes result sent to driver
[2025-07-19T19:57:18.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 116.0 in stage 3.0 (TID 170) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 93.0 in stage 3.0 (TID 161) in 140 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T19:57:18.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 116.0 in stage 3.0 (TID 170)
[2025-07-19T19:57:18.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.1.delta.96bd94c6-03d2-47ac-b109-0d647502a6c0.TID167.tmp
[2025-07-19T19:57:18.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6295ef0d
[2025-07-19T19:57:18.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/115] for update
[2025-07-19T19:57:18.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.1.delta.7d12b338-e497-4df2-84a8-44fed8027ec6.TID164.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/103/1.delta
[2025-07-19T19:57:18.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/103] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/103/1.delta
[2025-07-19T19:57:18.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 164, attempt 0, stage 3.0)
[2025-07-19T19:57:18.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 101 (task 163, attempt 0, stage 3.0)
[2025-07-19T19:57:18.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 101.0 in stage 3.0 (TID 163). 6243 bytes result sent to driver
[2025-07-19T19:57:18.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 124.0 in stage 3.0 (TID 171) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 124.0 in stage 3.0 (TID 171)
[2025-07-19T19:57:18.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.1.delta.60232331-ebe1-494d-8328-d17972a2b0ce.TID168.tmp
[2025-07-19T19:57:18.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 101.0 in stage 3.0 (TID 163) in 99 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T19:57:18.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 103 (task 164, attempt 0, stage 3.0)
[2025-07-19T19:57:18.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25e1f72f
[2025-07-19T19:57:18.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/116] for update
[2025-07-19T19:57:18.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 103.0 in stage 3.0 (TID 164). 6243 bytes result sent to driver
[2025-07-19T19:57:18.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:18.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.1.delta.d8fbfcf6-f541-48d4-90d4-551734bffa7e.TID169.tmp
[2025-07-19T19:57:18.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 125.0 in stage 3.0 (TID 172) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 103.0 in stage 3.0 (TID 164) in 95 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T19:57:18.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 125.0 in stage 3.0 (TID 172)
[2025-07-19T19:57:18.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7490e9ae
[2025-07-19T19:57:18.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.704+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/124] for update
[2025-07-19T19:57:18.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.1.delta.2acc23e7-db81-4313-a3fd-0bbed647bf26.TID166.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/109/1.delta
[2025-07-19T19:57:18.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/109] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/109/1.delta
[2025-07-19T19:57:18.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.1.delta.750cad68-6dc0-43f9-b6cd-3df1a7ff976f.TID165.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/108/1.delta
[2025-07-19T19:57:18.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/108] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/108/1.delta
[2025-07-19T19:57:18.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 165, attempt 0, stage 3.0)
[2025-07-19T19:57:18.710+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 166, attempt 0, stage 3.0)
[2025-07-19T19:57:18.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@472cc95b
[2025-07-19T19:57:18.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/125] for update
[2025-07-19T19:57:18.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 109 (task 166, attempt 0, stage 3.0)
[2025-07-19T19:57:18.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 109.0 in stage 3.0 (TID 166). 6243 bytes result sent to driver
[2025-07-19T19:57:18.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 126.0 in stage 3.0 (TID 173) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 109.0 in stage 3.0 (TID 166) in 96 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T19:57:18.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 126.0 in stage 3.0 (TID 173)
[2025-07-19T19:57:18.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.1.delta.80d074b9-adee-497b-bd81-9fb4e2af697e.TID170.tmp
[2025-07-19T19:57:18.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.1.delta.96bd94c6-03d2-47ac-b109-0d647502a6c0.TID167.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/112/1.delta
[2025-07-19T19:57:18.722+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/112] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/112/1.delta
[2025-07-19T19:57:18.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 167, attempt 0, stage 3.0)
[2025-07-19T19:57:18.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 108 (task 165, attempt 0, stage 3.0)
[2025-07-19T19:57:18.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 108.0 in stage 3.0 (TID 165). 6243 bytes result sent to driver
[2025-07-19T19:57:18.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.1.delta.0b34586e-746f-4b81-97ff-7051e4b2f326.TID171.tmp
[2025-07-19T19:57:18.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.1.delta.60232331-ebe1-494d-8328-d17972a2b0ce.TID168.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/114/1.delta
[2025-07-19T19:57:18.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/114] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/114/1.delta
[2025-07-19T19:57:18.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 168, attempt 0, stage 3.0)
[2025-07-19T19:57:18.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 127.0 in stage 3.0 (TID 174) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.729+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.1.delta.d6789418-cb76-47f7-80af-63dc19ef4902.TID172.tmp
[2025-07-19T19:57:18.729+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 114 (task 168, attempt 0, stage 3.0)
[2025-07-19T19:57:18.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 127.0 in stage 3.0 (TID 174)
[2025-07-19T19:57:18.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 114.0 in stage 3.0 (TID 168). 6243 bytes result sent to driver
[2025-07-19T19:57:18.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 108.0 in stage 3.0 (TID 165) in 116 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T19:57:18.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 132.0 in stage 3.0 (TID 175) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 114.0 in stage 3.0 (TID 168) in 99 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T19:57:18.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51b4f221
[2025-07-19T19:57:18.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 132.0 in stage 3.0 (TID 175)
[2025-07-19T19:57:18.737+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/126] for update
[2025-07-19T19:57:18.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 112 (task 167, attempt 0, stage 3.0)
[2025-07-19T19:57:18.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 112.0 in stage 3.0 (TID 167). 6243 bytes result sent to driver
[2025-07-19T19:57:18.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 133.0 in stage 3.0 (TID 176) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.1.delta.d8fbfcf6-f541-48d4-90d4-551734bffa7e.TID169.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/115/1.delta
[2025-07-19T19:57:18.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 112.0 in stage 3.0 (TID 167) in 108 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T19:57:18.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/115] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/115/1.delta
[2025-07-19T19:57:18.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 133.0 in stage 3.0 (TID 176)
[2025-07-19T19:57:18.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d491d12
[2025-07-19T19:57:18.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/132] for update
[2025-07-19T19:57:18.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 169, attempt 0, stage 3.0)
[2025-07-19T19:57:18.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64a383c
[2025-07-19T19:57:18.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/127] for update
[2025-07-19T19:57:18.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.1.delta.0b34586e-746f-4b81-97ff-7051e4b2f326.TID171.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/124/1.delta
[2025-07-19T19:57:18.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/124] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/124/1.delta
[2025-07-19T19:57:18.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.1.delta.80d074b9-adee-497b-bd81-9fb4e2af697e.TID170.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/116/1.delta
[2025-07-19T19:57:18.754+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/116] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/116/1.delta
[2025-07-19T19:57:18.754+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 171, attempt 0, stage 3.0)
[2025-07-19T19:57:18.754+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 170, attempt 0, stage 3.0)
[2025-07-19T19:57:18.754+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 115 (task 169, attempt 0, stage 3.0)
[2025-07-19T19:57:18.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 115.0 in stage 3.0 (TID 169). 6200 bytes result sent to driver
[2025-07-19T19:57:18.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.1.delta.254aead5-86c8-4d3c-97c1-f17a2fdc65a5.TID173.tmp
[2025-07-19T19:57:18.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.758+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 134.0 in stage 3.0 (TID 177) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.758+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 116 (task 170, attempt 0, stage 3.0)
[2025-07-19T19:57:18.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c566e21
[2025-07-19T19:57:18.761+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.762+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 116.0 in stage 3.0 (TID 170). 6200 bytes result sent to driver
[2025-07-19T19:57:18.763+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 124 (task 171, attempt 0, stage 3.0)
[2025-07-19T19:57:18.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/133] for update
[2025-07-19T19:57:18.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 124.0 in stage 3.0 (TID 171). 6200 bytes result sent to driver
[2025-07-19T19:57:18.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 134.0 in stage 3.0 (TID 177)
[2025-07-19T19:57:18.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 135.0 in stage 3.0 (TID 178) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 139.0 in stage 3.0 (TID 179) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 115.0 in stage 3.0 (TID 169) in 106 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T19:57:18.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 116.0 in stage 3.0 (TID 170) in 89 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T19:57:18.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 124.0 in stage 3.0 (TID 171) in 76 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T19:57:18.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 135.0 in stage 3.0 (TID 178)
[2025-07-19T19:57:18.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 139.0 in stage 3.0 (TID 179)
[2025-07-19T19:57:18.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3174837c
[2025-07-19T19:57:18.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.1.delta.19d20782-ba14-4e0c-9489-1605e8f28590.TID174.tmp
[2025-07-19T19:57:18.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.1.delta.79381fbc-27f1-4175-abde-b07711e1d368.TID175.tmp
[2025-07-19T19:57:18.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/134] for update
[2025-07-19T19:57:18.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.778+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.1.delta.5d6e54c7-d38e-443e-835e-eeef9c0e9919.TID176.tmp
[2025-07-19T19:57:18.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.1.delta.d6789418-cb76-47f7-80af-63dc19ef4902.TID172.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/125/1.delta
[2025-07-19T19:57:18.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2477739e
[2025-07-19T19:57:18.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/125] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/125/1.delta
[2025-07-19T19:57:18.782+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 172, attempt 0, stage 3.0)
[2025-07-19T19:57:18.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/139] for update
[2025-07-19T19:57:18.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 125 (task 172, attempt 0, stage 3.0)
[2025-07-19T19:57:18.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.1.delta.e17e27f3-697f-4dc9-b6ce-4d005df8a61c.TID177.tmp
[2025-07-19T19:57:18.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2982d52
[2025-07-19T19:57:18.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/135] for update
[2025-07-19T19:57:18.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 125.0 in stage 3.0 (TID 172). 6200 bytes result sent to driver
[2025-07-19T19:57:18.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 141.0 in stage 3.0 (TID 180) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 125.0 in stage 3.0 (TID 172) in 95 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T19:57:18.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 141.0 in stage 3.0 (TID 180)
[2025-07-19T19:57:18.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.1.delta.abd3de24-bc1f-4353-aac8-a1f185312988.TID179.tmp
[2025-07-19T19:57:18.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:18.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@106beeab
[2025-07-19T19:57:18.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.798+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/141] for update
[2025-07-19T19:57:18.799+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.1.delta.dc3d633f-c745-4618-9186-bb84da63d001.TID178.tmp
[2025-07-19T19:57:18.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.1.delta.254aead5-86c8-4d3c-97c1-f17a2fdc65a5.TID173.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/126/1.delta
[2025-07-19T19:57:18.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/126] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/126/1.delta
[2025-07-19T19:57:18.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 173, attempt 0, stage 3.0)
[2025-07-19T19:57:18.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 126 (task 173, attempt 0, stage 3.0)
[2025-07-19T19:57:18.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 126.0 in stage 3.0 (TID 173). 6200 bytes result sent to driver
[2025-07-19T19:57:18.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.1.delta.19d20782-ba14-4e0c-9489-1605e8f28590.TID174.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/127/1.delta
[2025-07-19T19:57:18.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/127] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/127/1.delta
[2025-07-19T19:57:18.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 142.0 in stage 3.0 (TID 181) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 174, attempt 0, stage 3.0)
[2025-07-19T19:57:18.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 126.0 in stage 3.0 (TID 173) in 100 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T19:57:18.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.1.delta.5d6e54c7-d38e-443e-835e-eeef9c0e9919.TID176.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/133/1.delta
[2025-07-19T19:57:18.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 142.0 in stage 3.0 (TID 181)
[2025-07-19T19:57:18.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/133] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/133/1.delta
[2025-07-19T19:57:18.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 176, attempt 0, stage 3.0)
[2025-07-19T19:57:18.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.1.delta.79381fbc-27f1-4175-abde-b07711e1d368.TID175.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/132/1.delta
[2025-07-19T19:57:18.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/132] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/132/1.delta
[2025-07-19T19:57:18.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 175, attempt 0, stage 3.0)
[2025-07-19T19:57:18.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:18.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 127 (task 174, attempt 0, stage 3.0)
[2025-07-19T19:57:18.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.1.delta.c49dc7ab-2876-496a-9fdb-83c612423e27.TID180.tmp
[2025-07-19T19:57:18.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 133 (task 176, attempt 0, stage 3.0)
[2025-07-19T19:57:18.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 127.0 in stage 3.0 (TID 174). 6200 bytes result sent to driver
[2025-07-19T19:57:18.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 133.0 in stage 3.0 (TID 176). 6200 bytes result sent to driver
[2025-07-19T19:57:18.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.1.delta.abd3de24-bc1f-4353-aac8-a1f185312988.TID179.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/139/1.delta
[2025-07-19T19:57:18.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/139] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/139/1.delta
[2025-07-19T19:57:18.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 132 (task 175, attempt 0, stage 3.0)
[2025-07-19T19:57:18.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 127.0 in stage 3.0 (TID 174) in 98 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T19:57:18.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 143.0 in stage 3.0 (TID 182) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 146.0 in stage 3.0 (TID 183) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 133.0 in stage 3.0 (TID 176) in 88 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T19:57:18.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 143.0 in stage 3.0 (TID 182)
[2025-07-19T19:57:18.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 146.0 in stage 3.0 (TID 183)
[2025-07-19T19:57:18.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71b32435
[2025-07-19T19:57:18.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 179, attempt 0, stage 3.0)
[2025-07-19T19:57:18.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 132.0 in stage 3.0 (TID 175). 6200 bytes result sent to driver
[2025-07-19T19:57:18.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 139 (task 179, attempt 0, stage 3.0)
[2025-07-19T19:57:18.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/142] for update
[2025-07-19T19:57:18.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 139.0 in stage 3.0 (TID 179). 6200 bytes result sent to driver
[2025-07-19T19:57:18.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 147.0 in stage 3.0 (TID 184) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 132.0 in stage 3.0 (TID 175) in 101 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T19:57:18.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 139.0 in stage 3.0 (TID 179) in 74 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T19:57:18.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 148.0 in stage 3.0 (TID 185) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.843+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 147.0 in stage 3.0 (TID 184)
[2025-07-19T19:57:18.843+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 148.0 in stage 3.0 (TID 185)
[2025-07-19T19:57:18.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.1.delta.e17e27f3-697f-4dc9-b6ce-4d005df8a61c.TID177.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/134/1.delta
[2025-07-19T19:57:18.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/134] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/134/1.delta
[2025-07-19T19:57:18.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f64d05a
[2025-07-19T19:57:18.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.1.delta.dc3d633f-c745-4618-9186-bb84da63d001.TID178.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/135/1.delta
[2025-07-19T19:57:18.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/135] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/135/1.delta
[2025-07-19T19:57:18.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 177, attempt 0, stage 3.0)
[2025-07-19T19:57:18.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:18.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 178, attempt 0, stage 3.0)
[2025-07-19T19:57:18.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/143] for update
[2025-07-19T19:57:18.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.1.delta.e05abe55-b4f0-4766-9a64-61fd8ac14004.TID181.tmp
[2025-07-19T19:57:18.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 134 (task 177, attempt 0, stage 3.0)
[2025-07-19T19:57:18.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 134.0 in stage 3.0 (TID 177). 6200 bytes result sent to driver
[2025-07-19T19:57:18.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 151.0 in stage 3.0 (TID 186) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 134.0 in stage 3.0 (TID 177) in 96 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T19:57:18.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 135 (task 178, attempt 0, stage 3.0)
[2025-07-19T19:57:18.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 151.0 in stage 3.0 (TID 186)
[2025-07-19T19:57:18.858+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 135.0 in stage 3.0 (TID 178). 6200 bytes result sent to driver
[2025-07-19T19:57:18.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 152.0 in stage 3.0 (TID 187) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 135.0 in stage 3.0 (TID 178) in 92 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T19:57:18.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 152.0 in stage 3.0 (TID 187)
[2025-07-19T19:57:18.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@779334c3
[2025-07-19T19:57:18.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/146] for update
[2025-07-19T19:57:18.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.1.delta.c49dc7ab-2876-496a-9fdb-83c612423e27.TID180.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/141/1.delta
[2025-07-19T19:57:18.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/141] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/141/1.delta
[2025-07-19T19:57:18.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 180, attempt 0, stage 3.0)
[2025-07-19T19:57:18.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76c1597e
[2025-07-19T19:57:18.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.1.delta.7051a529-efb8-4cbe-82a0-649245eaba86.TID182.tmp
[2025-07-19T19:57:18.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/152] for update
[2025-07-19T19:57:18.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 141 (task 180, attempt 0, stage 3.0)
[2025-07-19T19:57:18.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.1.delta.e12448b8-ea83-46fa-bcff-df9370665672.TID183.tmp
[2025-07-19T19:57:18.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 141.0 in stage 3.0 (TID 180). 6200 bytes result sent to driver
[2025-07-19T19:57:18.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 156.0 in stage 3.0 (TID 188) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 141.0 in stage 3.0 (TID 180) in 84 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T19:57:18.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 156.0 in stage 3.0 (TID 188)
[2025-07-19T19:57:18.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e6922de
[2025-07-19T19:57:18.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/151] for update
[2025-07-19T19:57:18.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e6a9005
[2025-07-19T19:57:18.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/148] for update
[2025-07-19T19:57:18.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.1.delta.84d47fab-655c-4a6d-9795-72463f0da3d8.TID187.tmp
[2025-07-19T19:57:18.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.1.delta.531dface-8cbe-4262-a825-72a9d2fbfbc9.TID186.tmp
[2025-07-19T19:57:18.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53f45b9a
[2025-07-19T19:57:18.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.1.delta.e05abe55-b4f0-4766-9a64-61fd8ac14004.TID181.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/142/1.delta
[2025-07-19T19:57:18.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/142] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/142/1.delta
[2025-07-19T19:57:18.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/147] for update
[2025-07-19T19:57:18.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 181, attempt 0, stage 3.0)
[2025-07-19T19:57:18.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.1.delta.6782a9da-7040-49a4-be21-251315b83156.TID185.tmp
[2025-07-19T19:57:18.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35dfc96e
[2025-07-19T19:57:18.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/156] for update
[2025-07-19T19:57:18.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 142 (task 181, attempt 0, stage 3.0)
[2025-07-19T19:57:18.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 142.0 in stage 3.0 (TID 181). 6200 bytes result sent to driver
[2025-07-19T19:57:18.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 157.0 in stage 3.0 (TID 189) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 142.0 in stage 3.0 (TID 181) in 97 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T19:57:18.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 157.0 in stage 3.0 (TID 189)
[2025-07-19T19:57:18.910+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.1.delta.7051a529-efb8-4cbe-82a0-649245eaba86.TID182.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/143/1.delta
[2025-07-19T19:57:18.910+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/143] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/143/1.delta
[2025-07-19T19:57:18.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.1.delta.597d7409-aad6-4697-b436-969c4fdd1e3d.TID184.tmp
[2025-07-19T19:57:18.916+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.1.delta.e12448b8-ea83-46fa-bcff-df9370665672.TID183.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/146/1.delta
[2025-07-19T19:57:18.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/146] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/146/1.delta
[2025-07-19T19:57:18.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.1.delta.4773548b-974a-42b5-b3f9-fc916a6e0660.TID188.tmp
[2025-07-19T19:57:18.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 183, attempt 0, stage 3.0)
[2025-07-19T19:57:18.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.1.delta.84d47fab-655c-4a6d-9795-72463f0da3d8.TID187.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/152/1.delta
[2025-07-19T19:57:18.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 182, attempt 0, stage 3.0)
[2025-07-19T19:57:18.922+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/152] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/152/1.delta
[2025-07-19T19:57:18.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 187, attempt 0, stage 3.0)
[2025-07-19T19:57:18.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23eb1369
[2025-07-19T19:57:18.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 152 (task 187, attempt 0, stage 3.0)
[2025-07-19T19:57:18.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/157] for update
[2025-07-19T19:57:18.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 152.0 in stage 3.0 (TID 187). 6200 bytes result sent to driver
[2025-07-19T19:57:18.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 162.0 in stage 3.0 (TID 190) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 143 (task 182, attempt 0, stage 3.0)
[2025-07-19T19:57:18.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 152.0 in stage 3.0 (TID 187) in 75 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T19:57:18.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 146 (task 183, attempt 0, stage 3.0)
[2025-07-19T19:57:18.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 162.0 in stage 3.0 (TID 190)
[2025-07-19T19:57:18.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 146.0 in stage 3.0 (TID 183). 6200 bytes result sent to driver
[2025-07-19T19:57:18.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:18.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 143.0 in stage 3.0 (TID 182). 6200 bytes result sent to driver
[2025-07-19T19:57:18.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 164.0 in stage 3.0 (TID 191) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 166.0 in stage 3.0 (TID 192) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 143.0 in stage 3.0 (TID 182) in 108 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T19:57:18.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 146.0 in stage 3.0 (TID 183) in 108 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T19:57:18.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 164.0 in stage 3.0 (TID 191)
[2025-07-19T19:57:18.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 166.0 in stage 3.0 (TID 192)
[2025-07-19T19:57:18.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@174312a0
[2025-07-19T19:57:18.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:18.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:18.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.1.delta.9cca9251-60e4-403f-ab73-280df7f62bbe.TID189.tmp
[2025-07-19T19:57:18.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/162] for update
[2025-07-19T19:57:18.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.1.delta.531dface-8cbe-4262-a825-72a9d2fbfbc9.TID186.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/151/1.delta
[2025-07-19T19:57:18.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/151] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/151/1.delta
[2025-07-19T19:57:18.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.1.delta.597d7409-aad6-4697-b436-969c4fdd1e3d.TID184.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/147/1.delta
[2025-07-19T19:57:18.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/147] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/147/1.delta
[2025-07-19T19:57:18.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 186, attempt 0, stage 3.0)
[2025-07-19T19:57:18.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 184, attempt 0, stage 3.0)
[2025-07-19T19:57:18.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.1.delta.6782a9da-7040-49a4-be21-251315b83156.TID185.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/148/1.delta
[2025-07-19T19:57:18.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/148] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/148/1.delta
[2025-07-19T19:57:18.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 185, attempt 0, stage 3.0)
[2025-07-19T19:57:18.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56c502e4
[2025-07-19T19:57:18.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/164] for update
[2025-07-19T19:57:18.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.1.delta.81548503-c19a-433f-8a2a-0fe473b396f3.TID190.tmp
[2025-07-19T19:57:18.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 147 (task 184, attempt 0, stage 3.0)
[2025-07-19T19:57:18.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 147.0 in stage 3.0 (TID 184). 6243 bytes result sent to driver
[2025-07-19T19:57:18.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 147.0 in stage 3.0 (TID 184) in 123 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T19:57:18.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 148 (task 185, attempt 0, stage 3.0)
[2025-07-19T19:57:18.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 151 (task 186, attempt 0, stage 3.0)
[2025-07-19T19:57:18.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 167.0 in stage 3.0 (TID 193) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 167.0 in stage 3.0 (TID 193)
[2025-07-19T19:57:18.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 151.0 in stage 3.0 (TID 186). 6200 bytes result sent to driver
[2025-07-19T19:57:18.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 148.0 in stage 3.0 (TID 185). 6243 bytes result sent to driver
[2025-07-19T19:57:18.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 168.0 in stage 3.0 (TID 194) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@713151f0
[2025-07-19T19:57:18.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 151.0 in stage 3.0 (TID 186) in 113 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T19:57:18.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 148.0 in stage 3.0 (TID 185) in 128 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T19:57:18.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.1.delta.4773548b-974a-42b5-b3f9-fc916a6e0660.TID188.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/156/1.delta
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/156] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/156/1.delta
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 168.0 in stage 3.0 (TID 194)
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 171.0 in stage 3.0 (TID 195) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 171.0 in stage 3.0 (TID 195)
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/166] for update
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 188, attempt 0, stage 3.0)
[2025-07-19T19:57:18.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:18.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.1.delta.33769aa2-a400-4788-9564-4cb92baaa7cf.TID191.tmp
[2025-07-19T19:57:18.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a5cef1a
[2025-07-19T19:57:18.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/167] for update
[2025-07-19T19:57:18.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 156 (task 188, attempt 0, stage 3.0)
[2025-07-19T19:57:18.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47ea56cc
[2025-07-19T19:57:18.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/171] for update
[2025-07-19T19:57:18.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 156.0 in stage 3.0 (TID 188). 6200 bytes result sent to driver
[2025-07-19T19:57:18.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.1.delta.5c9f7903-ce23-42f3-9c4c-c3e415e0c9c0.TID192.tmp
[2025-07-19T19:57:18.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.1.delta.9cca9251-60e4-403f-ab73-280df7f62bbe.TID189.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/157/1.delta
[2025-07-19T19:57:18.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/157] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/157/1.delta
[2025-07-19T19:57:18.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Starting task 173.0 in stage 3.0 (TID 196) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:18.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Running task 173.0 in stage 3.0 (TID 196)
[2025-07-19T19:57:18.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO TaskSetManager: Finished task 156.0 in stage 3.0 (TID 188) in 110 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T19:57:18.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 189, attempt 0, stage 3.0)
[2025-07-19T19:57:18.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:18.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:18.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ddf869f
[2025-07-19T19:57:18.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:18.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/168] for update
[2025-07-19T19:57:18.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.1.delta.81548503-c19a-433f-8a2a-0fe473b396f3.TID190.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/162/1.delta
[2025-07-19T19:57:18.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/162] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/162/1.delta
[2025-07-19T19:57:18.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 190, attempt 0, stage 3.0)
[2025-07-19T19:57:18.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO DataWritingSparkTask: Committed partition 157 (task 189, attempt 0, stage 3.0)
[2025-07-19T19:57:18.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:18.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.1.delta.297a7f24-58ab-4f67-a16e-39192d123a54.TID195.tmp
[2025-07-19T19:57:19.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO Executor: Finished task 157.0 in stage 3.0 (TID 189). 6243 bytes result sent to driver
[2025-07-19T19:57:19.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.1.delta.0b9c75c5-2178-4764-9779-1b971bf0b1e0.TID193.tmp
[2025-07-19T19:57:19.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2925591b
[2025-07-19T19:57:19.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/173] for update
[2025-07-19T19:57:19.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 175.0 in stage 3.0 (TID 197) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 175.0 in stage 3.0 (TID 197)
[2025-07-19T19:57:19.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 157.0 in stage 3.0 (TID 189) in 99 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T19:57:19.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 162 (task 190, attempt 0, stage 3.0)
[2025-07-19T19:57:19.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 162.0 in stage 3.0 (TID 190). 6200 bytes result sent to driver
[2025-07-19T19:57:19.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 176.0 in stage 3.0 (TID 198) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 176.0 in stage 3.0 (TID 198)
[2025-07-19T19:57:19.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 162.0 in stage 3.0 (TID 190) in 85 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T19:57:19.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.1.delta.e97106c6-689a-4e46-87ea-fd98dea1d35b.TID194.tmp
[2025-07-19T19:57:19.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e7b52a7
[2025-07-19T19:57:19.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/175] for update
[2025-07-19T19:57:19.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.1.delta.6a70a161-f92c-4ff6-aaf8-2e5d1eef29f4.TID196.tmp
[2025-07-19T19:57:19.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.1.delta.33769aa2-a400-4788-9564-4cb92baaa7cf.TID191.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/164/1.delta
[2025-07-19T19:57:19.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/164] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/164/1.delta
[2025-07-19T19:57:19.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 191, attempt 0, stage 3.0)
[2025-07-19T19:57:19.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39c81875
[2025-07-19T19:57:19.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/176] for update
[2025-07-19T19:57:19.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.1.delta.5c9f7903-ce23-42f3-9c4c-c3e415e0c9c0.TID192.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/166/1.delta
[2025-07-19T19:57:19.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/166] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/166/1.delta
[2025-07-19T19:57:19.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 192, attempt 0, stage 3.0)
[2025-07-19T19:57:19.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.1.delta.31d508a1-26cc-4e1d-900d-d9f9fcea0de0.TID197.tmp
[2025-07-19T19:57:19.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 164 (task 191, attempt 0, stage 3.0)
[2025-07-19T19:57:19.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.1.delta.297a7f24-58ab-4f67-a16e-39192d123a54.TID195.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/171/1.delta
[2025-07-19T19:57:19.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/171] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/171/1.delta
[2025-07-19T19:57:19.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 195, attempt 0, stage 3.0)
[2025-07-19T19:57:19.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 166 (task 192, attempt 0, stage 3.0)
[2025-07-19T19:57:19.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 164.0 in stage 3.0 (TID 191). 6200 bytes result sent to driver
[2025-07-19T19:57:19.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 166.0 in stage 3.0 (TID 192). 6200 bytes result sent to driver
[2025-07-19T19:57:19.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 184.0 in stage 3.0 (TID 199) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 164.0 in stage 3.0 (TID 191) in 106 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T19:57:19.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 185.0 in stage 3.0 (TID 200) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 184.0 in stage 3.0 (TID 199)
[2025-07-19T19:57:19.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 185.0 in stage 3.0 (TID 200)
[2025-07-19T19:57:19.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 171 (task 195, attempt 0, stage 3.0)
[2025-07-19T19:57:19.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 171.0 in stage 3.0 (TID 195). 6200 bytes result sent to driver
[2025-07-19T19:57:19.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 186.0 in stage 3.0 (TID 201) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 186.0 in stage 3.0 (TID 201)
[2025-07-19T19:57:19.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 166.0 in stage 3.0 (TID 192) in 108 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T19:57:19.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 171.0 in stage 3.0 (TID 195) in 79 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T19:57:19.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f4f01e9
[2025-07-19T19:57:19.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/184] for update
[2025-07-19T19:57:19.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.1.delta.0b9c75c5-2178-4764-9779-1b971bf0b1e0.TID193.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/167/1.delta
[2025-07-19T19:57:19.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/167] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/167/1.delta
[2025-07-19T19:57:19.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.1.delta.15726db8-106b-4067-9cd6-5511774a4a62.TID198.tmp
[2025-07-19T19:57:19.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 193, attempt 0, stage 3.0)
[2025-07-19T19:57:19.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e698c98
[2025-07-19T19:57:19.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.1.delta.e97106c6-689a-4e46-87ea-fd98dea1d35b.TID194.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/168/1.delta
[2025-07-19T19:57:19.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/168] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/168/1.delta
[2025-07-19T19:57:19.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 194, attempt 0, stage 3.0)
[2025-07-19T19:57:19.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/186] for update
[2025-07-19T19:57:19.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 167 (task 193, attempt 0, stage 3.0)
[2025-07-19T19:57:19.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 167.0 in stage 3.0 (TID 193). 6243 bytes result sent to driver
[2025-07-19T19:57:19.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 167.0 in stage 3.0 (TID 193) in 106 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T19:57:19.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.1.delta.6a70a161-f92c-4ff6-aaf8-2e5d1eef29f4.TID196.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/173/1.delta
[2025-07-19T19:57:19.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/173] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/173/1.delta
[2025-07-19T19:57:19.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 187.0 in stage 3.0 (TID 202) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 187.0 in stage 3.0 (TID 202)
[2025-07-19T19:57:19.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 196, attempt 0, stage 3.0)
[2025-07-19T19:57:19.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 168 (task 194, attempt 0, stage 3.0)
[2025-07-19T19:57:19.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 168.0 in stage 3.0 (TID 194). 6243 bytes result sent to driver
[2025-07-19T19:57:19.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2770459
[2025-07-19T19:57:19.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/185] for update
[2025-07-19T19:57:19.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 189.0 in stage 3.0 (TID 203) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 189.0 in stage 3.0 (TID 203)
[2025-07-19T19:57:19.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 168.0 in stage 3.0 (TID 194) in 108 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T19:57:19.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.1.delta.c785ce4c-cdcf-475d-9187-f997de7446d4.TID201.tmp
[2025-07-19T19:57:19.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.1.delta.31d508a1-26cc-4e1d-900d-d9f9fcea0de0.TID197.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/175/1.delta
[2025-07-19T19:57:19.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/175] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/175/1.delta
[2025-07-19T19:57:19.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 197, attempt 0, stage 3.0)
[2025-07-19T19:57:19.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4221ae83
[2025-07-19T19:57:19.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/187] for update
[2025-07-19T19:57:19.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 173 (task 196, attempt 0, stage 3.0)
[2025-07-19T19:57:19.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 173.0 in stage 3.0 (TID 196). 6243 bytes result sent to driver
[2025-07-19T19:57:19.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 173.0 in stage 3.0 (TID 196) in 101 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T19:57:19.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 191.0 in stage 3.0 (TID 204) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 191.0 in stage 3.0 (TID 204)
[2025-07-19T19:57:19.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.1.delta.12106f23-c39c-4ddd-8196-f0346c00d7a8.TID199.tmp
[2025-07-19T19:57:19.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.1.delta.8eb89ff9-8c83-4ddd-a4fc-cd9caf4ca57f.TID200.tmp
[2025-07-19T19:57:19.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 175 (task 197, attempt 0, stage 3.0)
[2025-07-19T19:57:19.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 175.0 in stage 3.0 (TID 197). 6243 bytes result sent to driver
[2025-07-19T19:57:19.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 193.0 in stage 3.0 (TID 205) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 175.0 in stage 3.0 (TID 197) in 87 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T19:57:19.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 193.0 in stage 3.0 (TID 205)
[2025-07-19T19:57:19.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c9a86dd
[2025-07-19T19:57:19.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/189] for update
[2025-07-19T19:57:19.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.1.delta.b33e148e-51a6-4e6a-936a-398b1708c862.TID202.tmp
[2025-07-19T19:57:19.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24b47152
[2025-07-19T19:57:19.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/191] for update
[2025-07-19T19:57:19.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.1.delta.15726db8-106b-4067-9cd6-5511774a4a62.TID198.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/176/1.delta
[2025-07-19T19:57:19.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/176] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/176/1.delta
[2025-07-19T19:57:19.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 198, attempt 0, stage 3.0)
[2025-07-19T19:57:19.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63c52848
[2025-07-19T19:57:19.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/193] for update
[2025-07-19T19:57:19.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.1.delta.02677f0a-0c10-4239-932a-c02beb2db9a5.TID203.tmp
[2025-07-19T19:57:19.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 176 (task 198, attempt 0, stage 3.0)
[2025-07-19T19:57:19.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 176.0 in stage 3.0 (TID 198). 6243 bytes result sent to driver
[2025-07-19T19:57:19.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 194.0 in stage 3.0 (TID 206) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.1.delta.c785ce4c-cdcf-475d-9187-f997de7446d4.TID201.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/186/1.delta
[2025-07-19T19:57:19.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/186] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/186/1.delta
[2025-07-19T19:57:19.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 201, attempt 0, stage 3.0)
[2025-07-19T19:57:19.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 176.0 in stage 3.0 (TID 198) in 112 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T19:57:19.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 194.0 in stage 3.0 (TID 206)
[2025-07-19T19:57:19.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.1.delta.2248dd93-1b04-4830-970b-c890c6dfcf76.TID205.tmp
[2025-07-19T19:57:19.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.1.delta.f1d2c9f6-68c0-453c-ae90-b426408b5217.TID204.tmp
[2025-07-19T19:57:19.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.1.delta.12106f23-c39c-4ddd-8196-f0346c00d7a8.TID199.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/184/1.delta
[2025-07-19T19:57:19.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/184] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/184/1.delta
[2025-07-19T19:57:19.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 199, attempt 0, stage 3.0)
[2025-07-19T19:57:19.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a27d688
[2025-07-19T19:57:19.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/194] for update
[2025-07-19T19:57:19.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 186 (task 201, attempt 0, stage 3.0)
[2025-07-19T19:57:19.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 186.0 in stage 3.0 (TID 201). 6243 bytes result sent to driver
[2025-07-19T19:57:19.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 196.0 in stage 3.0 (TID 207) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 186.0 in stage 3.0 (TID 201) in 94 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T19:57:19.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 196.0 in stage 3.0 (TID 207)
[2025-07-19T19:57:19.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.1.delta.8eb89ff9-8c83-4ddd-a4fc-cd9caf4ca57f.TID200.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/185/1.delta
[2025-07-19T19:57:19.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/185] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/185/1.delta
[2025-07-19T19:57:19.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 184 (task 199, attempt 0, stage 3.0)
[2025-07-19T19:57:19.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 184.0 in stage 3.0 (TID 199). 6243 bytes result sent to driver
[2025-07-19T19:57:19.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 197.0 in stage 3.0 (TID 208) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 200, attempt 0, stage 3.0)
[2025-07-19T19:57:19.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 197.0 in stage 3.0 (TID 208)
[2025-07-19T19:57:19.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 184.0 in stage 3.0 (TID 199) in 105 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T19:57:19.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 185 (task 200, attempt 0, stage 3.0)
[2025-07-19T19:57:19.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 185.0 in stage 3.0 (TID 200). 6243 bytes result sent to driver
[2025-07-19T19:57:19.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 198.0 in stage 3.0 (TID 209) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.150+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 185.0 in stage 3.0 (TID 200) in 110 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T19:57:19.150+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 198.0 in stage 3.0 (TID 209)
[2025-07-19T19:57:19.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54f6125e
[2025-07-19T19:57:19.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.1.delta.b33e148e-51a6-4e6a-936a-398b1708c862.TID202.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/187/1.delta
[2025-07-19T19:57:19.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/187] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/187/1.delta
[2025-07-19T19:57:19.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 202, attempt 0, stage 3.0)
[2025-07-19T19:57:19.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.156+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.1.delta.3756350d-86ac-4b26-8935-c19e287493ff.TID206.tmp
[2025-07-19T19:57:19.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/196] for update
[2025-07-19T19:57:19.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.158+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 187 (task 202, attempt 0, stage 3.0)
[2025-07-19T19:57:19.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 187.0 in stage 3.0 (TID 202). 6200 bytes result sent to driver
[2025-07-19T19:57:19.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.1.delta.02677f0a-0c10-4239-932a-c02beb2db9a5.TID203.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/189/1.delta
[2025-07-19T19:57:19.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/189] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/189/1.delta
[2025-07-19T19:57:19.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 203, attempt 0, stage 3.0)
[2025-07-19T19:57:19.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 199.0 in stage 3.0 (TID 210) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 187.0 in stage 3.0 (TID 202) in 99 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T19:57:19.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 199.0 in stage 3.0 (TID 210)
[2025-07-19T19:57:19.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.1.delta.2248dd93-1b04-4830-970b-c890c6dfcf76.TID205.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/193/1.delta
[2025-07-19T19:57:19.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/193] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/193/1.delta
[2025-07-19T19:57:19.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.1.delta.f1d2c9f6-68c0-453c-ae90-b426408b5217.TID204.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/191/1.delta
[2025-07-19T19:57:19.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/191] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/191/1.delta
[2025-07-19T19:57:19.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 204, attempt 0, stage 3.0)
[2025-07-19T19:57:19.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 205, attempt 0, stage 3.0)
[2025-07-19T19:57:19.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.1.delta.cdb4bd77-ab0d-4b88-b938-71a62b0d758e.TID207.tmp
[2025-07-19T19:57:19.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 191 (task 204, attempt 0, stage 3.0)
[2025-07-19T19:57:19.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 193 (task 205, attempt 0, stage 3.0)
[2025-07-19T19:57:19.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 191.0 in stage 3.0 (TID 204). 6200 bytes result sent to driver
[2025-07-19T19:57:19.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 193.0 in stage 3.0 (TID 205). 6200 bytes result sent to driver
[2025-07-19T19:57:19.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 189 (task 203, attempt 0, stage 3.0)
[2025-07-19T19:57:19.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 211) (8b44f3d35cfa, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 212) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 0.0 in stage 5.0 (TID 211)
[2025-07-19T19:57:19.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 189.0 in stage 3.0 (TID 203). 6200 bytes result sent to driver
[2025-07-19T19:57:19.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22681352
[2025-07-19T19:57:19.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 193.0 in stage 3.0 (TID 205) in 83 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T19:57:19.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 1.0 in stage 5.0 (TID 212)
[2025-07-19T19:57:19.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/198] for update
[2025-07-19T19:57:19.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 191.0 in stage 3.0 (TID 204) in 89 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T19:57:19.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 213) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 2.0 in stage 5.0 (TID 213)
[2025-07-19T19:57:19.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 189.0 in stage 3.0 (TID 203) in 108 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T19:57:19.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39838f6b
[2025-07-19T19:57:19.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/197] for update
[2025-07-19T19:57:19.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.1.delta.c636e98a-f9f7-4b44-be76-185316350971.TID209.tmp
[2025-07-19T19:57:19.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.1.delta.0e31391d-1ad8-4798-9f8a-575cec6590fd.TID208.tmp
[2025-07-19T19:57:19.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.1.delta.3756350d-86ac-4b26-8935-c19e287493ff.TID206.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/194/1.delta
[2025-07-19T19:57:19.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/194] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/194/1.delta
[2025-07-19T19:57:19.195+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 206, attempt 0, stage 3.0)
[2025-07-19T19:57:19.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 194 (task 206, attempt 0, stage 3.0)
[2025-07-19T19:57:19.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 194.0 in stage 3.0 (TID 206). 6200 bytes result sent to driver
[2025-07-19T19:57:19.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.1.delta.cdb4bd77-ab0d-4b88-b938-71a62b0d758e.TID207.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/196/1.delta
[2025-07-19T19:57:19.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/196] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/196/1.delta
[2025-07-19T19:57:19.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/.schema.59b4c06f-c602-41bf-b408-2a11303dff98.TID211.tmp
[2025-07-19T19:57:19.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 214) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 207, attempt 0, stage 3.0)
[2025-07-19T19:57:19.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 194.0 in stage 3.0 (TID 206) in 86 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T19:57:19.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 3.0 in stage 5.0 (TID 214)
[2025-07-19T19:57:19.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 196 (task 207, attempt 0, stage 3.0)
[2025-07-19T19:57:19.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 196.0 in stage 3.0 (TID 207). 6200 bytes result sent to driver
[2025-07-19T19:57:19.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:19.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 215) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 4.0 in stage 5.0 (TID 215)
[2025-07-19T19:57:19.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 196.0 in stage 3.0 (TID 207) in 80 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T19:57:19.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.1.delta.0e31391d-1ad8-4798-9f8a-575cec6590fd.TID208.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/197/1.delta
[2025-07-19T19:57:19.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/197] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/197/1.delta
[2025-07-19T19:57:19.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 208, attempt 0, stage 3.0)
[2025-07-19T19:57:19.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.1.delta.c636e98a-f9f7-4b44-be76-185316350971.TID209.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/198/1.delta
[2025-07-19T19:57:19.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/198] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/198/1.delta
[2025-07-19T19:57:19.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 209, attempt 0, stage 3.0)
[2025-07-19T19:57:19.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 198 (task 209, attempt 0, stage 3.0)
[2025-07-19T19:57:19.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 197 (task 208, attempt 0, stage 3.0)
[2025-07-19T19:57:19.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 198.0 in stage 3.0 (TID 209). 6200 bytes result sent to driver
[2025-07-19T19:57:19.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 197.0 in stage 3.0 (TID 208). 6200 bytes result sent to driver
[2025-07-19T19:57:19.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 198.0 in stage 3.0 (TID 209) in 77 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T19:57:19.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 216) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 217) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 197.0 in stage 3.0 (TID 208) in 87 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T19:57:19.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 9.0 in stage 5.0 (TID 217)
[2025-07-19T19:57:19.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 7.0 in stage 5.0 (TID 216)
[2025-07-19T19:57:19.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/.schema.59b4c06f-c602-41bf-b408-2a11303dff98.TID211.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/schema
[2025-07-19T19:57:19.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6349b8e1
[2025-07-19T19:57:19.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0] for update
[2025-07-19T19:57:19.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@434a1d1c
[2025-07-19T19:57:19.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2] for update
[2025-07-19T19:57:19.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.1.delta.832da937-f699-4097-97b3-f856d7f351f7.TID211.tmp
[2025-07-19T19:57:19.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58072c8f
[2025-07-19T19:57:19.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1] for update
[2025-07-19T19:57:19.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.1.delta.e7da9fc6-9868-4d96-b1a4-b547cee96151.TID213.tmp
[2025-07-19T19:57:19.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4affbaa3
[2025-07-19T19:57:19.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],8d7b6976-38a8-4337-af61-4ae74f3cdde4) is active
[2025-07-19T19:57:19.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/199] for update
[2025-07-19T19:57:19.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.1.delta.5dfa982d-26e3-43e5-82bc-f6a834fb609d.TID212.tmp
[2025-07-19T19:57:19.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ae632ae
[2025-07-19T19:57:19.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9] for update
[2025-07-19T19:57:19.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.1.delta.f95fdbb0-b1e5-4ea6-8151-2cba84f839c9.TID210.tmp
[2025-07-19T19:57:19.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c2b30ac
[2025-07-19T19:57:19.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7] for update
[2025-07-19T19:57:19.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.1.delta.832da937-f699-4097-97b3-f856d7f351f7.TID211.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/1.delta
[2025-07-19T19:57:19.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/1.delta
[2025-07-19T19:57:19.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b0a25d8
[2025-07-19T19:57:19.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.1.delta.c7ed34de-2f83-4296-9796-4039b8b2376b.TID217.tmp
[2025-07-19T19:57:19.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 211, attempt 0, stage 5.0)
[2025-07-19T19:57:19.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4] for update
[2025-07-19T19:57:19.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73ee8a8e
[2025-07-19T19:57:19.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3] for update
[2025-07-19T19:57:19.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.1.delta.e7da9fc6-9868-4d96-b1a4-b547cee96151.TID213.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/1.delta
[2025-07-19T19:57:19.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/1.delta
[2025-07-19T19:57:19.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.1.delta.305a17ba-bc75-4a80-85af-f0ce7e5f9a41.TID216.tmp
[2025-07-19T19:57:19.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.1.delta.9aeb690b-e857-41e9-845c-99e10415a3bf.TID215.tmp
[2025-07-19T19:57:19.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 213, attempt 0, stage 5.0)
[2025-07-19T19:57:19.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.1.delta.d69d00b8-6f31-415f-bd1b-aadc17526c5c.TID214.tmp
[2025-07-19T19:57:19.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 0 (task 211, attempt 0, stage 5.0)
[2025-07-19T19:57:19.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 0.0 in stage 5.0 (TID 211). 9113 bytes result sent to driver
[2025-07-19T19:57:19.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 211) in 115 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T19:57:19.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.1.delta.5dfa982d-26e3-43e5-82bc-f6a834fb609d.TID212.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/1.delta
[2025-07-19T19:57:19.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/1.delta
[2025-07-19T19:57:19.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 212, attempt 0, stage 5.0)
[2025-07-19T19:57:19.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 218) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.1.delta.f95fdbb0-b1e5-4ea6-8151-2cba84f839c9.TID210.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/199/1.delta
[2025-07-19T19:57:19.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/199] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/state/0/199/1.delta
[2025-07-19T19:57:19.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 210, attempt 0, stage 3.0)
[2025-07-19T19:57:19.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 10.0 in stage 5.0 (TID 218)
[2025-07-19T19:57:19.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 199 (task 210, attempt 0, stage 3.0)
[2025-07-19T19:57:19.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 199.0 in stage 3.0 (TID 210). 6200 bytes result sent to driver
[2025-07-19T19:57:19.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 219) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 199.0 in stage 3.0 (TID 210) in 138 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T19:57:19.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-07-19T19:57:19.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DAGScheduler: ResultStage 3 (start at <unknown>:0) finished in 4.204 s
[2025-07-19T19:57:19.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 11.0 in stage 5.0 (TID 219)
[2025-07-19T19:57:19.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T19:57:19.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-07-19T19:57:19.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c548544
[2025-07-19T19:57:19.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10] for update
[2025-07-19T19:57:19.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 5.663195 s
[2025-07-19T19:57:19.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 1 (task 212, attempt 0, stage 5.0)
[2025-07-19T19:57:19.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 2 (task 213, attempt 0, stage 5.0)
[2025-07-19T19:57:19.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 2.0 in stage 5.0 (TID 213). 9113 bytes result sent to driver
[2025-07-19T19:57:19.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 220) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.1.delta.c7ed34de-2f83-4296-9796-4039b8b2376b.TID217.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/1.delta
[2025-07-19T19:57:19.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/1.delta
[2025-07-19T19:57:19.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] is committing.
[2025-07-19T19:57:19.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO SparkWrite: Committing epoch 0 for query 5253d98e-255c-4533-9785-660d38a21faf in append mode
[2025-07-19T19:57:19.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 217, attempt 0, stage 5.0)
[2025-07-19T19:57:19.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 213) in 140 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T19:57:19.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b5db735
[2025-07-19T19:57:19.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 12.0 in stage 5.0 (TID 220)
[2025-07-19T19:57:19.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.1.delta.03c97c98-61ff-48d7-ac25-ecc09839fb47.TID218.tmp
[2025-07-19T19:57:19.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11] for update
[2025-07-19T19:57:19.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 1.0 in stage 5.0 (TID 212). 9107 bytes result sent to driver
[2025-07-19T19:57:19.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 221) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 13.0 in stage 5.0 (TID 221)
[2025-07-19T19:57:19.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 212) in 148 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T19:57:19.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.1.delta.9aeb690b-e857-41e9-845c-99e10415a3bf.TID215.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/1.delta
[2025-07-19T19:57:19.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/1.delta
[2025-07-19T19:57:19.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.1.delta.d69d00b8-6f31-415f-bd1b-aadc17526c5c.TID214.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/1.delta
[2025-07-19T19:57:19.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/1.delta
[2025-07-19T19:57:19.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.1.delta.305a17ba-bc75-4a80-85af-f0ce7e5f9a41.TID216.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/1.delta
[2025-07-19T19:57:19.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/1.delta
[2025-07-19T19:57:19.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 216, attempt 0, stage 5.0)
[2025-07-19T19:57:19.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 214, attempt 0, stage 5.0)
[2025-07-19T19:57:19.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 215, attempt 0, stage 5.0)
[2025-07-19T19:57:19.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.1.delta.70dd84b9-4d4c-4f99-9861-6973c95e9620.TID219.tmp
[2025-07-19T19:57:19.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75ffdbac
[2025-07-19T19:57:19.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12] for update
[2025-07-19T19:57:19.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b92b4b8
[2025-07-19T19:57:19.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 9 (task 217, attempt 0, stage 5.0)
[2025-07-19T19:57:19.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13] for update
[2025-07-19T19:57:19.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 9.0 in stage 5.0 (TID 217). 9119 bytes result sent to driver
[2025-07-19T19:57:19.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.1.delta.03c97c98-61ff-48d7-ac25-ecc09839fb47.TID218.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/1.delta
[2025-07-19T19:57:19.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/1.delta
[2025-07-19T19:57:19.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 222) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 218, attempt 0, stage 5.0)
[2025-07-19T19:57:19.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.1.delta.77cbb874-4a5d-44ed-80da-eec457ae49e5.TID220.tmp
[2025-07-19T19:57:19.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 14.0 in stage 5.0 (TID 222)
[2025-07-19T19:57:19.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 217) in 122 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T19:57:19.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 7 (task 216, attempt 0, stage 5.0)
[2025-07-19T19:57:19.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 4 (task 215, attempt 0, stage 5.0)
[2025-07-19T19:57:19.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 7.0 in stage 5.0 (TID 216). 9105 bytes result sent to driver
[2025-07-19T19:57:19.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 223) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 15.0 in stage 5.0 (TID 223)
[2025-07-19T19:57:19.362+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 216) in 133 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T19:57:19.362+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 4.0 in stage 5.0 (TID 215). 9158 bytes result sent to driver
[2025-07-19T19:57:19.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 224) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 16.0 in stage 5.0 (TID 224)
[2025-07-19T19:57:19.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.1.delta.b52e91e2-4cfb-4d0e-b406-6196302741c4.TID221.tmp
[2025-07-19T19:57:19.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5269ca07
[2025-07-19T19:57:19.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 3 (task 214, attempt 0, stage 5.0)
[2025-07-19T19:57:19.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14] for update
[2025-07-19T19:57:19.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 3.0 in stage 5.0 (TID 214). 9109 bytes result sent to driver
[2025-07-19T19:57:19.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 215) in 153 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T19:57:19.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO SparkWrite: Committing streaming append with 115 new data files to table my_catalog.bronze.Reservations_raw
[2025-07-19T19:57:19.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 225) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 18.0 in stage 5.0 (TID 225)
[2025-07-19T19:57:19.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 214) in 166 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T19:57:19.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5888c20f
[2025-07-19T19:57:19.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.1.delta.70dd84b9-4d4c-4f99-9861-6973c95e9620.TID219.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/1.delta
[2025-07-19T19:57:19.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/1.delta
[2025-07-19T19:57:19.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 10 (task 218, attempt 0, stage 5.0)
[2025-07-19T19:57:19.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 219, attempt 0, stage 5.0)
[2025-07-19T19:57:19.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 10.0 in stage 5.0 (TID 218). 9101 bytes result sent to driver
[2025-07-19T19:57:19.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15] for update
[2025-07-19T19:57:19.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 226) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 23.0 in stage 5.0 (TID 226)
[2025-07-19T19:57:19.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 218) in 87 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T19:57:19.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.1.delta.b5548a57-9bed-4ad7-99db-2534fc667c64.TID222.tmp
[2025-07-19T19:57:19.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@596c2106
[2025-07-19T19:57:19.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.1.delta.5913064f-321b-4219-a4a4-cb4d5c12a113.TID223.tmp
[2025-07-19T19:57:19.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16] for update
[2025-07-19T19:57:19.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d364309
[2025-07-19T19:57:19.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.394+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18] for update
[2025-07-19T19:57:19.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.1.delta.77cbb874-4a5d-44ed-80da-eec457ae49e5.TID220.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/1.delta
[2025-07-19T19:57:19.397+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/1.delta
[2025-07-19T19:57:19.397+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.1.delta.599d6f48-a2e1-44ac-aa90-f04f216a2c91.TID224.tmp
[2025-07-19T19:57:19.398+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 220, attempt 0, stage 5.0)
[2025-07-19T19:57:19.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.1.delta.b52e91e2-4cfb-4d0e-b406-6196302741c4.TID221.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/1.delta
[2025-07-19T19:57:19.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/1.delta
[2025-07-19T19:57:19.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 221, attempt 0, stage 5.0)
[2025-07-19T19:57:19.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4402df28
[2025-07-19T19:57:19.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.1.delta.e0afdfb0-a606-4bf6-b556-a6a906e0dd51.TID225.tmp
[2025-07-19T19:57:19.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.1.delta.5913064f-321b-4219-a4a4-cb4d5c12a113.TID223.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/1.delta
[2025-07-19T19:57:19.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/1.delta
[2025-07-19T19:57:19.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 223, attempt 0, stage 5.0)
[2025-07-19T19:57:19.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23] for update
[2025-07-19T19:57:19.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.1.delta.b5548a57-9bed-4ad7-99db-2534fc667c64.TID222.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/1.delta
[2025-07-19T19:57:19.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/1.delta
[2025-07-19T19:57:19.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 222, attempt 0, stage 5.0)
[2025-07-19T19:57:19.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 11 (task 219, attempt 0, stage 5.0)
[2025-07-19T19:57:19.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 11.0 in stage 5.0 (TID 219). 9106 bytes result sent to driver
[2025-07-19T19:57:19.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 227) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 26.0 in stage 5.0 (TID 227)
[2025-07-19T19:57:19.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 219) in 123 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T19:57:19.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.1.delta.85702ecc-fef2-4330-bb4d-932ca2294dc6.TID226.tmp
[2025-07-19T19:57:19.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 12 (task 220, attempt 0, stage 5.0)
[2025-07-19T19:57:19.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 12.0 in stage 5.0 (TID 220). 9127 bytes result sent to driver
[2025-07-19T19:57:19.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 228) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28beea9c
[2025-07-19T19:57:19.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26] for update
[2025-07-19T19:57:19.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 27.0 in stage 5.0 (TID 228)
[2025-07-19T19:57:19.438+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 220) in 121 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T19:57:19.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 14 (task 222, attempt 0, stage 5.0)
[2025-07-19T19:57:19.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 13 (task 221, attempt 0, stage 5.0)
[2025-07-19T19:57:19.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 15 (task 223, attempt 0, stage 5.0)
[2025-07-19T19:57:19.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 13.0 in stage 5.0 (TID 221). 9172 bytes result sent to driver
[2025-07-19T19:57:19.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 14.0 in stage 5.0 (TID 222). 9107 bytes result sent to driver
[2025-07-19T19:57:19.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:19.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 229) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 28.0 in stage 5.0 (TID 229)
[2025-07-19T19:57:19.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 221) in 125 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T19:57:19.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 230) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 15.0 in stage 5.0 (TID 223). 9114 bytes result sent to driver
[2025-07-19T19:57:19.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 231) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 222) in 101 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T19:57:19.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 223) in 90 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T19:57:19.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.1.delta.599d6f48-a2e1-44ac-aa90-f04f216a2c91.TID224.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/1.delta
[2025-07-19T19:57:19.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/1.delta
[2025-07-19T19:57:19.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 31.0 in stage 5.0 (TID 231)
[2025-07-19T19:57:19.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 30.0 in stage 5.0 (TID 230)
[2025-07-19T19:57:19.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ebc5f36
[2025-07-19T19:57:19.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27] for update
[2025-07-19T19:57:19.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 224, attempt 0, stage 5.0)
[2025-07-19T19:57:19.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.1.delta.d1ec3c45-c7f7-436c-a0ba-728e174f8a44.TID227.tmp
[2025-07-19T19:57:19.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3194e69e
[2025-07-19T19:57:19.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28] for update
[2025-07-19T19:57:19.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.479+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25537aa2
[2025-07-19T19:57:19.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31] for update
[2025-07-19T19:57:19.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.1.delta.7ba053df-cfce-42b4-9376-71f853f49369.TID228.tmp
[2025-07-19T19:57:19.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.1.delta.e0afdfb0-a606-4bf6-b556-a6a906e0dd51.TID225.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/1.delta
[2025-07-19T19:57:19.488+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.1.delta.527e6e7f-e553-4971-91f0-912a6b3713c5.TID229.tmp
[2025-07-19T19:57:19.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/1.delta
[2025-07-19T19:57:19.490+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 225, attempt 0, stage 5.0)
[2025-07-19T19:57:19.492+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.1.delta.85702ecc-fef2-4330-bb4d-932ca2294dc6.TID226.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/1.delta
[2025-07-19T19:57:19.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/1.delta
[2025-07-19T19:57:19.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 16 (task 224, attempt 0, stage 5.0)
[2025-07-19T19:57:19.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 226, attempt 0, stage 5.0)
[2025-07-19T19:57:19.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f9ed6c9
[2025-07-19T19:57:19.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 16.0 in stage 5.0 (TID 224). 9184 bytes result sent to driver
[2025-07-19T19:57:19.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30] for update
[2025-07-19T19:57:19.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.1.delta.a66af4de-5baa-4de1-8a11-507683d3aa61.TID231.tmp
[2025-07-19T19:57:19.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 232) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 33.0 in stage 5.0 (TID 232)
[2025-07-19T19:57:19.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 224) in 140 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T19:57:19.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.1.delta.d1ec3c45-c7f7-436c-a0ba-728e174f8a44.TID227.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/1.delta
[2025-07-19T19:57:19.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/1.delta
[2025-07-19T19:57:19.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 227, attempt 0, stage 5.0)
[2025-07-19T19:57:19.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.1.delta.19497db9-cd37-41a2-927e-3a510d0c2e42.TID230.tmp
[2025-07-19T19:57:19.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1698b576
[2025-07-19T19:57:19.513+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.513+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33] for update
[2025-07-19T19:57:19.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 18 (task 225, attempt 0, stage 5.0)
[2025-07-19T19:57:19.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 18.0 in stage 5.0 (TID 225). 9156 bytes result sent to driver
[2025-07-19T19:57:19.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 233) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 35.0 in stage 5.0 (TID 233)
[2025-07-19T19:57:19.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.1.delta.7ba053df-cfce-42b4-9376-71f853f49369.TID228.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/1.delta
[2025-07-19T19:57:19.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/1.delta
[2025-07-19T19:57:19.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 228, attempt 0, stage 5.0)
[2025-07-19T19:57:19.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 225) in 156 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T19:57:19.526+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 23 (task 226, attempt 0, stage 5.0)
[2025-07-19T19:57:19.526+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 26 (task 227, attempt 0, stage 5.0)
[2025-07-19T19:57:19.532+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 23.0 in stage 5.0 (TID 226). 9214 bytes result sent to driver
[2025-07-19T19:57:19.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 234) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 26.0 in stage 5.0 (TID 227). 9160 bytes result sent to driver
[2025-07-19T19:57:19.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 235) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 227) in 119 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T19:57:19.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 37.0 in stage 5.0 (TID 234)
[2025-07-19T19:57:19.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 39.0 in stage 5.0 (TID 235)
[2025-07-19T19:57:19.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 226) in 163 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T19:57:19.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.1.delta.245c381b-0e79-4619-afc7-18aaf2d2845a.TID232.tmp
[2025-07-19T19:57:19.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:19.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:19.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:19.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.1.delta.527e6e7f-e553-4971-91f0-912a6b3713c5.TID229.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/1.delta
[2025-07-19T19:57:19.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/1.delta
[2025-07-19T19:57:19.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 27 (task 228, attempt 0, stage 5.0)
[2025-07-19T19:57:19.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 27.0 in stage 5.0 (TID 228). 9156 bytes result sent to driver
[2025-07-19T19:57:19.546+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.1.delta.a66af4de-5baa-4de1-8a11-507683d3aa61.TID231.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/1.delta
[2025-07-19T19:57:19.546+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/1.delta
[2025-07-19T19:57:19.546+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.1.delta.19497db9-cd37-41a2-927e-3a510d0c2e42.TID230.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/1.delta
[2025-07-19T19:57:19.546+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/1.delta
[2025-07-19T19:57:19.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 229, attempt 0, stage 5.0)
[2025-07-19T19:57:19.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 231, attempt 0, stage 5.0)
[2025-07-19T19:57:19.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6076aa3f
[2025-07-19T19:57:19.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 230, attempt 0, stage 5.0)
[2025-07-19T19:57:19.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 236) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 41.0 in stage 5.0 (TID 236)
[2025-07-19T19:57:19.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37] for update
[2025-07-19T19:57:19.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 228) in 126 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T19:57:19.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:19.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@82fec24
[2025-07-19T19:57:19.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39] for update
[2025-07-19T19:57:19.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.1.delta.27f0d4a2-5f05-4df2-bf11-4b62848f0555.TID234.tmp
[2025-07-19T19:57:19.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 28 (task 229, attempt 0, stage 5.0)
[2025-07-19T19:57:19.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 28.0 in stage 5.0 (TID 229). 9171 bytes result sent to driver
[2025-07-19T19:57:19.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 237) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 42.0 in stage 5.0 (TID 237)
[2025-07-19T19:57:19.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a30cec3
[2025-07-19T19:57:19.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 229) in 135 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T19:57:19.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35] for update
[2025-07-19T19:57:19.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.1.delta.245c381b-0e79-4619-afc7-18aaf2d2845a.TID232.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/1.delta
[2025-07-19T19:57:19.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/1.delta
[2025-07-19T19:57:19.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 232, attempt 0, stage 5.0)
[2025-07-19T19:57:19.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.1.delta.16ab883e-0cd5-4b2f-bd49-4d0c2c8f94ad.TID235.tmp
[2025-07-19T19:57:19.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b9d407c
[2025-07-19T19:57:19.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42] for update
[2025-07-19T19:57:19.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 30 (task 230, attempt 0, stage 5.0)
[2025-07-19T19:57:19.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 30.0 in stage 5.0 (TID 230). 9163 bytes result sent to driver
[2025-07-19T19:57:19.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 238) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 31 (task 231, attempt 0, stage 5.0)
[2025-07-19T19:57:19.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 230) in 146 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T19:57:19.597+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 43.0 in stage 5.0 (TID 238)
[2025-07-19T19:57:19.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 31.0 in stage 5.0 (TID 231). 9168 bytes result sent to driver
[2025-07-19T19:57:19.600+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 239) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 48.0 in stage 5.0 (TID 239)
[2025-07-19T19:57:19.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10eefe74
[2025-07-19T19:57:19.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 231) in 147 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T19:57:19.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.1.delta.ec0fb179-dc44-4b16-906b-8d763361713e.TID233.tmp
[2025-07-19T19:57:19.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41] for update
[2025-07-19T19:57:19.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.1.delta.f7e8a1d2-31e2-4244-bf5e-9f8058c57bb1.TID237.tmp
[2025-07-19T19:57:19.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5526d04
[2025-07-19T19:57:19.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48] for update
[2025-07-19T19:57:19.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1245cf1
[2025-07-19T19:57:19.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 33 (task 232, attempt 0, stage 5.0)
[2025-07-19T19:57:19.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 33.0 in stage 5.0 (TID 232). 9191 bytes result sent to driver
[2025-07-19T19:57:19.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 50.0 in stage 5.0 (TID 240) (8b44f3d35cfa, executor driver, partition 50, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 50.0 in stage 5.0 (TID 240)
[2025-07-19T19:57:19.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43] for update
[2025-07-19T19:57:19.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 232) in 119 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T19:57:19.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.1.delta.5ac12aff-9843-4067-9e2e-b152f2d3dd1a.TID236.tmp
[2025-07-19T19:57:19.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.1.delta.8c0b5b01-2757-4b75-9268-2f067bb53a2a.TID239.tmp
[2025-07-19T19:57:19.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.1.delta.27f0d4a2-5f05-4df2-bf11-4b62848f0555.TID234.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/1.delta
[2025-07-19T19:57:19.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/1.delta
[2025-07-19T19:57:19.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 234, attempt 0, stage 5.0)
[2025-07-19T19:57:19.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.1.delta.16ab883e-0cd5-4b2f-bd49-4d0c2c8f94ad.TID235.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/1.delta
[2025-07-19T19:57:19.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/1.delta
[2025-07-19T19:57:19.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ff39a63
[2025-07-19T19:57:19.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 235, attempt 0, stage 5.0)
[2025-07-19T19:57:19.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50] for update
[2025-07-19T19:57:19.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.1.delta.b21c40e4-fb9d-4101-a9a3-f88c3e21d736.TID238.tmp
[2025-07-19T19:57:19.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.1.delta.c7dac153-fdf4-40eb-844c-5984cbd764be.TID240.tmp
[2025-07-19T19:57:19.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.1.delta.f7e8a1d2-31e2-4244-bf5e-9f8058c57bb1.TID237.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/1.delta
[2025-07-19T19:57:19.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/1.delta
[2025-07-19T19:57:19.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 237, attempt 0, stage 5.0)
[2025-07-19T19:57:19.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.1.delta.ec0fb179-dc44-4b16-906b-8d763361713e.TID233.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/1.delta
[2025-07-19T19:57:19.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/1.delta
[2025-07-19T19:57:19.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 233, attempt 0, stage 5.0)
[2025-07-19T19:57:19.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 37 (task 234, attempt 0, stage 5.0)
[2025-07-19T19:57:19.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 37.0 in stage 5.0 (TID 234). 9113 bytes result sent to driver
[2025-07-19T19:57:19.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 51.0 in stage 5.0 (TID 241) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 51.0 in stage 5.0 (TID 241)
[2025-07-19T19:57:19.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 234) in 134 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T19:57:19.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.1.delta.5ac12aff-9843-4067-9e2e-b152f2d3dd1a.TID236.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/1.delta
[2025-07-19T19:57:19.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/1.delta
[2025-07-19T19:57:19.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 236, attempt 0, stage 5.0)
[2025-07-19T19:57:19.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:19.674+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 39 (task 235, attempt 0, stage 5.0)
[2025-07-19T19:57:19.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 39.0 in stage 5.0 (TID 235). 9103 bytes result sent to driver
[2025-07-19T19:57:19.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 52.0 in stage 5.0 (TID 242) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 42 (task 237, attempt 0, stage 5.0)
[2025-07-19T19:57:19.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 35 (task 233, attempt 0, stage 5.0)
[2025-07-19T19:57:19.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 42.0 in stage 5.0 (TID 237). 9117 bytes result sent to driver
[2025-07-19T19:57:19.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 35.0 in stage 5.0 (TID 233). 9148 bytes result sent to driver
[2025-07-19T19:57:19.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 52.0 in stage 5.0 (TID 242)
[2025-07-19T19:57:19.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 235) in 144 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T19:57:19.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 55.0 in stage 5.0 (TID 243) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 59.0 in stage 5.0 (TID 244) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 55.0 in stage 5.0 (TID 243)
[2025-07-19T19:57:19.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.1.delta.8c0b5b01-2757-4b75-9268-2f067bb53a2a.TID239.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/1.delta
[2025-07-19T19:57:19.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/1.delta
[2025-07-19T19:57:19.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 59.0 in stage 5.0 (TID 244)
[2025-07-19T19:57:19.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 237) in 112 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T19:57:19.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c216674
[2025-07-19T19:57:19.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 239, attempt 0, stage 5.0)
[2025-07-19T19:57:19.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 233) in 164 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T19:57:19.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51] for update
[2025-07-19T19:57:19.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.1.delta.b21c40e4-fb9d-4101-a9a3-f88c3e21d736.TID238.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/1.delta
[2025-07-19T19:57:19.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/1.delta
[2025-07-19T19:57:19.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 238, attempt 0, stage 5.0)
[2025-07-19T19:57:19.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@557b7816
[2025-07-19T19:57:19.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59] for update
[2025-07-19T19:57:19.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.1.delta.bda64842-7529-40b7-9cab-4669139fbf58.TID241.tmp
[2025-07-19T19:57:19.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.1.delta.c7dac153-fdf4-40eb-844c-5984cbd764be.TID240.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/1.delta
[2025-07-19T19:57:19.702+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/1.delta
[2025-07-19T19:57:19.702+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17ae33ff
[2025-07-19T19:57:19.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 240, attempt 0, stage 5.0)
[2025-07-19T19:57:19.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55] for update
[2025-07-19T19:57:19.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 41 (task 236, attempt 0, stage 5.0)
[2025-07-19T19:57:19.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 41.0 in stage 5.0 (TID 236). 9135 bytes result sent to driver
[2025-07-19T19:57:19.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 60.0 in stage 5.0 (TID 245) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 236) in 156 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T19:57:19.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 60.0 in stage 5.0 (TID 245)
[2025-07-19T19:57:19.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.1.delta.8f5d5454-6dbf-4900-b16f-6afd0b85a64a.TID244.tmp
[2025-07-19T19:57:19.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 48 (task 239, attempt 0, stage 5.0)
[2025-07-19T19:57:19.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 48.0 in stage 5.0 (TID 239). 9109 bytes result sent to driver
[2025-07-19T19:57:19.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@124e93a1
[2025-07-19T19:57:19.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 62.0 in stage 5.0 (TID 246) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 62.0 in stage 5.0 (TID 246)
[2025-07-19T19:57:19.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 239) in 122 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T19:57:19.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52] for update
[2025-07-19T19:57:19.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 43 (task 238, attempt 0, stage 5.0)
[2025-07-19T19:57:19.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 43.0 in stage 5.0 (TID 238). 9094 bytes result sent to driver
[2025-07-19T19:57:19.722+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 63.0 in stage 5.0 (TID 247) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 63.0 in stage 5.0 (TID 247)
[2025-07-19T19:57:19.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:19.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 238) in 138 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T19:57:19.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 50 (task 240, attempt 0, stage 5.0)
[2025-07-19T19:57:19.729+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.1.delta.bda64842-7529-40b7-9cab-4669139fbf58.TID241.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/1.delta
[2025-07-19T19:57:19.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/1.delta
[2025-07-19T19:57:19.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 241, attempt 0, stage 5.0)
[2025-07-19T19:57:19.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c5e7d4
[2025-07-19T19:57:19.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 50.0 in stage 5.0 (TID 240). 9117 bytes result sent to driver
[2025-07-19T19:57:19.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.1.delta.52baaa23-d76e-49c6-84de-cfd568b3fa99.TID243.tmp
[2025-07-19T19:57:19.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 66.0 in stage 5.0 (TID 248) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 66.0 in stage 5.0 (TID 248)
[2025-07-19T19:57:19.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 50.0 in stage 5.0 (TID 240) in 117 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T19:57:19.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60] for update
[2025-07-19T19:57:19.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.1.delta.a70c0b9d-8998-4e40-9c6d-1a421d2f3a95.TID242.tmp
[2025-07-19T19:57:19.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.737+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.1.delta.595733bb-74af-4329-b727-d57ed3ea9969.TID245.tmp
[2025-07-19T19:57:19.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.1.delta.8f5d5454-6dbf-4900-b16f-6afd0b85a64a.TID244.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/1.delta
[2025-07-19T19:57:19.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/1.delta
[2025-07-19T19:57:19.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 51 (task 241, attempt 0, stage 5.0)
[2025-07-19T19:57:19.749+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 244, attempt 0, stage 5.0)
[2025-07-19T19:57:19.749+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 51.0 in stage 5.0 (TID 241). 9107 bytes result sent to driver
[2025-07-19T19:57:19.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 67.0 in stage 5.0 (TID 249) (8b44f3d35cfa, executor driver, partition 67, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 51.0 in stage 5.0 (TID 241) in 85 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T19:57:19.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37a7ebca
[2025-07-19T19:57:19.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 67.0 in stage 5.0 (TID 249)
[2025-07-19T19:57:19.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:19.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66] for update
[2025-07-19T19:57:19.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.1.delta.a70c0b9d-8998-4e40-9c6d-1a421d2f3a95.TID242.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/1.delta
[2025-07-19T19:57:19.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/1.delta
[2025-07-19T19:57:19.758+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 242, attempt 0, stage 5.0)
[2025-07-19T19:57:19.762+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58a1d448
[2025-07-19T19:57:19.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.1.delta.52baaa23-d76e-49c6-84de-cfd568b3fa99.TID243.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/1.delta
[2025-07-19T19:57:19.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/1.delta
[2025-07-19T19:57:19.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.1.delta.595733bb-74af-4329-b727-d57ed3ea9969.TID245.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/1.delta
[2025-07-19T19:57:19.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/1.delta
[2025-07-19T19:57:19.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67] for update
[2025-07-19T19:57:19.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 245, attempt 0, stage 5.0)
[2025-07-19T19:57:19.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 243, attempt 0, stage 5.0)
[2025-07-19T19:57:19.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22261c7
[2025-07-19T19:57:19.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63] for update
[2025-07-19T19:57:19.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.1.delta.9cf33868-06aa-4e9d-bff0-6f34aeb1dd9f.TID248.tmp
[2025-07-19T19:57:19.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 59 (task 244, attempt 0, stage 5.0)
[2025-07-19T19:57:19.778+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.1.delta.8bf3dd69-507e-40a4-b3c3-ca867c2f1424.TID249.tmp
[2025-07-19T19:57:19.780+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 59.0 in stage 5.0 (TID 244). 9119 bytes result sent to driver
[2025-07-19T19:57:19.780+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f31e311
[2025-07-19T19:57:19.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 68.0 in stage 5.0 (TID 250) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.782+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 59.0 in stage 5.0 (TID 244) in 99 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T19:57:19.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62] for update
[2025-07-19T19:57:19.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 55 (task 243, attempt 0, stage 5.0)
[2025-07-19T19:57:19.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 55.0 in stage 5.0 (TID 243). 9109 bytes result sent to driver
[2025-07-19T19:57:19.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 71.0 in stage 5.0 (TID 251) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.1.delta.70b8ec71-6fa5-4e12-9844-4a48fd7eedf8.TID247.tmp
[2025-07-19T19:57:19.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 52 (task 242, attempt 0, stage 5.0)
[2025-07-19T19:57:19.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 55.0 in stage 5.0 (TID 243) in 109 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T19:57:19.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 71.0 in stage 5.0 (TID 251)
[2025-07-19T19:57:19.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 52.0 in stage 5.0 (TID 242). 9105 bytes result sent to driver
[2025-07-19T19:57:19.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 72.0 in stage 5.0 (TID 252) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 72.0 in stage 5.0 (TID 252)
[2025-07-19T19:57:19.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.1.delta.d2d25e4c-4390-4502-95de-9ce4569580a8.TID246.tmp
[2025-07-19T19:57:19.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 52.0 in stage 5.0 (TID 242) in 120 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T19:57:19.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 68.0 in stage 5.0 (TID 250)
[2025-07-19T19:57:19.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T19:57:19.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 60 (task 245, attempt 0, stage 5.0)
[2025-07-19T19:57:19.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f331d76
[2025-07-19T19:57:19.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 60.0 in stage 5.0 (TID 245). 9120 bytes result sent to driver
[2025-07-19T19:57:19.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T19:57:19.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71] for update
[2025-07-19T19:57:19.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 74.0 in stage 5.0 (TID 253) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 60.0 in stage 5.0 (TID 245) in 104 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T19:57:19.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 74.0 in stage 5.0 (TID 253)
[2025-07-19T19:57:19.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20a3db92
[2025-07-19T19:57:19.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:19.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.1.delta.b225ee4f-c0ca-42ba-a6a7-90d51470fdf1.TID251.tmp
[2025-07-19T19:57:19.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72] for update
[2025-07-19T19:57:19.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.1.delta.9cf33868-06aa-4e9d-bff0-6f34aeb1dd9f.TID248.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/1.delta
[2025-07-19T19:57:19.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/1.delta
[2025-07-19T19:57:19.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 248, attempt 0, stage 5.0)
[2025-07-19T19:57:19.827+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@165d5879
[2025-07-19T19:57:19.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68] for update
[2025-07-19T19:57:19.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.1.delta.4d15f382-4e89-4074-a7e8-ec98a97c8fac.TID252.tmp
[2025-07-19T19:57:19.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.1.delta.8bf3dd69-507e-40a4-b3c3-ca867c2f1424.TID249.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/1.delta
[2025-07-19T19:57:19.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/1.delta
[2025-07-19T19:57:19.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 249, attempt 0, stage 5.0)
[2025-07-19T19:57:19.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.1.delta.70b8ec71-6fa5-4e12-9844-4a48fd7eedf8.TID247.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/1.delta
[2025-07-19T19:57:19.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/1.delta
[2025-07-19T19:57:19.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 247, attempt 0, stage 5.0)
[2025-07-19T19:57:19.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.1.delta.d2d25e4c-4390-4502-95de-9ce4569580a8.TID246.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/1.delta
[2025-07-19T19:57:19.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/1.delta
[2025-07-19T19:57:19.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 246, attempt 0, stage 5.0)
[2025-07-19T19:57:19.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@892abcb
[2025-07-19T19:57:19.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74] for update
[2025-07-19T19:57:19.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 66 (task 248, attempt 0, stage 5.0)
[2025-07-19T19:57:19.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 66.0 in stage 5.0 (TID 248). 9099 bytes result sent to driver
[2025-07-19T19:57:19.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 75.0 in stage 5.0 (TID 254) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 66.0 in stage 5.0 (TID 248) in 114 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T19:57:19.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 75.0 in stage 5.0 (TID 254)
[2025-07-19T19:57:19.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 63 (task 247, attempt 0, stage 5.0)
[2025-07-19T19:57:19.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 63.0 in stage 5.0 (TID 247). 9117 bytes result sent to driver
[2025-07-19T19:57:19.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 76.0 in stage 5.0 (TID 255) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.1.delta.0baa5266-aca2-4fc8-8315-fc8ce2fed5d9.TID250.tmp
[2025-07-19T19:57:19.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 76.0 in stage 5.0 (TID 255)
[2025-07-19T19:57:19.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 63.0 in stage 5.0 (TID 247) in 128 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T19:57:19.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.1.delta.555a6fe4-65ad-4046-aa23-874ced92bf4c.TID253.tmp
[2025-07-19T19:57:19.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 62 (task 246, attempt 0, stage 5.0)
[2025-07-19T19:57:19.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 62.0 in stage 5.0 (TID 246). 9101 bytes result sent to driver
[2025-07-19T19:57:19.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 77.0 in stage 5.0 (TID 256) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.1.delta.b225ee4f-c0ca-42ba-a6a7-90d51470fdf1.TID251.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/1.delta
[2025-07-19T19:57:19.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/1.delta
[2025-07-19T19:57:19.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 251, attempt 0, stage 5.0)
[2025-07-19T19:57:19.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 62.0 in stage 5.0 (TID 246) in 146 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T19:57:19.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69102a9f
[2025-07-19T19:57:19.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 77.0 in stage 5.0 (TID 256)
[2025-07-19T19:57:19.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75] for update
[2025-07-19T19:57:19.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 67 (task 249, attempt 0, stage 5.0)
[2025-07-19T19:57:19.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 67.0 in stage 5.0 (TID 249). 9117 bytes result sent to driver
[2025-07-19T19:57:19.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 78.0 in stage 5.0 (TID 257) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bafe97e
[2025-07-19T19:57:19.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.1.delta.29777e18-e60c-4ef0-a1a0-61605ccc9624.TID254.tmp
[2025-07-19T19:57:19.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77] for update
[2025-07-19T19:57:19.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 71 (task 251, attempt 0, stage 5.0)
[2025-07-19T19:57:19.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 71.0 in stage 5.0 (TID 251). 9122 bytes result sent to driver
[2025-07-19T19:57:19.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 78.0 in stage 5.0 (TID 257)
[2025-07-19T19:57:19.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 80.0 in stage 5.0 (TID 258) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 71.0 in stage 5.0 (TID 251) in 92 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T19:57:19.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 67.0 in stage 5.0 (TID 249) in 129 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T19:57:19.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.1.delta.4d15f382-4e89-4074-a7e8-ec98a97c8fac.TID252.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/1.delta
[2025-07-19T19:57:19.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/1.delta
[2025-07-19T19:57:19.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 80.0 in stage 5.0 (TID 258)
[2025-07-19T19:57:19.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 252, attempt 0, stage 5.0)
[2025-07-19T19:57:19.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T19:57:19.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:19.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69c15066
[2025-07-19T19:57:19.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76] for update
[2025-07-19T19:57:19.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 72 (task 252, attempt 0, stage 5.0)
[2025-07-19T19:57:19.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.1.delta.acd55d93-ab45-47fc-ba1e-ffc26401dc78.TID256.tmp
[2025-07-19T19:57:19.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 72.0 in stage 5.0 (TID 252). 9100 bytes result sent to driver
[2025-07-19T19:57:19.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 82.0 in stage 5.0 (TID 259) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.902+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 82.0 in stage 5.0 (TID 259)
[2025-07-19T19:57:19.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.1.delta.0baa5266-aca2-4fc8-8315-fc8ce2fed5d9.TID250.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/1.delta
[2025-07-19T19:57:19.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/1.delta
[2025-07-19T19:57:19.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 72.0 in stage 5.0 (TID 252) in 111 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T19:57:19.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57252ec6
[2025-07-19T19:57:19.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.913+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80] for update
[2025-07-19T19:57:19.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 250, attempt 0, stage 5.0)
[2025-07-19T19:57:19.916+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.1.delta.555a6fe4-65ad-4046-aa23-874ced92bf4c.TID253.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/1.delta
[2025-07-19T19:57:19.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/1.delta
[2025-07-19T19:57:19.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 253, attempt 0, stage 5.0)
[2025-07-19T19:57:19.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.1.delta.bec68207-2eb4-4f72-ad94-13bac4995cbb.TID255.tmp
[2025-07-19T19:57:19.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e26b2c1
[2025-07-19T19:57:19.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78] for update
[2025-07-19T19:57:19.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.1.delta.29777e18-e60c-4ef0-a1a0-61605ccc9624.TID254.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/1.delta
[2025-07-19T19:57:19.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/1.delta
[2025-07-19T19:57:19.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 254, attempt 0, stage 5.0)
[2025-07-19T19:57:19.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@761c13e6
[2025-07-19T19:57:19.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.1.delta.691c053e-6c45-412b-9a74-740932943ea2.TID258.tmp
[2025-07-19T19:57:19.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82] for update
[2025-07-19T19:57:19.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 68 (task 250, attempt 0, stage 5.0)
[2025-07-19T19:57:19.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.1.delta.001093d5-b40e-4aac-81e3-8449a9cb2cc3.TID257.tmp
[2025-07-19T19:57:19.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 68.0 in stage 5.0 (TID 250). 9162 bytes result sent to driver
[2025-07-19T19:57:19.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 74 (task 253, attempt 0, stage 5.0)
[2025-07-19T19:57:19.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 74.0 in stage 5.0 (TID 253). 9113 bytes result sent to driver
[2025-07-19T19:57:19.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 68.0 in stage 5.0 (TID 250) in 161 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T19:57:19.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 83.0 in stage 5.0 (TID 260) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 83.0 in stage 5.0 (TID 260)
[2025-07-19T19:57:19.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 84.0 in stage 5.0 (TID 261) (8b44f3d35cfa, executor driver, partition 84, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 84.0 in stage 5.0 (TID 261)
[2025-07-19T19:57:19.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:19.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.1.delta.b411dde1-92b3-4ae0-a645-3bbfb66f1c86.TID259.tmp
[2025-07-19T19:57:19.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 74.0 in stage 5.0 (TID 253) in 136 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T19:57:19.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 75 (task 254, attempt 0, stage 5.0)
[2025-07-19T19:57:19.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 75.0 in stage 5.0 (TID 254). 9115 bytes result sent to driver
[2025-07-19T19:57:19.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 85.0 in stage 5.0 (TID 262) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e3e0cd6
[2025-07-19T19:57:19.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 85.0 in stage 5.0 (TID 262)
[2025-07-19T19:57:19.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 75.0 in stage 5.0 (TID 254) in 108 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T19:57:19.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83] for update
[2025-07-19T19:57:19.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.1.delta.acd55d93-ab45-47fc-ba1e-ffc26401dc78.TID256.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/1.delta
[2025-07-19T19:57:19.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.1.delta.bec68207-2eb4-4f72-ad94-13bac4995cbb.TID255.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/1.delta
[2025-07-19T19:57:19.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/1.delta
[2025-07-19T19:57:19.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 255, attempt 0, stage 5.0)
[2025-07-19T19:57:19.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/1.delta
[2025-07-19T19:57:19.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 256, attempt 0, stage 5.0)
[2025-07-19T19:57:19.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a123c5b
[2025-07-19T19:57:19.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84] for update
[2025-07-19T19:57:19.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:19.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.1.delta.06ca816e-36f2-41ab-948f-536237e9a699.TID260.tmp
[2025-07-19T19:57:19.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.1.delta.691c053e-6c45-412b-9a74-740932943ea2.TID258.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/1.delta
[2025-07-19T19:57:19.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/1.delta
[2025-07-19T19:57:19.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 258, attempt 0, stage 5.0)
[2025-07-19T19:57:19.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@720ddd59
[2025-07-19T19:57:19.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:19.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85] for update
[2025-07-19T19:57:19.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:19.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 77 (task 256, attempt 0, stage 5.0)
[2025-07-19T19:57:19.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 76 (task 255, attempt 0, stage 5.0)
[2025-07-19T19:57:19.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.1.delta.d8cdfd36-730b-4e42-98f5-d97ca9853cd6.TID261.tmp
[2025-07-19T19:57:19.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 76.0 in stage 5.0 (TID 255). 9152 bytes result sent to driver
[2025-07-19T19:57:19.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 77.0 in stage 5.0 (TID 256). 9175 bytes result sent to driver
[2025-07-19T19:57:19.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 88.0 in stage 5.0 (TID 263) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:19.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 76.0 in stage 5.0 (TID 255) in 139 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T19:57:19.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.1.delta.001093d5-b40e-4aac-81e3-8449a9cb2cc3.TID257.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/1.delta
[2025-07-19T19:57:19.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/1.delta
[2025-07-19T19:57:19.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 257, attempt 0, stage 5.0)
[2025-07-19T19:57:19.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 88.0 in stage 5.0 (TID 263)
[2025-07-19T19:57:19.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Committed partition 80 (task 258, attempt 0, stage 5.0)
[2025-07-19T19:57:19.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Finished task 80.0 in stage 5.0 (TID 258). 9162 bytes result sent to driver
[2025-07-19T19:57:19.994+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:19.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:19.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.1.delta.b411dde1-92b3-4ae0-a645-3bbfb66f1c86.TID259.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/1.delta
[2025-07-19T19:57:19.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.1.delta.97f207fa-91b4-4be3-a155-a02e628ffbde.TID262.tmp
[2025-07-19T19:57:19.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/1.delta
[2025-07-19T19:57:19.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 94.0 in stage 5.0 (TID 264) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 259, attempt 0, stage 5.0)
[2025-07-19T19:57:20.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 94.0 in stage 5.0 (TID 264)
[2025-07-19T19:57:20.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Finished task 77.0 in stage 5.0 (TID 256) in 143 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T19:57:20.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO TaskSetManager: Starting task 96.0 in stage 5.0 (TID 265) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:19 INFO Executor: Running task 96.0 in stage 5.0 (TID 265)
[2025-07-19T19:57:20.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 80.0 in stage 5.0 (TID 258) in 126 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T19:57:20.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a63135c
[2025-07-19T19:57:20.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:20.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:20.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88] for update
[2025-07-19T19:57:20.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67237980
[2025-07-19T19:57:20.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 78 (task 257, attempt 0, stage 5.0)
[2025-07-19T19:57:20.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 78.0 in stage 5.0 (TID 257). 9172 bytes result sent to driver
[2025-07-19T19:57:20.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94] for update
[2025-07-19T19:57:20.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 97.0 in stage 5.0 (TID 266) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 78.0 in stage 5.0 (TID 257) in 161 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T19:57:20.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 97.0 in stage 5.0 (TID 266)
[2025-07-19T19:57:20.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.1.delta.06ca816e-36f2-41ab-948f-536237e9a699.TID260.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/1.delta
[2025-07-19T19:57:20.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/1.delta
[2025-07-19T19:57:20.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c37c67c
[2025-07-19T19:57:20.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 82 (task 259, attempt 0, stage 5.0)
[2025-07-19T19:57:20.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 260, attempt 0, stage 5.0)
[2025-07-19T19:57:20.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96] for update
[2025-07-19T19:57:20.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.1.delta.d8cdfd36-730b-4e42-98f5-d97ca9853cd6.TID261.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/1.delta
[2025-07-19T19:57:20.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/1.delta
[2025-07-19T19:57:20.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 261, attempt 0, stage 5.0)
[2025-07-19T19:57:20.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 82.0 in stage 5.0 (TID 259). 9148 bytes result sent to driver
[2025-07-19T19:57:20.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.1.delta.ee664c12-24b0-4936-bb23-4d1a5ced9d04.TID263.tmp
[2025-07-19T19:57:20.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 99.0 in stage 5.0 (TID 267) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 82.0 in stage 5.0 (TID 259) in 138 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T19:57:20.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 99.0 in stage 5.0 (TID 267)
[2025-07-19T19:57:20.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.1.delta.606cee2d-90b6-4045-8930-b7c7365871a0.TID264.tmp
[2025-07-19T19:57:20.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7590a785
[2025-07-19T19:57:20.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97] for update
[2025-07-19T19:57:20.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.1.delta.97f207fa-91b4-4be3-a155-a02e628ffbde.TID262.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/1.delta
[2025-07-19T19:57:20.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/1.delta
[2025-07-19T19:57:20.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 262, attempt 0, stage 5.0)
[2025-07-19T19:57:20.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.1.delta.99ec402a-151c-41d2-873c-5d4ee7857e48.TID265.tmp
[2025-07-19T19:57:20.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T19:57:20.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.1.delta.ffac8291-2e1e-4e9a-a281-afa423fc4498.TID266.tmp
[2025-07-19T19:57:20.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ef54479
[2025-07-19T19:57:20.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99] for update
[2025-07-19T19:57:20.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 83 (task 260, attempt 0, stage 5.0)
[2025-07-19T19:57:20.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 84 (task 261, attempt 0, stage 5.0)
[2025-07-19T19:57:20.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 83.0 in stage 5.0 (TID 260). 9156 bytes result sent to driver
[2025-07-19T19:57:20.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 84.0 in stage 5.0 (TID 261). 9154 bytes result sent to driver
[2025-07-19T19:57:20.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 100.0 in stage 5.0 (TID 268) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 103.0 in stage 5.0 (TID 269) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 100.0 in stage 5.0 (TID 268)
[2025-07-19T19:57:20.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 83.0 in stage 5.0 (TID 260) in 125 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T19:57:20.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 84.0 in stage 5.0 (TID 261) in 124 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T19:57:20.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 103.0 in stage 5.0 (TID 269)
[2025-07-19T19:57:20.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 85 (task 262, attempt 0, stage 5.0)
[2025-07-19T19:57:20.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.1.delta.2bba58cf-20ad-4d53-bcab-58755796583f.TID267.tmp
[2025-07-19T19:57:20.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.1.delta.ee664c12-24b0-4936-bb23-4d1a5ced9d04.TID263.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/1.delta
[2025-07-19T19:57:20.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/1.delta
[2025-07-19T19:57:20.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 85.0 in stage 5.0 (TID 262). 9203 bytes result sent to driver
[2025-07-19T19:57:20.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 263, attempt 0, stage 5.0)
[2025-07-19T19:57:20.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@223bb8f7
[2025-07-19T19:57:20.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 104.0 in stage 5.0 (TID 270) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103] for update
[2025-07-19T19:57:20.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Reservations_raw/metadata/v45.metadata.json
[2025-07-19T19:57:20.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 85.0 in stage 5.0 (TID 262) in 197 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T19:57:20.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 104.0 in stage 5.0 (TID 270)
[2025-07-19T19:57:20.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.1.delta.606cee2d-90b6-4045-8930-b7c7365871a0.TID264.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/1.delta
[2025-07-19T19:57:20.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/1.delta
[2025-07-19T19:57:20.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 264, attempt 0, stage 5.0)
[2025-07-19T19:57:20.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 88 (task 263, attempt 0, stage 5.0)
[2025-07-19T19:57:20.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 88.0 in stage 5.0 (TID 263). 9162 bytes result sent to driver
[2025-07-19T19:57:20.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f04799
[2025-07-19T19:57:20.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100] for update
[2025-07-19T19:57:20.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 106.0 in stage 5.0 (TID 271) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 88.0 in stage 5.0 (TID 263) in 182 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T19:57:20.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 106.0 in stage 5.0 (TID 271)
[2025-07-19T19:57:20.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.1.delta.99ec402a-151c-41d2-873c-5d4ee7857e48.TID265.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/1.delta
[2025-07-19T19:57:20.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/1.delta
[2025-07-19T19:57:20.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.1.delta.2bba58cf-20ad-4d53-bcab-58755796583f.TID267.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/1.delta
[2025-07-19T19:57:20.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/1.delta
[2025-07-19T19:57:20.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.1.delta.ffac8291-2e1e-4e9a-a281-afa423fc4498.TID266.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/1.delta
[2025-07-19T19:57:20.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/1.delta
[2025-07-19T19:57:20.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 265, attempt 0, stage 5.0)
[2025-07-19T19:57:20.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 266, attempt 0, stage 5.0)
[2025-07-19T19:57:20.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 267, attempt 0, stage 5.0)
[2025-07-19T19:57:20.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@582af1a6
[2025-07-19T19:57:20.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104] for update
[2025-07-19T19:57:20.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.1.delta.de2fec6c-9a42-4537-a573-5c0cc67e9942.TID269.tmp
[2025-07-19T19:57:20.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.1.delta.3935ec1c-ab53-4951-89ba-ba03302c5952.TID268.tmp
[2025-07-19T19:57:20.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5302f314
[2025-07-19T19:57:20.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106] for update
[2025-07-19T19:57:20.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.1.delta.503a8a0a-31c3-48d8-a6a2-573630016754.TID270.tmp
[2025-07-19T19:57:20.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 99 (task 267, attempt 0, stage 5.0)
[2025-07-19T19:57:20.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 97 (task 266, attempt 0, stage 5.0)
[2025-07-19T19:57:20.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 96 (task 265, attempt 0, stage 5.0)
[2025-07-19T19:57:20.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 97.0 in stage 5.0 (TID 266). 9141 bytes result sent to driver
[2025-07-19T19:57:20.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 99.0 in stage 5.0 (TID 267). 9201 bytes result sent to driver
[2025-07-19T19:57:20.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.1.delta.f96ea55d-3acd-4ba1-abfe-5fc54c57c201.TID271.tmp
[2025-07-19T19:57:20.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 111.0 in stage 5.0 (TID 272) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 96.0 in stage 5.0 (TID 265). 9213 bytes result sent to driver
[2025-07-19T19:57:20.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 111.0 in stage 5.0 (TID 272)
[2025-07-19T19:57:20.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 112.0 in stage 5.0 (TID 273) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 113.0 in stage 5.0 (TID 274) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 97.0 in stage 5.0 (TID 266) in 182 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T19:57:20.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 112.0 in stage 5.0 (TID 273)
[2025-07-19T19:57:20.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 99.0 in stage 5.0 (TID 267) in 171 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T19:57:20.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 113.0 in stage 5.0 (TID 274)
[2025-07-19T19:57:20.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 96.0 in stage 5.0 (TID 265) in 207 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T19:57:20.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:20.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:20.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 94 (task 264, attempt 0, stage 5.0)
[2025-07-19T19:57:20.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 94.0 in stage 5.0 (TID 264). 9163 bytes result sent to driver
[2025-07-19T19:57:20.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 114.0 in stage 5.0 (TID 275) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 114.0 in stage 5.0 (TID 275)
[2025-07-19T19:57:20.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 94.0 in stage 5.0 (TID 264) in 217 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T19:57:20.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6019cbde
[2025-07-19T19:57:20.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111] for update
[2025-07-19T19:57:20.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12123ed8
[2025-07-19T19:57:20.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113] for update
[2025-07-19T19:57:20.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.1.delta.3935ec1c-ab53-4951-89ba-ba03302c5952.TID268.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/1.delta
[2025-07-19T19:57:20.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/1.delta
[2025-07-19T19:57:20.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO SnapshotProducer: Committed snapshot 1361893699345442556 (FastAppend)
[2025-07-19T19:57:20.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.1.delta.de2fec6c-9a42-4537-a573-5c0cc67e9942.TID269.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/1.delta
[2025-07-19T19:57:20.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/1.delta
[2025-07-19T19:57:20.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 268, attempt 0, stage 5.0)
[2025-07-19T19:57:20.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 269, attempt 0, stage 5.0)
[2025-07-19T19:57:20.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.1.delta.503a8a0a-31c3-48d8-a6a2-573630016754.TID270.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/1.delta
[2025-07-19T19:57:20.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/1.delta
[2025-07-19T19:57:20.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 270, attempt 0, stage 5.0)
[2025-07-19T19:57:20.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.1.delta.2a62de14-313e-4426-9c23-1a1eaf1f0ff0.TID272.tmp
[2025-07-19T19:57:20.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14889a86
[2025-07-19T19:57:20.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114] for update
[2025-07-19T19:57:20.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.1.delta.ebb465f8-d442-4e02-a461-c455c5b9962e.TID274.tmp
[2025-07-19T19:57:20.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.1.delta.f96ea55d-3acd-4ba1-abfe-5fc54c57c201.TID271.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/1.delta
[2025-07-19T19:57:20.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/1.delta
[2025-07-19T19:57:20.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f0078ff
[2025-07-19T19:57:20.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 271, attempt 0, stage 5.0)
[2025-07-19T19:57:20.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112] for update
[2025-07-19T19:57:20.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.1.delta.f04f2fb2-0f29-4887-90f4-c603e5879e74.TID275.tmp
[2025-07-19T19:57:20.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 100 (task 268, attempt 0, stage 5.0)
[2025-07-19T19:57:20.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 103 (task 269, attempt 0, stage 5.0)
[2025-07-19T19:57:20.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 100.0 in stage 5.0 (TID 268). 9163 bytes result sent to driver
[2025-07-19T19:57:20.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 103.0 in stage 5.0 (TID 269). 9148 bytes result sent to driver
[2025-07-19T19:57:20.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 115.0 in stage 5.0 (TID 276) (8b44f3d35cfa, executor driver, partition 115, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 115.0 in stage 5.0 (TID 276)
[2025-07-19T19:57:20.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 117.0 in stage 5.0 (TID 277) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 117.0 in stage 5.0 (TID 277)
[2025-07-19T19:57:20.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 100.0 in stage 5.0 (TID 268) in 189 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T19:57:20.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 103.0 in stage 5.0 (TID 269) in 190 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T19:57:20.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 104 (task 270, attempt 0, stage 5.0)
[2025-07-19T19:57:20.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 104.0 in stage 5.0 (TID 270). 9160 bytes result sent to driver
[2025-07-19T19:57:20.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 118.0 in stage 5.0 (TID 278) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 118.0 in stage 5.0 (TID 278)
[2025-07-19T19:57:20.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 104.0 in stage 5.0 (TID 270) in 132 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T19:57:20.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.1.delta.a3a43d17-af3a-428e-974d-1e927ac02ed8.TID273.tmp
[2025-07-19T19:57:20.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 106 (task 271, attempt 0, stage 5.0)
[2025-07-19T19:57:20.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2178b4c5
[2025-07-19T19:57:20.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 106.0 in stage 5.0 (TID 271). 9156 bytes result sent to driver
[2025-07-19T19:57:20.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 119.0 in stage 5.0 (TID 279) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115] for update
[2025-07-19T19:57:20.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 119.0 in stage 5.0 (TID 279)
[2025-07-19T19:57:20.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 106.0 in stage 5.0 (TID 271) in 100 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T19:57:20.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.1.delta.2a62de14-313e-4426-9c23-1a1eaf1f0ff0.TID272.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/1.delta
[2025-07-19T19:57:20.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/1.delta
[2025-07-19T19:57:20.277+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 272, attempt 0, stage 5.0)
[2025-07-19T19:57:20.277+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ce09cc3
[2025-07-19T19:57:20.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117] for update
[2025-07-19T19:57:20.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.1.delta.893f3236-581d-403f-b565-9faba6590418.TID276.tmp
[2025-07-19T19:57:20.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a985a82
[2025-07-19T19:57:20.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118] for update
[2025-07-19T19:57:20.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.1.delta.ebb465f8-d442-4e02-a461-c455c5b9962e.TID274.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/1.delta
[2025-07-19T19:57:20.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/1.delta
[2025-07-19T19:57:20.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 274, attempt 0, stage 5.0)
[2025-07-19T19:57:20.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@218460cd
[2025-07-19T19:57:20.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119] for update
[2025-07-19T19:57:20.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.1.delta.f04f2fb2-0f29-4887-90f4-c603e5879e74.TID275.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/1.delta
[2025-07-19T19:57:20.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/1.delta
[2025-07-19T19:57:20.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 275, attempt 0, stage 5.0)
[2025-07-19T19:57:20.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 111 (task 272, attempt 0, stage 5.0)
[2025-07-19T19:57:20.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.1.delta.333d9e04-3d12-4232-a232-ce6327732986.TID278.tmp
[2025-07-19T19:57:20.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 111.0 in stage 5.0 (TID 272). 9167 bytes result sent to driver
[2025-07-19T19:57:20.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 120.0 in stage 5.0 (TID 280) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.1.delta.1828f8b9-c6cf-4a1f-bac2-d15202a15c9d.TID277.tmp
[2025-07-19T19:57:20.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 120.0 in stage 5.0 (TID 280)
[2025-07-19T19:57:20.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 111.0 in stage 5.0 (TID 272) in 107 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T19:57:20.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.1.delta.a3a43d17-af3a-428e-974d-1e927ac02ed8.TID273.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/1.delta
[2025-07-19T19:57:20.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/1.delta
[2025-07-19T19:57:20.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 273, attempt 0, stage 5.0)
[2025-07-19T19:57:20.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1adaaeaa
[2025-07-19T19:57:20.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120] for update
[2025-07-19T19:57:20.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.1.delta.2fbd996c-e251-4a5e-891b-6b22d1678e10.TID279.tmp
[2025-07-19T19:57:20.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 113 (task 274, attempt 0, stage 5.0)
[2025-07-19T19:57:20.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 113.0 in stage 5.0 (TID 274). 9158 bytes result sent to driver
[2025-07-19T19:57:20.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 114 (task 275, attempt 0, stage 5.0)
[2025-07-19T19:57:20.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 114.0 in stage 5.0 (TID 275). 9156 bytes result sent to driver
[2025-07-19T19:57:20.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.1.delta.893f3236-581d-403f-b565-9faba6590418.TID276.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/1.delta
[2025-07-19T19:57:20.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/1.delta
[2025-07-19T19:57:20.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 121.0 in stage 5.0 (TID 281) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 276, attempt 0, stage 5.0)
[2025-07-19T19:57:20.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 121.0 in stage 5.0 (TID 281)
[2025-07-19T19:57:20.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 122.0 in stage 5.0 (TID 282) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 122.0 in stage 5.0 (TID 282)
[2025-07-19T19:57:20.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 114.0 in stage 5.0 (TID 275) in 116 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T19:57:20.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 113.0 in stage 5.0 (TID 274) in 121 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T19:57:20.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.1.delta.2fe7a8d6-aa92-4691-922a-cd8d00813b96.TID280.tmp
[2025-07-19T19:57:20.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.1.delta.333d9e04-3d12-4232-a232-ce6327732986.TID278.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/1.delta
[2025-07-19T19:57:20.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/1.delta
[2025-07-19T19:57:20.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.1.delta.1828f8b9-c6cf-4a1f-bac2-d15202a15c9d.TID277.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/1.delta
[2025-07-19T19:57:20.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/1.delta
[2025-07-19T19:57:20.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 278, attempt 0, stage 5.0)
[2025-07-19T19:57:20.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 277, attempt 0, stage 5.0)
[2025-07-19T19:57:20.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ac070a
[2025-07-19T19:57:20.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122] for update
[2025-07-19T19:57:20.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Reservations_raw, snapshotId=1361893699345442556, sequenceNumber=44, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.938816959S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=115}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=3641}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=168}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=4732}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=343414}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=10832104}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752955029831, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T19:57:20.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO SparkWrite: Committed in 974 ms
[2025-07-19T19:57:20.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23d5fe48
[2025-07-19T19:57:20.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] committed.
[2025-07-19T19:57:20.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121] for update
[2025-07-19T19:57:20.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 112 (task 273, attempt 0, stage 5.0)
[2025-07-19T19:57:20.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 112.0 in stage 5.0 (TID 273). 9166 bytes result sent to driver
[2025-07-19T19:57:20.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 125.0 in stage 5.0 (TID 283) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 112.0 in stage 5.0 (TID 273) in 140 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T19:57:20.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 125.0 in stage 5.0 (TID 283)
[2025-07-19T19:57:20.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.1.delta.2fbd996c-e251-4a5e-891b-6b22d1678e10.TID279.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/1.delta
[2025-07-19T19:57:20.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/1.delta
[2025-07-19T19:57:20.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 279, attempt 0, stage 5.0)
[2025-07-19T19:57:20.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:20.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.1.delta.2fe7a8d6-aa92-4691-922a-cd8d00813b96.TID280.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/1.delta
[2025-07-19T19:57:20.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/1.delta
[2025-07-19T19:57:20.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 280, attempt 0, stage 5.0)
[2025-07-19T19:57:20.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.1.delta.9dfc5c63-acf3-40e7-8781-467fdbeeb845.TID281.tmp
[2025-07-19T19:57:20.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.1.delta.6d8da8e3-9f40-4bd7-9f63-7b3d9a472ec9.TID282.tmp
[2025-07-19T19:57:20.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 117 (task 277, attempt 0, stage 5.0)
[2025-07-19T19:57:20.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 117.0 in stage 5.0 (TID 277). 9119 bytes result sent to driver
[2025-07-19T19:57:20.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e4615f4
[2025-07-19T19:57:20.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 128.0 in stage 5.0 (TID 284) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 115 (task 276, attempt 0, stage 5.0)
[2025-07-19T19:57:20.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 128.0 in stage 5.0 (TID 284)
[2025-07-19T19:57:20.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 117.0 in stage 5.0 (TID 277) in 117 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T19:57:20.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125] for update
[2025-07-19T19:57:20.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 115.0 in stage 5.0 (TID 276). 9099 bytes result sent to driver
[2025-07-19T19:57:20.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 129.0 in stage 5.0 (TID 285) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.391+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.391+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 129.0 in stage 5.0 (TID 285)
[2025-07-19T19:57:20.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:20.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 115.0 in stage 5.0 (TID 276) in 124 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T19:57:20.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 119 (task 279, attempt 0, stage 5.0)
[2025-07-19T19:57:20.394+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 119.0 in stage 5.0 (TID 279). 9109 bytes result sent to driver
[2025-07-19T19:57:20.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 130.0 in stage 5.0 (TID 286) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 119.0 in stage 5.0 (TID 279) in 114 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T19:57:20.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78fea74c
[2025-07-19T19:57:20.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 130.0 in stage 5.0 (TID 286)
[2025-07-19T19:57:20.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128] for update
[2025-07-19T19:57:20.397+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 120 (task 280, attempt 0, stage 5.0)
[2025-07-19T19:57:20.397+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.398+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.1.delta.b3fcba08-1a50-4155-beeb-49574e8ce75d.TID283.tmp
[2025-07-19T19:57:20.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 120.0 in stage 5.0 (TID 280). 9126 bytes result sent to driver
[2025-07-19T19:57:20.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 131.0 in stage 5.0 (TID 287) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/commits/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/commits/.0.3209b041-2b26-4311-8fcc-669a91cd8cfd.tmp
[2025-07-19T19:57:20.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 131.0 in stage 5.0 (TID 287)
[2025-07-19T19:57:20.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 120.0 in stage 5.0 (TID 280) in 97 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T19:57:20.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 118 (task 278, attempt 0, stage 5.0)
[2025-07-19T19:57:20.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 118.0 in stage 5.0 (TID 278). 9113 bytes result sent to driver
[2025-07-19T19:57:20.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ae84f79
[2025-07-19T19:57:20.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 133.0 in stage 5.0 (TID 288) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129] for update
[2025-07-19T19:57:20.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 133.0 in stage 5.0 (TID 288)
[2025-07-19T19:57:20.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 118.0 in stage 5.0 (TID 278) in 144 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T19:57:20.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.1.delta.3e08252c-88dd-4e08-8c26-27ce5a2fdc33.TID284.tmp
[2025-07-19T19:57:20.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52b0d18c
[2025-07-19T19:57:20.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:20.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131] for update
[2025-07-19T19:57:20.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.1.delta.1d04a0f8-b27c-4c37-a439-8d1210657393.TID285.tmp
[2025-07-19T19:57:20.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.1.delta.9dfc5c63-acf3-40e7-8781-467fdbeeb845.TID281.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/1.delta
[2025-07-19T19:57:20.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/1.delta
[2025-07-19T19:57:20.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 281, attempt 0, stage 5.0)
[2025-07-19T19:57:20.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47df7432
[2025-07-19T19:57:20.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.1.delta.6d8da8e3-9f40-4bd7-9f63-7b3d9a472ec9.TID282.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/1.delta
[2025-07-19T19:57:20.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/1.delta
[2025-07-19T19:57:20.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130] for update
[2025-07-19T19:57:20.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 282, attempt 0, stage 5.0)
[2025-07-19T19:57:20.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.1.delta.ad2ea120-284e-4e3d-9c76-60c348ac6466.TID287.tmp
[2025-07-19T19:57:20.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38cb94aa
[2025-07-19T19:57:20.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133] for update
[2025-07-19T19:57:20.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.1.delta.a58dab2c-d88a-48c2-b9e1-56588b399b4e.TID286.tmp
[2025-07-19T19:57:20.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 121 (task 281, attempt 0, stage 5.0)
[2025-07-19T19:57:20.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 122 (task 282, attempt 0, stage 5.0)
[2025-07-19T19:57:20.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 122.0 in stage 5.0 (TID 282). 9152 bytes result sent to driver
[2025-07-19T19:57:20.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 121.0 in stage 5.0 (TID 281). 9152 bytes result sent to driver
[2025-07-19T19:57:20.438+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.1.delta.b3fcba08-1a50-4155-beeb-49574e8ce75d.TID283.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/1.delta
[2025-07-19T19:57:20.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/1.delta
[2025-07-19T19:57:20.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 134.0 in stage 5.0 (TID 289) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 134.0 in stage 5.0 (TID 289)
[2025-07-19T19:57:20.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 135.0 in stage 5.0 (TID 290) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 135.0 in stage 5.0 (TID 290)
[2025-07-19T19:57:20.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 121.0 in stage 5.0 (TID 281) in 118 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T19:57:20.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 122.0 in stage 5.0 (TID 282) in 117 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T19:57:20.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 283, attempt 0, stage 5.0)
[2025-07-19T19:57:20.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.1.delta.bbc4708a-f3cc-4a8b-a634-e8b926e58a42.TID288.tmp
[2025-07-19T19:57:20.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/commits/.0.3209b041-2b26-4311-8fcc-669a91cd8cfd.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T19:54:00+00:00/commits/0
[2025-07-19T19:57:20.446+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.446+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:20.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.1.delta.3e08252c-88dd-4e08-8c26-27ce5a2fdc33.TID284.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/1.delta
[2025-07-19T19:57:20.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/1.delta
[2025-07-19T19:57:20.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 284, attempt 0, stage 5.0)
[2025-07-19T19:57:20.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b725173
[2025-07-19T19:57:20.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135] for update
[2025-07-19T19:57:20.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 125 (task 283, attempt 0, stage 5.0)
[2025-07-19T19:57:20.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 125.0 in stage 5.0 (TID 283). 9158 bytes result sent to driver
[2025-07-19T19:57:20.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39897c76
[2025-07-19T19:57:20.464+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.464+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134] for update
[2025-07-19T19:57:20.465+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 137.0 in stage 5.0 (TID 291) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.1.delta.1d04a0f8-b27c-4c37-a439-8d1210657393.TID285.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/1.delta
[2025-07-19T19:57:20.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 137.0 in stage 5.0 (TID 291)
[2025-07-19T19:57:20.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/1.delta
[2025-07-19T19:57:20.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 128 (task 284, attempt 0, stage 5.0)
[2025-07-19T19:57:20.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 285, attempt 0, stage 5.0)
[2025-07-19T19:57:20.476+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 125.0 in stage 5.0 (TID 283) in 126 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T19:57:20.476+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 128.0 in stage 5.0 (TID 284). 9169 bytes result sent to driver
[2025-07-19T19:57:20.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 139.0 in stage 5.0 (TID 292) (8b44f3d35cfa, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.1.delta.ad2ea120-284e-4e3d-9c76-60c348ac6466.TID287.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/1.delta
[2025-07-19T19:57:20.478+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/1.delta
[2025-07-19T19:57:20.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 128.0 in stage 5.0 (TID 284) in 109 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T19:57:20.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 287, attempt 0, stage 5.0)
[2025-07-19T19:57:20.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 139.0 in stage 5.0 (TID 292)
[2025-07-19T19:57:20.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.1.delta.56df4926-062c-4c07-b793-f59f5a21b8e0.TID289.tmp
[2025-07-19T19:57:20.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.1.delta.320ed07c-c1ad-49ab-8cd5-f2eedda5d3d6.TID290.tmp
[2025-07-19T19:57:20.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.1.delta.a58dab2c-d88a-48c2-b9e1-56588b399b4e.TID286.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/1.delta
[2025-07-19T19:57:20.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/1.delta
[2025-07-19T19:57:20.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 286, attempt 0, stage 5.0)
[2025-07-19T19:57:20.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79f1016c
[2025-07-19T19:57:20.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137] for update
[2025-07-19T19:57:20.492+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7470334c
[2025-07-19T19:57:20.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139] for update
[2025-07-19T19:57:20.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 131 (task 287, attempt 0, stage 5.0)
[2025-07-19T19:57:20.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 131.0 in stage 5.0 (TID 287). 9152 bytes result sent to driver
[2025-07-19T19:57:20.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 141.0 in stage 5.0 (TID 293) (8b44f3d35cfa, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 141.0 in stage 5.0 (TID 293)
[2025-07-19T19:57:20.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 131.0 in stage 5.0 (TID 287) in 111 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T19:57:20.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:20.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 129 (task 285, attempt 0, stage 5.0)
[2025-07-19T19:57:20.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 129.0 in stage 5.0 (TID 285). 9149 bytes result sent to driver
[2025-07-19T19:57:20.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.1.delta.41bcc964-21c4-40d2-a2dd-c2a0c0a331e8.TID291.tmp
[2025-07-19T19:57:20.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 142.0 in stage 5.0 (TID 294) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 142.0 in stage 5.0 (TID 294)
[2025-07-19T19:57:20.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 129.0 in stage 5.0 (TID 285) in 139 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T19:57:20.514+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.1.delta.329f259b-419f-41aa-8b5d-e5bcb5e5f0a2.TID292.tmp
[2025-07-19T19:57:20.514+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.1.delta.bbc4708a-f3cc-4a8b-a634-e8b926e58a42.TID288.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/1.delta
[2025-07-19T19:57:20.515+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/1.delta
[2025-07-19T19:57:20.516+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 130 (task 286, attempt 0, stage 5.0)
[2025-07-19T19:57:20.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b02f96d
[2025-07-19T19:57:20.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 288, attempt 0, stage 5.0)
[2025-07-19T19:57:20.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141] for update
[2025-07-19T19:57:20.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 130.0 in stage 5.0 (TID 286). 9174 bytes result sent to driver
[2025-07-19T19:57:20.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 143.0 in stage 5.0 (TID 295) (8b44f3d35cfa, executor driver, partition 143, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 143.0 in stage 5.0 (TID 295)
[2025-07-19T19:57:20.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 130.0 in stage 5.0 (TID 286) in 135 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T19:57:20.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T19:57:20.522+0000] {subprocess.py:93} INFO -   "id" : "5253d98e-255c-4533-9785-660d38a21faf",
[2025-07-19T19:57:20.522+0000] {subprocess.py:93} INFO -   "runId" : "8d7b6976-38a8-4337-af61-4ae74f3cdde4",
[2025-07-19T19:57:20.522+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T19:57:20.523+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T19:57:11.960Z",
[2025-07-19T19:57:20.523+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T19:57:20.524+0000] {subprocess.py:93} INFO -   "numInputRows" : 174,
[2025-07-19T19:57:20.524+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:20.524+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 20.506776664702418,
[2025-07-19T19:57:20.525+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T19:57:20.525+0000] {subprocess.py:93} INFO -     "addBatch" : 7289,
[2025-07-19T19:57:20.526+0000] {subprocess.py:93} INFO -     "commitOffsets" : 75,
[2025-07-19T19:57:20.526+0000] {subprocess.py:93} INFO -     "getBatch" : 19,
[2025-07-19T19:57:20.526+0000] {subprocess.py:93} INFO -     "latestOffset" : 520,
[2025-07-19T19:57:20.527+0000] {subprocess.py:93} INFO -     "queryPlanning" : 499,
[2025-07-19T19:57:20.527+0000] {subprocess.py:93} INFO -     "triggerExecution" : 8484,
[2025-07-19T19:57:20.527+0000] {subprocess.py:93} INFO -     "walCommit" : 47
[2025-07-19T19:57:20.528+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:20.531+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T19:57:20.531+0000] {subprocess.py:93} INFO -     "avg" : "1970-01-01T00:00:00.000Z",
[2025-07-19T19:57:20.531+0000] {subprocess.py:93} INFO -     "max" : "1970-01-01T00:00:00.000Z",
[2025-07-19T19:57:20.532+0000] {subprocess.py:93} INFO -     "min" : "1970-01-01T00:00:00.000Z",
[2025-07-19T19:57:20.532+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T19:57:20.532+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:20.533+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T19:57:20.533+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T19:57:20.535+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 168,
[2025-07-19T19:57:20.535+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 168,
[2025-07-19T19:57:20.536+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 2713,
[2025-07-19T19:57:20.536+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T19:57:20.536+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 256,
[2025-07-19T19:57:20.537+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 10679,
[2025-07-19T19:57:20.537+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 88112,
[2025-07-19T19:57:20.537+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T19:57:20.537+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T19:57:20.537+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T19:57:20.537+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T19:57:20.538+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T19:57:20.538+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T19:57:20.538+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 6,
[2025-07-19T19:57:20.538+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 59312
[2025-07-19T19:57:20.538+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:20.539+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:20.539+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T19:57:20.540+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[reservations]]",
[2025-07-19T19:57:20.540+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T19:57:20.540+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T19:57:20.541+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T19:57:20.541+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:20.541+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:20.541+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:20.541+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T19:57:20.542+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T19:57:20.542+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:20.542+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:20.542+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:20.542+0000] {subprocess.py:93} INFO -     "numInputRows" : 174,
[2025-07-19T19:57:20.542+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:20.542+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 20.506776664702418,
[2025-07-19T19:57:20.543+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T19:57:20.543+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T19:57:20.543+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T19:57:20.543+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T19:57:20.544+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:20.544+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:20.544+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T19:57:20.545+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Reservations_raw",
[2025-07-19T19:57:20.546+0000] {subprocess.py:93} INFO -     "numOutputRows" : 168
[2025-07-19T19:57:20.547+0000] {subprocess.py:93} INFO -   }
[2025-07-19T19:57:20.547+0000] {subprocess.py:93} INFO - }
[2025-07-19T19:57:20.548+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.1.delta.f6c45fea-d51b-44c7-aa94-a01c924e638b.TID293.tmp
[2025-07-19T19:57:20.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d14c20
[2025-07-19T19:57:20.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142] for update
[2025-07-19T19:57:20.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.1.delta.56df4926-062c-4c07-b793-f59f5a21b8e0.TID289.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/1.delta
[2025-07-19T19:57:20.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/1.delta
[2025-07-19T19:57:20.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 289, attempt 0, stage 5.0)
[2025-07-19T19:57:20.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4288de7d
[2025-07-19T19:57:20.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 133 (task 288, attempt 0, stage 5.0)
[2025-07-19T19:57:20.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143] for update
[2025-07-19T19:57:20.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 133.0 in stage 5.0 (TID 288). 9203 bytes result sent to driver
[2025-07-19T19:57:20.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 144.0 in stage 5.0 (TID 296) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.1.delta.0e37ed0e-09cc-49af-a9a1-cdd24a2d813a.TID294.tmp
[2025-07-19T19:57:20.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.1.delta.320ed07c-c1ad-49ab-8cd5-f2eedda5d3d6.TID290.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/1.delta
[2025-07-19T19:57:20.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/1.delta
[2025-07-19T19:57:20.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 144.0 in stage 5.0 (TID 296)
[2025-07-19T19:57:20.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 290, attempt 0, stage 5.0)
[2025-07-19T19:57:20.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 133.0 in stage 5.0 (TID 288) in 152 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T19:57:20.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.1.delta.329f259b-419f-41aa-8b5d-e5bcb5e5f0a2.TID292.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/1.delta
[2025-07-19T19:57:20.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/1.delta
[2025-07-19T19:57:20.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.1.delta.41bcc964-21c4-40d2-a2dd-c2a0c0a331e8.TID291.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/1.delta
[2025-07-19T19:57:20.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/1.delta
[2025-07-19T19:57:20.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.1.delta.59548117-c4be-4efa-a30b-da29b1b5c4bd.TID295.tmp
[2025-07-19T19:57:20.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 291, attempt 0, stage 5.0)
[2025-07-19T19:57:20.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 292, attempt 0, stage 5.0)
[2025-07-19T19:57:20.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 134 (task 289, attempt 0, stage 5.0)
[2025-07-19T19:57:20.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 134.0 in stage 5.0 (TID 289). 9162 bytes result sent to driver
[2025-07-19T19:57:20.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 135 (task 290, attempt 0, stage 5.0)
[2025-07-19T19:57:20.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72d338b8
[2025-07-19T19:57:20.585+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 135.0 in stage 5.0 (TID 290). 9156 bytes result sent to driver
[2025-07-19T19:57:20.586+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 146.0 in stage 5.0 (TID 297) (8b44f3d35cfa, executor driver, partition 146, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144] for update
[2025-07-19T19:57:20.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 146.0 in stage 5.0 (TID 297)
[2025-07-19T19:57:20.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 147.0 in stage 5.0 (TID 298) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 147.0 in stage 5.0 (TID 298)
[2025-07-19T19:57:20.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 134.0 in stage 5.0 (TID 289) in 135 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T19:57:20.606+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 135.0 in stage 5.0 (TID 290) in 135 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T19:57:20.608+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.1.delta.f6c45fea-d51b-44c7-aa94-a01c924e638b.TID293.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/1.delta
[2025-07-19T19:57:20.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/1.delta
[2025-07-19T19:57:20.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 293, attempt 0, stage 5.0)
[2025-07-19T19:57:20.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11e1a948
[2025-07-19T19:57:20.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147] for update
[2025-07-19T19:57:20.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.1.delta.a9298665-561d-45a8-9f00-0096fa3a0245.TID296.tmp
[2025-07-19T19:57:20.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dab952d
[2025-07-19T19:57:20.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146] for update
[2025-07-19T19:57:20.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.1.delta.0e37ed0e-09cc-49af-a9a1-cdd24a2d813a.TID294.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/1.delta
[2025-07-19T19:57:20.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/1.delta
[2025-07-19T19:57:20.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 294, attempt 0, stage 5.0)
[2025-07-19T19:57:20.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.1.delta.fd01c0f9-1022-40d9-aee4-be3577ad56d0.TID298.tmp
[2025-07-19T19:57:20.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 141 (task 293, attempt 0, stage 5.0)
[2025-07-19T19:57:20.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 141.0 in stage 5.0 (TID 293). 9146 bytes result sent to driver
[2025-07-19T19:57:20.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 139 (task 292, attempt 0, stage 5.0)
[2025-07-19T19:57:20.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 148.0 in stage 5.0 (TID 299) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 139.0 in stage 5.0 (TID 292). 9158 bytes result sent to driver
[2025-07-19T19:57:20.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 141.0 in stage 5.0 (TID 293) in 134 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T19:57:20.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 137 (task 291, attempt 0, stage 5.0)
[2025-07-19T19:57:20.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 137.0 in stage 5.0 (TID 291). 9164 bytes result sent to driver
[2025-07-19T19:57:20.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 148.0 in stage 5.0 (TID 299)
[2025-07-19T19:57:20.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 149.0 in stage 5.0 (TID 300) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 150.0 in stage 5.0 (TID 301) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 149.0 in stage 5.0 (TID 300)
[2025-07-19T19:57:20.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 150.0 in stage 5.0 (TID 301)
[2025-07-19T19:57:20.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 139.0 in stage 5.0 (TID 292) in 164 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T19:57:20.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 137.0 in stage 5.0 (TID 291) in 170 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T19:57:20.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.1.delta.99408d7a-7e55-4eff-be9d-1ff0f62f9139.TID297.tmp
[2025-07-19T19:57:20.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@190cfb3c
[2025-07-19T19:57:20.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.1.delta.59548117-c4be-4efa-a30b-da29b1b5c4bd.TID295.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/1.delta
[2025-07-19T19:57:20.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/1.delta
[2025-07-19T19:57:20.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 295, attempt 0, stage 5.0)
[2025-07-19T19:57:20.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.647+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150] for update
[2025-07-19T19:57:20.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 142 (task 294, attempt 0, stage 5.0)
[2025-07-19T19:57:20.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 142.0 in stage 5.0 (TID 294). 9164 bytes result sent to driver
[2025-07-19T19:57:20.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 151.0 in stage 5.0 (TID 302) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 151.0 in stage 5.0 (TID 302)
[2025-07-19T19:57:20.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 142.0 in stage 5.0 (TID 294) in 145 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T19:57:20.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:20.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.1.delta.a9298665-561d-45a8-9f00-0096fa3a0245.TID296.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/1.delta
[2025-07-19T19:57:20.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f68273c
[2025-07-19T19:57:20.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/1.delta
[2025-07-19T19:57:20.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 296, attempt 0, stage 5.0)
[2025-07-19T19:57:20.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.674+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149] for update
[2025-07-19T19:57:20.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.1.delta.aebc2623-c698-460e-88e7-d8b7e9f94e29.TID301.tmp
[2025-07-19T19:57:20.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 143 (task 295, attempt 0, stage 5.0)
[2025-07-19T19:57:20.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31a6f7b2
[2025-07-19T19:57:20.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148] for update
[2025-07-19T19:57:20.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 143.0 in stage 5.0 (TID 295). 9195 bytes result sent to driver
[2025-07-19T19:57:20.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 153.0 in stage 5.0 (TID 303) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 153.0 in stage 5.0 (TID 303)
[2025-07-19T19:57:20.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.1.delta.99408d7a-7e55-4eff-be9d-1ff0f62f9139.TID297.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/1.delta
[2025-07-19T19:57:20.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/1.delta
[2025-07-19T19:57:20.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 297, attempt 0, stage 5.0)
[2025-07-19T19:57:20.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 143.0 in stage 5.0 (TID 295) in 166 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T19:57:20.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:20.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6561965e
[2025-07-19T19:57:20.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151] for update
[2025-07-19T19:57:20.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 144 (task 296, attempt 0, stage 5.0)
[2025-07-19T19:57:20.704+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 144.0 in stage 5.0 (TID 296). 9180 bytes result sent to driver
[2025-07-19T19:57:20.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.1.delta.fd01c0f9-1022-40d9-aee4-be3577ad56d0.TID298.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/1.delta
[2025-07-19T19:57:20.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/1.delta
[2025-07-19T19:57:20.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 154.0 in stage 5.0 (TID 304) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 298, attempt 0, stage 5.0)
[2025-07-19T19:57:20.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 144.0 in stage 5.0 (TID 296) in 157 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T19:57:20.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 154.0 in stage 5.0 (TID 304)
[2025-07-19T19:57:20.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@361ce122
[2025-07-19T19:57:20.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.1.delta.f634dd94-693c-4774-8cc5-28de4c679092.TID300.tmp
[2025-07-19T19:57:20.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153] for update
[2025-07-19T19:57:20.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.1.delta.0c0ec15d-ed31-4842-b5ed-6ddf90dca9de.TID299.tmp
[2025-07-19T19:57:20.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33c746fd
[2025-07-19T19:57:20.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.1.delta.95239f77-ab18-45d6-8bc1-dc7564efda52.TID302.tmp
[2025-07-19T19:57:20.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 146 (task 297, attempt 0, stage 5.0)
[2025-07-19T19:57:20.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154] for update
[2025-07-19T19:57:20.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.1.delta.57c864c7-986a-4248-ac4c-c367498a2520.TID303.tmp
[2025-07-19T19:57:20.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 146.0 in stage 5.0 (TID 297). 9146 bytes result sent to driver
[2025-07-19T19:57:20.722+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.1.delta.aebc2623-c698-460e-88e7-d8b7e9f94e29.TID301.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/1.delta
[2025-07-19T19:57:20.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/1.delta
[2025-07-19T19:57:20.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 156.0 in stage 5.0 (TID 305) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 301, attempt 0, stage 5.0)
[2025-07-19T19:57:20.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 156.0 in stage 5.0 (TID 305)
[2025-07-19T19:57:20.729+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 146.0 in stage 5.0 (TID 297) in 157 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T19:57:20.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 147 (task 298, attempt 0, stage 5.0)
[2025-07-19T19:57:20.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 147.0 in stage 5.0 (TID 298). 9154 bytes result sent to driver
[2025-07-19T19:57:20.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 158.0 in stage 5.0 (TID 306) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 158.0 in stage 5.0 (TID 306)
[2025-07-19T19:57:20.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 147.0 in stage 5.0 (TID 298) in 160 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T19:57:20.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.1.delta.709f26c7-d7f6-4fcc-a336-9474ee5c9870.TID304.tmp
[2025-07-19T19:57:20.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15ea8d82
[2025-07-19T19:57:20.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 150 (task 301, attempt 0, stage 5.0)
[2025-07-19T19:57:20.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 150.0 in stage 5.0 (TID 301). 9132 bytes result sent to driver
[2025-07-19T19:57:20.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156] for update
[2025-07-19T19:57:20.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 159.0 in stage 5.0 (TID 307) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 150.0 in stage 5.0 (TID 301) in 106 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T19:57:20.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 159.0 in stage 5.0 (TID 307)
[2025-07-19T19:57:20.749+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.1.delta.f634dd94-693c-4774-8cc5-28de4c679092.TID300.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/1.delta
[2025-07-19T19:57:20.749+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/1.delta
[2025-07-19T19:57:20.749+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 300, attempt 0, stage 5.0)
[2025-07-19T19:57:20.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4964c17e
[2025-07-19T19:57:20.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.1.delta.7428dc4c-aec4-4f21-baf4-c4c337196fa1.TID305.tmp
[2025-07-19T19:57:20.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.754+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158] for update
[2025-07-19T19:57:20.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.1.delta.95239f77-ab18-45d6-8bc1-dc7564efda52.TID302.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/1.delta
[2025-07-19T19:57:20.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/1.delta
[2025-07-19T19:57:20.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 302, attempt 0, stage 5.0)
[2025-07-19T19:57:20.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1df70d9a
[2025-07-19T19:57:20.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159] for update
[2025-07-19T19:57:20.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.1.delta.57c864c7-986a-4248-ac4c-c367498a2520.TID303.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/1.delta
[2025-07-19T19:57:20.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/1.delta
[2025-07-19T19:57:20.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.1.delta.0c0ec15d-ed31-4842-b5ed-6ddf90dca9de.TID299.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/1.delta
[2025-07-19T19:57:20.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/1.delta
[2025-07-19T19:57:20.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 303, attempt 0, stage 5.0)
[2025-07-19T19:57:20.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 299, attempt 0, stage 5.0)
[2025-07-19T19:57:20.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.1.delta.d5c721d8-220a-480f-99eb-f9249922925a.TID306.tmp
[2025-07-19T19:57:20.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 149 (task 300, attempt 0, stage 5.0)
[2025-07-19T19:57:20.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 151 (task 302, attempt 0, stage 5.0)
[2025-07-19T19:57:20.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 151.0 in stage 5.0 (TID 302). 9148 bytes result sent to driver
[2025-07-19T19:57:20.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.1.delta.709f26c7-d7f6-4fcc-a336-9474ee5c9870.TID304.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/1.delta
[2025-07-19T19:57:20.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/1.delta
[2025-07-19T19:57:20.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 149.0 in stage 5.0 (TID 300). 9154 bytes result sent to driver
[2025-07-19T19:57:20.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 162.0 in stage 5.0 (TID 308) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 165.0 in stage 5.0 (TID 309) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 304, attempt 0, stage 5.0)
[2025-07-19T19:57:20.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 165.0 in stage 5.0 (TID 309)
[2025-07-19T19:57:20.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.1.delta.7428dc4c-aec4-4f21-baf4-c4c337196fa1.TID305.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/1.delta
[2025-07-19T19:57:20.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/1.delta
[2025-07-19T19:57:20.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 162.0 in stage 5.0 (TID 308)
[2025-07-19T19:57:20.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 305, attempt 0, stage 5.0)
[2025-07-19T19:57:20.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 153 (task 303, attempt 0, stage 5.0)
[2025-07-19T19:57:20.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46ccf3ad
[2025-07-19T19:57:20.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 148 (task 299, attempt 0, stage 5.0)
[2025-07-19T19:57:20.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165] for update
[2025-07-19T19:57:20.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 148.0 in stage 5.0 (TID 299). 9160 bytes result sent to driver
[2025-07-19T19:57:20.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 153.0 in stage 5.0 (TID 303). 9154 bytes result sent to driver
[2025-07-19T19:57:20.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 151.0 in stage 5.0 (TID 302) in 138 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T19:57:20.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 167.0 in stage 5.0 (TID 310) (8b44f3d35cfa, executor driver, partition 167, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.798+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.799+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 169.0 in stage 5.0 (TID 311) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 167.0 in stage 5.0 (TID 310)
[2025-07-19T19:57:20.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 149.0 in stage 5.0 (TID 300) in 162 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T19:57:20.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.1.delta.c889895c-b1da-4946-bb52-93eda9e8d036.TID307.tmp
[2025-07-19T19:57:20.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 148.0 in stage 5.0 (TID 299) in 165 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T19:57:20.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 153.0 in stage 5.0 (TID 303) in 120 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T19:57:20.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 169.0 in stage 5.0 (TID 311)
[2025-07-19T19:57:20.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 154 (task 304, attempt 0, stage 5.0)
[2025-07-19T19:57:20.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 154.0 in stage 5.0 (TID 304). 9160 bytes result sent to driver
[2025-07-19T19:57:20.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.1.delta.48a5da9e-83ef-487d-baba-54b860738f0c.TID309.tmp
[2025-07-19T19:57:20.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T19:57:20.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.1.delta.d5c721d8-220a-480f-99eb-f9249922925a.TID306.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/1.delta
[2025-07-19T19:57:20.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 170.0 in stage 5.0 (TID 312) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/1.delta
[2025-07-19T19:57:20.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 306, attempt 0, stage 5.0)
[2025-07-19T19:57:20.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d8f6cb
[2025-07-19T19:57:20.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 170.0 in stage 5.0 (TID 312)
[2025-07-19T19:57:20.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 154.0 in stage 5.0 (TID 304) in 102 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T19:57:20.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167] for update
[2025-07-19T19:57:20.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a729442
[2025-07-19T19:57:20.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162] for update
[2025-07-19T19:57:20.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 156 (task 305, attempt 0, stage 5.0)
[2025-07-19T19:57:20.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fcfadd1
[2025-07-19T19:57:20.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169] for update
[2025-07-19T19:57:20.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 156.0 in stage 5.0 (TID 305). 9166 bytes result sent to driver
[2025-07-19T19:57:20.824+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 171.0 in stage 5.0 (TID 313) (8b44f3d35cfa, executor driver, partition 171, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.824+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 156.0 in stage 5.0 (TID 305) in 94 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T19:57:20.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 171.0 in stage 5.0 (TID 313)
[2025-07-19T19:57:20.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 158 (task 306, attempt 0, stage 5.0)
[2025-07-19T19:57:20.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 158.0 in stage 5.0 (TID 306). 9165 bytes result sent to driver
[2025-07-19T19:57:20.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 158.0 in stage 5.0 (TID 306) in 93 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T19:57:20.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 172.0 in stage 5.0 (TID 314) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.1.delta.f99a49c8-77e1-4aa8-9eb7-89f888f78c41.TID308.tmp
[2025-07-19T19:57:20.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 172.0 in stage 5.0 (TID 314)
[2025-07-19T19:57:20.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.1.delta.74298b48-5f1d-406e-b121-28b91e77d680.TID310.tmp
[2025-07-19T19:57:20.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.1.delta.c889895c-b1da-4946-bb52-93eda9e8d036.TID307.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/1.delta
[2025-07-19T19:57:20.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/1.delta
[2025-07-19T19:57:20.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2524a3a6
[2025-07-19T19:57:20.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.1.delta.f26f06ae-c617-4b28-8905-ed799d955ff2.TID311.tmp
[2025-07-19T19:57:20.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 307, attempt 0, stage 5.0)
[2025-07-19T19:57:20.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170] for update
[2025-07-19T19:57:20.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59f52c13
[2025-07-19T19:57:20.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172] for update
[2025-07-19T19:57:20.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.1.delta.5b91a763-d2ea-44af-aa5b-662fa4b23114.TID312.tmp
[2025-07-19T19:57:20.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.1.delta.48a5da9e-83ef-487d-baba-54b860738f0c.TID309.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/1.delta
[2025-07-19T19:57:20.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/1.delta
[2025-07-19T19:57:20.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 309, attempt 0, stage 5.0)
[2025-07-19T19:57:20.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4752cb3f
[2025-07-19T19:57:20.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171] for update
[2025-07-19T19:57:20.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 159 (task 307, attempt 0, stage 5.0)
[2025-07-19T19:57:20.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 159.0 in stage 5.0 (TID 307). 9199 bytes result sent to driver
[2025-07-19T19:57:20.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.1.delta.4bf89c7e-a806-4dd8-84eb-ebafc029e920.TID314.tmp
[2025-07-19T19:57:20.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 173.0 in stage 5.0 (TID 315) (8b44f3d35cfa, executor driver, partition 173, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 173.0 in stage 5.0 (TID 315)
[2025-07-19T19:57:20.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 159.0 in stage 5.0 (TID 307) in 122 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T19:57:20.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5eb9c15a
[2025-07-19T19:57:20.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173] for update
[2025-07-19T19:57:20.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.1.delta.f99a49c8-77e1-4aa8-9eb7-89f888f78c41.TID308.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/1.delta
[2025-07-19T19:57:20.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/1.delta
[2025-07-19T19:57:20.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 308, attempt 0, stage 5.0)
[2025-07-19T19:57:20.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 165 (task 309, attempt 0, stage 5.0)
[2025-07-19T19:57:20.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 165.0 in stage 5.0 (TID 309). 9109 bytes result sent to driver
[2025-07-19T19:57:20.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 174.0 in stage 5.0 (TID 316) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 174.0 in stage 5.0 (TID 316)
[2025-07-19T19:57:20.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 165.0 in stage 5.0 (TID 309) in 98 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T19:57:20.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.1.delta.f26f06ae-c617-4b28-8905-ed799d955ff2.TID311.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/1.delta
[2025-07-19T19:57:20.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/1.delta
[2025-07-19T19:57:20.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.1.delta.74298b48-5f1d-406e-b121-28b91e77d680.TID310.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/1.delta
[2025-07-19T19:57:20.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/1.delta
[2025-07-19T19:57:20.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 311, attempt 0, stage 5.0)
[2025-07-19T19:57:20.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 310, attempt 0, stage 5.0)
[2025-07-19T19:57:20.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.1.delta.6e09d256-9d22-44da-aced-c65ef1759510.TID313.tmp
[2025-07-19T19:57:20.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e16c15
[2025-07-19T19:57:20.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174] for update
[2025-07-19T19:57:20.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.897+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.1.delta.6bf4b95e-30e3-497a-abc4-223c1391c015.TID315.tmp
[2025-07-19T19:57:20.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.1.delta.5b91a763-d2ea-44af-aa5b-662fa4b23114.TID312.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/1.delta
[2025-07-19T19:57:20.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/1.delta
[2025-07-19T19:57:20.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.1.delta.afa0b2b9-a368-44a2-ae46-f590b3118048.TID316.tmp
[2025-07-19T19:57:20.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 312, attempt 0, stage 5.0)
[2025-07-19T19:57:20.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.1.delta.4bf89c7e-a806-4dd8-84eb-ebafc029e920.TID314.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/1.delta
[2025-07-19T19:57:20.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/1.delta
[2025-07-19T19:57:20.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 314, attempt 0, stage 5.0)
[2025-07-19T19:57:20.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.1.delta.6e09d256-9d22-44da-aced-c65ef1759510.TID313.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/1.delta
[2025-07-19T19:57:20.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/1.delta
[2025-07-19T19:57:20.913+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 313, attempt 0, stage 5.0)
[2025-07-19T19:57:20.913+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 162 (task 308, attempt 0, stage 5.0)
[2025-07-19T19:57:20.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 162.0 in stage 5.0 (TID 308). 9103 bytes result sent to driver
[2025-07-19T19:57:20.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 175.0 in stage 5.0 (TID 317) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 170 (task 312, attempt 0, stage 5.0)
[2025-07-19T19:57:20.916+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 162.0 in stage 5.0 (TID 308) in 131 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T19:57:20.916+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 175.0 in stage 5.0 (TID 317)
[2025-07-19T19:57:20.916+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.1.delta.6bf4b95e-30e3-497a-abc4-223c1391c015.TID315.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/1.delta
[2025-07-19T19:57:20.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 170.0 in stage 5.0 (TID 312). 9111 bytes result sent to driver
[2025-07-19T19:57:20.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/1.delta
[2025-07-19T19:57:20.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 178.0 in stage 5.0 (TID 318) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 178.0 in stage 5.0 (TID 318)
[2025-07-19T19:57:20.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 170.0 in stage 5.0 (TID 312) in 113 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T19:57:20.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 315, attempt 0, stage 5.0)
[2025-07-19T19:57:20.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 169 (task 311, attempt 0, stage 5.0)
[2025-07-19T19:57:20.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 169.0 in stage 5.0 (TID 311). 9111 bytes result sent to driver
[2025-07-19T19:57:20.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:20.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 179.0 in stage 5.0 (TID 319) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 167 (task 310, attempt 0, stage 5.0)
[2025-07-19T19:57:20.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 167.0 in stage 5.0 (TID 310). 9121 bytes result sent to driver
[2025-07-19T19:57:20.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 169.0 in stage 5.0 (TID 311) in 130 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T19:57:20.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 179.0 in stage 5.0 (TID 319)
[2025-07-19T19:57:20.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:20.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 180.0 in stage 5.0 (TID 320) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 167.0 in stage 5.0 (TID 310) in 131 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T19:57:20.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 180.0 in stage 5.0 (TID 320)
[2025-07-19T19:57:20.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e63782d
[2025-07-19T19:57:20.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 172 (task 314, attempt 0, stage 5.0)
[2025-07-19T19:57:20.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178] for update
[2025-07-19T19:57:20.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 172.0 in stage 5.0 (TID 314). 9110 bytes result sent to driver
[2025-07-19T19:57:20.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c76279e
[2025-07-19T19:57:20.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.1.delta.afa0b2b9-a368-44a2-ae46-f590b3118048.TID316.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/1.delta
[2025-07-19T19:57:20.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/1.delta
[2025-07-19T19:57:20.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180] for update
[2025-07-19T19:57:20.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 181.0 in stage 5.0 (TID 321) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 316, attempt 0, stage 5.0)
[2025-07-19T19:57:20.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 181.0 in stage 5.0 (TID 321)
[2025-07-19T19:57:20.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 172.0 in stage 5.0 (TID 314) in 118 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T19:57:20.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fa19233
[2025-07-19T19:57:20.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 171 (task 313, attempt 0, stage 5.0)
[2025-07-19T19:57:20.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 171.0 in stage 5.0 (TID 313). 9195 bytes result sent to driver
[2025-07-19T19:57:20.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179] for update
[2025-07-19T19:57:20.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 182.0 in stage 5.0 (TID 322) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 173 (task 315, attempt 0, stage 5.0)
[2025-07-19T19:57:20.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.1.delta.17157a01-7e09-4d25-86b7-70d504b98ddc.TID320.tmp
[2025-07-19T19:57:20.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 173.0 in stage 5.0 (TID 315). 9158 bytes result sent to driver
[2025-07-19T19:57:20.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 182.0 in stage 5.0 (TID 322)
[2025-07-19T19:57:20.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 183.0 in stage 5.0 (TID 323) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 171.0 in stage 5.0 (TID 313) in 138 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T19:57:20.959+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.959+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.959+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 173.0 in stage 5.0 (TID 315) in 97 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T19:57:20.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a76b433
[2025-07-19T19:57:20.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175] for update
[2025-07-19T19:57:20.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 183.0 in stage 5.0 (TID 323)
[2025-07-19T19:57:20.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.1.delta.89ff053b-3621-4480-8e4f-c1a2216dde32.TID318.tmp
[2025-07-19T19:57:20.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Committed partition 174 (task 316, attempt 0, stage 5.0)
[2025-07-19T19:57:20.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Finished task 174.0 in stage 5.0 (TID 316). 9144 bytes result sent to driver
[2025-07-19T19:57:20.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Finished task 174.0 in stage 5.0 (TID 316) in 83 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T19:57:20.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:20.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO TaskSetManager: Starting task 184.0 in stage 5.0 (TID 324) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:20.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO Executor: Running task 184.0 in stage 5.0 (TID 324)
[2025-07-19T19:57:20.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:20.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:20.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29ccb57e
[2025-07-19T19:57:20.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.1.delta.054ac244-79fa-4143-ba07-2fd01d78b99e.TID319.tmp
[2025-07-19T19:57:20.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.1.delta.2e44fb4c-fc9a-40fc-86af-8c0940b7bcd0.TID317.tmp
[2025-07-19T19:57:20.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181] for update
[2025-07-19T19:57:20.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53477a41
[2025-07-19T19:57:20.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:20.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184] for update
[2025-07-19T19:57:20.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.1.delta.b145dd10-cad1-40b2-b8b1-70c83830f222.TID321.tmp
[2025-07-19T19:57:20.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.1.delta.17157a01-7e09-4d25-86b7-70d504b98ddc.TID320.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/1.delta
[2025-07-19T19:57:20.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/1.delta
[2025-07-19T19:57:20.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 320, attempt 0, stage 5.0)
[2025-07-19T19:57:20.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:20.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.1.delta.89ff053b-3621-4480-8e4f-c1a2216dde32.TID318.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/1.delta
[2025-07-19T19:57:21.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/1.delta
[2025-07-19T19:57:21.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 318, attempt 0, stage 5.0)
[2025-07-19T19:57:21.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2925ad2c
[2025-07-19T19:57:21.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.1.delta.eff89f84-4d66-4cf2-ba50-8578132c0d3d.TID324.tmp
[2025-07-19T19:57:21.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183] for update
[2025-07-19T19:57:21.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6acc737f
[2025-07-19T19:57:21.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.1.delta.054ac244-79fa-4143-ba07-2fd01d78b99e.TID319.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/1.delta
[2025-07-19T19:57:21.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/1.delta
[2025-07-19T19:57:21.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182] for update
[2025-07-19T19:57:21.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 319, attempt 0, stage 5.0)
[2025-07-19T19:57:21.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.1.delta.2e44fb4c-fc9a-40fc-86af-8c0940b7bcd0.TID317.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/1.delta
[2025-07-19T19:57:21.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/1.delta
[2025-07-19T19:57:21.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 317, attempt 0, stage 5.0)
[2025-07-19T19:57:21.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 180 (task 320, attempt 0, stage 5.0)
[2025-07-19T19:57:21.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 178 (task 318, attempt 0, stage 5.0)
[2025-07-19T19:57:21.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 178.0 in stage 5.0 (TID 318). 9156 bytes result sent to driver
[2025-07-19T19:57:21.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 180.0 in stage 5.0 (TID 320). 9150 bytes result sent to driver
[2025-07-19T19:57:21.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 185.0 in stage 5.0 (TID 325) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 179 (task 319, attempt 0, stage 5.0)
[2025-07-19T19:57:21.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 178.0 in stage 5.0 (TID 318) in 105 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T19:57:21.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 179.0 in stage 5.0 (TID 319). 9150 bytes result sent to driver
[2025-07-19T19:57:21.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 185.0 in stage 5.0 (TID 325)
[2025-07-19T19:57:21.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 180.0 in stage 5.0 (TID 320) in 95 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T19:57:21.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 187.0 in stage 5.0 (TID 326) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 187.0 in stage 5.0 (TID 326)
[2025-07-19T19:57:21.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 188.0 in stage 5.0 (TID 327) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.1.delta.9ced7bd7-2279-4101-b8d9-24b9f500ef1f.TID323.tmp
[2025-07-19T19:57:21.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 188.0 in stage 5.0 (TID 327)
[2025-07-19T19:57:21.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.1.delta.b145dd10-cad1-40b2-b8b1-70c83830f222.TID321.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/1.delta
[2025-07-19T19:57:21.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/1.delta
[2025-07-19T19:57:21.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.1.delta.950cb5e6-565a-4885-95b9-5d8cdfd9c9b2.TID322.tmp
[2025-07-19T19:57:21.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 179.0 in stage 5.0 (TID 319) in 102 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T19:57:21.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:21.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 321, attempt 0, stage 5.0)
[2025-07-19T19:57:21.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e04c4f1
[2025-07-19T19:57:21.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187] for update
[2025-07-19T19:57:21.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52639eea
[2025-07-19T19:57:21.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185] for update
[2025-07-19T19:57:21.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 175 (task 317, attempt 0, stage 5.0)
[2025-07-19T19:57:21.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 175.0 in stage 5.0 (TID 317). 9152 bytes result sent to driver
[2025-07-19T19:57:21.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 189.0 in stage 5.0 (TID 328) (8b44f3d35cfa, executor driver, partition 189, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 189.0 in stage 5.0 (TID 328)
[2025-07-19T19:57:21.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 175.0 in stage 5.0 (TID 317) in 123 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T19:57:21.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.1.delta.32d8ac96-bbe5-4d5f-aa04-cbb3a4f665cc.TID326.tmp
[2025-07-19T19:57:21.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ad5c3b3
[2025-07-19T19:57:21.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188] for update
[2025-07-19T19:57:21.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 181 (task 321, attempt 0, stage 5.0)
[2025-07-19T19:57:21.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.1.delta.eff89f84-4d66-4cf2-ba50-8578132c0d3d.TID324.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/1.delta
[2025-07-19T19:57:21.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/1.delta
[2025-07-19T19:57:21.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 181.0 in stage 5.0 (TID 321). 9156 bytes result sent to driver
[2025-07-19T19:57:21.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 192.0 in stage 5.0 (TID 329) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 181.0 in stage 5.0 (TID 321) in 109 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T19:57:21.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 324, attempt 0, stage 5.0)
[2025-07-19T19:57:21.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 192.0 in stage 5.0 (TID 329)
[2025-07-19T19:57:21.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f0874c
[2025-07-19T19:57:21.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.1.delta.e06df501-b655-45de-ae74-ce8a494bbf0c.TID325.tmp
[2025-07-19T19:57:21.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189] for update
[2025-07-19T19:57:21.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.1.delta.68b6b072-534a-409c-b5d9-c8bb4263b14a.TID327.tmp
[2025-07-19T19:57:21.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 184 (task 324, attempt 0, stage 5.0)
[2025-07-19T19:57:21.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28de5eb9
[2025-07-19T19:57:21.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.1.delta.9ced7bd7-2279-4101-b8d9-24b9f500ef1f.TID323.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/1.delta
[2025-07-19T19:57:21.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/1.delta
[2025-07-19T19:57:21.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 323, attempt 0, stage 5.0)
[2025-07-19T19:57:21.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 184.0 in stage 5.0 (TID 324). 9193 bytes result sent to driver
[2025-07-19T19:57:21.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.1.delta.950cb5e6-565a-4885-95b9-5d8cdfd9c9b2.TID322.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/1.delta
[2025-07-19T19:57:21.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/1.delta
[2025-07-19T19:57:21.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 184.0 in stage 5.0 (TID 324) in 106 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T19:57:21.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 194.0 in stage 5.0 (TID 330) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192] for update
[2025-07-19T19:57:21.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 194.0 in stage 5.0 (TID 330)
[2025-07-19T19:57:21.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 322, attempt 0, stage 5.0)
[2025-07-19T19:57:21.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.1.delta.b09034b8-1ec1-443a-bb32-0013de191d78.TID328.tmp
[2025-07-19T19:57:21.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b951c53
[2025-07-19T19:57:21.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194] for update
[2025-07-19T19:57:21.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.1.delta.5f99ac73-b69d-4bcb-83b5-5b44cc5846ea.TID329.tmp
[2025-07-19T19:57:21.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 183 (task 323, attempt 0, stage 5.0)
[2025-07-19T19:57:21.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 183.0 in stage 5.0 (TID 323). 9184 bytes result sent to driver
[2025-07-19T19:57:21.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 196.0 in stage 5.0 (TID 331) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 196.0 in stage 5.0 (TID 331)
[2025-07-19T19:57:21.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 182 (task 322, attempt 0, stage 5.0)
[2025-07-19T19:57:21.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 183.0 in stage 5.0 (TID 323) in 136 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T19:57:21.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 182.0 in stage 5.0 (TID 322). 9154 bytes result sent to driver
[2025-07-19T19:57:21.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.1.delta.32d8ac96-bbe5-4d5f-aa04-cbb3a4f665cc.TID326.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/1.delta
[2025-07-19T19:57:21.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/1.delta
[2025-07-19T19:57:21.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 197.0 in stage 5.0 (TID 332) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 197.0 in stage 5.0 (TID 332)
[2025-07-19T19:57:21.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 182.0 in stage 5.0 (TID 322) in 142 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T19:57:21.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 326, attempt 0, stage 5.0)
[2025-07-19T19:57:21.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.1.delta.68b6b072-534a-409c-b5d9-c8bb4263b14a.TID327.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/1.delta
[2025-07-19T19:57:21.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/1.delta
[2025-07-19T19:57:21.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.1.delta.9e3a79e4-3ef3-49f1-bc61-0ba092549cb7.TID330.tmp
[2025-07-19T19:57:21.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 327, attempt 0, stage 5.0)
[2025-07-19T19:57:21.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:21.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.1.delta.e06df501-b655-45de-ae74-ce8a494bbf0c.TID325.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/1.delta
[2025-07-19T19:57:21.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/1.delta
[2025-07-19T19:57:21.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7500d1c1
[2025-07-19T19:57:21.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 325, attempt 0, stage 5.0)
[2025-07-19T19:57:21.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197] for update
[2025-07-19T19:57:21.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.115+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e295eb4
[2025-07-19T19:57:21.115+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196] for update
[2025-07-19T19:57:21.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.1.delta.5f99ac73-b69d-4bcb-83b5-5b44cc5846ea.TID329.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/1.delta
[2025-07-19T19:57:21.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/1.delta
[2025-07-19T19:57:21.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 329, attempt 0, stage 5.0)
[2025-07-19T19:57:21.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 187 (task 326, attempt 0, stage 5.0)
[2025-07-19T19:57:21.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.1.delta.b09034b8-1ec1-443a-bb32-0013de191d78.TID328.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/1.delta
[2025-07-19T19:57:21.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/1.delta
[2025-07-19T19:57:21.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.1.delta.0587b501-5469-46cd-8795-0b7d1ac332f3.TID332.tmp
[2025-07-19T19:57:21.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 188 (task 327, attempt 0, stage 5.0)
[2025-07-19T19:57:21.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 328, attempt 0, stage 5.0)
[2025-07-19T19:57:21.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 187.0 in stage 5.0 (TID 326). 9171 bytes result sent to driver
[2025-07-19T19:57:21.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 188.0 in stage 5.0 (TID 327). 9163 bytes result sent to driver
[2025-07-19T19:57:21.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 185 (task 325, attempt 0, stage 5.0)
[2025-07-19T19:57:21.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 199.0 in stage 5.0 (TID 333) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.1.delta.28f78eab-2b1e-4c98-b51c-788db7e9d278.TID331.tmp
[2025-07-19T19:57:21.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 199.0 in stage 5.0 (TID 333)
[2025-07-19T19:57:21.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 187.0 in stage 5.0 (TID 326) in 110 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T19:57:21.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 334) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 185.0 in stage 5.0 (TID 325). 9199 bytes result sent to driver
[2025-07-19T19:57:21.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.1.delta.9e3a79e4-3ef3-49f1-bc61-0ba092549cb7.TID330.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/1.delta
[2025-07-19T19:57:21.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/1.delta
[2025-07-19T19:57:21.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 330, attempt 0, stage 5.0)
[2025-07-19T19:57:21.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 188.0 in stage 5.0 (TID 327) in 112 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T19:57:21.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 335) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 6.0 in stage 5.0 (TID 335)
[2025-07-19T19:57:21.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 5.0 in stage 5.0 (TID 334)
[2025-07-19T19:57:21.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 192 (task 329, attempt 0, stage 5.0)
[2025-07-19T19:57:21.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 185.0 in stage 5.0 (TID 325) in 117 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T19:57:21.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 192.0 in stage 5.0 (TID 329). 9150 bytes result sent to driver
[2025-07-19T19:57:21.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 336) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:21.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 192.0 in stage 5.0 (TID 329) in 95 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T19:57:21.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 8.0 in stage 5.0 (TID 336)
[2025-07-19T19:57:21.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:21.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 189 (task 328, attempt 0, stage 5.0)
[2025-07-19T19:57:21.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d9a298f
[2025-07-19T19:57:21.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 189.0 in stage 5.0 (TID 328). 9158 bytes result sent to driver
[2025-07-19T19:57:21.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199] for update
[2025-07-19T19:57:21.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 337) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 17.0 in stage 5.0 (TID 337)
[2025-07-19T19:57:21.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:21.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 189.0 in stage 5.0 (TID 328) in 111 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T19:57:21.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4422c5a8
[2025-07-19T19:57:21.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.156+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6] for update
[2025-07-19T19:57:21.156+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.1.delta.28f78eab-2b1e-4c98-b51c-788db7e9d278.TID331.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/1.delta
[2025-07-19T19:57:21.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/1.delta
[2025-07-19T19:57:21.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 331, attempt 0, stage 5.0)
[2025-07-19T19:57:21.158+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 194 (task 330, attempt 0, stage 5.0)
[2025-07-19T19:57:21.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 194.0 in stage 5.0 (TID 330). 9101 bytes result sent to driver
[2025-07-19T19:57:21.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.1.delta.39ee001c-e86f-4f02-b25d-f0ff33c8360d.TID333.tmp
[2025-07-19T19:57:21.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.1.delta.0587b501-5469-46cd-8795-0b7d1ac332f3.TID332.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/1.delta
[2025-07-19T19:57:21.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/1.delta
[2025-07-19T19:57:21.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 338) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 332, attempt 0, stage 5.0)
[2025-07-19T19:57:21.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 19.0 in stage 5.0 (TID 338)
[2025-07-19T19:57:21.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 194.0 in stage 5.0 (TID 330) in 89 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T19:57:21.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ac85a52
[2025-07-19T19:57:21.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5] for update
[2025-07-19T19:57:21.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.1.delta.fc8bfb17-7c42-4d84-8f92-fc8f63ae8cc0.TID335.tmp
[2025-07-19T19:57:21.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7758c499
[2025-07-19T19:57:21.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19] for update
[2025-07-19T19:57:21.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.1.delta.66c78731-fb0c-4b01-8ede-93cd431b6951.TID334.tmp
[2025-07-19T19:57:21.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fd6f79b
[2025-07-19T19:57:21.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17] for update
[2025-07-19T19:57:21.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 197 (task 332, attempt 0, stage 5.0)
[2025-07-19T19:57:21.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 197.0 in stage 5.0 (TID 332). 9113 bytes result sent to driver
[2025-07-19T19:57:21.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 196 (task 331, attempt 0, stage 5.0)
[2025-07-19T19:57:21.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 197.0 in stage 5.0 (TID 332) in 86 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T19:57:21.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f471be0
[2025-07-19T19:57:21.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 339) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 196.0 in stage 5.0 (TID 331). 9107 bytes result sent to driver
[2025-07-19T19:57:21.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8] for update
[2025-07-19T19:57:21.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 20.0 in stage 5.0 (TID 339)
[2025-07-19T19:57:21.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 340) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 196.0 in stage 5.0 (TID 331) in 92 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T19:57:21.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 21.0 in stage 5.0 (TID 340)
[2025-07-19T19:57:21.187+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.1.delta.280b9809-62fe-4b44-a5a6-f042217d0922.TID338.tmp
[2025-07-19T19:57:21.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.1.delta.9497dcc5-b17d-4a28-a403-682a1d714bba.TID337.tmp
[2025-07-19T19:57:21.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7eae855a
[2025-07-19T19:57:21.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20] for update
[2025-07-19T19:57:21.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.1.delta.39ee001c-e86f-4f02-b25d-f0ff33c8360d.TID333.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/1.delta
[2025-07-19T19:57:21.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/1.delta
[2025-07-19T19:57:21.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 333, attempt 0, stage 5.0)
[2025-07-19T19:57:21.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.1.delta.d5f82086-48ca-4562-8714-a889cdee3f93.TID336.tmp
[2025-07-19T19:57:21.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@176353d3
[2025-07-19T19:57:21.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21] for update
[2025-07-19T19:57:21.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.1.delta.fc8bfb17-7c42-4d84-8f92-fc8f63ae8cc0.TID335.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/1.delta
[2025-07-19T19:57:21.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/1.delta
[2025-07-19T19:57:21.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.1.delta.76ac07a3-8ae5-4cab-a9f8-cc4ab4001ed6.TID339.tmp
[2025-07-19T19:57:21.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 335, attempt 0, stage 5.0)
[2025-07-19T19:57:21.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 6 (task 335, attempt 0, stage 5.0)
[2025-07-19T19:57:21.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 6.0 in stage 5.0 (TID 335). 6243 bytes result sent to driver
[2025-07-19T19:57:21.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.1.delta.6a0b5db4-c616-4740-977d-d79d93e4cd65.TID340.tmp
[2025-07-19T19:57:21.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 199 (task 333, attempt 0, stage 5.0)
[2025-07-19T19:57:21.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 199.0 in stage 5.0 (TID 333). 9154 bytes result sent to driver
[2025-07-19T19:57:21.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 341) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 342) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 24.0 in stage 5.0 (TID 342)
[2025-07-19T19:57:21.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 22.0 in stage 5.0 (TID 341)
[2025-07-19T19:57:21.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 335) in 83 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T19:57:21.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.1.delta.66c78731-fb0c-4b01-8ede-93cd431b6951.TID334.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/1.delta
[2025-07-19T19:57:21.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/1.delta
[2025-07-19T19:57:21.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.1.delta.280b9809-62fe-4b44-a5a6-f042217d0922.TID338.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/1.delta
[2025-07-19T19:57:21.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/1.delta
[2025-07-19T19:57:21.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 338, attempt 0, stage 5.0)
[2025-07-19T19:57:21.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 334, attempt 0, stage 5.0)
[2025-07-19T19:57:21.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 199.0 in stage 5.0 (TID 333) in 93 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T19:57:21.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 5 (task 334, attempt 0, stage 5.0)
[2025-07-19T19:57:21.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 19 (task 338, attempt 0, stage 5.0)
[2025-07-19T19:57:21.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 19.0 in stage 5.0 (TID 338). 6243 bytes result sent to driver
[2025-07-19T19:57:21.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 5.0 in stage 5.0 (TID 334). 6243 bytes result sent to driver
[2025-07-19T19:57:21.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 343) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 344) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 338) in 69 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T19:57:21.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 25.0 in stage 5.0 (TID 343)
[2025-07-19T19:57:21.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 334) in 95 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T19:57:21.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 29.0 in stage 5.0 (TID 344)
[2025-07-19T19:57:21.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.1.delta.9497dcc5-b17d-4a28-a403-682a1d714bba.TID337.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/1.delta
[2025-07-19T19:57:21.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/1.delta
[2025-07-19T19:57:21.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 337, attempt 0, stage 5.0)
[2025-07-19T19:57:21.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@568f2235
[2025-07-19T19:57:21.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24] for update
[2025-07-19T19:57:21.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.1.delta.d5f82086-48ca-4562-8714-a889cdee3f93.TID336.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/1.delta
[2025-07-19T19:57:21.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/1.delta
[2025-07-19T19:57:21.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 336, attempt 0, stage 5.0)
[2025-07-19T19:57:21.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.1.delta.76ac07a3-8ae5-4cab-a9f8-cc4ab4001ed6.TID339.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/1.delta
[2025-07-19T19:57:21.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 17 (task 337, attempt 0, stage 5.0)
[2025-07-19T19:57:21.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/1.delta
[2025-07-19T19:57:21.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 17.0 in stage 5.0 (TID 337). 6243 bytes result sent to driver
[2025-07-19T19:57:21.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 339, attempt 0, stage 5.0)
[2025-07-19T19:57:21.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 345) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 32.0 in stage 5.0 (TID 345)
[2025-07-19T19:57:21.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 337) in 94 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T19:57:21.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24c82478
[2025-07-19T19:57:21.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 8 (task 336, attempt 0, stage 5.0)
[2025-07-19T19:57:21.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 8.0 in stage 5.0 (TID 336). 6243 bytes result sent to driver
[2025-07-19T19:57:21.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.1.delta.74d86b8b-b810-4fb9-b45d-8cba7ed1e6f5.TID342.tmp
[2025-07-19T19:57:21.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 346) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 34.0 in stage 5.0 (TID 346)
[2025-07-19T19:57:21.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25] for update
[2025-07-19T19:57:21.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 336) in 103 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T19:57:21.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.1.delta.6a0b5db4-c616-4740-977d-d79d93e4cd65.TID340.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/1.delta
[2025-07-19T19:57:21.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/1.delta
[2025-07-19T19:57:21.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 340, attempt 0, stage 5.0)
[2025-07-19T19:57:21.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@468663ff
[2025-07-19T19:57:21.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 20 (task 339, attempt 0, stage 5.0)
[2025-07-19T19:57:21.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 20.0 in stage 5.0 (TID 339). 6243 bytes result sent to driver
[2025-07-19T19:57:21.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29] for update
[2025-07-19T19:57:21.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 347) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 36.0 in stage 5.0 (TID 347)
[2025-07-19T19:57:21.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 339) in 66 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T19:57:21.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 21 (task 340, attempt 0, stage 5.0)
[2025-07-19T19:57:21.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 21.0 in stage 5.0 (TID 340). 6243 bytes result sent to driver
[2025-07-19T19:57:21.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 348) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 340) in 68 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T19:57:21.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 38.0 in stage 5.0 (TID 348)
[2025-07-19T19:57:21.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2931bd6c
[2025-07-19T19:57:21.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22] for update
[2025-07-19T19:57:21.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.1.delta.aa6d8f0f-efaf-423b-ab74-b4260281819a.TID343.tmp
[2025-07-19T19:57:21.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.1.delta.24af4de7-9866-482d-b46b-e4a963bd29e2.TID344.tmp
[2025-07-19T19:57:21.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30709386
[2025-07-19T19:57:21.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38] for update
[2025-07-19T19:57:21.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58bcfef2
[2025-07-19T19:57:21.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36] for update
[2025-07-19T19:57:21.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.1.delta.adf075f7-d99c-40c6-8987-c9d27bb0984f.TID341.tmp
[2025-07-19T19:57:21.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4461649a
[2025-07-19T19:57:21.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34] for update
[2025-07-19T19:57:21.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.1.delta.74d86b8b-b810-4fb9-b45d-8cba7ed1e6f5.TID342.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/1.delta
[2025-07-19T19:57:21.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/1.delta
[2025-07-19T19:57:21.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.1.delta.7622dae2-21d9-4a7a-a21a-72e9829f17d1.TID348.tmp
[2025-07-19T19:57:21.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 342, attempt 0, stage 5.0)
[2025-07-19T19:57:21.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.1.delta.9758c84b-fff1-457a-8ebd-68b6aab9328a.TID347.tmp
[2025-07-19T19:57:21.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@331a0fbd
[2025-07-19T19:57:21.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32] for update
[2025-07-19T19:57:21.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 24 (task 342, attempt 0, stage 5.0)
[2025-07-19T19:57:21.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 24.0 in stage 5.0 (TID 342). 6243 bytes result sent to driver
[2025-07-19T19:57:21.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 349) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 342) in 66 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T19:57:21.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 40.0 in stage 5.0 (TID 349)
[2025-07-19T19:57:21.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.1.delta.e047a6de-2c9b-4c4c-8bb7-0882d862a018.TID346.tmp
[2025-07-19T19:57:21.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18573984
[2025-07-19T19:57:21.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40] for update
[2025-07-19T19:57:21.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.1.delta.24af4de7-9866-482d-b46b-e4a963bd29e2.TID344.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/1.delta
[2025-07-19T19:57:21.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/1.delta
[2025-07-19T19:57:21.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 344, attempt 0, stage 5.0)
[2025-07-19T19:57:21.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.1.delta.aa6d8f0f-efaf-423b-ab74-b4260281819a.TID343.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/1.delta
[2025-07-19T19:57:21.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/1.delta
[2025-07-19T19:57:21.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 343, attempt 0, stage 5.0)
[2025-07-19T19:57:21.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.1.delta.47c56192-1b28-40ab-962b-5dd44f271af0.TID345.tmp
[2025-07-19T19:57:21.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 29 (task 344, attempt 0, stage 5.0)
[2025-07-19T19:57:21.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.1.delta.252df706-b674-450e-9bda-7d926d7bdc88.TID349.tmp
[2025-07-19T19:57:21.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 29.0 in stage 5.0 (TID 344). 6243 bytes result sent to driver
[2025-07-19T19:57:21.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 25 (task 343, attempt 0, stage 5.0)
[2025-07-19T19:57:21.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 25.0 in stage 5.0 (TID 343). 6243 bytes result sent to driver
[2025-07-19T19:57:21.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 350) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 44.0 in stage 5.0 (TID 350)
[2025-07-19T19:57:21.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 351) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 344) in 78 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T19:57:21.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 45.0 in stage 5.0 (TID 351)
[2025-07-19T19:57:21.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 343) in 79 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T19:57:21.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e37771d
[2025-07-19T19:57:21.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.1.delta.7622dae2-21d9-4a7a-a21a-72e9829f17d1.TID348.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/1.delta
[2025-07-19T19:57:21.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/1.delta
[2025-07-19T19:57:21.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 348, attempt 0, stage 5.0)
[2025-07-19T19:57:21.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44] for update
[2025-07-19T19:57:21.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.1.delta.9758c84b-fff1-457a-8ebd-68b6aab9328a.TID347.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/1.delta
[2025-07-19T19:57:21.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/1.delta
[2025-07-19T19:57:21.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 347, attempt 0, stage 5.0)
[2025-07-19T19:57:21.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.1.delta.adf075f7-d99c-40c6-8987-c9d27bb0984f.TID341.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/1.delta
[2025-07-19T19:57:21.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/1.delta
[2025-07-19T19:57:21.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 341, attempt 0, stage 5.0)
[2025-07-19T19:57:21.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57ae6296
[2025-07-19T19:57:21.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.321+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45] for update
[2025-07-19T19:57:21.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 36 (task 347, attempt 0, stage 5.0)
[2025-07-19T19:57:21.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 22 (task 341, attempt 0, stage 5.0)
[2025-07-19T19:57:21.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 38 (task 348, attempt 0, stage 5.0)
[2025-07-19T19:57:21.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.1.delta.e047a6de-2c9b-4c4c-8bb7-0882d862a018.TID346.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/1.delta
[2025-07-19T19:57:21.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/1.delta
[2025-07-19T19:57:21.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 22.0 in stage 5.0 (TID 341). 6243 bytes result sent to driver
[2025-07-19T19:57:21.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 36.0 in stage 5.0 (TID 347). 6243 bytes result sent to driver
[2025-07-19T19:57:21.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 38.0 in stage 5.0 (TID 348). 6243 bytes result sent to driver
[2025-07-19T19:57:21.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 346, attempt 0, stage 5.0)
[2025-07-19T19:57:21.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 352) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 46.0 in stage 5.0 (TID 352)
[2025-07-19T19:57:21.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 353) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 47.0 in stage 5.0 (TID 353)
[2025-07-19T19:57:21.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 354) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 49.0 in stage 5.0 (TID 354)
[2025-07-19T19:57:21.330+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 347) in 80 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T19:57:21.330+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 348) in 76 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T19:57:21.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 341) in 112 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T19:57:21.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 34 (task 346, attempt 0, stage 5.0)
[2025-07-19T19:57:21.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 34.0 in stage 5.0 (TID 346). 6243 bytes result sent to driver
[2025-07-19T19:57:21.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 53.0 in stage 5.0 (TID 355) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 53.0 in stage 5.0 (TID 355)
[2025-07-19T19:57:21.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 346) in 87 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T19:57:21.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.1.delta.428f6ae8-e21a-4a70-8f24-8d9f97858d50.TID350.tmp
[2025-07-19T19:57:21.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ab2c270
[2025-07-19T19:57:21.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.1.delta.252df706-b674-450e-9bda-7d926d7bdc88.TID349.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/1.delta
[2025-07-19T19:57:21.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/1.delta
[2025-07-19T19:57:21.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47] for update
[2025-07-19T19:57:21.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 349, attempt 0, stage 5.0)
[2025-07-19T19:57:21.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.1.delta.47c56192-1b28-40ab-962b-5dd44f271af0.TID345.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/1.delta
[2025-07-19T19:57:21.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/1.delta
[2025-07-19T19:57:21.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 345, attempt 0, stage 5.0)
[2025-07-19T19:57:21.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.1.delta.eac5ad4d-15ec-4fd5-b419-97141a90a07b.TID351.tmp
[2025-07-19T19:57:21.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 40 (task 349, attempt 0, stage 5.0)
[2025-07-19T19:57:21.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 40.0 in stage 5.0 (TID 349). 6200 bytes result sent to driver
[2025-07-19T19:57:21.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 54.0 in stage 5.0 (TID 356) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 349) in 58 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T19:57:21.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 32 (task 345, attempt 0, stage 5.0)
[2025-07-19T19:57:21.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 54.0 in stage 5.0 (TID 356)
[2025-07-19T19:57:21.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.1.delta.674eda54-9d8c-4da4-82fb-a8dfeeea1cb0.TID353.tmp
[2025-07-19T19:57:21.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 32.0 in stage 5.0 (TID 345). 6286 bytes result sent to driver
[2025-07-19T19:57:21.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 56.0 in stage 5.0 (TID 357) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 56.0 in stage 5.0 (TID 357)
[2025-07-19T19:57:21.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e38ffe1
[2025-07-19T19:57:21.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 345) in 112 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T19:57:21.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49] for update
[2025-07-19T19:57:21.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:21.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d276e21
[2025-07-19T19:57:21.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53] for update
[2025-07-19T19:57:21.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.1.delta.abf57cd6-46ba-48ab-b85e-1679d796ef9f.TID354.tmp
[2025-07-19T19:57:21.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.1.delta.428f6ae8-e21a-4a70-8f24-8d9f97858d50.TID350.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/1.delta
[2025-07-19T19:57:21.362+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/1.delta
[2025-07-19T19:57:21.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d7c2cca
[2025-07-19T19:57:21.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 350, attempt 0, stage 5.0)
[2025-07-19T19:57:21.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46] for update
[2025-07-19T19:57:21.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.1.delta.674eda54-9d8c-4da4-82fb-a8dfeeea1cb0.TID353.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/1.delta
[2025-07-19T19:57:21.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/1.delta
[2025-07-19T19:57:21.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 353, attempt 0, stage 5.0)
[2025-07-19T19:57:21.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.1.delta.eac5ad4d-15ec-4fd5-b419-97141a90a07b.TID351.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/1.delta
[2025-07-19T19:57:21.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/1.delta
[2025-07-19T19:57:21.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 351, attempt 0, stage 5.0)
[2025-07-19T19:57:21.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b9083c4
[2025-07-19T19:57:21.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 47 (task 353, attempt 0, stage 5.0)
[2025-07-19T19:57:21.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56] for update
[2025-07-19T19:57:21.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 44 (task 350, attempt 0, stage 5.0)
[2025-07-19T19:57:21.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 44.0 in stage 5.0 (TID 350). 6243 bytes result sent to driver
[2025-07-19T19:57:21.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 47.0 in stage 5.0 (TID 353). 6243 bytes result sent to driver
[2025-07-19T19:57:21.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 45 (task 351, attempt 0, stage 5.0)
[2025-07-19T19:57:21.379+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 57.0 in stage 5.0 (TID 358) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.379+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 45.0 in stage 5.0 (TID 351). 6200 bytes result sent to driver
[2025-07-19T19:57:21.379+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 58.0 in stage 5.0 (TID 359) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 57.0 in stage 5.0 (TID 358)
[2025-07-19T19:57:21.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 61.0 in stage 5.0 (TID 360) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 58.0 in stage 5.0 (TID 359)
[2025-07-19T19:57:21.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 350) in 70 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T19:57:21.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 353) in 50 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T19:57:21.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 61.0 in stage 5.0 (TID 360)
[2025-07-19T19:57:21.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 351) in 69 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T19:57:21.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.1.delta.eb3597f0-20f2-4494-afd8-591abde81b02.TID355.tmp
[2025-07-19T19:57:21.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@165d052
[2025-07-19T19:57:21.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54] for update
[2025-07-19T19:57:21.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.1.delta.adecbb7d-6549-402b-be2b-78a01482e218.TID352.tmp
[2025-07-19T19:57:21.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4927946
[2025-07-19T19:57:21.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58] for update
[2025-07-19T19:57:21.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.1.delta.1e66cbb0-5bb3-4674-983c-7af86e29f371.TID357.tmp
[2025-07-19T19:57:21.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@237cabfe
[2025-07-19T19:57:21.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61] for update
[2025-07-19T19:57:21.391+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.1.delta.df92db29-f196-42f1-829b-e7d05fe27ff7.TID356.tmp
[2025-07-19T19:57:21.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@173665ce
[2025-07-19T19:57:21.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.1.delta.abf57cd6-46ba-48ab-b85e-1679d796ef9f.TID354.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/1.delta
[2025-07-19T19:57:21.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/1.delta
[2025-07-19T19:57:21.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57] for update
[2025-07-19T19:57:21.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 354, attempt 0, stage 5.0)
[2025-07-19T19:57:21.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 49 (task 354, attempt 0, stage 5.0)
[2025-07-19T19:57:21.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 49.0 in stage 5.0 (TID 354). 6243 bytes result sent to driver
[2025-07-19T19:57:21.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.1.delta.d7dae346-4565-4074-bdeb-6992e37504ff.TID360.tmp
[2025-07-19T19:57:21.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 64.0 in stage 5.0 (TID 361) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.1.delta.bc26b654-ec0d-4c66-b8a6-c8ec060faf45.TID359.tmp
[2025-07-19T19:57:21.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 354) in 82 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T19:57:21.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 64.0 in stage 5.0 (TID 361)
[2025-07-19T19:57:21.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.1.delta.17d226ec-647e-4c1c-88fc-c18aa03f0860.TID358.tmp
[2025-07-19T19:57:21.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:21.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@625cc615
[2025-07-19T19:57:21.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64] for update
[2025-07-19T19:57:21.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.1.delta.eb3597f0-20f2-4494-afd8-591abde81b02.TID355.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/1.delta
[2025-07-19T19:57:21.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/1.delta
[2025-07-19T19:57:21.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.1.delta.adecbb7d-6549-402b-be2b-78a01482e218.TID352.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/1.delta
[2025-07-19T19:57:21.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/1.delta
[2025-07-19T19:57:21.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 352, attempt 0, stage 5.0)
[2025-07-19T19:57:21.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 355, attempt 0, stage 5.0)
[2025-07-19T19:57:21.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.1.delta.df92db29-f196-42f1-829b-e7d05fe27ff7.TID356.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/1.delta
[2025-07-19T19:57:21.438+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/1.delta
[2025-07-19T19:57:21.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 53 (task 355, attempt 0, stage 5.0)
[2025-07-19T19:57:21.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 356, attempt 0, stage 5.0)
[2025-07-19T19:57:21.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 53.0 in stage 5.0 (TID 355). 6243 bytes result sent to driver
[2025-07-19T19:57:21.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 46 (task 352, attempt 0, stage 5.0)
[2025-07-19T19:57:21.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 46.0 in stage 5.0 (TID 352). 6243 bytes result sent to driver
[2025-07-19T19:57:21.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.1.delta.a9774e20-a60a-4a13-bb2b-c5b5c8adcf2c.TID361.tmp
[2025-07-19T19:57:21.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.1.delta.1e66cbb0-5bb3-4674-983c-7af86e29f371.TID357.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/1.delta
[2025-07-19T19:57:21.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/1.delta
[2025-07-19T19:57:21.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 357, attempt 0, stage 5.0)
[2025-07-19T19:57:21.446+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 65.0 in stage 5.0 (TID 362) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.446+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 65.0 in stage 5.0 (TID 362)
[2025-07-19T19:57:21.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 69.0 in stage 5.0 (TID 363) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.448+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 53.0 in stage 5.0 (TID 355) in 114 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T19:57:21.448+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 352) in 120 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T19:57:21.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 56 (task 357, attempt 0, stage 5.0)
[2025-07-19T19:57:21.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 69.0 in stage 5.0 (TID 363)
[2025-07-19T19:57:21.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 54 (task 356, attempt 0, stage 5.0)
[2025-07-19T19:57:21.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.1.delta.bc26b654-ec0d-4c66-b8a6-c8ec060faf45.TID359.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/1.delta
[2025-07-19T19:57:21.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/1.delta
[2025-07-19T19:57:21.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 54.0 in stage 5.0 (TID 356). 6243 bytes result sent to driver
[2025-07-19T19:57:21.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 359, attempt 0, stage 5.0)
[2025-07-19T19:57:21.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:21.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 56.0 in stage 5.0 (TID 357). 6200 bytes result sent to driver
[2025-07-19T19:57:21.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 70.0 in stage 5.0 (TID 364) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 56.0 in stage 5.0 (TID 357) in 104 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T19:57:21.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 70.0 in stage 5.0 (TID 364)
[2025-07-19T19:57:21.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 58 (task 359, attempt 0, stage 5.0)
[2025-07-19T19:57:21.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 73.0 in stage 5.0 (TID 365) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 58.0 in stage 5.0 (TID 359). 6200 bytes result sent to driver
[2025-07-19T19:57:21.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 54.0 in stage 5.0 (TID 356) in 114 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T19:57:21.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 58.0 in stage 5.0 (TID 359) in 81 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T19:57:21.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.1.delta.d7dae346-4565-4074-bdeb-6992e37504ff.TID360.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/1.delta
[2025-07-19T19:57:21.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/1.delta
[2025-07-19T19:57:21.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 360, attempt 0, stage 5.0)
[2025-07-19T19:57:21.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 73.0 in stage 5.0 (TID 365)
[2025-07-19T19:57:21.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 79.0 in stage 5.0 (TID 366) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f921a06
[2025-07-19T19:57:21.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 79.0 in stage 5.0 (TID 366)
[2025-07-19T19:57:21.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65] for update
[2025-07-19T19:57:21.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:21.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.1.delta.17d226ec-647e-4c1c-88fc-c18aa03f0860.TID358.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/1.delta
[2025-07-19T19:57:21.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/1.delta
[2025-07-19T19:57:21.464+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 358, attempt 0, stage 5.0)
[2025-07-19T19:57:21.466+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 61 (task 360, attempt 0, stage 5.0)
[2025-07-19T19:57:21.466+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 61.0 in stage 5.0 (TID 360). 6286 bytes result sent to driver
[2025-07-19T19:57:21.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 81.0 in stage 5.0 (TID 367) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 61.0 in stage 5.0 (TID 360) in 93 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T19:57:21.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 81.0 in stage 5.0 (TID 367)
[2025-07-19T19:57:21.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58a3552d
[2025-07-19T19:57:21.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.471+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70] for update
[2025-07-19T19:57:21.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:21.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T19:57:21.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.476+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 57 (task 358, attempt 0, stage 5.0)
[2025-07-19T19:57:21.476+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 57.0 in stage 5.0 (TID 358). 6243 bytes result sent to driver
[2025-07-19T19:57:21.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.478+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 86.0 in stage 5.0 (TID 368) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 86.0 in stage 5.0 (TID 368)
[2025-07-19T19:57:21.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 57.0 in stage 5.0 (TID 358) in 102 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T19:57:21.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3453504a
[2025-07-19T19:57:21.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81] for update
[2025-07-19T19:57:21.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.1.delta.b432756f-8d13-4b6d-9d55-a2ff20752245.TID362.tmp
[2025-07-19T19:57:21.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.1.delta.4b27bfe9-d1cc-4a8c-9065-8256855447ca.TID364.tmp
[2025-07-19T19:57:21.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a9c8a9d
[2025-07-19T19:57:21.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69] for update
[2025-07-19T19:57:21.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.1.delta.a9774e20-a60a-4a13-bb2b-c5b5c8adcf2c.TID361.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/1.delta
[2025-07-19T19:57:21.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/1.delta
[2025-07-19T19:57:21.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 361, attempt 0, stage 5.0)
[2025-07-19T19:57:21.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60e8b236
[2025-07-19T19:57:21.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86] for update
[2025-07-19T19:57:21.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 64 (task 361, attempt 0, stage 5.0)
[2025-07-19T19:57:21.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 64.0 in stage 5.0 (TID 361). 6243 bytes result sent to driver
[2025-07-19T19:57:21.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.1.delta.5c79e0b8-4db5-4e40-a0d4-2f10e0d2217a.TID367.tmp
[2025-07-19T19:57:21.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 87.0 in stage 5.0 (TID 369) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 64.0 in stage 5.0 (TID 361) in 95 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T19:57:21.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 87.0 in stage 5.0 (TID 369)
[2025-07-19T19:57:21.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@327f5b92
[2025-07-19T19:57:21.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.1.delta.8f8bae25-2323-4629-a486-12aa420d73b8.TID363.tmp
[2025-07-19T19:57:21.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73] for update
[2025-07-19T19:57:21.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:21.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.516+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cbdf352
[2025-07-19T19:57:21.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.1.delta.e33b39b9-e47f-42aa-99ee-495a867db847.TID365.tmp
[2025-07-19T19:57:21.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.1.delta.2d92bf84-e641-44aa-bc3f-a0650cf06f64.TID368.tmp
[2025-07-19T19:57:21.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79] for update
[2025-07-19T19:57:21.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.1.delta.b432756f-8d13-4b6d-9d55-a2ff20752245.TID362.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/1.delta
[2025-07-19T19:57:21.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/1.delta
[2025-07-19T19:57:21.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.1.delta.4b27bfe9-d1cc-4a8c-9065-8256855447ca.TID364.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/1.delta
[2025-07-19T19:57:21.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/1.delta
[2025-07-19T19:57:21.526+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 362, attempt 0, stage 5.0)
[2025-07-19T19:57:21.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 364, attempt 0, stage 5.0)
[2025-07-19T19:57:21.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60f90698
[2025-07-19T19:57:21.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87] for update
[2025-07-19T19:57:21.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 65 (task 362, attempt 0, stage 5.0)
[2025-07-19T19:57:21.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 65.0 in stage 5.0 (TID 362). 6243 bytes result sent to driver
[2025-07-19T19:57:21.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 70 (task 364, attempt 0, stage 5.0)
[2025-07-19T19:57:21.532+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 70.0 in stage 5.0 (TID 364). 6243 bytes result sent to driver
[2025-07-19T19:57:21.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 89.0 in stage 5.0 (TID 370) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.1.delta.2f9df1e9-3e81-41d2-9a03-2d5b4d978b6f.TID366.tmp
[2025-07-19T19:57:21.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 65.0 in stage 5.0 (TID 362) in 94 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T19:57:21.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 90.0 in stage 5.0 (TID 371) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 89.0 in stage 5.0 (TID 370)
[2025-07-19T19:57:21.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 70.0 in stage 5.0 (TID 364) in 85 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T19:57:21.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 90.0 in stage 5.0 (TID 371)
[2025-07-19T19:57:21.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.1.delta.8f8bae25-2323-4629-a486-12aa420d73b8.TID363.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/1.delta
[2025-07-19T19:57:21.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/1.delta
[2025-07-19T19:57:21.547+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 363, attempt 0, stage 5.0)
[2025-07-19T19:57:21.548+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.1.delta.5c79e0b8-4db5-4e40-a0d4-2f10e0d2217a.TID367.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/1.delta
[2025-07-19T19:57:21.548+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/1.delta
[2025-07-19T19:57:21.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.1.delta.a8dbf43b-9fe6-44be-9438-b2028a111b27.TID369.tmp
[2025-07-19T19:57:21.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 367, attempt 0, stage 5.0)
[2025-07-19T19:57:21.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ee6c1b7
[2025-07-19T19:57:21.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 69 (task 363, attempt 0, stage 5.0)
[2025-07-19T19:57:21.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90] for update
[2025-07-19T19:57:21.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.1.delta.e33b39b9-e47f-42aa-99ee-495a867db847.TID365.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/1.delta
[2025-07-19T19:57:21.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/1.delta
[2025-07-19T19:57:21.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 69.0 in stage 5.0 (TID 363). 6243 bytes result sent to driver
[2025-07-19T19:57:21.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 365, attempt 0, stage 5.0)
[2025-07-19T19:57:21.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 81 (task 367, attempt 0, stage 5.0)
[2025-07-19T19:57:21.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 81.0 in stage 5.0 (TID 367). 6200 bytes result sent to driver
[2025-07-19T19:57:21.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 91.0 in stage 5.0 (TID 372) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 91.0 in stage 5.0 (TID 372)
[2025-07-19T19:57:21.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 69.0 in stage 5.0 (TID 363) in 117 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T19:57:21.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 81.0 in stage 5.0 (TID 367) in 93 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T19:57:21.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 92.0 in stage 5.0 (TID 373) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 92.0 in stage 5.0 (TID 373)
[2025-07-19T19:57:21.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21fa2121
[2025-07-19T19:57:21.569+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89] for update
[2025-07-19T19:57:21.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.1.delta.2d92bf84-e641-44aa-bc3f-a0650cf06f64.TID368.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/1.delta
[2025-07-19T19:57:21.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/1.delta
[2025-07-19T19:57:21.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 368, attempt 0, stage 5.0)
[2025-07-19T19:57:21.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 73 (task 365, attempt 0, stage 5.0)
[2025-07-19T19:57:21.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 73.0 in stage 5.0 (TID 365). 6243 bytes result sent to driver
[2025-07-19T19:57:21.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 93.0 in stage 5.0 (TID 374) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 93.0 in stage 5.0 (TID 374)
[2025-07-19T19:57:21.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 73.0 in stage 5.0 (TID 365) in 118 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T19:57:21.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.1.delta.4726b68d-5678-4b9b-96ad-f305006f135b.TID371.tmp
[2025-07-19T19:57:21.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bdf79ad
[2025-07-19T19:57:21.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 86 (task 368, attempt 0, stage 5.0)
[2025-07-19T19:57:21.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 86.0 in stage 5.0 (TID 368). 6200 bytes result sent to driver
[2025-07-19T19:57:21.580+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.580+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91] for update
[2025-07-19T19:57:21.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 95.0 in stage 5.0 (TID 375) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 86.0 in stage 5.0 (TID 368) in 105 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T19:57:21.582+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 95.0 in stage 5.0 (TID 375)
[2025-07-19T19:57:21.582+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.1.delta.2f9df1e9-3e81-41d2-9a03-2d5b4d978b6f.TID366.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/1.delta
[2025-07-19T19:57:21.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/1.delta
[2025-07-19T19:57:21.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 366, attempt 0, stage 5.0)
[2025-07-19T19:57:21.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.1.delta.c2e1f60a-4b95-4c12-94b5-38d2f0be3ce8.TID370.tmp
[2025-07-19T19:57:21.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 79 (task 366, attempt 0, stage 5.0)
[2025-07-19T19:57:21.597+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 79.0 in stage 5.0 (TID 366). 6286 bytes result sent to driver
[2025-07-19T19:57:21.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2202ac67
[2025-07-19T19:57:21.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.1.delta.28fa05a1-f971-409d-9cd6-42d8caaeb38d.TID372.tmp
[2025-07-19T19:57:21.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92] for update
[2025-07-19T19:57:21.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.1.delta.a8dbf43b-9fe6-44be-9438-b2028a111b27.TID369.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/1.delta
[2025-07-19T19:57:21.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/1.delta
[2025-07-19T19:57:21.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 369, attempt 0, stage 5.0)
[2025-07-19T19:57:21.606+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 98.0 in stage 5.0 (TID 376) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.606+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39629393
[2025-07-19T19:57:21.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 79.0 in stage 5.0 (TID 366) in 147 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T19:57:21.608+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.608+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 98.0 in stage 5.0 (TID 376)
[2025-07-19T19:57:21.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95] for update
[2025-07-19T19:57:21.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 87 (task 369, attempt 0, stage 5.0)
[2025-07-19T19:57:21.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 87.0 in stage 5.0 (TID 369). 6243 bytes result sent to driver
[2025-07-19T19:57:21.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 101.0 in stage 5.0 (TID 377) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 101.0 in stage 5.0 (TID 377)
[2025-07-19T19:57:21.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 87.0 in stage 5.0 (TID 369) in 112 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T19:57:21.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:21.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6331bcda
[2025-07-19T19:57:21.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93] for update
[2025-07-19T19:57:21.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.1.delta.f2118f66-12d0-487f-b9ae-9521dd8480bb.TID373.tmp
[2025-07-19T19:57:21.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.1.delta.427cae26-3afe-421c-810c-9b21ffbbfc71.TID375.tmp
[2025-07-19T19:57:21.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.1.delta.4726b68d-5678-4b9b-96ad-f305006f135b.TID371.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/1.delta
[2025-07-19T19:57:21.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/1.delta
[2025-07-19T19:57:21.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4577be57
[2025-07-19T19:57:21.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 371, attempt 0, stage 5.0)
[2025-07-19T19:57:21.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101] for update
[2025-07-19T19:57:21.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.1.delta.c2e1f60a-4b95-4c12-94b5-38d2f0be3ce8.TID370.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/1.delta
[2025-07-19T19:57:21.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/1.delta
[2025-07-19T19:57:21.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.1.delta.fe1ffe37-879e-4528-9eb6-f64321d34129.TID374.tmp
[2025-07-19T19:57:21.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@85c5da8
[2025-07-19T19:57:21.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 90 (task 371, attempt 0, stage 5.0)
[2025-07-19T19:57:21.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 90.0 in stage 5.0 (TID 371). 6243 bytes result sent to driver
[2025-07-19T19:57:21.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 102.0 in stage 5.0 (TID 378) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98] for update
[2025-07-19T19:57:21.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 90.0 in stage 5.0 (TID 371) in 97 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T19:57:21.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 370, attempt 0, stage 5.0)
[2025-07-19T19:57:21.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 102.0 in stage 5.0 (TID 378)
[2025-07-19T19:57:21.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.1.delta.73702e92-92e4-4b81-b389-5ea214f46817.TID377.tmp
[2025-07-19T19:57:21.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.1.delta.28fa05a1-f971-409d-9cd6-42d8caaeb38d.TID372.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/1.delta
[2025-07-19T19:57:21.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/1.delta
[2025-07-19T19:57:21.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 372, attempt 0, stage 5.0)
[2025-07-19T19:57:21.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 89 (task 370, attempt 0, stage 5.0)
[2025-07-19T19:57:21.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.1.delta.61e1ebb9-64ee-46cc-b115-05f92bdb09fd.TID376.tmp
[2025-07-19T19:57:21.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 89.0 in stage 5.0 (TID 370). 6243 bytes result sent to driver
[2025-07-19T19:57:21.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 105.0 in stage 5.0 (TID 379) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 105.0 in stage 5.0 (TID 379)
[2025-07-19T19:57:21.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 89.0 in stage 5.0 (TID 370) in 116 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T19:57:21.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@403d63be
[2025-07-19T19:57:21.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.1.delta.f2118f66-12d0-487f-b9ae-9521dd8480bb.TID373.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/1.delta
[2025-07-19T19:57:21.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/1.delta
[2025-07-19T19:57:21.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.1.delta.427cae26-3afe-421c-810c-9b21ffbbfc71.TID375.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/1.delta
[2025-07-19T19:57:21.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/1.delta
[2025-07-19T19:57:21.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 91 (task 372, attempt 0, stage 5.0)
[2025-07-19T19:57:21.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102] for update
[2025-07-19T19:57:21.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 375, attempt 0, stage 5.0)
[2025-07-19T19:57:21.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 91.0 in stage 5.0 (TID 372). 6243 bytes result sent to driver
[2025-07-19T19:57:21.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 373, attempt 0, stage 5.0)
[2025-07-19T19:57:21.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 107.0 in stage 5.0 (TID 380) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 107.0 in stage 5.0 (TID 380)
[2025-07-19T19:57:21.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 91.0 in stage 5.0 (TID 372) in 102 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T19:57:21.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 95 (task 375, attempt 0, stage 5.0)
[2025-07-19T19:57:21.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:21.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71cc0f1f
[2025-07-19T19:57:21.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 92 (task 373, attempt 0, stage 5.0)
[2025-07-19T19:57:21.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 92.0 in stage 5.0 (TID 373). 6243 bytes result sent to driver
[2025-07-19T19:57:21.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 95.0 in stage 5.0 (TID 375). 6243 bytes result sent to driver
[2025-07-19T19:57:21.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105] for update
[2025-07-19T19:57:21.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 108.0 in stage 5.0 (TID 381) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 109.0 in stage 5.0 (TID 382) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 92.0 in stage 5.0 (TID 373) in 107 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T19:57:21.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 108.0 in stage 5.0 (TID 381)
[2025-07-19T19:57:21.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 109.0 in stage 5.0 (TID 382)
[2025-07-19T19:57:21.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 95.0 in stage 5.0 (TID 375) in 92 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T19:57:21.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.1.delta.02b86424-aa41-4c5d-a062-2be42cf2258c.TID378.tmp
[2025-07-19T19:57:21.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56facb7b
[2025-07-19T19:57:21.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107] for update
[2025-07-19T19:57:21.674+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.1.delta.73702e92-92e4-4b81-b389-5ea214f46817.TID377.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/1.delta
[2025-07-19T19:57:21.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/1.delta
[2025-07-19T19:57:21.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 377, attempt 0, stage 5.0)
[2025-07-19T19:57:21.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.1.delta.61e1ebb9-64ee-46cc-b115-05f92bdb09fd.TID376.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/1.delta
[2025-07-19T19:57:21.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/1.delta
[2025-07-19T19:57:21.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.1.delta.fe1ffe37-879e-4528-9eb6-f64321d34129.TID374.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/1.delta
[2025-07-19T19:57:21.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/1.delta
[2025-07-19T19:57:21.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.1.delta.50769fb9-2a64-4427-a557-b747c91f0610.TID379.tmp
[2025-07-19T19:57:21.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 374, attempt 0, stage 5.0)
[2025-07-19T19:57:21.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 376, attempt 0, stage 5.0)
[2025-07-19T19:57:21.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 101 (task 377, attempt 0, stage 5.0)
[2025-07-19T19:57:21.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cbaec30
[2025-07-19T19:57:21.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 101.0 in stage 5.0 (TID 377). 6200 bytes result sent to driver
[2025-07-19T19:57:21.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 110.0 in stage 5.0 (TID 383) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109] for update
[2025-07-19T19:57:21.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 101.0 in stage 5.0 (TID 377) in 80 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T19:57:21.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 98 (task 376, attempt 0, stage 5.0)
[2025-07-19T19:57:21.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 110.0 in stage 5.0 (TID 383)
[2025-07-19T19:57:21.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 93 (task 374, attempt 0, stage 5.0)
[2025-07-19T19:57:21.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 98.0 in stage 5.0 (TID 376). 6200 bytes result sent to driver
[2025-07-19T19:57:21.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 93.0 in stage 5.0 (TID 374). 6286 bytes result sent to driver
[2025-07-19T19:57:21.693+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 116.0 in stage 5.0 (TID 384) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.693+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.1.delta.d272fa74-2351-4835-971e-7329829982f0.TID380.tmp
[2025-07-19T19:57:21.693+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 123.0 in stage 5.0 (TID 385) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 116.0 in stage 5.0 (TID 384)
[2025-07-19T19:57:21.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 98.0 in stage 5.0 (TID 376) in 92 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T19:57:21.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@583bc18d
[2025-07-19T19:57:21.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108] for update
[2025-07-19T19:57:21.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 123.0 in stage 5.0 (TID 385)
[2025-07-19T19:57:21.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 93.0 in stage 5.0 (TID 374) in 127 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T19:57:21.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71952d3c
[2025-07-19T19:57:21.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.1.delta.746eac56-ebfc-44f5-bb9d-890b26b2952e.TID382.tmp
[2025-07-19T19:57:21.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.1.delta.02b86424-aa41-4c5d-a062-2be42cf2258c.TID378.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/1.delta
[2025-07-19T19:57:21.710+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/1.delta
[2025-07-19T19:57:21.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110] for update
[2025-07-19T19:57:21.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 378, attempt 0, stage 5.0)
[2025-07-19T19:57:21.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 102 (task 378, attempt 0, stage 5.0)
[2025-07-19T19:57:21.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 102.0 in stage 5.0 (TID 378). 6243 bytes result sent to driver
[2025-07-19T19:57:21.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.1.delta.6519eac2-b4a5-4161-8980-a13bcdbe6e9d.TID381.tmp
[2025-07-19T19:57:21.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.1.delta.04a0cd54-1576-4976-8269-916a0cf0f248.TID383.tmp
[2025-07-19T19:57:21.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d731768
[2025-07-19T19:57:21.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116] for update
[2025-07-19T19:57:21.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.1.delta.50769fb9-2a64-4427-a557-b747c91f0610.TID379.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/1.delta
[2025-07-19T19:57:21.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/1.delta
[2025-07-19T19:57:21.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 124.0 in stage 5.0 (TID 386) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 102.0 in stage 5.0 (TID 378) in 95 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T19:57:21.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 124.0 in stage 5.0 (TID 386)
[2025-07-19T19:57:21.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 379, attempt 0, stage 5.0)
[2025-07-19T19:57:21.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 105 (task 379, attempt 0, stage 5.0)
[2025-07-19T19:57:21.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 105.0 in stage 5.0 (TID 379). 6243 bytes result sent to driver
[2025-07-19T19:57:21.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51bc4a6e
[2025-07-19T19:57:21.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 126.0 in stage 5.0 (TID 387) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123] for update
[2025-07-19T19:57:21.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 105.0 in stage 5.0 (TID 379) in 89 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T19:57:21.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 126.0 in stage 5.0 (TID 387)
[2025-07-19T19:57:21.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.1.delta.d272fa74-2351-4835-971e-7329829982f0.TID380.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/1.delta
[2025-07-19T19:57:21.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/1.delta
[2025-07-19T19:57:21.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 380, attempt 0, stage 5.0)
[2025-07-19T19:57:21.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46555c31
[2025-07-19T19:57:21.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.1.delta.6349f478-1020-40b4-9826-a1b6a1e7fee0.TID384.tmp
[2025-07-19T19:57:21.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124] for update
[2025-07-19T19:57:21.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.1.delta.04a0cd54-1576-4976-8269-916a0cf0f248.TID383.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/1.delta
[2025-07-19T19:57:21.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/1.delta
[2025-07-19T19:57:21.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.1.delta.6519eac2-b4a5-4161-8980-a13bcdbe6e9d.TID381.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/1.delta
[2025-07-19T19:57:21.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/1.delta
[2025-07-19T19:57:21.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 383, attempt 0, stage 5.0)
[2025-07-19T19:57:21.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@464c7059
[2025-07-19T19:57:21.758+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 381, attempt 0, stage 5.0)
[2025-07-19T19:57:21.760+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.1.delta.21e861ee-a553-46aa-a4f5-15d0ae171bc1.TID385.tmp
[2025-07-19T19:57:21.760+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.761+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126] for update
[2025-07-19T19:57:21.762+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.763+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.1.delta.35c347f2-83bf-4682-9b75-9f871dd625d2.TID386.tmp
[2025-07-19T19:57:21.764+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 107 (task 380, attempt 0, stage 5.0)
[2025-07-19T19:57:21.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 110 (task 383, attempt 0, stage 5.0)
[2025-07-19T19:57:21.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 107.0 in stage 5.0 (TID 380). 6243 bytes result sent to driver
[2025-07-19T19:57:21.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.1.delta.746eac56-ebfc-44f5-bb9d-890b26b2952e.TID382.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/1.delta
[2025-07-19T19:57:21.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/1.delta
[2025-07-19T19:57:21.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 127.0 in stage 5.0 (TID 388) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 107.0 in stage 5.0 (TID 380) in 109 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T19:57:21.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 110.0 in stage 5.0 (TID 383). 6243 bytes result sent to driver
[2025-07-19T19:57:21.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 382, attempt 0, stage 5.0)
[2025-07-19T19:57:21.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 132.0 in stage 5.0 (TID 389) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 132.0 in stage 5.0 (TID 389)
[2025-07-19T19:57:21.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 108 (task 381, attempt 0, stage 5.0)
[2025-07-19T19:57:21.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 110.0 in stage 5.0 (TID 383) in 83 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T19:57:21.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 127.0 in stage 5.0 (TID 388)
[2025-07-19T19:57:21.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.1.delta.d1d30f4e-852a-433d-84c0-f90041b4a614.TID387.tmp
[2025-07-19T19:57:21.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 108.0 in stage 5.0 (TID 381). 6243 bytes result sent to driver
[2025-07-19T19:57:21.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 136.0 in stage 5.0 (TID 390) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 108.0 in stage 5.0 (TID 381) in 105 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T19:57:21.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 109 (task 382, attempt 0, stage 5.0)
[2025-07-19T19:57:21.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 109.0 in stage 5.0 (TID 382). 6243 bytes result sent to driver
[2025-07-19T19:57:21.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 136.0 in stage 5.0 (TID 390)
[2025-07-19T19:57:21.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 138.0 in stage 5.0 (TID 391) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 138.0 in stage 5.0 (TID 391)
[2025-07-19T19:57:21.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 109.0 in stage 5.0 (TID 382) in 107 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T19:57:21.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.778+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6de48103
[2025-07-19T19:57:21.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132] for update
[2025-07-19T19:57:21.780+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.1.delta.21e861ee-a553-46aa-a4f5-15d0ae171bc1.TID385.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/1.delta
[2025-07-19T19:57:21.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/1.delta
[2025-07-19T19:57:21.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 385, attempt 0, stage 5.0)
[2025-07-19T19:57:21.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.1.delta.6349f478-1020-40b4-9826-a1b6a1e7fee0.TID384.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/1.delta
[2025-07-19T19:57:21.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/1.delta
[2025-07-19T19:57:21.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 384, attempt 0, stage 5.0)
[2025-07-19T19:57:21.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 123 (task 385, attempt 0, stage 5.0)
[2025-07-19T19:57:21.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f5faff2
[2025-07-19T19:57:21.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 116 (task 384, attempt 0, stage 5.0)
[2025-07-19T19:57:21.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138] for update
[2025-07-19T19:57:21.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 123.0 in stage 5.0 (TID 385). 6243 bytes result sent to driver
[2025-07-19T19:57:21.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 116.0 in stage 5.0 (TID 384). 6243 bytes result sent to driver
[2025-07-19T19:57:21.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 140.0 in stage 5.0 (TID 392) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 145.0 in stage 5.0 (TID 393) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 140.0 in stage 5.0 (TID 392)
[2025-07-19T19:57:21.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 145.0 in stage 5.0 (TID 393)
[2025-07-19T19:57:21.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.1.delta.5d258b5f-9ab2-49a6-902f-a274f416880e.TID389.tmp
[2025-07-19T19:57:21.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 123.0 in stage 5.0 (TID 385) in 104 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T19:57:21.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 116.0 in stage 5.0 (TID 384) in 105 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T19:57:21.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.798+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.1.delta.35c347f2-83bf-4682-9b75-9f871dd625d2.TID386.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/1.delta
[2025-07-19T19:57:21.798+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/1.delta
[2025-07-19T19:57:21.799+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 386, attempt 0, stage 5.0)
[2025-07-19T19:57:21.799+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@366d1e81
[2025-07-19T19:57:21.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127] for update
[2025-07-19T19:57:21.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 124 (task 386, attempt 0, stage 5.0)
[2025-07-19T19:57:21.803+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 124.0 in stage 5.0 (TID 386). 6200 bytes result sent to driver
[2025-07-19T19:57:21.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 152.0 in stage 5.0 (TID 394) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.1.delta.5af6ff99-8044-4461-83c6-331748101f6f.TID391.tmp
[2025-07-19T19:57:21.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 152.0 in stage 5.0 (TID 394)
[2025-07-19T19:57:21.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 124.0 in stage 5.0 (TID 386) in 90 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T19:57:21.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d5bcf95
[2025-07-19T19:57:21.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136] for update
[2025-07-19T19:57:21.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.1.delta.51eb84de-12dd-439f-b003-1453d89130db.TID388.tmp
[2025-07-19T19:57:21.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.1.delta.d1d30f4e-852a-433d-84c0-f90041b4a614.TID387.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/1.delta
[2025-07-19T19:57:21.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/1.delta
[2025-07-19T19:57:21.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64bde757
[2025-07-19T19:57:21.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 387, attempt 0, stage 5.0)
[2025-07-19T19:57:21.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152] for update
[2025-07-19T19:57:21.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@288dc0ff
[2025-07-19T19:57:21.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.1.delta.c30fe6ba-2a80-40ab-b590-c54134b2442f.TID390.tmp
[2025-07-19T19:57:21.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140] for update
[2025-07-19T19:57:21.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 126 (task 387, attempt 0, stage 5.0)
[2025-07-19T19:57:21.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.1.delta.ac0d60fa-c946-49ac-a47f-1239b98b03e5.TID394.tmp
[2025-07-19T19:57:21.827+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 126.0 in stage 5.0 (TID 387). 6243 bytes result sent to driver
[2025-07-19T19:57:21.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@379ddd17
[2025-07-19T19:57:21.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 155.0 in stage 5.0 (TID 395) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145] for update
[2025-07-19T19:57:21.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 126.0 in stage 5.0 (TID 387) in 96 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T19:57:21.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 155.0 in stage 5.0 (TID 395)
[2025-07-19T19:57:21.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.1.delta.5d258b5f-9ab2-49a6-902f-a274f416880e.TID389.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/1.delta
[2025-07-19T19:57:21.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/1.delta
[2025-07-19T19:57:21.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:21.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 389, attempt 0, stage 5.0)
[2025-07-19T19:57:21.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3261af50
[2025-07-19T19:57:21.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.1.delta.51eb84de-12dd-439f-b003-1453d89130db.TID388.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/1.delta
[2025-07-19T19:57:21.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/1.delta
[2025-07-19T19:57:21.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.1.delta.cfb60056-1937-48e0-8583-946c03ec43a3.TID393.tmp
[2025-07-19T19:57:21.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.1.delta.a9112a7f-5048-42aa-97eb-9958008c4edb.TID392.tmp
[2025-07-19T19:57:21.843+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 132 (task 389, attempt 0, stage 5.0)
[2025-07-19T19:57:21.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155] for update
[2025-07-19T19:57:21.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 388, attempt 0, stage 5.0)
[2025-07-19T19:57:21.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 132.0 in stage 5.0 (TID 389). 6243 bytes result sent to driver
[2025-07-19T19:57:21.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.1.delta.5af6ff99-8044-4461-83c6-331748101f6f.TID391.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/1.delta
[2025-07-19T19:57:21.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/1.delta
[2025-07-19T19:57:21.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 391, attempt 0, stage 5.0)
[2025-07-19T19:57:21.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 157.0 in stage 5.0 (TID 396) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 157.0 in stage 5.0 (TID 396)
[2025-07-19T19:57:21.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 132.0 in stage 5.0 (TID 389) in 77 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T19:57:21.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 127 (task 388, attempt 0, stage 5.0)
[2025-07-19T19:57:21.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 127.0 in stage 5.0 (TID 388). 6243 bytes result sent to driver
[2025-07-19T19:57:21.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 160.0 in stage 5.0 (TID 397) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 138 (task 391, attempt 0, stage 5.0)
[2025-07-19T19:57:21.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 160.0 in stage 5.0 (TID 397)
[2025-07-19T19:57:21.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 138.0 in stage 5.0 (TID 391). 6243 bytes result sent to driver
[2025-07-19T19:57:21.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 161.0 in stage 5.0 (TID 398) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a23482c
[2025-07-19T19:57:21.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160] for update
[2025-07-19T19:57:21.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 161.0 in stage 5.0 (TID 398)
[2025-07-19T19:57:21.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 127.0 in stage 5.0 (TID 388) in 92 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T19:57:21.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 138.0 in stage 5.0 (TID 391) in 86 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T19:57:21.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.1.delta.c30fe6ba-2a80-40ab-b590-c54134b2442f.TID390.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/1.delta
[2025-07-19T19:57:21.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/1.delta
[2025-07-19T19:57:21.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 390, attempt 0, stage 5.0)
[2025-07-19T19:57:21.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3812cf83
[2025-07-19T19:57:21.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157] for update
[2025-07-19T19:57:21.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 136 (task 390, attempt 0, stage 5.0)
[2025-07-19T19:57:21.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.1.delta.ac0d60fa-c946-49ac-a47f-1239b98b03e5.TID394.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/1.delta
[2025-07-19T19:57:21.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/1.delta
[2025-07-19T19:57:21.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 136.0 in stage 5.0 (TID 390). 6243 bytes result sent to driver
[2025-07-19T19:57:21.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.1.delta.907960d6-dd5e-47dc-a8e4-19934af1d735.TID397.tmp
[2025-07-19T19:57:21.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 394, attempt 0, stage 5.0)
[2025-07-19T19:57:21.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.1.delta.b9a504bc-873d-49ef-ad5f-39afa9bddeed.TID395.tmp
[2025-07-19T19:57:21.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 163.0 in stage 5.0 (TID 399) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.1.delta.cfb60056-1937-48e0-8583-946c03ec43a3.TID393.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/1.delta
[2025-07-19T19:57:21.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/1.delta
[2025-07-19T19:57:21.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 136.0 in stage 5.0 (TID 390) in 99 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T19:57:21.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 163.0 in stage 5.0 (TID 399)
[2025-07-19T19:57:21.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49d8d970
[2025-07-19T19:57:21.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 152 (task 394, attempt 0, stage 5.0)
[2025-07-19T19:57:21.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 393, attempt 0, stage 5.0)
[2025-07-19T19:57:21.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 152.0 in stage 5.0 (TID 394). 6243 bytes result sent to driver
[2025-07-19T19:57:21.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161] for update
[2025-07-19T19:57:21.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.1.delta.7fd435b0-07c8-4c41-a92a-16f0588f06f3.TID396.tmp
[2025-07-19T19:57:21.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 164.0 in stage 5.0 (TID 400) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 152.0 in stage 5.0 (TID 394) in 74 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T19:57:21.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 164.0 in stage 5.0 (TID 400)
[2025-07-19T19:57:21.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 145 (task 393, attempt 0, stage 5.0)
[2025-07-19T19:57:21.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 145.0 in stage 5.0 (TID 393). 6243 bytes result sent to driver
[2025-07-19T19:57:21.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 166.0 in stage 5.0 (TID 401) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 145.0 in stage 5.0 (TID 393) in 88 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T19:57:21.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 166.0 in stage 5.0 (TID 401)
[2025-07-19T19:57:21.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c8b230
[2025-07-19T19:57:21.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.1.delta.a9112a7f-5048-42aa-97eb-9958008c4edb.TID392.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/1.delta
[2025-07-19T19:57:21.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/1.delta
[2025-07-19T19:57:21.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 392, attempt 0, stage 5.0)
[2025-07-19T19:57:21.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163] for update
[2025-07-19T19:57:21.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 140 (task 392, attempt 0, stage 5.0)
[2025-07-19T19:57:21.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 140.0 in stage 5.0 (TID 392). 6243 bytes result sent to driver
[2025-07-19T19:57:21.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 168.0 in stage 5.0 (TID 402) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 140.0 in stage 5.0 (TID 392) in 96 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T19:57:21.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 168.0 in stage 5.0 (TID 402)
[2025-07-19T19:57:21.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31f83fd6
[2025-07-19T19:57:21.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164] for update
[2025-07-19T19:57:21.897+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.1.delta.9ec65b1d-92da-4dfc-b483-642d669820fc.TID398.tmp
[2025-07-19T19:57:21.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:21.901+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dfaeaa4
[2025-07-19T19:57:21.902+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166] for update
[2025-07-19T19:57:21.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.1.delta.18f85f13-7e47-4bbf-b88a-8e9079564d99.TID399.tmp
[2025-07-19T19:57:21.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.1.delta.907960d6-dd5e-47dc-a8e4-19934af1d735.TID397.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/1.delta
[2025-07-19T19:57:21.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/1.delta
[2025-07-19T19:57:21.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 397, attempt 0, stage 5.0)
[2025-07-19T19:57:21.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.1.delta.4c1b0706-e405-47ca-8b22-fe02b196c595.TID400.tmp
[2025-07-19T19:57:21.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.1.delta.b9a504bc-873d-49ef-ad5f-39afa9bddeed.TID395.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/1.delta
[2025-07-19T19:57:21.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/1.delta
[2025-07-19T19:57:21.910+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 395, attempt 0, stage 5.0)
[2025-07-19T19:57:21.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 160 (task 397, attempt 0, stage 5.0)
[2025-07-19T19:57:21.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 160.0 in stage 5.0 (TID 397). 6200 bytes result sent to driver
[2025-07-19T19:57:21.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ab2192f
[2025-07-19T19:57:21.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 176.0 in stage 5.0 (TID 403) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 176.0 in stage 5.0 (TID 403)
[2025-07-19T19:57:21.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 160.0 in stage 5.0 (TID 397) in 64 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T19:57:21.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.1.delta.6a561e77-c35f-4a89-8e16-949683aab8b9.TID401.tmp
[2025-07-19T19:57:21.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 155 (task 395, attempt 0, stage 5.0)
[2025-07-19T19:57:21.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168] for update
[2025-07-19T19:57:21.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 155.0 in stage 5.0 (TID 395). 6286 bytes result sent to driver
[2025-07-19T19:57:21.922+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 177.0 in stage 5.0 (TID 404) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 177.0 in stage 5.0 (TID 404)
[2025-07-19T19:57:21.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.1.delta.7fd435b0-07c8-4c41-a92a-16f0588f06f3.TID396.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/1.delta
[2025-07-19T19:57:21.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/1.delta
[2025-07-19T19:57:21.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 155.0 in stage 5.0 (TID 395) in 93 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T19:57:21.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 396, attempt 0, stage 5.0)
[2025-07-19T19:57:21.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77bd7814
[2025-07-19T19:57:21.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176] for update
[2025-07-19T19:57:21.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 157 (task 396, attempt 0, stage 5.0)
[2025-07-19T19:57:21.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d70bbf
[2025-07-19T19:57:21.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 157.0 in stage 5.0 (TID 396). 6286 bytes result sent to driver
[2025-07-19T19:57:21.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177] for update
[2025-07-19T19:57:21.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.1.delta.34663578-9c13-46b7-a0e0-616248cf2150.TID402.tmp
[2025-07-19T19:57:21.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 186.0 in stage 5.0 (TID 405) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 186.0 in stage 5.0 (TID 405)
[2025-07-19T19:57:21.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.1.delta.9ec65b1d-92da-4dfc-b483-642d669820fc.TID398.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/1.delta
[2025-07-19T19:57:21.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/1.delta
[2025-07-19T19:57:21.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 157.0 in stage 5.0 (TID 396) in 92 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T19:57:21.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:21.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.1.delta.18f85f13-7e47-4bbf-b88a-8e9079564d99.TID399.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/1.delta
[2025-07-19T19:57:21.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/1.delta
[2025-07-19T19:57:21.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 399, attempt 0, stage 5.0)
[2025-07-19T19:57:21.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 398, attempt 0, stage 5.0)
[2025-07-19T19:57:21.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.1.delta.2ab0307d-e826-4f60-bb3a-be21ecb560d7.TID403.tmp
[2025-07-19T19:57:21.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 161 (task 398, attempt 0, stage 5.0)
[2025-07-19T19:57:21.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 161.0 in stage 5.0 (TID 398). 6243 bytes result sent to driver
[2025-07-19T19:57:21.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 190.0 in stage 5.0 (TID 406) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.1.delta.4c1b0706-e405-47ca-8b22-fe02b196c595.TID400.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/1.delta
[2025-07-19T19:57:21.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 163 (task 399, attempt 0, stage 5.0)
[2025-07-19T19:57:21.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/1.delta
[2025-07-19T19:57:21.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 161.0 in stage 5.0 (TID 398) in 97 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T19:57:21.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 400, attempt 0, stage 5.0)
[2025-07-19T19:57:21.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 163.0 in stage 5.0 (TID 399). 6243 bytes result sent to driver
[2025-07-19T19:57:21.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 191.0 in stage 5.0 (TID 407) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 163.0 in stage 5.0 (TID 399) in 80 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T19:57:21.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 191.0 in stage 5.0 (TID 407)
[2025-07-19T19:57:21.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 190.0 in stage 5.0 (TID 406)
[2025-07-19T19:57:21.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 164 (task 400, attempt 0, stage 5.0)
[2025-07-19T19:57:21.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 164.0 in stage 5.0 (TID 400). 6243 bytes result sent to driver
[2025-07-19T19:57:21.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ea66288
[2025-07-19T19:57:21.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 193.0 in stage 5.0 (TID 408) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186] for update
[2025-07-19T19:57:21.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 193.0 in stage 5.0 (TID 408)
[2025-07-19T19:57:21.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.1.delta.6a561e77-c35f-4a89-8e16-949683aab8b9.TID401.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/1.delta
[2025-07-19T19:57:21.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/1.delta
[2025-07-19T19:57:21.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 164.0 in stage 5.0 (TID 400) in 79 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T19:57:21.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 401, attempt 0, stage 5.0)
[2025-07-19T19:57:21.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@106bbc2c
[2025-07-19T19:57:21.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.1.delta.3d132f3a-33c8-48d5-90ef-59a0f2a58e4f.TID404.tmp
[2025-07-19T19:57:21.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191] for update
[2025-07-19T19:57:21.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 166 (task 401, attempt 0, stage 5.0)
[2025-07-19T19:57:21.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 166.0 in stage 5.0 (TID 401). 6243 bytes result sent to driver
[2025-07-19T19:57:21.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 195.0 in stage 5.0 (TID 409) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 195.0 in stage 5.0 (TID 409)
[2025-07-19T19:57:21.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 166.0 in stage 5.0 (TID 401) in 86 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T19:57:21.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c0e282c
[2025-07-19T19:57:21.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190] for update
[2025-07-19T19:57:21.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.1.delta.09589d06-85c7-4100-8f72-0e74da45ef84.TID405.tmp
[2025-07-19T19:57:21.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.1.delta.a3608779-d1b9-4a34-8af4-6f356cbf7047.TID407.tmp
[2025-07-19T19:57:21.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.1.delta.2ab0307d-e826-4f60-bb3a-be21ecb560d7.TID403.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/1.delta
[2025-07-19T19:57:21.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/1.delta
[2025-07-19T19:57:21.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 403, attempt 0, stage 5.0)
[2025-07-19T19:57:21.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20903750
[2025-07-19T19:57:21.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195] for update
[2025-07-19T19:57:21.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c00f36b
[2025-07-19T19:57:21.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.1.delta.34663578-9c13-46b7-a0e0-616248cf2150.TID402.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/1.delta
[2025-07-19T19:57:21.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/1.delta
[2025-07-19T19:57:21.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 402, attempt 0, stage 5.0)
[2025-07-19T19:57:21.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193] for update
[2025-07-19T19:57:21.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 176 (task 403, attempt 0, stage 5.0)
[2025-07-19T19:57:21.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 176.0 in stage 5.0 (TID 403). 6243 bytes result sent to driver
[2025-07-19T19:57:21.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 198.0 in stage 5.0 (TID 410) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 198.0 in stage 5.0 (TID 410)
[2025-07-19T19:57:21.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 176.0 in stage 5.0 (TID 403) in 73 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T19:57:21.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Committed partition 168 (task 402, attempt 0, stage 5.0)
[2025-07-19T19:57:21.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Finished task 168.0 in stage 5.0 (TID 402). 6243 bytes result sent to driver
[2025-07-19T19:57:21.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 411) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:21.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.1.delta.41be58b6-741c-4146-a4e9-35b5ff98fcb1.TID406.tmp
[2025-07-19T19:57:21.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO TaskSetManager: Finished task 168.0 in stage 5.0 (TID 402) in 96 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T19:57:21.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO Executor: Running task 15.0 in stage 1.0 (TID 411)
[2025-07-19T19:57:21.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f072199
[2025-07-19T19:57:21.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.1.delta.449ddbca-0320-4378-9e0d-3a2ba106c0ba.TID409.tmp
[2025-07-19T19:57:21.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:21.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198] for update
[2025-07-19T19:57:21.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:21.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:21.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:21.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.1.delta.2a0425d4-c0ba-4033-957c-d3a152454e89.TID408.tmp
[2025-07-19T19:57:22.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fd2c293
[2025-07-19T19:57:22.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.1.delta.3d132f3a-33c8-48d5-90ef-59a0f2a58e4f.TID404.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/1.delta
[2025-07-19T19:57:22.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/1.delta
[2025-07-19T19:57:22.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 404, attempt 0, stage 5.0)
[2025-07-19T19:57:22.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15] for update
[2025-07-19T19:57:22.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 177 (task 404, attempt 0, stage 5.0)
[2025-07-19T19:57:22.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.1.delta.a3608779-d1b9-4a34-8af4-6f356cbf7047.TID407.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/1.delta
[2025-07-19T19:57:22.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/1.delta
[2025-07-19T19:57:22.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 177.0 in stage 5.0 (TID 404). 6200 bytes result sent to driver
[2025-07-19T19:57:22.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 412) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 16.0 in stage 1.0 (TID 412)
[2025-07-19T19:57:22.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 177.0 in stage 5.0 (TID 404) in 86 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T19:57:22.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.1.delta.d67a683b-98ab-4e61-8df7-baf4d4ba7908.TID410.tmp
[2025-07-19T19:57:22.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 407, attempt 0, stage 5.0)
[2025-07-19T19:57:22.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.1.delta.06b2ea33-c106-45ef-a576-b10c9fba0506.TID411.tmp
[2025-07-19T19:57:22.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 191 (task 407, attempt 0, stage 5.0)
[2025-07-19T19:57:22.014+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79e03eba
[2025-07-19T19:57:22.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 191.0 in stage 5.0 (TID 407). 6200 bytes result sent to driver
[2025-07-19T19:57:22.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16] for update
[2025-07-19T19:57:22.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 191.0 in stage 5.0 (TID 407) in 66 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T19:57:22.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 413) (8b44f3d35cfa, executor driver, partition 17, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 17.0 in stage 1.0 (TID 413)
[2025-07-19T19:57:22.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.1.delta.09589d06-85c7-4100-8f72-0e74da45ef84.TID405.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/1.delta
[2025-07-19T19:57:22.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/1.delta
[2025-07-19T19:57:22.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 405, attempt 0, stage 5.0)
[2025-07-19T19:57:22.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@309b7002
[2025-07-19T19:57:22.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17] for update
[2025-07-19T19:57:22.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 186 (task 405, attempt 0, stage 5.0)
[2025-07-19T19:57:22.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 186.0 in stage 5.0 (TID 405). 6243 bytes result sent to driver
[2025-07-19T19:57:22.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 414) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 186.0 in stage 5.0 (TID 405) in 98 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T19:57:22.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 18.0 in stage 1.0 (TID 414)
[2025-07-19T19:57:22.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.1.delta.33bfb576-68c4-4366-9593-70e72fda0a9e.TID412.tmp
[2025-07-19T19:57:22.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.1.delta.41be58b6-741c-4146-a4e9-35b5ff98fcb1.TID406.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/1.delta
[2025-07-19T19:57:22.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/1.delta
[2025-07-19T19:57:22.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 406, attempt 0, stage 5.0)
[2025-07-19T19:57:22.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.1.delta.449ddbca-0320-4378-9e0d-3a2ba106c0ba.TID409.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/1.delta
[2025-07-19T19:57:22.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/1.delta
[2025-07-19T19:57:22.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 409, attempt 0, stage 5.0)
[2025-07-19T19:57:22.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 190 (task 406, attempt 0, stage 5.0)
[2025-07-19T19:57:22.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 190.0 in stage 5.0 (TID 406). 6243 bytes result sent to driver
[2025-07-19T19:57:22.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 415) (8b44f3d35cfa, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.1.delta.d67a683b-98ab-4e61-8df7-baf4d4ba7908.TID410.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/1.delta
[2025-07-19T19:57:22.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/1.delta
[2025-07-19T19:57:22.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 19.0 in stage 1.0 (TID 415)
[2025-07-19T19:57:22.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 190.0 in stage 5.0 (TID 406) in 94 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T19:57:22.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.1.delta.2acf4620-d691-4b4d-896c-a724684e9c3a.TID413.tmp
[2025-07-19T19:57:22.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 410, attempt 0, stage 5.0)
[2025-07-19T19:57:22.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c00d6b9
[2025-07-19T19:57:22.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18] for update
[2025-07-19T19:57:22.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.1.delta.2a0425d4-c0ba-4033-957c-d3a152454e89.TID408.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/1.delta
[2025-07-19T19:57:22.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/1.delta
[2025-07-19T19:57:22.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 408, attempt 0, stage 5.0)
[2025-07-19T19:57:22.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 198 (task 410, attempt 0, stage 5.0)
[2025-07-19T19:57:22.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 193 (task 408, attempt 0, stage 5.0)
[2025-07-19T19:57:22.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 193.0 in stage 5.0 (TID 408). 6243 bytes result sent to driver
[2025-07-19T19:57:22.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 195 (task 409, attempt 0, stage 5.0)
[2025-07-19T19:57:22.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 198.0 in stage 5.0 (TID 410). 6243 bytes result sent to driver
[2025-07-19T19:57:22.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 195.0 in stage 5.0 (TID 409). 6243 bytes result sent to driver
[2025-07-19T19:57:22.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 193.0 in stage 5.0 (TID 408) in 98 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T19:57:22.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 416) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 417) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.052+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 418) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3120797c
[2025-07-19T19:57:22.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 195.0 in stage 5.0 (TID 409) in 88 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T19:57:22.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 198.0 in stage 5.0 (TID 410) in 70 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T19:57:22.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-19T19:57:22.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19] for update
[2025-07-19T19:57:22.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: ResultStage 5 (start at <unknown>:0) finished in 7.034 s
[2025-07-19T19:57:22.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T19:57:22.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-19T19:57:22.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 20.0 in stage 1.0 (TID 416)
[2025-07-19T19:57:22.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: Job 1 finished: start at <unknown>:0, took 8.411795 s
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Committing epoch 0 for query e64be3f7-c229-4a3a-b3cc-de24eff1ecd3 in append mode
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.1.delta.c8b48422-2a61-4b00-98d5-99b656b1a6e6.TID414.tmp
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 24.0 in stage 1.0 (TID 417)
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 26.0 in stage 1.0 (TID 418)
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.1.delta.06b2ea33-c106-45ef-a576-b10c9fba0506.TID411.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/1.delta
[2025-07-19T19:57:22.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/1.delta
[2025-07-19T19:57:22.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 411, attempt 0, stage 1.0)
[2025-07-19T19:57:22.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@547f1851
[2025-07-19T19:57:22.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26] for update
[2025-07-19T19:57:22.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.1.delta.d9348e81-edc8-443b-ba6b-f0642b2a2c87.TID415.tmp
[2025-07-19T19:57:22.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:22.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.1.delta.33bfb576-68c4-4366-9593-70e72fda0a9e.TID412.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/1.delta
[2025-07-19T19:57:22.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/1.delta
[2025-07-19T19:57:22.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 412, attempt 0, stage 1.0)
[2025-07-19T19:57:22.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@642af2ff
[2025-07-19T19:57:22.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20] for update
[2025-07-19T19:57:22.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.1.delta.2acf4620-d691-4b4d-896c-a724684e9c3a.TID413.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/1.delta
[2025-07-19T19:57:22.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/1.delta
[2025-07-19T19:57:22.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 413, attempt 0, stage 1.0)
[2025-07-19T19:57:22.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 15 (task 411, attempt 0, stage 1.0)
[2025-07-19T19:57:22.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 15.0 in stage 1.0 (TID 411). 9306 bytes result sent to driver
[2025-07-19T19:57:22.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10d03665
[2025-07-19T19:57:22.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 419) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 411) in 91 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T19:57:22.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24] for update
[2025-07-19T19:57:22.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 27.0 in stage 1.0 (TID 419)
[2025-07-19T19:57:22.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.1.delta.dd4baeb1-6aed-4db3-a0a4-7e623774d68d.TID418.tmp
[2025-07-19T19:57:22.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@527737b
[2025-07-19T19:57:22.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27] for update
[2025-07-19T19:57:22.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.1.delta.5c134209-5fa4-4da3-be5d-12ebdf84c5d0.TID416.tmp
[2025-07-19T19:57:22.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Committing streaming append with 123 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.1.delta.6eda7c67-16a7-448f-84a4-27edd8e41f1b.TID417.tmp
[2025-07-19T19:57:22.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 16 (task 412, attempt 0, stage 1.0)
[2025-07-19T19:57:22.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 16.0 in stage 1.0 (TID 412). 9304 bytes result sent to driver
[2025-07-19T19:57:22.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 420) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 17 (task 413, attempt 0, stage 1.0)
[2025-07-19T19:57:22.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 412) in 91 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T19:57:22.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 17.0 in stage 1.0 (TID 413). 9295 bytes result sent to driver
[2025-07-19T19:57:22.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 28.0 in stage 1.0 (TID 420)
[2025-07-19T19:57:22.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.1.delta.fa4c5e06-040e-4f1c-b317-40edad13935c.TID419.tmp
[2025-07-19T19:57:22.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 421) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.1.delta.c8b48422-2a61-4b00-98d5-99b656b1a6e6.TID414.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/1.delta
[2025-07-19T19:57:22.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/1.delta
[2025-07-19T19:57:22.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 30.0 in stage 1.0 (TID 421)
[2025-07-19T19:57:22.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 414, attempt 0, stage 1.0)
[2025-07-19T19:57:22.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 413) in 86 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T19:57:22.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.1.delta.d9348e81-edc8-443b-ba6b-f0642b2a2c87.TID415.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/1.delta
[2025-07-19T19:57:22.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/1.delta
[2025-07-19T19:57:22.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 415, attempt 0, stage 1.0)
[2025-07-19T19:57:22.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:22.112+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1815c571
[2025-07-19T19:57:22.115+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30] for update
[2025-07-19T19:57:22.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e47955f
[2025-07-19T19:57:22.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28] for update
[2025-07-19T19:57:22.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.1.delta.dd4baeb1-6aed-4db3-a0a4-7e623774d68d.TID418.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/1.delta
[2025-07-19T19:57:22.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/1.delta
[2025-07-19T19:57:22.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 418, attempt 0, stage 1.0)
[2025-07-19T19:57:22.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 19 (task 415, attempt 0, stage 1.0)
[2025-07-19T19:57:22.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 19.0 in stage 1.0 (TID 415). 9261 bytes result sent to driver
[2025-07-19T19:57:22.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 422) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 31.0 in stage 1.0 (TID 422)
[2025-07-19T19:57:22.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.1.delta.5c134209-5fa4-4da3-be5d-12ebdf84c5d0.TID416.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/1.delta
[2025-07-19T19:57:22.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/1.delta
[2025-07-19T19:57:22.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 415) in 85 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T19:57:22.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 416, attempt 0, stage 1.0)
[2025-07-19T19:57:22.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 18 (task 414, attempt 0, stage 1.0)
[2025-07-19T19:57:22.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 18.0 in stage 1.0 (TID 414). 9245 bytes result sent to driver
[2025-07-19T19:57:22.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 423) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 32.0 in stage 1.0 (TID 423)
[2025-07-19T19:57:22.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 414) in 98 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T19:57:22.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.1.delta.fa4c5e06-040e-4f1c-b317-40edad13935c.TID419.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/1.delta
[2025-07-19T19:57:22.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/1.delta
[2025-07-19T19:57:22.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.1.delta.6eda7c67-16a7-448f-84a4-27edd8e41f1b.TID417.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/1.delta
[2025-07-19T19:57:22.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/1.delta
[2025-07-19T19:57:22.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 417, attempt 0, stage 1.0)
[2025-07-19T19:57:22.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 419, attempt 0, stage 1.0)
[2025-07-19T19:57:22.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.1.delta.211c6055-dd18-469f-ad9a-8b3fa9b8478e.TID420.tmp
[2025-07-19T19:57:22.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.1.delta.a7c0d29a-38a5-44cb-b365-25a3975f8078.TID421.tmp
[2025-07-19T19:57:22.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4401e584
[2025-07-19T19:57:22.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31] for update
[2025-07-19T19:57:22.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 26 (task 418, attempt 0, stage 1.0)
[2025-07-19T19:57:22.158+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 26.0 in stage 1.0 (TID 418). 9337 bytes result sent to driver
[2025-07-19T19:57:22.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 20 (task 416, attempt 0, stage 1.0)
[2025-07-19T19:57:22.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 20.0 in stage 1.0 (TID 416). 9272 bytes result sent to driver
[2025-07-19T19:57:22.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 424) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 425) (8b44f3d35cfa, executor driver, partition 34, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 34.0 in stage 1.0 (TID 425)
[2025-07-19T19:57:22.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5866a5e0
[2025-07-19T19:57:22.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32] for update
[2025-07-19T19:57:22.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 33.0 in stage 1.0 (TID 424)
[2025-07-19T19:57:22.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 418) in 109 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T19:57:22.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 416) in 110 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T19:57:22.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.1.delta.c1638d38-e79c-41c5-a2f9-dc745ef61076.TID422.tmp
[2025-07-19T19:57:22.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 27 (task 419, attempt 0, stage 1.0)
[2025-07-19T19:57:22.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 27.0 in stage 1.0 (TID 419). 9302 bytes result sent to driver
[2025-07-19T19:57:22.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 24 (task 417, attempt 0, stage 1.0)
[2025-07-19T19:57:22.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 426) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 35.0 in stage 1.0 (TID 426)
[2025-07-19T19:57:22.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 24.0 in stage 1.0 (TID 417). 9293 bytes result sent to driver
[2025-07-19T19:57:22.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 419) in 91 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T19:57:22.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bc28112
[2025-07-19T19:57:22.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 427) (8b44f3d35cfa, executor driver, partition 36, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 36.0 in stage 1.0 (TID 427)
[2025-07-19T19:57:22.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34] for update
[2025-07-19T19:57:22.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 417) in 119 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T19:57:22.177+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:22.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.1.delta.12b884f5-b639-4519-a126-3e76293fdadf.TID423.tmp
[2025-07-19T19:57:22.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.1.delta.211c6055-dd18-469f-ad9a-8b3fa9b8478e.TID420.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/1.delta
[2025-07-19T19:57:22.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/1.delta
[2025-07-19T19:57:22.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 420, attempt 0, stage 1.0)
[2025-07-19T19:57:22.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f6a4158
[2025-07-19T19:57:22.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33] for update
[2025-07-19T19:57:22.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.1.delta.a7c0d29a-38a5-44cb-b365-25a3975f8078.TID421.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/1.delta
[2025-07-19T19:57:22.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/1.delta
[2025-07-19T19:57:22.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 421, attempt 0, stage 1.0)
[2025-07-19T19:57:22.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.1.delta.3782c0f3-979b-4eea-a9fd-16e2cea8546a.TID425.tmp
[2025-07-19T19:57:22.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@93dca57
[2025-07-19T19:57:22.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35] for update
[2025-07-19T19:57:22.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.1.delta.af949889-0876-44b9-be19-6f93111cc399.TID424.tmp
[2025-07-19T19:57:22.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 28 (task 420, attempt 0, stage 1.0)
[2025-07-19T19:57:22.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bf0c42b
[2025-07-19T19:57:22.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36] for update
[2025-07-19T19:57:22.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 28.0 in stage 1.0 (TID 420). 9285 bytes result sent to driver
[2025-07-19T19:57:22.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 420) in 105 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T19:57:22.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 428) (8b44f3d35cfa, executor driver, partition 40, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 40.0 in stage 1.0 (TID 428)
[2025-07-19T19:57:22.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.1.delta.1312c1a7-d00d-4b26-82f0-d321acbbeedb.TID426.tmp
[2025-07-19T19:57:22.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 30 (task 421, attempt 0, stage 1.0)
[2025-07-19T19:57:22.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 30.0 in stage 1.0 (TID 421). 9287 bytes result sent to driver
[2025-07-19T19:57:22.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.1.delta.b2ed3812-5258-457f-a19a-7c0debd76b48.TID427.tmp
[2025-07-19T19:57:22.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 421) in 111 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T19:57:22.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 429) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5325808e
[2025-07-19T19:57:22.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 41.0 in stage 1.0 (TID 429)
[2025-07-19T19:57:22.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.1.delta.c1638d38-e79c-41c5-a2f9-dc745ef61076.TID422.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/1.delta
[2025-07-19T19:57:22.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/1.delta
[2025-07-19T19:57:22.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40] for update
[2025-07-19T19:57:22.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.1.delta.12b884f5-b639-4519-a126-3e76293fdadf.TID423.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/1.delta
[2025-07-19T19:57:22.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/1.delta
[2025-07-19T19:57:22.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 423, attempt 0, stage 1.0)
[2025-07-19T19:57:22.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 422, attempt 0, stage 1.0)
[2025-07-19T19:57:22.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@165fd68c
[2025-07-19T19:57:22.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41] for update
[2025-07-19T19:57:22.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.1.delta.3782c0f3-979b-4eea-a9fd-16e2cea8546a.TID425.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/1.delta
[2025-07-19T19:57:22.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/1.delta
[2025-07-19T19:57:22.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 425, attempt 0, stage 1.0)
[2025-07-19T19:57:22.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.1.delta.3b85231e-eb7a-4d72-bbed-e653c8c7aabb.TID428.tmp
[2025-07-19T19:57:22.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 31 (task 422, attempt 0, stage 1.0)
[2025-07-19T19:57:22.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.1.delta.af949889-0876-44b9-be19-6f93111cc399.TID424.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/1.delta
[2025-07-19T19:57:22.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/1.delta
[2025-07-19T19:57:22.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 31.0 in stage 1.0 (TID 422). 9279 bytes result sent to driver
[2025-07-19T19:57:22.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 32 (task 423, attempt 0, stage 1.0)
[2025-07-19T19:57:22.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 424, attempt 0, stage 1.0)
[2025-07-19T19:57:22.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 32.0 in stage 1.0 (TID 423). 9293 bytes result sent to driver
[2025-07-19T19:57:22.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 430) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 431) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 422) in 110 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T19:57:22.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 46.0 in stage 1.0 (TID 431)
[2025-07-19T19:57:22.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 42.0 in stage 1.0 (TID 430)
[2025-07-19T19:57:22.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 423) in 109 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T19:57:22.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.1.delta.5f65a7c4-d69d-43e2-9033-b1049395ed6e.TID429.tmp
[2025-07-19T19:57:22.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:22.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.1.delta.b2ed3812-5258-457f-a19a-7c0debd76b48.TID427.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/1.delta
[2025-07-19T19:57:22.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:22.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/1.delta
[2025-07-19T19:57:22.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.1.delta.1312c1a7-d00d-4b26-82f0-d321acbbeedb.TID426.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/1.delta
[2025-07-19T19:57:22.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/1.delta
[2025-07-19T19:57:22.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 34 (task 425, attempt 0, stage 1.0)
[2025-07-19T19:57:22.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 427, attempt 0, stage 1.0)
[2025-07-19T19:57:22.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 426, attempt 0, stage 1.0)
[2025-07-19T19:57:22.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 34.0 in stage 1.0 (TID 425). 9250 bytes result sent to driver
[2025-07-19T19:57:22.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 432) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 425) in 90 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T19:57:22.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 47.0 in stage 1.0 (TID 432)
[2025-07-19T19:57:22.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65398a9f
[2025-07-19T19:57:22.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46] for update
[2025-07-19T19:57:22.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:22.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 33 (task 424, attempt 0, stage 1.0)
[2025-07-19T19:57:22.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 33.0 in stage 1.0 (TID 424). 9246 bytes result sent to driver
[2025-07-19T19:57:22.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 433) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 48.0 in stage 1.0 (TID 433)
[2025-07-19T19:57:22.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 424) in 98 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T19:57:22.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5940bc1a
[2025-07-19T19:57:22.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42] for update
[2025-07-19T19:57:22.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 35 (task 426, attempt 0, stage 1.0)
[2025-07-19T19:57:22.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 36 (task 427, attempt 0, stage 1.0)
[2025-07-19T19:57:22.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 35.0 in stage 1.0 (TID 426). 9247 bytes result sent to driver
[2025-07-19T19:57:22.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 36.0 in stage 1.0 (TID 427). 9316 bytes result sent to driver
[2025-07-19T19:57:22.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 434) (8b44f3d35cfa, executor driver, partition 49, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 49.0 in stage 1.0 (TID 434)
[2025-07-19T19:57:22.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 426) in 98 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T19:57:22.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 435) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 427) in 95 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T19:57:22.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 51.0 in stage 1.0 (TID 435)
[2025-07-19T19:57:22.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49294cbf
[2025-07-19T19:57:22.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.1.delta.980fc849-d28b-454f-9df3-69346ceb78af.TID431.tmp
[2025-07-19T19:57:22.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:22.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48] for update
[2025-07-19T19:57:22.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.277+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.1.delta.5a92b76a-4fd5-457f-ba93-bca09e36319f.TID430.tmp
[2025-07-19T19:57:22.277+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52b42d21
[2025-07-19T19:57:22.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47] for update
[2025-07-19T19:57:22.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.1.delta.3b85231e-eb7a-4d72-bbed-e653c8c7aabb.TID428.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/1.delta
[2025-07-19T19:57:22.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/1.delta
[2025-07-19T19:57:22.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 428, attempt 0, stage 1.0)
[2025-07-19T19:57:22.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.1.delta.cfa388d6-02f3-4d3c-800f-488e1676dfa6.TID433.tmp
[2025-07-19T19:57:22.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f753ab9
[2025-07-19T19:57:22.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.1.delta.5f65a7c4-d69d-43e2-9033-b1049395ed6e.TID429.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/1.delta
[2025-07-19T19:57:22.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/1.delta
[2025-07-19T19:57:22.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 429, attempt 0, stage 1.0)
[2025-07-19T19:57:22.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.1.delta.4542d08c-d227-447d-b460-885330d5ab92.TID432.tmp
[2025-07-19T19:57:22.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v88.metadata.json
[2025-07-19T19:57:22.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51] for update
[2025-07-19T19:57:22.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 40 (task 428, attempt 0, stage 1.0)
[2025-07-19T19:57:22.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 40.0 in stage 1.0 (TID 428). 9304 bytes result sent to driver
[2025-07-19T19:57:22.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 54.0 in stage 1.0 (TID 436) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 428) in 103 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T19:57:22.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 54.0 in stage 1.0 (TID 436)
[2025-07-19T19:57:22.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66e1422a
[2025-07-19T19:57:22.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.1.delta.017426ff-9657-4cbb-9461-b4f5151c034e.TID435.tmp
[2025-07-19T19:57:22.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49] for update
[2025-07-19T19:57:22.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 41 (task 429, attempt 0, stage 1.0)
[2025-07-19T19:57:22.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 41.0 in stage 1.0 (TID 429). 9289 bytes result sent to driver
[2025-07-19T19:57:22.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 55.0 in stage 1.0 (TID 437) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 55.0 in stage 1.0 (TID 437)
[2025-07-19T19:57:22.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 429) in 105 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T19:57:22.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53846457
[2025-07-19T19:57:22.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.1.delta.980fc849-d28b-454f-9df3-69346ceb78af.TID431.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/1.delta
[2025-07-19T19:57:22.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/1.delta
[2025-07-19T19:57:22.321+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 431, attempt 0, stage 1.0)
[2025-07-19T19:57:22.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54] for update
[2025-07-19T19:57:22.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.1.delta.cfa388d6-02f3-4d3c-800f-488e1676dfa6.TID433.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/1.delta
[2025-07-19T19:57:22.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/1.delta
[2025-07-19T19:57:22.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 433, attempt 0, stage 1.0)
[2025-07-19T19:57:22.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.1.delta.5a92b76a-4fd5-457f-ba93-bca09e36319f.TID430.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/1.delta
[2025-07-19T19:57:22.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/1.delta
[2025-07-19T19:57:22.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 430, attempt 0, stage 1.0)
[2025-07-19T19:57:22.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.1.delta.1a3eaf7a-44bb-4639-9de4-47aa95e95202.TID434.tmp
[2025-07-19T19:57:22.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@459041e2
[2025-07-19T19:57:22.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55] for update
[2025-07-19T19:57:22.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 46 (task 431, attempt 0, stage 1.0)
[2025-07-19T19:57:22.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.1.delta.a2d0c8a7-6df2-4958-9a19-227d51aa6c72.TID436.tmp
[2025-07-19T19:57:22.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 46.0 in stage 1.0 (TID 431). 9287 bytes result sent to driver
[2025-07-19T19:57:22.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.1.delta.4542d08c-d227-447d-b460-885330d5ab92.TID432.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/1.delta
[2025-07-19T19:57:22.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/1.delta
[2025-07-19T19:57:22.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 432, attempt 0, stage 1.0)
[2025-07-19T19:57:22.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 57.0 in stage 1.0 (TID 438) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 57.0 in stage 1.0 (TID 438)
[2025-07-19T19:57:22.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 48 (task 433, attempt 0, stage 1.0)
[2025-07-19T19:57:22.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SnapshotProducer: Committed snapshot 5541658889941357423 (FastAppend)
[2025-07-19T19:57:22.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 48.0 in stage 1.0 (TID 433). 9309 bytes result sent to driver
[2025-07-19T19:57:22.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 431) in 110 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T19:57:22.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 42 (task 430, attempt 0, stage 1.0)
[2025-07-19T19:57:22.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 42.0 in stage 1.0 (TID 430). 9295 bytes result sent to driver
[2025-07-19T19:57:22.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 58.0 in stage 1.0 (TID 439) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 58.0 in stage 1.0 (TID 439)
[2025-07-19T19:57:22.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 60.0 in stage 1.0 (TID 440) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.1.delta.5837e9c8-2b33-4668-b5f5-e99a40b4a740.TID437.tmp
[2025-07-19T19:57:22.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 433) in 96 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T19:57:22.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 60.0 in stage 1.0 (TID 440)
[2025-07-19T19:57:22.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 430) in 117 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T19:57:22.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.1.delta.017426ff-9657-4cbb-9461-b4f5151c034e.TID435.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/1.delta
[2025-07-19T19:57:22.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/1.delta
[2025-07-19T19:57:22.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 435, attempt 0, stage 1.0)
[2025-07-19T19:57:22.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36a1b043
[2025-07-19T19:57:22.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57] for update
[2025-07-19T19:57:22.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.1.delta.1a3eaf7a-44bb-4639-9de4-47aa95e95202.TID434.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/1.delta
[2025-07-19T19:57:22.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/1.delta
[2025-07-19T19:57:22.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 434, attempt 0, stage 1.0)
[2025-07-19T19:57:22.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 47 (task 432, attempt 0, stage 1.0)
[2025-07-19T19:57:22.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cb9270b
[2025-07-19T19:57:22.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 47.0 in stage 1.0 (TID 432). 9362 bytes result sent to driver
[2025-07-19T19:57:22.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58] for update
[2025-07-19T19:57:22.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 62.0 in stage 1.0 (TID 441) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 62.0 in stage 1.0 (TID 441)
[2025-07-19T19:57:22.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 432) in 131 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T19:57:22.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.1.delta.a2d0c8a7-6df2-4958-9a19-227d51aa6c72.TID436.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/1.delta
[2025-07-19T19:57:22.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/1.delta
[2025-07-19T19:57:22.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@524bb906
[2025-07-19T19:57:22.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 436, attempt 0, stage 1.0)
[2025-07-19T19:57:22.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60] for update
[2025-07-19T19:57:22.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.1.delta.d98c77aa-e3ca-45d8-aa09-a4da17c42707.TID438.tmp
[2025-07-19T19:57:22.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 49 (task 434, attempt 0, stage 1.0)
[2025-07-19T19:57:22.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 51 (task 435, attempt 0, stage 1.0)
[2025-07-19T19:57:22.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 51.0 in stage 1.0 (TID 435). 9312 bytes result sent to driver
[2025-07-19T19:57:22.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 63.0 in stage 1.0 (TID 442) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 63.0 in stage 1.0 (TID 442)
[2025-07-19T19:57:22.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 435) in 119 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T19:57:22.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.1.delta.5d2a7635-4200-40a6-aba1-dc7593c8ff8f.TID439.tmp
[2025-07-19T19:57:22.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 49.0 in stage 1.0 (TID 434). 9304 bytes result sent to driver
[2025-07-19T19:57:22.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 64.0 in stage 1.0 (TID 443) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 434) in 123 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T19:57:22.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:22.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4df5323b
[2025-07-19T19:57:22.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62] for update
[2025-07-19T19:57:22.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 64.0 in stage 1.0 (TID 443)
[2025-07-19T19:57:22.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77657ded
[2025-07-19T19:57:22.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.1.delta.04072dcc-436f-447c-a8d4-8109abb6fc9f.TID440.tmp
[2025-07-19T19:57:22.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63] for update
[2025-07-19T19:57:22.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 54 (task 436, attempt 0, stage 1.0)
[2025-07-19T19:57:22.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=5541658889941357423, sequenceNumber=87, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.311612208S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=123}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=3672}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=174}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=4818}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=354824}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=10558323}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752955029831, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T19:57:22.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Committed in 312 ms
[2025-07-19T19:57:22.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T19:57:22.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 54.0 in stage 1.0 (TID 436). 9302 bytes result sent to driver
[2025-07-19T19:57:22.411+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 66.0 in stage 1.0 (TID 444) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752782223000 ms
[2025-07-19T19:57:22.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 66.0 in stage 1.0 (TID 444)
[2025-07-19T19:57:22.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 54.0 in stage 1.0 (TID 436) in 99 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T19:57:22.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.1.delta.5837e9c8-2b33-4668-b5f5-e99a40b4a740.TID437.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/1.delta
[2025-07-19T19:57:22.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/1.delta
[2025-07-19T19:57:22.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 437, attempt 0, stage 1.0)
[2025-07-19T19:57:22.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:22.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.1.delta.9d150ff8-dd02-4041-80d3-40a08fffe4b6.TID441.tmp
[2025-07-19T19:57:22.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bc327f4
[2025-07-19T19:57:22.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64] for update
[2025-07-19T19:57:22.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.1.delta.3e306c2e-fc33-4221-a13a-b3ce0cfcc563.TID442.tmp
[2025-07-19T19:57:22.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/commits/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/commits/.0.32a5e18c-97b4-43f0-9ae4-21db50147241.tmp
[2025-07-19T19:57:22.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 55 (task 437, attempt 0, stage 1.0)
[2025-07-19T19:57:22.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62dab87d
[2025-07-19T19:57:22.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 55.0 in stage 1.0 (TID 437). 9284 bytes result sent to driver
[2025-07-19T19:57:22.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66] for update
[2025-07-19T19:57:22.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 68.0 in stage 1.0 (TID 445) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 68.0 in stage 1.0 (TID 445)
[2025-07-19T19:57:22.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 55.0 in stage 1.0 (TID 437) in 110 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T19:57:22.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.1.delta.15a7ff6f-0ba1-43b2-a02b-da89eacaa99a.TID443.tmp
[2025-07-19T19:57:22.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.1.delta.3005499d-5532-4e78-8101-db4363094313.TID444.tmp
[2025-07-19T19:57:22.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.1.delta.d98c77aa-e3ca-45d8-aa09-a4da17c42707.TID438.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/1.delta
[2025-07-19T19:57:22.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/1.delta
[2025-07-19T19:57:22.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 438, attempt 0, stage 1.0)
[2025-07-19T19:57:22.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b24a61c
[2025-07-19T19:57:22.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68] for update
[2025-07-19T19:57:22.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.448+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.1.delta.5d2a7635-4200-40a6-aba1-dc7593c8ff8f.TID439.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/1.delta
[2025-07-19T19:57:22.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/1.delta
[2025-07-19T19:57:22.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 439, attempt 0, stage 1.0)
[2025-07-19T19:57:22.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.1.delta.04072dcc-436f-447c-a8d4-8109abb6fc9f.TID440.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/1.delta
[2025-07-19T19:57:22.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/1.delta
[2025-07-19T19:57:22.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 440, attempt 0, stage 1.0)
[2025-07-19T19:57:22.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.1.delta.1780df83-fdf4-4f8a-899f-39e3b8802f18.TID445.tmp
[2025-07-19T19:57:22.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 57 (task 438, attempt 0, stage 1.0)
[2025-07-19T19:57:22.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 57.0 in stage 1.0 (TID 438). 9330 bytes result sent to driver
[2025-07-19T19:57:22.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 71.0 in stage 1.0 (TID 446) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 71.0 in stage 1.0 (TID 446)
[2025-07-19T19:57:22.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 57.0 in stage 1.0 (TID 438) in 118 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T19:57:22.464+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.464+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.466+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fcd1110
[2025-07-19T19:57:22.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71] for update
[2025-07-19T19:57:22.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.1.delta.3e306c2e-fc33-4221-a13a-b3ce0cfcc563.TID442.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/1.delta
[2025-07-19T19:57:22.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/1.delta
[2025-07-19T19:57:22.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 442, attempt 0, stage 1.0)
[2025-07-19T19:57:22.472+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 58 (task 439, attempt 0, stage 1.0)
[2025-07-19T19:57:22.472+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 58.0 in stage 1.0 (TID 439). 9289 bytes result sent to driver
[2025-07-19T19:57:22.472+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 73.0 in stage 1.0 (TID 447) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 60 (task 440, attempt 0, stage 1.0)
[2025-07-19T19:57:22.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 73.0 in stage 1.0 (TID 447)
[2025-07-19T19:57:22.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 58.0 in stage 1.0 (TID 439) in 132 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T19:57:22.481+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 60.0 in stage 1.0 (TID 440). 9295 bytes result sent to driver
[2025-07-19T19:57:22.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 74.0 in stage 1.0 (TID 448) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 74.0 in stage 1.0 (TID 448)
[2025-07-19T19:57:22.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 60.0 in stage 1.0 (TID 440) in 135 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T19:57:22.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.1.delta.ab0d1848-bda0-49f2-89ce-000973fe2faa.TID446.tmp
[2025-07-19T19:57:22.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.1.delta.3005499d-5532-4e78-8101-db4363094313.TID444.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/1.delta
[2025-07-19T19:57:22.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/1.delta
[2025-07-19T19:57:22.490+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 444, attempt 0, stage 1.0)
[2025-07-19T19:57:22.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.1.delta.9d150ff8-dd02-4041-80d3-40a08fffe4b6.TID441.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/1.delta
[2025-07-19T19:57:22.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/1.delta
[2025-07-19T19:57:22.492+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.1.delta.15a7ff6f-0ba1-43b2-a02b-da89eacaa99a.TID443.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/1.delta
[2025-07-19T19:57:22.492+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/1.delta
[2025-07-19T19:57:22.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 443, attempt 0, stage 1.0)
[2025-07-19T19:57:22.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/commits/.0.32a5e18c-97b4-43f0-9ae4-21db50147241.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/commits/0
[2025-07-19T19:57:22.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 441, attempt 0, stage 1.0)
[2025-07-19T19:57:22.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d16474
[2025-07-19T19:57:22.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73] for update
[2025-07-19T19:57:22.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 63 (task 442, attempt 0, stage 1.0)
[2025-07-19T19:57:22.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T19:57:22.500+0000] {subprocess.py:93} INFO -   "id" : "e64be3f7-c229-4a3a-b3cc-de24eff1ecd3",
[2025-07-19T19:57:22.500+0000] {subprocess.py:93} INFO -   "runId" : "b5fdfb25-db44-4f9a-8656-6e80fbb359f7",
[2025-07-19T19:57:22.501+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T19:57:22.502+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T19:57:12.219Z",
[2025-07-19T19:57:22.502+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T19:57:22.503+0000] {subprocess.py:93} INFO -   "numInputRows" : 174,
[2025-07-19T19:57:22.503+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:22.504+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 16.94585118815738,
[2025-07-19T19:57:22.504+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T19:57:22.505+0000] {subprocess.py:93} INFO -     "addBatch" : 9336,
[2025-07-19T19:57:22.505+0000] {subprocess.py:93} INFO -     "commitOffsets" : 86,
[2025-07-19T19:57:22.505+0000] {subprocess.py:93} INFO -     "getBatch" : 19,
[2025-07-19T19:57:22.506+0000] {subprocess.py:93} INFO -     "latestOffset" : 272,
[2025-07-19T19:57:22.506+0000] {subprocess.py:93} INFO -     "queryPlanning" : 499,
[2025-07-19T19:57:22.506+0000] {subprocess.py:93} INFO -     "triggerExecution" : 10268,
[2025-07-19T19:57:22.507+0000] {subprocess.py:93} INFO -     "walCommit" : 47
[2025-07-19T19:57:22.507+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:22.507+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T19:57:22.508+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T18:49:08.999Z",
[2025-07-19T19:57:22.510+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T19:57:03.000Z",
[2025-07-19T19:57:22.511+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T18:00:01.000Z",
[2025-07-19T19:57:22.511+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T19:57:22.511+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:22.512+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T19:57:22.513+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T19:57:22.514+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 174,
[2025-07-19T19:57:22.515+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 174,
[2025-07-19T19:57:22.515+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 2016,
[2025-07-19T19:57:22.516+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T19:57:22.517+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 113,
[2025-07-19T19:57:22.517+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 9612,
[2025-07-19T19:57:22.518+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 89856,
[2025-07-19T19:57:22.518+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T19:57:22.518+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T19:57:22.519+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T19:57:22.519+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T19:57:22.519+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T19:57:22.520+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T19:57:22.520+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T19:57:22.521+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 61056
[2025-07-19T19:57:22.522+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:22.522+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:22.522+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T19:57:22.523+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T19:57:22.523+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T19:57:22.524+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T19:57:22.525+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T19:57:22.526+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:22.527+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:22.528+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:22.528+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T19:57:22.529+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T19:57:22.529+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:22.529+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:22.529+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:22.530+0000] {subprocess.py:93} INFO -     "numInputRows" : 174,
[2025-07-19T19:57:22.531+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:22.531+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 16.94585118815738,
[2025-07-19T19:57:22.531+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T19:57:22.532+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T19:57:22.533+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T19:57:22.533+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T19:57:22.533+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:22.534+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:22.534+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T19:57:22.534+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T19:57:22.535+0000] {subprocess.py:93} INFO -     "numOutputRows" : 174
[2025-07-19T19:57:22.538+0000] {subprocess.py:93} INFO -   }
[2025-07-19T19:57:22.538+0000] {subprocess.py:93} INFO - }
[2025-07-19T19:57:22.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.1.delta.1780df83-fdf4-4f8a-899f-39e3b8802f18.TID445.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/1.delta
[2025-07-19T19:57:22.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/1.delta
[2025-07-19T19:57:22.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 445, attempt 0, stage 1.0)
[2025-07-19T19:57:22.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@621a940d
[2025-07-19T19:57:22.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 63.0 in stage 1.0 (TID 442). 9291 bytes result sent to driver
[2025-07-19T19:57:22.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74] for update
[2025-07-19T19:57:22.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 76.0 in stage 1.0 (TID 449) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 63.0 in stage 1.0 (TID 442) in 116 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T19:57:22.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 76.0 in stage 1.0 (TID 449)
[2025-07-19T19:57:22.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 62 (task 441, attempt 0, stage 1.0)
[2025-07-19T19:57:22.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 62.0 in stage 1.0 (TID 441). 9295 bytes result sent to driver
[2025-07-19T19:57:22.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 79.0 in stage 1.0 (TID 450) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.1.delta.b494f251-f8b5-4b63-989c-770281b8f05a.TID447.tmp
[2025-07-19T19:57:22.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@562828e9
[2025-07-19T19:57:22.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 79.0 in stage 1.0 (TID 450)
[2025-07-19T19:57:22.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.1.delta.c188b2c0-7665-4457-8c5d-3571f80e55fe.TID448.tmp
[2025-07-19T19:57:22.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76] for update
[2025-07-19T19:57:22.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 62.0 in stage 1.0 (TID 441) in 143 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T19:57:22.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 64 (task 443, attempt 0, stage 1.0)
[2025-07-19T19:57:22.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 66 (task 444, attempt 0, stage 1.0)
[2025-07-19T19:57:22.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 64.0 in stage 1.0 (TID 443). 9313 bytes result sent to driver
[2025-07-19T19:57:22.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 66.0 in stage 1.0 (TID 444). 9313 bytes result sent to driver
[2025-07-19T19:57:22.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 80.0 in stage 1.0 (TID 451) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 80.0 in stage 1.0 (TID 451)
[2025-07-19T19:57:22.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 82.0 in stage 1.0 (TID 452) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 64.0 in stage 1.0 (TID 443) in 133 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T19:57:22.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 82.0 in stage 1.0 (TID 452)
[2025-07-19T19:57:22.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 66.0 in stage 1.0 (TID 444) in 116 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T19:57:22.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 68 (task 445, attempt 0, stage 1.0)
[2025-07-19T19:57:22.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:22.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/offsets/.1.148d5187-42dd-4c15-af72-c0adb4e4c750.tmp
[2025-07-19T19:57:22.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 68.0 in stage 1.0 (TID 445). 9307 bytes result sent to driver
[2025-07-19T19:57:22.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 83.0 in stage 1.0 (TID 453) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 83.0 in stage 1.0 (TID 453)
[2025-07-19T19:57:22.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b8cf67f
[2025-07-19T19:57:22.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 68.0 in stage 1.0 (TID 445) in 100 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T19:57:22.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79] for update
[2025-07-19T19:57:22.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.1.delta.25d84f6b-dd0a-428a-9a96-fbb157df4baa.TID449.tmp
[2025-07-19T19:57:22.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.569+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.1.delta.ab0d1848-bda0-49f2-89ce-000973fe2faa.TID446.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/1.delta
[2025-07-19T19:57:22.569+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/1.delta
[2025-07-19T19:57:22.569+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 446, attempt 0, stage 1.0)
[2025-07-19T19:57:22.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22c04527
[2025-07-19T19:57:22.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80] for update
[2025-07-19T19:57:22.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.1.delta.c837e9f1-ddc6-4bd6-b449-81ac6aae0a6e.TID450.tmp
[2025-07-19T19:57:22.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.1.delta.b494f251-f8b5-4b63-989c-770281b8f05a.TID447.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/1.delta
[2025-07-19T19:57:22.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/1.delta
[2025-07-19T19:57:22.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a7b0c51
[2025-07-19T19:57:22.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 447, attempt 0, stage 1.0)
[2025-07-19T19:57:22.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82] for update
[2025-07-19T19:57:22.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.1.delta.c188b2c0-7665-4457-8c5d-3571f80e55fe.TID448.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/1.delta
[2025-07-19T19:57:22.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/1.delta
[2025-07-19T19:57:22.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 448, attempt 0, stage 1.0)
[2025-07-19T19:57:22.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 71 (task 446, attempt 0, stage 1.0)
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 71.0 in stage 1.0 (TID 446). 9301 bytes result sent to driver
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.1.delta.04625830-6a9f-4dd7-ae38-e09f79f9e6a1.TID451.tmp
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 86.0 in stage 1.0 (TID 454) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 86.0 in stage 1.0 (TID 454)
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 71.0 in stage 1.0 (TID 446) in 93 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ca59588
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83] for update
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.1.delta.ece931cf-660b-41d5-baaa-27dc6cb66fd3.TID452.tmp
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 73 (task 447, attempt 0, stage 1.0)
[2025-07-19T19:57:22.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 73.0 in stage 1.0 (TID 447). 9235 bytes result sent to driver
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 87.0 in stage 1.0 (TID 455) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/offsets/.1.148d5187-42dd-4c15-af72-c0adb4e4c750.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/offsets/1
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 87.0 in stage 1.0 (TID 455)
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.1.delta.2c4d53db-4f6c-4556-950a-b534d33594f3.TID453.tmp
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.1.delta.25d84f6b-dd0a-428a-9a96-fbb157df4baa.TID449.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/1.delta
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/1.delta
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e9c05f4
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 449, attempt 0, stage 1.0)
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86] for update
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.1.delta.c837e9f1-ddc6-4bd6-b449-81ac6aae0a6e.TID450.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/1.delta
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/1.delta
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 450, attempt 0, stage 1.0)
[2025-07-19T19:57:22.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 76 (task 449, attempt 0, stage 1.0)
[2025-07-19T19:57:22.582+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 73.0 in stage 1.0 (TID 447) in 111 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T19:57:22.585+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752782223000,1752955042500,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T19:57:22.586+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 76.0 in stage 1.0 (TID 449). 9353 bytes result sent to driver
[2025-07-19T19:57:22.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 88.0 in stage 1.0 (TID 456) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 76.0 in stage 1.0 (TID 449) in 90 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T19:57:22.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 88.0 in stage 1.0 (TID 456)
[2025-07-19T19:57:22.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ff38ed9
[2025-07-19T19:57:22.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.1.delta.04625830-6a9f-4dd7-ae38-e09f79f9e6a1.TID451.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/1.delta
[2025-07-19T19:57:22.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/1.delta
[2025-07-19T19:57:22.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87] for update
[2025-07-19T19:57:22.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 451, attempt 0, stage 1.0)
[2025-07-19T19:57:22.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.1.delta.ece931cf-660b-41d5-baaa-27dc6cb66fd3.TID452.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/1.delta
[2025-07-19T19:57:22.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/1.delta
[2025-07-19T19:57:22.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 452, attempt 0, stage 1.0)
[2025-07-19T19:57:22.601+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12f290e8
[2025-07-19T19:57:22.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.1.delta.ee73e6d3-8489-480b-98eb-be32619a22cd.TID454.tmp
[2025-07-19T19:57:22.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88] for update
[2025-07-19T19:57:22.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.1.delta.2c4d53db-4f6c-4556-950a-b534d33594f3.TID453.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/1.delta
[2025-07-19T19:57:22.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/1.delta
[2025-07-19T19:57:22.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 453, attempt 0, stage 1.0)
[2025-07-19T19:57:22.606+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 79 (task 450, attempt 0, stage 1.0)
[2025-07-19T19:57:22.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 79.0 in stage 1.0 (TID 450). 9296 bytes result sent to driver
[2025-07-19T19:57:22.608+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 90.0 in stage 1.0 (TID 457) (8b44f3d35cfa, executor driver, partition 90, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 79.0 in stage 1.0 (TID 450) in 100 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T19:57:22.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 90.0 in stage 1.0 (TID 457)
[2025-07-19T19:57:22.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 74 (task 448, attempt 0, stage 1.0)
[2025-07-19T19:57:22.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 74.0 in stage 1.0 (TID 448). 9308 bytes result sent to driver
[2025-07-19T19:57:22.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.1.delta.546d437f-4172-4311-9bd9-58f708aa87d7.TID455.tmp
[2025-07-19T19:57:22.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 93.0 in stage 1.0 (TID 458) (8b44f3d35cfa, executor driver, partition 93, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 74.0 in stage 1.0 (TID 448) in 132 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T19:57:22.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 93.0 in stage 1.0 (TID 458)
[2025-07-19T19:57:22.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 80 (task 451, attempt 0, stage 1.0)
[2025-07-19T19:57:22.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 82 (task 452, attempt 0, stage 1.0)
[2025-07-19T19:57:22.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 80.0 in stage 1.0 (TID 451). 9295 bytes result sent to driver
[2025-07-19T19:57:22.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 82.0 in stage 1.0 (TID 452). 9309 bytes result sent to driver
[2025-07-19T19:57:22.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 96.0 in stage 1.0 (TID 459) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 97.0 in stage 1.0 (TID 460) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 82.0 in stage 1.0 (TID 452) in 100 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T19:57:22.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 80.0 in stage 1.0 (TID 451) in 102 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T19:57:22.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 96.0 in stage 1.0 (TID 459)
[2025-07-19T19:57:22.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.1.delta.d9ebfd57-67a7-4c31-b662-a2976f2084dd.TID456.tmp
[2025-07-19T19:57:22.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 97.0 in stage 1.0 (TID 460)
[2025-07-19T19:57:22.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@436fdf0a
[2025-07-19T19:57:22.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93] for update
[2025-07-19T19:57:22.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 83 (task 453, attempt 0, stage 1.0)
[2025-07-19T19:57:22.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:22.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:22.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fce7067
[2025-07-19T19:57:22.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 83.0 in stage 1.0 (TID 453). 9335 bytes result sent to driver
[2025-07-19T19:57:22.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 99.0 in stage 1.0 (TID 461) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90] for update
[2025-07-19T19:57:22.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 99.0 in stage 1.0 (TID 461)
[2025-07-19T19:57:22.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 83.0 in stage 1.0 (TID 453) in 110 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T19:57:22.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.1.delta.ee73e6d3-8489-480b-98eb-be32619a22cd.TID454.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/1.delta
[2025-07-19T19:57:22.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/1.delta
[2025-07-19T19:57:22.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.1.delta.29270480-5204-4e11-b1b1-56c59421a636.TID458.tmp
[2025-07-19T19:57:22.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 454, attempt 0, stage 1.0)
[2025-07-19T19:57:22.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64cc28ac
[2025-07-19T19:57:22.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97] for update
[2025-07-19T19:57:22.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.1.delta.b6dbd0ec-0e5e-496f-b924-c8d91b821e44.TID457.tmp
[2025-07-19T19:57:22.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.1.delta.b2ca42d9-8e97-476f-9cf2-79e5d1469be2.TID460.tmp
[2025-07-19T19:57:22.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.1.delta.546d437f-4172-4311-9bd9-58f708aa87d7.TID455.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/1.delta
[2025-07-19T19:57:22.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/1.delta
[2025-07-19T19:57:22.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4545c221
[2025-07-19T19:57:22.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 455, attempt 0, stage 1.0)
[2025-07-19T19:57:22.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 86 (task 454, attempt 0, stage 1.0)
[2025-07-19T19:57:22.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96] for update
[2025-07-19T19:57:22.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 86.0 in stage 1.0 (TID 454). 9316 bytes result sent to driver
[2025-07-19T19:57:22.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 100.0 in stage 1.0 (TID 462) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.1.delta.d9ebfd57-67a7-4c31-b662-a2976f2084dd.TID456.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/1.delta
[2025-07-19T19:57:22.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/1.delta
[2025-07-19T19:57:22.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 456, attempt 0, stage 1.0)
[2025-07-19T19:57:22.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 86.0 in stage 1.0 (TID 454) in 107 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T19:57:22.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 100.0 in stage 1.0 (TID 462)
[2025-07-19T19:57:22.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.661+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.661+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@be3ab5c
[2025-07-19T19:57:22.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99] for update
[2025-07-19T19:57:22.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.1.delta.3b3a7928-85ee-467d-9ec7-7140f8f1a927.TID459.tmp
[2025-07-19T19:57:22.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:22.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.1.delta.29270480-5204-4e11-b1b1-56c59421a636.TID458.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/1.delta
[2025-07-19T19:57:22.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/1.delta
[2025-07-19T19:57:22.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 87 (task 455, attempt 0, stage 1.0)
[2025-07-19T19:57:22.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 458, attempt 0, stage 1.0)
[2025-07-19T19:57:22.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 87.0 in stage 1.0 (TID 455). 9354 bytes result sent to driver
[2025-07-19T19:57:22.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48338a26
[2025-07-19T19:57:22.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.1.delta.4c88e57a-30ae-413e-a953-58ed698e5926.TID461.tmp
[2025-07-19T19:57:22.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 102.0 in stage 1.0 (TID 463) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100] for update
[2025-07-19T19:57:22.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 87.0 in stage 1.0 (TID 455) in 124 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T19:57:22.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 88 (task 456, attempt 0, stage 1.0)
[2025-07-19T19:57:22.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 102.0 in stage 1.0 (TID 463)
[2025-07-19T19:57:22.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.1.delta.b6dbd0ec-0e5e-496f-b924-c8d91b821e44.TID457.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/1.delta
[2025-07-19T19:57:22.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/1.delta
[2025-07-19T19:57:22.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 88.0 in stage 1.0 (TID 456). 9305 bytes result sent to driver
[2025-07-19T19:57:22.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 103.0 in stage 1.0 (TID 464) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 457, attempt 0, stage 1.0)
[2025-07-19T19:57:22.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 103.0 in stage 1.0 (TID 464)
[2025-07-19T19:57:22.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 88.0 in stage 1.0 (TID 456) in 102 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T19:57:22.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:22.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 93 (task 458, attempt 0, stage 1.0)
[2025-07-19T19:57:22.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46065ecc
[2025-07-19T19:57:22.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 93.0 in stage 1.0 (TID 458). 9270 bytes result sent to driver
[2025-07-19T19:57:22.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.1.delta.9c691a58-f706-4b88-8dc0-39a473048cc2.TID462.tmp
[2025-07-19T19:57:22.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102] for update
[2025-07-19T19:57:22.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 105.0 in stage 1.0 (TID 465) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 105.0 in stage 1.0 (TID 465)
[2025-07-19T19:57:22.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 93.0 in stage 1.0 (TID 458) in 86 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T19:57:22.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.702+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.702+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 90 (task 457, attempt 0, stage 1.0)
[2025-07-19T19:57:22.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 90.0 in stage 1.0 (TID 457). 9302 bytes result sent to driver
[2025-07-19T19:57:22.704+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 106.0 in stage 1.0 (TID 466) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.704+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 106.0 in stage 1.0 (TID 466)
[2025-07-19T19:57:22.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 90.0 in stage 1.0 (TID 457) in 98 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T19:57:22.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c7bec06
[2025-07-19T19:57:22.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103] for update
[2025-07-19T19:57:22.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.1.delta.3b3a7928-85ee-467d-9ec7-7140f8f1a927.TID459.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/1.delta
[2025-07-19T19:57:22.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/1.delta
[2025-07-19T19:57:22.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.1.delta.b2ca42d9-8e97-476f-9cf2-79e5d1469be2.TID460.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/1.delta
[2025-07-19T19:57:22.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/1.delta
[2025-07-19T19:57:22.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 459, attempt 0, stage 1.0)
[2025-07-19T19:57:22.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 460, attempt 0, stage 1.0)
[2025-07-19T19:57:22.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 209.0 KiB, free 433.1 MiB)
[2025-07-19T19:57:22.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ff57f2f
[2025-07-19T19:57:22.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.1.delta.0eb6f5f7-aa9a-48c8-ba29-b66f07c7bc4a.TID463.tmp
[2025-07-19T19:57:22.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105] for update
[2025-07-19T19:57:22.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.1.delta.b317c99b-481b-4123-954b-f875edd4ecce.TID464.tmp
[2025-07-19T19:57:22.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 97 (task 460, attempt 0, stage 1.0)
[2025-07-19T19:57:22.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 97.0 in stage 1.0 (TID 460). 9314 bytes result sent to driver
[2025-07-19T19:57:22.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.1.delta.4c88e57a-30ae-413e-a953-58ed698e5926.TID461.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/1.delta
[2025-07-19T19:57:22.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/1.delta
[2025-07-19T19:57:22.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 109.0 in stage 1.0 (TID 467) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65b043fd
[2025-07-19T19:57:22.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 461, attempt 0, stage 1.0)
[2025-07-19T19:57:22.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106] for update
[2025-07-19T19:57:22.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 97.0 in stage 1.0 (TID 460) in 112 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T19:57:22.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 109.0 in stage 1.0 (TID 467)
[2025-07-19T19:57:22.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.1.delta.9c691a58-f706-4b88-8dc0-39a473048cc2.TID462.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/1.delta
[2025-07-19T19:57:22.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/1.delta
[2025-07-19T19:57:22.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 462, attempt 0, stage 1.0)
[2025-07-19T19:57:22.737+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.1.delta.df821db5-67df-43c6-8894-498d1f640091.TID466.tmp
[2025-07-19T19:57:22.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.1.delta.b531551f-dc31-4673-bb87-d4afe09b2b6d.TID465.tmp
[2025-07-19T19:57:22.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.1 MiB)
[2025-07-19T19:57:22.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b785250
[2025-07-19T19:57:22.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 8b44f3d35cfa:44249 (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T19:57:22.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109] for update
[2025-07-19T19:57:22.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.1.delta.0eb6f5f7-aa9a-48c8-ba29-b66f07c7bc4a.TID463.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/1.delta
[2025-07-19T19:57:22.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/1.delta
[2025-07-19T19:57:22.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkContext: Created broadcast 12 from start at <unknown>:0
[2025-07-19T19:57:22.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 96 (task 459, attempt 0, stage 1.0)
[2025-07-19T19:57:22.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 463, attempt 0, stage 1.0)
[2025-07-19T19:57:22.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 96.0 in stage 1.0 (TID 459). 9324 bytes result sent to driver
[2025-07-19T19:57:22.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 110.0 in stage 1.0 (TID 468) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 96.0 in stage 1.0 (TID 459) in 129 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T19:57:22.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 110.0 in stage 1.0 (TID 468)
[2025-07-19T19:57:22.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 100 (task 462, attempt 0, stage 1.0)
[2025-07-19T19:57:22.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 99 (task 461, attempt 0, stage 1.0)
[2025-07-19T19:57:22.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-07-19T19:57:22.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.0 MiB)
[2025-07-19T19:57:22.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 99.0 in stage 1.0 (TID 461). 9321 bytes result sent to driver
[2025-07-19T19:57:22.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 8b44f3d35cfa:44249 (size: 29.5 KiB, free: 434.1 MiB)
[2025-07-19T19:57:22.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkContext: Created broadcast 13 from start at <unknown>:0
[2025-07-19T19:57:22.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 111.0 in stage 1.0 (TID 469) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T19:57:22.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 111.0 in stage 1.0 (TID 469)
[2025-07-19T19:57:22.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 100.0 in stage 1.0 (TID 462). 9337 bytes result sent to driver
[2025-07-19T19:57:22.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 99.0 in stage 1.0 (TID 461) in 128 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T19:57:22.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4468e337
[2025-07-19T19:57:22.761+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.763+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110] for update
[2025-07-19T19:57:22.764+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T19:57:22.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 102 (task 463, attempt 0, stage 1.0)
[2025-07-19T19:57:22.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 102.0 in stage 1.0 (TID 463). 9287 bytes result sent to driver
[2025-07-19T19:57:22.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 112.0 in stage 1.0 (TID 470) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 112.0 in stage 1.0 (TID 470)
[2025-07-19T19:57:22.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 113.0 in stage 1.0 (TID 471) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.1.delta.e3178764-4fdc-48de-9376-c8fea1239393.TID467.tmp
[2025-07-19T19:57:22.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 102.0 in stage 1.0 (TID 463) in 88 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T19:57:22.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 100.0 in stage 1.0 (TID 462) in 112 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T19:57:22.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 113.0 in stage 1.0 (TID 471)
[2025-07-19T19:57:22.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.1.delta.0197892f-5bcf-429f-95e9-3df6bebe9d63.TID468.tmp
[2025-07-19T19:57:22.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.1.delta.df821db5-67df-43c6-8894-498d1f640091.TID466.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/1.delta
[2025-07-19T19:57:22.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/1.delta
[2025-07-19T19:57:22.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: Registering RDD 27 (start at <unknown>:0) as input to shuffle 3
[2025-07-19T19:57:22.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.1.delta.b531551f-dc31-4673-bb87-d4afe09b2b6d.TID465.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/1.delta
[2025-07-19T19:57:22.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/1.delta
[2025-07-19T19:57:22.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 465, attempt 0, stage 1.0)
[2025-07-19T19:57:22.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 466, attempt 0, stage 1.0)
[2025-07-19T19:57:22.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.1.delta.b317c99b-481b-4123-954b-f875edd4ecce.TID464.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/1.delta
[2025-07-19T19:57:22.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/1.delta
[2025-07-19T19:57:22.780+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ddc9d40
[2025-07-19T19:57:22.780+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 464, attempt 0, stage 1.0)
[2025-07-19T19:57:22.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: Got job 3 (start at <unknown>:0) with 200 output partitions
[2025-07-19T19:57:22.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: Final stage: ResultStage 7 (start at <unknown>:0)
[2025-07-19T19:57:22.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2025-07-19T19:57:22.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111] for update
[2025-07-19T19:57:22.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: Missing parents: List()
[2025-07-19T19:57:22.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: Submitting ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0), which has no missing parents
[2025-07-19T19:57:22.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.1.delta.48dcacce-091e-424d-9774-8b9373070c2c.TID469.tmp
[2025-07-19T19:57:22.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14fb6af8
[2025-07-19T19:57:22.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113] for update
[2025-07-19T19:57:22.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.798+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.1.delta.e3178764-4fdc-48de-9376-c8fea1239393.TID467.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/1.delta
[2025-07-19T19:57:22.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.1.delta.0197892f-5bcf-429f-95e9-3df6bebe9d63.TID468.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/1.delta
[2025-07-19T19:57:22.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/1.delta
[2025-07-19T19:57:22.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/1.delta
[2025-07-19T19:57:22.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 467, attempt 0, stage 1.0)
[2025-07-19T19:57:22.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59b44910
[2025-07-19T19:57:22.803+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 468, attempt 0, stage 1.0)
[2025-07-19T19:57:22.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 106 (task 466, attempt 0, stage 1.0)
[2025-07-19T19:57:22.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 105 (task 465, attempt 0, stage 1.0)
[2025-07-19T19:57:22.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 105.0 in stage 1.0 (TID 465). 9295 bytes result sent to driver
[2025-07-19T19:57:22.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 114.0 in stage 1.0 (TID 472) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112] for update
[2025-07-19T19:57:22.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 103 (task 464, attempt 0, stage 1.0)
[2025-07-19T19:57:22.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 105.0 in stage 1.0 (TID 465) in 106 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T19:57:22.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 114.0 in stage 1.0 (TID 472)
[2025-07-19T19:57:22.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.1.delta.e5dac31f-c697-4ff5-a14d-e20d74c7792b.TID471.tmp
[2025-07-19T19:57:22.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 106.0 in stage 1.0 (TID 466). 9291 bytes result sent to driver
[2025-07-19T19:57:22.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 103.0 in stage 1.0 (TID 464). 9304 bytes result sent to driver
[2025-07-19T19:57:22.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 116.0 in stage 1.0 (TID 473) (8b44f3d35cfa, executor driver, partition 116, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 117.0 in stage 1.0 (TID 474) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 116.0 in stage 1.0 (TID 473)
[2025-07-19T19:57:22.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 106.0 in stage 1.0 (TID 466) in 107 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T19:57:22.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 103.0 in stage 1.0 (TID 464) in 123 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T19:57:22.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 117.0 in stage 1.0 (TID 474)
[2025-07-19T19:57:22.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:22.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.1.delta.e765d38b-8d93-4660-b2cf-36185eed489f.TID470.tmp
[2025-07-19T19:57:22.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73314c1a
[2025-07-19T19:57:22.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114] for update
[2025-07-19T19:57:22.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 110 (task 468, attempt 0, stage 1.0)
[2025-07-19T19:57:22.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 110.0 in stage 1.0 (TID 468). 9306 bytes result sent to driver
[2025-07-19T19:57:22.827+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 109 (task 467, attempt 0, stage 1.0)
[2025-07-19T19:57:22.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 118.0 in stage 1.0 (TID 475) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 109.0 in stage 1.0 (TID 467). 9314 bytes result sent to driver
[2025-07-19T19:57:22.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 118.0 in stage 1.0 (TID 475)
[2025-07-19T19:57:22.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 119.0 in stage 1.0 (TID 476) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 119.0 in stage 1.0 (TID 476)
[2025-07-19T19:57:22.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 110.0 in stage 1.0 (TID 468) in 84 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T19:57:22.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@389e2334
[2025-07-19T19:57:22.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 109.0 in stage 1.0 (TID 467) in 103 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T19:57:22.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116] for update
[2025-07-19T19:57:22.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31ebbcb
[2025-07-19T19:57:22.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117] for update
[2025-07-19T19:57:22.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.1.delta.48dcacce-091e-424d-9774-8b9373070c2c.TID469.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/1.delta
[2025-07-19T19:57:22.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/1.delta
[2025-07-19T19:57:22.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 469, attempt 0, stage 1.0)
[2025-07-19T19:57:22.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.1.delta.f69b5964-8765-4485-8583-453adc75f2e5.TID472.tmp
[2025-07-19T19:57:22.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d796ee
[2025-07-19T19:57:22.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119] for update
[2025-07-19T19:57:22.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.7 KiB, free 433.0 MiB)
[2025-07-19T19:57:22.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.0 MiB)
[2025-07-19T19:57:22.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 8b44f3d35cfa:44249 (size: 15.8 KiB, free: 434.1 MiB)
[2025-07-19T19:57:22.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.1.delta.abb3541b-ca72-4bf1-8b42-88b2ac58f988.TID473.tmp
[2025-07-19T19:57:22.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1611
[2025-07-19T19:57:22.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T19:57:22.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSchedulerImpl: Adding task set 7.0 with 200 tasks resource profile 0
[2025-07-19T19:57:22.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 111 (task 469, attempt 0, stage 1.0)
[2025-07-19T19:57:22.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5861022b
[2025-07-19T19:57:22.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.1.delta.a955d51e-d63c-4ac4-abd2-57ba691e7bc7.TID474.tmp
[2025-07-19T19:57:22.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 111.0 in stage 1.0 (TID 469). 9311 bytes result sent to driver
[2025-07-19T19:57:22.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118] for update
[2025-07-19T19:57:22.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.1.delta.e765d38b-8d93-4660-b2cf-36185eed489f.TID470.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/1.delta
[2025-07-19T19:57:22.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/1.delta
[2025-07-19T19:57:22.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 470, attempt 0, stage 1.0)
[2025-07-19T19:57:22.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.1.delta.e5dac31f-c697-4ff5-a14d-e20d74c7792b.TID471.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/1.delta
[2025-07-19T19:57:22.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/1.delta
[2025-07-19T19:57:22.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 471, attempt 0, stage 1.0)
[2025-07-19T19:57:22.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.1.delta.1369aa31-5dec-4438-ac6b-31bd499427e4.TID476.tmp
[2025-07-19T19:57:22.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.1.delta.796cb5fb-962f-43a5-9d4c-9cda917d8b16.TID475.tmp
[2025-07-19T19:57:22.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 124.0 in stage 1.0 (TID 477) (8b44f3d35cfa, executor driver, partition 124, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 111.0 in stage 1.0 (TID 469) in 123 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T19:57:22.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.1.delta.f69b5964-8765-4485-8583-453adc75f2e5.TID472.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/1.delta
[2025-07-19T19:57:22.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/1.delta
[2025-07-19T19:57:22.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 472, attempt 0, stage 1.0)
[2025-07-19T19:57:22.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 124.0 in stage 1.0 (TID 477)
[2025-07-19T19:57:22.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 113 (task 471, attempt 0, stage 1.0)
[2025-07-19T19:57:22.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 113.0 in stage 1.0 (TID 471). 9242 bytes result sent to driver
[2025-07-19T19:57:22.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.1.delta.abb3541b-ca72-4bf1-8b42-88b2ac58f988.TID473.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/1.delta
[2025-07-19T19:57:22.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 125.0 in stage 1.0 (TID 478) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/1.delta
[2025-07-19T19:57:22.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 125.0 in stage 1.0 (TID 478)
[2025-07-19T19:57:22.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 112 (task 470, attempt 0, stage 1.0)
[2025-07-19T19:57:22.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 473, attempt 0, stage 1.0)
[2025-07-19T19:57:22.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 112.0 in stage 1.0 (TID 470). 9239 bytes result sent to driver
[2025-07-19T19:57:22.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 126.0 in stage 1.0 (TID 479) (8b44f3d35cfa, executor driver, partition 126, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 126.0 in stage 1.0 (TID 479)
[2025-07-19T19:57:22.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 112.0 in stage 1.0 (TID 470) in 135 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T19:57:22.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 113.0 in stage 1.0 (TID 471) in 129 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T19:57:22.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14b54b23
[2025-07-19T19:57:22.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124] for update
[2025-07-19T19:57:22.897+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.1.delta.a955d51e-d63c-4ac4-abd2-57ba691e7bc7.TID474.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/1.delta
[2025-07-19T19:57:22.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/1.delta
[2025-07-19T19:57:22.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 474, attempt 0, stage 1.0)
[2025-07-19T19:57:22.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.1.delta.796cb5fb-962f-43a5-9d4c-9cda917d8b16.TID475.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/1.delta
[2025-07-19T19:57:22.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/1.delta
[2025-07-19T19:57:22.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.1.delta.1369aa31-5dec-4438-ac6b-31bd499427e4.TID476.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/1.delta
[2025-07-19T19:57:22.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/1.delta
[2025-07-19T19:57:22.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 116 (task 473, attempt 0, stage 1.0)
[2025-07-19T19:57:22.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 116.0 in stage 1.0 (TID 473). 9265 bytes result sent to driver
[2025-07-19T19:57:22.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.1.delta.a020cb4e-350b-4945-84b3-631a1f336217.TID477.tmp
[2025-07-19T19:57:22.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25f63fb0
[2025-07-19T19:57:22.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 476, attempt 0, stage 1.0)
[2025-07-19T19:57:22.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 127.0 in stage 1.0 (TID 480) (8b44f3d35cfa, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 127.0 in stage 1.0 (TID 480)
[2025-07-19T19:57:22.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 114 (task 472, attempt 0, stage 1.0)
[2025-07-19T19:57:22.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 116.0 in stage 1.0 (TID 473) in 101 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T19:57:22.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 475, attempt 0, stage 1.0)
[2025-07-19T19:57:22.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 114.0 in stage 1.0 (TID 472). 9343 bytes result sent to driver
[2025-07-19T19:57:22.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 130.0 in stage 1.0 (TID 481) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 114.0 in stage 1.0 (TID 472) in 114 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T19:57:22.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 130.0 in stage 1.0 (TID 481)
[2025-07-19T19:57:22.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126] for update
[2025-07-19T19:57:22.922+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 117 (task 474, attempt 0, stage 1.0)
[2025-07-19T19:57:22.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 117.0 in stage 1.0 (TID 474). 9315 bytes result sent to driver
[2025-07-19T19:57:22.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 131.0 in stage 1.0 (TID 482) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 117.0 in stage 1.0 (TID 474) in 120 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T19:57:22.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 131.0 in stage 1.0 (TID 482)
[2025-07-19T19:57:22.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a6acf9
[2025-07-19T19:57:22.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125] for update
[2025-07-19T19:57:22.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.1.delta.a8845bd4-a277-4732-be18-c3b3e528d080.TID479.tmp
[2025-07-19T19:57:22.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d0d3c1f
[2025-07-19T19:57:22.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 118 (task 475, attempt 0, stage 1.0)
[2025-07-19T19:57:22.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130] for update
[2025-07-19T19:57:22.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 119 (task 476, attempt 0, stage 1.0)
[2025-07-19T19:57:22.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 119.0 in stage 1.0 (TID 476). 9287 bytes result sent to driver
[2025-07-19T19:57:22.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 134.0 in stage 1.0 (TID 483) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 134.0 in stage 1.0 (TID 483)
[2025-07-19T19:57:22.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 118.0 in stage 1.0 (TID 475). 9262 bytes result sent to driver
[2025-07-19T19:57:22.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 119.0 in stage 1.0 (TID 476) in 111 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T19:57:22.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 135.0 in stage 1.0 (TID 484) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 118.0 in stage 1.0 (TID 475) in 113 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T19:57:22.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 135.0 in stage 1.0 (TID 484)
[2025-07-19T19:57:22.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:22.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2351b5c4
[2025-07-19T19:57:22.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.1.delta.1f631669-368d-4ca0-8965-4611b8f69604.TID478.tmp
[2025-07-19T19:57:22.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.1.delta.5d1b9d79-4dcd-4475-8180-d7c4ab301a14.TID481.tmp
[2025-07-19T19:57:22.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.1.delta.a020cb4e-350b-4945-84b3-631a1f336217.TID477.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/1.delta
[2025-07-19T19:57:22.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/1.delta
[2025-07-19T19:57:22.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 477, attempt 0, stage 1.0)
[2025-07-19T19:57:22.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127] for update
[2025-07-19T19:57:22.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cf6ac3d
[2025-07-19T19:57:22.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135] for update
[2025-07-19T19:57:22.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e4614b0
[2025-07-19T19:57:22.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.1.delta.1038d4d1-2a38-4b0c-8255-806beb7304e7.TID480.tmp
[2025-07-19T19:57:22.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134] for update
[2025-07-19T19:57:22.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 124 (task 477, attempt 0, stage 1.0)
[2025-07-19T19:57:22.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 124.0 in stage 1.0 (TID 477). 9300 bytes result sent to driver
[2025-07-19T19:57:22.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 136.0 in stage 1.0 (TID 485) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 136.0 in stage 1.0 (TID 485)
[2025-07-19T19:57:22.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 124.0 in stage 1.0 (TID 477) in 94 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T19:57:22.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ea1a227
[2025-07-19T19:57:22.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131] for update
[2025-07-19T19:57:22.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.1.delta.2d2b74d8-f5c4-4bca-8f58-72f736d0ff80.TID483.tmp
[2025-07-19T19:57:22.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.1.delta.a8845bd4-a277-4732-be18-c3b3e528d080.TID479.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/1.delta
[2025-07-19T19:57:22.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/1.delta
[2025-07-19T19:57:22.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 479, attempt 0, stage 1.0)
[2025-07-19T19:57:22.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.1.delta.21652541-aaf3-450c-8aaf-dc48caf6d25c.TID484.tmp
[2025-07-19T19:57:22.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@375ddd7d
[2025-07-19T19:57:22.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:22.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136] for update
[2025-07-19T19:57:22.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:22.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.1.delta.eb3d4daf-0fa7-4a1a-bc85-a74b094f69b2.TID482.tmp
[2025-07-19T19:57:22.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.1.delta.af5ea0cc-4704-4d91-b12e-6360c3d2e68c.TID485.tmp
[2025-07-19T19:57:22.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.1.delta.5d1b9d79-4dcd-4475-8180-d7c4ab301a14.TID481.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/1.delta
[2025-07-19T19:57:22.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/1.delta
[2025-07-19T19:57:22.994+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.1.delta.1f631669-368d-4ca0-8965-4611b8f69604.TID478.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/1.delta
[2025-07-19T19:57:22.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/1.delta
[2025-07-19T19:57:22.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 481, attempt 0, stage 1.0)
[2025-07-19T19:57:22.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Committed partition 126 (task 479, attempt 0, stage 1.0)
[2025-07-19T19:57:22.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Finished task 126.0 in stage 1.0 (TID 479). 9282 bytes result sent to driver
[2025-07-19T19:57:22.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Starting task 137.0 in stage 1.0 (TID 486) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:22.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO TaskSetManager: Finished task 126.0 in stage 1.0 (TID 479) in 102 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T19:57:22.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO Executor: Running task 137.0 in stage 1.0 (TID 486)
[2025-07-19T19:57:22.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 478, attempt 0, stage 1.0)
[2025-07-19T19:57:22.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:22.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:22.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.1.delta.1038d4d1-2a38-4b0c-8255-806beb7304e7.TID480.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/1.delta
[2025-07-19T19:57:22.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/1.delta
[2025-07-19T19:57:23.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:22 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 480, attempt 0, stage 1.0)
[2025-07-19T19:57:23.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52b29609
[2025-07-19T19:57:23.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137] for update
[2025-07-19T19:57:23.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 125 (task 478, attempt 0, stage 1.0)
[2025-07-19T19:57:23.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 125.0 in stage 1.0 (TID 478). 9293 bytes result sent to driver
[2025-07-19T19:57:23.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 140.0 in stage 1.0 (TID 487) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 125.0 in stage 1.0 (TID 478) in 124 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T19:57:23.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 140.0 in stage 1.0 (TID 487)
[2025-07-19T19:57:23.014+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 130 (task 481, attempt 0, stage 1.0)
[2025-07-19T19:57:23.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 130.0 in stage 1.0 (TID 481). 9248 bytes result sent to driver
[2025-07-19T19:57:23.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 142.0 in stage 1.0 (TID 488) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 130.0 in stage 1.0 (TID 481) in 99 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T19:57:23.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.1.delta.2d2b74d8-f5c4-4bca-8f58-72f736d0ff80.TID483.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/1.delta
[2025-07-19T19:57:23.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 142.0 in stage 1.0 (TID 488)
[2025-07-19T19:57:23.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/1.delta
[2025-07-19T19:57:23.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 127 (task 480, attempt 0, stage 1.0)
[2025-07-19T19:57:23.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 483, attempt 0, stage 1.0)
[2025-07-19T19:57:23.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 127.0 in stage 1.0 (TID 480). 9286 bytes result sent to driver
[2025-07-19T19:57:23.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 144.0 in stage 1.0 (TID 489) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 144.0 in stage 1.0 (TID 489)
[2025-07-19T19:57:23.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 127.0 in stage 1.0 (TID 480) in 113 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T19:57:23.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39ddbf82
[2025-07-19T19:57:23.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140] for update
[2025-07-19T19:57:23.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.1.delta.f53f94bd-aa4d-4fd8-9efb-b393c4fdaf17.TID486.tmp
[2025-07-19T19:57:23.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c58644b
[2025-07-19T19:57:23.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.1.delta.eb3d4daf-0fa7-4a1a-bc85-a74b094f69b2.TID482.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/1.delta
[2025-07-19T19:57:23.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/1.delta
[2025-07-19T19:57:23.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.1.delta.21652541-aaf3-450c-8aaf-dc48caf6d25c.TID484.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/1.delta
[2025-07-19T19:57:23.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/1.delta
[2025-07-19T19:57:23.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142] for update
[2025-07-19T19:57:23.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 484, attempt 0, stage 1.0)
[2025-07-19T19:57:23.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 482, attempt 0, stage 1.0)
[2025-07-19T19:57:23.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.1.delta.56ef4ec3-7c4b-4db6-8444-16fe8de736e2.TID487.tmp
[2025-07-19T19:57:23.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d65b767
[2025-07-19T19:57:23.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.1.delta.af5ea0cc-4704-4d91-b12e-6360c3d2e68c.TID485.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/1.delta
[2025-07-19T19:57:23.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/1.delta
[2025-07-19T19:57:23.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 134 (task 483, attempt 0, stage 1.0)
[2025-07-19T19:57:23.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 485, attempt 0, stage 1.0)
[2025-07-19T19:57:23.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 134.0 in stage 1.0 (TID 483). 9334 bytes result sent to driver
[2025-07-19T19:57:23.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 145.0 in stage 1.0 (TID 490) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 145.0 in stage 1.0 (TID 490)
[2025-07-19T19:57:23.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.1.delta.0120a4c6-1286-4aba-a4ad-f961ed9c49e4.TID488.tmp
[2025-07-19T19:57:23.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 134.0 in stage 1.0 (TID 483) in 110 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T19:57:23.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144] for update
[2025-07-19T19:57:23.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 131 (task 482, attempt 0, stage 1.0)
[2025-07-19T19:57:23.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 131.0 in stage 1.0 (TID 482). 9300 bytes result sent to driver
[2025-07-19T19:57:23.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 147.0 in stage 1.0 (TID 491) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 147.0 in stage 1.0 (TID 491)
[2025-07-19T19:57:23.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 131.0 in stage 1.0 (TID 482) in 126 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T19:57:23.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 135 (task 484, attempt 0, stage 1.0)
[2025-07-19T19:57:23.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 135.0 in stage 1.0 (TID 484). 9300 bytes result sent to driver
[2025-07-19T19:57:23.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 135.0 in stage 1.0 (TID 484) in 117 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T19:57:23.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 148.0 in stage 1.0 (TID 492) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 148.0 in stage 1.0 (TID 492)
[2025-07-19T19:57:23.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a4af691
[2025-07-19T19:57:23.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145] for update
[2025-07-19T19:57:23.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.1.delta.3102d700-cc57-4712-b335-117a6d940186.TID489.tmp
[2025-07-19T19:57:23.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43f49833
[2025-07-19T19:57:23.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148] for update
[2025-07-19T19:57:23.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.1.delta.81a5b09c-b411-4e99-9809-e3cb8785d4b0.TID490.tmp
[2025-07-19T19:57:23.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 136 (task 485, attempt 0, stage 1.0)
[2025-07-19T19:57:23.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5eff24eb
[2025-07-19T19:57:23.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147] for update
[2025-07-19T19:57:23.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 136.0 in stage 1.0 (TID 485). 9287 bytes result sent to driver
[2025-07-19T19:57:23.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 149.0 in stage 1.0 (TID 493) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 149.0 in stage 1.0 (TID 493)
[2025-07-19T19:57:23.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 136.0 in stage 1.0 (TID 485) in 108 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T19:57:23.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:23.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.1.delta.f53f94bd-aa4d-4fd8-9efb-b393c4fdaf17.TID486.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/1.delta
[2025-07-19T19:57:23.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/1.delta
[2025-07-19T19:57:23.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 486, attempt 0, stage 1.0)
[2025-07-19T19:57:23.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6332a3ff
[2025-07-19T19:57:23.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149] for update
[2025-07-19T19:57:23.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.1.delta.7b298a0e-da4b-453c-a01e-418e06932c81.TID492.tmp
[2025-07-19T19:57:23.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.1.delta.4f4c4c91-2c02-4cfa-94b4-6644cebf81ea.TID491.tmp
[2025-07-19T19:57:23.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.1.delta.0120a4c6-1286-4aba-a4ad-f961ed9c49e4.TID488.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/1.delta
[2025-07-19T19:57:23.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/1.delta
[2025-07-19T19:57:23.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 488, attempt 0, stage 1.0)
[2025-07-19T19:57:23.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.1.delta.56ef4ec3-7c4b-4db6-8444-16fe8de736e2.TID487.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/1.delta
[2025-07-19T19:57:23.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/1.delta
[2025-07-19T19:57:23.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 487, attempt 0, stage 1.0)
[2025-07-19T19:57:23.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 137 (task 486, attempt 0, stage 1.0)
[2025-07-19T19:57:23.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.1.delta.659a4a1e-e766-4a75-8511-c9279509a665.TID493.tmp
[2025-07-19T19:57:23.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 137.0 in stage 1.0 (TID 486). 9302 bytes result sent to driver
[2025-07-19T19:57:23.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 151.0 in stage 1.0 (TID 494) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 151.0 in stage 1.0 (TID 494)
[2025-07-19T19:57:23.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 137.0 in stage 1.0 (TID 486) in 109 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T19:57:23.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 140 (task 487, attempt 0, stage 1.0)
[2025-07-19T19:57:23.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 140.0 in stage 1.0 (TID 487). 9270 bytes result sent to driver
[2025-07-19T19:57:23.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 152.0 in stage 1.0 (TID 495) (8b44f3d35cfa, executor driver, partition 152, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@be741b2
[2025-07-19T19:57:23.112+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.114+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151] for update
[2025-07-19T19:57:23.115+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 152.0 in stage 1.0 (TID 495)
[2025-07-19T19:57:23.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 142 (task 488, attempt 0, stage 1.0)
[2025-07-19T19:57:23.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 140.0 in stage 1.0 (TID 487) in 104 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T19:57:23.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 142.0 in stage 1.0 (TID 488). 9286 bytes result sent to driver
[2025-07-19T19:57:23.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 153.0 in stage 1.0 (TID 496) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 153.0 in stage 1.0 (TID 496)
[2025-07-19T19:57:23.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 142.0 in stage 1.0 (TID 488) in 100 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T19:57:23.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.1.delta.3102d700-cc57-4712-b335-117a6d940186.TID489.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/1.delta
[2025-07-19T19:57:23.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/1.delta
[2025-07-19T19:57:23.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 489, attempt 0, stage 1.0)
[2025-07-19T19:57:23.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.1.delta.81a5b09c-b411-4e99-9809-e3cb8785d4b0.TID490.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/1.delta
[2025-07-19T19:57:23.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/1.delta
[2025-07-19T19:57:23.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 490, attempt 0, stage 1.0)
[2025-07-19T19:57:23.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12d68d55
[2025-07-19T19:57:23.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153] for update
[2025-07-19T19:57:23.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.1.delta.4f4c4c91-2c02-4cfa-94b4-6644cebf81ea.TID491.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/1.delta
[2025-07-19T19:57:23.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/1.delta
[2025-07-19T19:57:23.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 491, attempt 0, stage 1.0)
[2025-07-19T19:57:23.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 144 (task 489, attempt 0, stage 1.0)
[2025-07-19T19:57:23.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 144.0 in stage 1.0 (TID 489). 9313 bytes result sent to driver
[2025-07-19T19:57:23.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 144.0 in stage 1.0 (TID 489) in 113 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T19:57:23.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 155.0 in stage 1.0 (TID 497) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 155.0 in stage 1.0 (TID 497)
[2025-07-19T19:57:23.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.1.delta.ebac74d9-a217-420d-b4d9-cb2153faee35.TID494.tmp
[2025-07-19T19:57:23.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.1.delta.7b298a0e-da4b-453c-a01e-418e06932c81.TID492.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/1.delta
[2025-07-19T19:57:23.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/1.delta
[2025-07-19T19:57:23.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 492, attempt 0, stage 1.0)
[2025-07-19T19:57:23.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.1.delta.eec3c17f-bdb7-4334-8ac1-58fbe8b83a83.TID496.tmp
[2025-07-19T19:57:23.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6af13da4
[2025-07-19T19:57:23.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 145 (task 490, attempt 0, stage 1.0)
[2025-07-19T19:57:23.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 145.0 in stage 1.0 (TID 490). 9252 bytes result sent to driver
[2025-07-19T19:57:23.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152] for update
[2025-07-19T19:57:23.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 156.0 in stage 1.0 (TID 498) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 145.0 in stage 1.0 (TID 490) in 93 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T19:57:23.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 156.0 in stage 1.0 (TID 498)
[2025-07-19T19:57:23.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.1.delta.659a4a1e-e766-4a75-8511-c9279509a665.TID493.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/1.delta
[2025-07-19T19:57:23.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/1.delta
[2025-07-19T19:57:23.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 493, attempt 0, stage 1.0)
[2025-07-19T19:57:23.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4524a7cf
[2025-07-19T19:57:23.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156] for update
[2025-07-19T19:57:23.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.1.delta.4e2fffbc-b7a1-4d6d-b47b-27a5729b77f9.TID495.tmp
[2025-07-19T19:57:23.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35e01901
[2025-07-19T19:57:23.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 147 (task 491, attempt 0, stage 1.0)
[2025-07-19T19:57:23.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155] for update
[2025-07-19T19:57:23.158+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 147.0 in stage 1.0 (TID 491). 9325 bytes result sent to driver
[2025-07-19T19:57:23.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 157.0 in stage 1.0 (TID 499) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 157.0 in stage 1.0 (TID 499)
[2025-07-19T19:57:23.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 148 (task 492, attempt 0, stage 1.0)
[2025-07-19T19:57:23.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 147.0 in stage 1.0 (TID 491) in 109 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T19:57:23.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 148.0 in stage 1.0 (TID 492). 9291 bytes result sent to driver
[2025-07-19T19:57:23.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 160.0 in stage 1.0 (TID 500) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 160.0 in stage 1.0 (TID 500)
[2025-07-19T19:57:23.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 148.0 in stage 1.0 (TID 492) in 108 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T19:57:23.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.1.delta.3224aba5-c4f2-4ae4-a3e3-392b7e5035b5.TID498.tmp
[2025-07-19T19:57:23.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:23.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.1.delta.eec3c17f-bdb7-4334-8ac1-58fbe8b83a83.TID496.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/1.delta
[2025-07-19T19:57:23.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/1.delta
[2025-07-19T19:57:23.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 496, attempt 0, stage 1.0)
[2025-07-19T19:57:23.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.1.delta.e3a8f354-b3fc-40a4-b206-5ef61000a5ad.TID497.tmp
[2025-07-19T19:57:23.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 149 (task 493, attempt 0, stage 1.0)
[2025-07-19T19:57:23.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 149.0 in stage 1.0 (TID 493). 9307 bytes result sent to driver
[2025-07-19T19:57:23.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.1.delta.ebac74d9-a217-420d-b4d9-cb2153faee35.TID494.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/1.delta
[2025-07-19T19:57:23.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/1.delta
[2025-07-19T19:57:23.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dc79b35
[2025-07-19T19:57:23.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 162.0 in stage 1.0 (TID 501) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 162.0 in stage 1.0 (TID 501)
[2025-07-19T19:57:23.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 149.0 in stage 1.0 (TID 493) in 104 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T19:57:23.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 494, attempt 0, stage 1.0)
[2025-07-19T19:57:23.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160] for update
[2025-07-19T19:57:23.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b2deb4a
[2025-07-19T19:57:23.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157] for update
[2025-07-19T19:57:23.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.1.delta.4e2fffbc-b7a1-4d6d-b47b-27a5729b77f9.TID495.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/1.delta
[2025-07-19T19:57:23.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/1.delta
[2025-07-19T19:57:23.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 495, attempt 0, stage 1.0)
[2025-07-19T19:57:23.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:23.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 153 (task 496, attempt 0, stage 1.0)
[2025-07-19T19:57:23.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 153.0 in stage 1.0 (TID 496). 9302 bytes result sent to driver
[2025-07-19T19:57:23.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 165.0 in stage 1.0 (TID 502) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 151 (task 494, attempt 0, stage 1.0)
[2025-07-19T19:57:23.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 165.0 in stage 1.0 (TID 502)
[2025-07-19T19:57:23.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 151.0 in stage 1.0 (TID 494). 9302 bytes result sent to driver
[2025-07-19T19:57:23.195+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 166.0 in stage 1.0 (TID 503) (8b44f3d35cfa, executor driver, partition 166, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 151.0 in stage 1.0 (TID 494) in 93 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T19:57:23.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57771e6
[2025-07-19T19:57:23.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 153.0 in stage 1.0 (TID 496) in 82 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T19:57:23.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162] for update
[2025-07-19T19:57:23.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.1.delta.86fdb253-a5d6-43d5-b0c3-c1877c114ffc.TID500.tmp
[2025-07-19T19:57:23.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 166.0 in stage 1.0 (TID 503)
[2025-07-19T19:57:23.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.1.delta.3224aba5-c4f2-4ae4-a3e3-392b7e5035b5.TID498.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/1.delta
[2025-07-19T19:57:23.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/1.delta
[2025-07-19T19:57:23.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 498, attempt 0, stage 1.0)
[2025-07-19T19:57:23.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.1.delta.c6de34c9-dfad-4509-a63d-eb738110bc77.TID499.tmp
[2025-07-19T19:57:23.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 152 (task 495, attempt 0, stage 1.0)
[2025-07-19T19:57:23.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 152.0 in stage 1.0 (TID 495). 9302 bytes result sent to driver
[2025-07-19T19:57:23.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70147e22
[2025-07-19T19:57:23.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 174.0 in stage 1.0 (TID 504) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 152.0 in stage 1.0 (TID 495) in 93 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T19:57:23.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165] for update
[2025-07-19T19:57:23.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 174.0 in stage 1.0 (TID 504)
[2025-07-19T19:57:23.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.1.delta.a1c828cd-1f5a-42d5-96f4-01520a2f277a.TID501.tmp
[2025-07-19T19:57:23.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.1.delta.e3a8f354-b3fc-40a4-b206-5ef61000a5ad.TID497.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/1.delta
[2025-07-19T19:57:23.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/1.delta
[2025-07-19T19:57:23.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 497, attempt 0, stage 1.0)
[2025-07-19T19:57:23.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.1.delta.34f42e2e-ff14-4602-8d77-75894b3abb33.TID502.tmp
[2025-07-19T19:57:23.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@246de5e
[2025-07-19T19:57:23.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166] for update
[2025-07-19T19:57:23.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 156 (task 498, attempt 0, stage 1.0)
[2025-07-19T19:57:23.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 156.0 in stage 1.0 (TID 498). 9305 bytes result sent to driver
[2025-07-19T19:57:23.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b3d2817
[2025-07-19T19:57:23.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 175.0 in stage 1.0 (TID 505) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 175.0 in stage 1.0 (TID 505)
[2025-07-19T19:57:23.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174] for update
[2025-07-19T19:57:23.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 156.0 in stage 1.0 (TID 498) in 94 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T19:57:23.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.1.delta.86fdb253-a5d6-43d5-b0c3-c1877c114ffc.TID500.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/1.delta
[2025-07-19T19:57:23.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/1.delta
[2025-07-19T19:57:23.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 155 (task 497, attempt 0, stage 1.0)
[2025-07-19T19:57:23.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.1.delta.d1fcc8ab-f7b7-44ec-8ec0-53edc44a56b0.TID503.tmp
[2025-07-19T19:57:23.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 155.0 in stage 1.0 (TID 497). 9276 bytes result sent to driver
[2025-07-19T19:57:23.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 500, attempt 0, stage 1.0)
[2025-07-19T19:57:23.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 176.0 in stage 1.0 (TID 506) (8b44f3d35cfa, executor driver, partition 176, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 155.0 in stage 1.0 (TID 497) in 104 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T19:57:23.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 176.0 in stage 1.0 (TID 506)
[2025-07-19T19:57:23.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.1.delta.a1c828cd-1f5a-42d5-96f4-01520a2f277a.TID501.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/1.delta
[2025-07-19T19:57:23.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/1.delta
[2025-07-19T19:57:23.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 501, attempt 0, stage 1.0)
[2025-07-19T19:57:23.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c1c0666
[2025-07-19T19:57:23.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175] for update
[2025-07-19T19:57:23.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.1.delta.c6de34c9-dfad-4509-a63d-eb738110bc77.TID499.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/1.delta
[2025-07-19T19:57:23.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/1.delta
[2025-07-19T19:57:23.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 499, attempt 0, stage 1.0)
[2025-07-19T19:57:23.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.1.delta.5f16d613-0cbf-4160-84cd-d7e7bfd93029.TID504.tmp
[2025-07-19T19:57:23.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 160 (task 500, attempt 0, stage 1.0)
[2025-07-19T19:57:23.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.1.delta.3c31290d-850b-4836-bdd1-cd257b71a283.TID505.tmp
[2025-07-19T19:57:23.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 160.0 in stage 1.0 (TID 500). 9243 bytes result sent to driver
[2025-07-19T19:57:23.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 178.0 in stage 1.0 (TID 507) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15e86d72
[2025-07-19T19:57:23.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 178.0 in stage 1.0 (TID 507)
[2025-07-19T19:57:23.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 160.0 in stage 1.0 (TID 500) in 94 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T19:57:23.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176] for update
[2025-07-19T19:57:23.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.1.delta.34f42e2e-ff14-4602-8d77-75894b3abb33.TID502.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/1.delta
[2025-07-19T19:57:23.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/1.delta
[2025-07-19T19:57:23.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 502, attempt 0, stage 1.0)
[2025-07-19T19:57:23.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@183673cd
[2025-07-19T19:57:23.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178] for update
[2025-07-19T19:57:23.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.1.delta.a39992f6-a0ee-4953-a5ec-52458445b876.TID506.tmp
[2025-07-19T19:57:23.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 157 (task 499, attempt 0, stage 1.0)
[2025-07-19T19:57:23.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 157.0 in stage 1.0 (TID 499). 9245 bytes result sent to driver
[2025-07-19T19:57:23.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 179.0 in stage 1.0 (TID 508) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 157.0 in stage 1.0 (TID 499) in 109 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T19:57:23.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 162 (task 501, attempt 0, stage 1.0)
[2025-07-19T19:57:23.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.1.delta.97bc84ae-19f2-48f9-bb61-2f52fa06837c.TID507.tmp
[2025-07-19T19:57:23.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 162.0 in stage 1.0 (TID 501). 9267 bytes result sent to driver
[2025-07-19T19:57:23.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 179.0 in stage 1.0 (TID 508)
[2025-07-19T19:57:23.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 182.0 in stage 1.0 (TID 509) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 162.0 in stage 1.0 (TID 501) in 98 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T19:57:23.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 182.0 in stage 1.0 (TID 509)
[2025-07-19T19:57:23.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 165 (task 502, attempt 0, stage 1.0)
[2025-07-19T19:57:23.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 165.0 in stage 1.0 (TID 502). 9343 bytes result sent to driver
[2025-07-19T19:57:23.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 183.0 in stage 1.0 (TID 510) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.1.delta.5f16d613-0cbf-4160-84cd-d7e7bfd93029.TID504.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/1.delta
[2025-07-19T19:57:23.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/1.delta
[2025-07-19T19:57:23.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 183.0 in stage 1.0 (TID 510)
[2025-07-19T19:57:23.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 504, attempt 0, stage 1.0)
[2025-07-19T19:57:23.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 165.0 in stage 1.0 (TID 502) in 91 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T19:57:23.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.1.delta.d1fcc8ab-f7b7-44ec-8ec0-53edc44a56b0.TID503.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/1.delta
[2025-07-19T19:57:23.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/1.delta
[2025-07-19T19:57:23.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:23.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 503, attempt 0, stage 1.0)
[2025-07-19T19:57:23.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:23.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@343c7154
[2025-07-19T19:57:23.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183] for update
[2025-07-19T19:57:23.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 166 (task 503, attempt 0, stage 1.0)
[2025-07-19T19:57:23.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 166.0 in stage 1.0 (TID 503). 9307 bytes result sent to driver
[2025-07-19T19:57:23.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.1.delta.3c31290d-850b-4836-bdd1-cd257b71a283.TID505.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/1.delta
[2025-07-19T19:57:23.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/1.delta
[2025-07-19T19:57:23.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 184.0 in stage 1.0 (TID 511) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 505, attempt 0, stage 1.0)
[2025-07-19T19:57:23.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 184.0 in stage 1.0 (TID 511)
[2025-07-19T19:57:23.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 174 (task 504, attempt 0, stage 1.0)
[2025-07-19T19:57:23.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 166.0 in stage 1.0 (TID 503) in 108 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T19:57:23.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 174.0 in stage 1.0 (TID 504). 9305 bytes result sent to driver
[2025-07-19T19:57:23.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66950e43
[2025-07-19T19:57:23.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 185.0 in stage 1.0 (TID 512) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.1.delta.a39992f6-a0ee-4953-a5ec-52458445b876.TID506.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/1.delta
[2025-07-19T19:57:23.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/1.delta
[2025-07-19T19:57:23.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182] for update
[2025-07-19T19:57:23.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 174.0 in stage 1.0 (TID 504) in 102 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T19:57:23.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 506, attempt 0, stage 1.0)
[2025-07-19T19:57:23.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 185.0 in stage 1.0 (TID 512)
[2025-07-19T19:57:23.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.1.delta.5bec72d8-ba9f-4fcf-bd89-cd1eae3b239c.TID510.tmp
[2025-07-19T19:57:23.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.1.delta.97bc84ae-19f2-48f9-bb61-2f52fa06837c.TID507.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/1.delta
[2025-07-19T19:57:23.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/1.delta
[2025-07-19T19:57:23.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 507, attempt 0, stage 1.0)
[2025-07-19T19:57:23.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.1.delta.60235b5b-cabe-4251-a307-26d0f3844f21.TID509.tmp
[2025-07-19T19:57:23.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b64d59a
[2025-07-19T19:57:23.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179] for update
[2025-07-19T19:57:23.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 175 (task 505, attempt 0, stage 1.0)
[2025-07-19T19:57:23.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 175.0 in stage 1.0 (TID 505). 9287 bytes result sent to driver
[2025-07-19T19:57:23.321+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 187.0 in stage 1.0 (TID 513) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 187.0 in stage 1.0 (TID 513)
[2025-07-19T19:57:23.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 176 (task 506, attempt 0, stage 1.0)
[2025-07-19T19:57:23.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 175.0 in stage 1.0 (TID 505) in 95 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T19:57:23.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 176.0 in stage 1.0 (TID 506). 9291 bytes result sent to driver
[2025-07-19T19:57:23.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 188.0 in stage 1.0 (TID 514) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@495ea374
[2025-07-19T19:57:23.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 176.0 in stage 1.0 (TID 506) in 92 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T19:57:23.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 188.0 in stage 1.0 (TID 514)
[2025-07-19T19:57:23.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185] for update
[2025-07-19T19:57:23.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 178 (task 507, attempt 0, stage 1.0)
[2025-07-19T19:57:23.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 178.0 in stage 1.0 (TID 507). 9307 bytes result sent to driver
[2025-07-19T19:57:23.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 191.0 in stage 1.0 (TID 515) (8b44f3d35cfa, executor driver, partition 191, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 191.0 in stage 1.0 (TID 515)
[2025-07-19T19:57:23.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 178.0 in stage 1.0 (TID 507) in 77 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T19:57:23.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.1.delta.1b9ee6ba-bb43-43a6-a07e-e3eab84dd63f.TID508.tmp
[2025-07-19T19:57:23.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@284b4049
[2025-07-19T19:57:23.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184] for update
[2025-07-19T19:57:23.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bbb3146
[2025-07-19T19:57:23.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187] for update
[2025-07-19T19:57:23.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.1.delta.f519a4e4-1ebf-41b6-a269-0271b948336c.TID512.tmp
[2025-07-19T19:57:23.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.1.delta.7b39ab4f-495c-4fa2-ba4d-6f5b78199db9.TID511.tmp
[2025-07-19T19:57:23.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.1.delta.5bec72d8-ba9f-4fcf-bd89-cd1eae3b239c.TID510.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/1.delta
[2025-07-19T19:57:23.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/1.delta
[2025-07-19T19:57:23.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.1.delta.a3da98ed-79cb-45dd-be00-ceb4fb7a3d9c.TID513.tmp
[2025-07-19T19:57:23.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 510, attempt 0, stage 1.0)
[2025-07-19T19:57:23.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.1.delta.60235b5b-cabe-4251-a307-26d0f3844f21.TID509.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/1.delta
[2025-07-19T19:57:23.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/1.delta
[2025-07-19T19:57:23.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33a98d0
[2025-07-19T19:57:23.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 509, attempt 0, stage 1.0)
[2025-07-19T19:57:23.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188] for update
[2025-07-19T19:57:23.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@115b4e41
[2025-07-19T19:57:23.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191] for update
[2025-07-19T19:57:23.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 183 (task 510, attempt 0, stage 1.0)
[2025-07-19T19:57:23.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 182 (task 509, attempt 0, stage 1.0)
[2025-07-19T19:57:23.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.1.delta.1b9ee6ba-bb43-43a6-a07e-e3eab84dd63f.TID508.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/1.delta
[2025-07-19T19:57:23.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/1.delta
[2025-07-19T19:57:23.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 182.0 in stage 1.0 (TID 509). 9300 bytes result sent to driver
[2025-07-19T19:57:23.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 194.0 in stage 1.0 (TID 516) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 508, attempt 0, stage 1.0)
[2025-07-19T19:57:23.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 194.0 in stage 1.0 (TID 516)
[2025-07-19T19:57:23.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 182.0 in stage 1.0 (TID 509) in 95 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T19:57:23.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 183.0 in stage 1.0 (TID 510). 9279 bytes result sent to driver
[2025-07-19T19:57:23.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.1.delta.e81114ad-d001-4299-afc3-684841682cd4.TID514.tmp
[2025-07-19T19:57:23.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 196.0 in stage 1.0 (TID 517) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 183.0 in stage 1.0 (TID 510) in 87 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T19:57:23.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 196.0 in stage 1.0 (TID 517)
[2025-07-19T19:57:23.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:23.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.1.delta.fb2c3651-e4a5-4447-a9e6-1f9c82bb999c.TID515.tmp
[2025-07-19T19:57:23.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:23.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fe34966
[2025-07-19T19:57:23.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194] for update
[2025-07-19T19:57:23.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.1.delta.f519a4e4-1ebf-41b6-a269-0271b948336c.TID512.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/1.delta
[2025-07-19T19:57:23.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/1.delta
[2025-07-19T19:57:23.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.1.delta.a3da98ed-79cb-45dd-be00-ceb4fb7a3d9c.TID513.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/1.delta
[2025-07-19T19:57:23.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/1.delta
[2025-07-19T19:57:23.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 512, attempt 0, stage 1.0)
[2025-07-19T19:57:23.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c51ecc0
[2025-07-19T19:57:23.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196] for update
[2025-07-19T19:57:23.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 513, attempt 0, stage 1.0)
[2025-07-19T19:57:23.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 179 (task 508, attempt 0, stage 1.0)
[2025-07-19T19:57:23.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.1.delta.07a77320-b876-4278-9850-5f58a6d12444.TID516.tmp
[2025-07-19T19:57:23.397+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 179.0 in stage 1.0 (TID 508). 9352 bytes result sent to driver
[2025-07-19T19:57:23.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 197.0 in stage 1.0 (TID 518) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 179.0 in stage 1.0 (TID 508) in 133 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T19:57:23.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 197.0 in stage 1.0 (TID 518)
[2025-07-19T19:57:23.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.1.delta.7b39ab4f-495c-4fa2-ba4d-6f5b78199db9.TID511.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/1.delta
[2025-07-19T19:57:23.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/1.delta
[2025-07-19T19:57:23.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 511, attempt 0, stage 1.0)
[2025-07-19T19:57:23.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.1.delta.db7332a4-0065-4f7e-afff-f04897bbff85.TID517.tmp
[2025-07-19T19:57:23.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 185 (task 512, attempt 0, stage 1.0)
[2025-07-19T19:57:23.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 185.0 in stage 1.0 (TID 512). 9278 bytes result sent to driver
[2025-07-19T19:57:23.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 198.0 in stage 1.0 (TID 519) (8b44f3d35cfa, executor driver, partition 198, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.411+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 198.0 in stage 1.0 (TID 519)
[2025-07-19T19:57:23.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 185.0 in stage 1.0 (TID 512) in 110 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T19:57:23.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.1.delta.e81114ad-d001-4299-afc3-684841682cd4.TID514.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/1.delta
[2025-07-19T19:57:23.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/1.delta
[2025-07-19T19:57:23.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 514, attempt 0, stage 1.0)
[2025-07-19T19:57:23.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.1.delta.fb2c3651-e4a5-4447-a9e6-1f9c82bb999c.TID515.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/1.delta
[2025-07-19T19:57:23.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/1.delta
[2025-07-19T19:57:23.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 515, attempt 0, stage 1.0)
[2025-07-19T19:57:23.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 187 (task 513, attempt 0, stage 1.0)
[2025-07-19T19:57:23.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@780a1df5
[2025-07-19T19:57:23.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197] for update
[2025-07-19T19:57:23.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 187.0 in stage 1.0 (TID 513). 9300 bytes result sent to driver
[2025-07-19T19:57:23.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 199.0 in stage 1.0 (TID 520) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 187.0 in stage 1.0 (TID 513) in 102 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T19:57:23.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 184 (task 511, attempt 0, stage 1.0)
[2025-07-19T19:57:23.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 184.0 in stage 1.0 (TID 511). 9291 bytes result sent to driver
[2025-07-19T19:57:23.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 199.0 in stage 1.0 (TID 520)
[2025-07-19T19:57:23.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 188 (task 514, attempt 0, stage 1.0)
[2025-07-19T19:57:23.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 521) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 521)
[2025-07-19T19:57:23.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 184.0 in stage 1.0 (TID 511) in 131 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T19:57:23.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 191 (task 515, attempt 0, stage 1.0)
[2025-07-19T19:57:23.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 191.0 in stage 1.0 (TID 515). 9321 bytes result sent to driver
[2025-07-19T19:57:23.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 188.0 in stage 1.0 (TID 514). 9343 bytes result sent to driver
[2025-07-19T19:57:23.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29899512
[2025-07-19T19:57:23.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 522) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 522)
[2025-07-19T19:57:23.438+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198] for update
[2025-07-19T19:57:23.438+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.1.delta.8a6e4775-faed-43a1-8ef1-86d099a41187.TID518.tmp
[2025-07-19T19:57:23.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 191.0 in stage 1.0 (TID 515) in 104 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T19:57:23.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 523) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 188.0 in stage 1.0 (TID 514) in 111 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T19:57:23.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 3.0 in stage 1.0 (TID 523)
[2025-07-19T19:57:23.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.1.delta.07a77320-b876-4278-9850-5f58a6d12444.TID516.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/1.delta
[2025-07-19T19:57:23.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/1.delta
[2025-07-19T19:57:23.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T19:57:23.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.1.delta.db7332a4-0065-4f7e-afff-f04897bbff85.TID517.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/1.delta
[2025-07-19T19:57:23.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/1.delta
[2025-07-19T19:57:23.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 516, attempt 0, stage 1.0)
[2025-07-19T19:57:23.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 517, attempt 0, stage 1.0)
[2025-07-19T19:57:23.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.1.delta.9d8c40e8-e3b7-4e1c-810d-4f76366e98be.TID519.tmp
[2025-07-19T19:57:23.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2025-07-19T19:57:23.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/.schema.4ea1037c-dd0d-4163-8749-abc72455c4bd.TID521.tmp
[2025-07-19T19:57:23.466+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 196 (task 517, attempt 0, stage 1.0)
[2025-07-19T19:57:23.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 196.0 in stage 1.0 (TID 517). 9300 bytes result sent to driver
[2025-07-19T19:57:23.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 194 (task 516, attempt 0, stage 1.0)
[2025-07-19T19:57:23.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 194.0 in stage 1.0 (TID 516). 9293 bytes result sent to driver
[2025-07-19T19:57:23.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.1.delta.8a6e4775-faed-43a1-8ef1-86d099a41187.TID518.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/1.delta
[2025-07-19T19:57:23.471+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/1.delta
[2025-07-19T19:57:23.472+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 524) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 525) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 6.0 in stage 1.0 (TID 525)
[2025-07-19T19:57:23.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 4.0 in stage 1.0 (TID 524)
[2025-07-19T19:57:23.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 196.0 in stage 1.0 (TID 517) in 107 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T19:57:23.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 518, attempt 0, stage 1.0)
[2025-07-19T19:57:23.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 194.0 in stage 1.0 (TID 516) in 111 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T19:57:23.476+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/.schema.4ea1037c-dd0d-4163-8749-abc72455c4bd.TID521.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/_metadata/schema
[2025-07-19T19:57:23.488+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31936bdd
[2025-07-19T19:57:23.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0] for update
[2025-07-19T19:57:23.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.1.delta.9d8c40e8-e3b7-4e1c-810d-4f76366e98be.TID519.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/1.delta
[2025-07-19T19:57:23.490+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/1.delta
[2025-07-19T19:57:23.490+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 519, attempt 0, stage 1.0)
[2025-07-19T19:57:23.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61d9d690
[2025-07-19T19:57:23.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199] for update
[2025-07-19T19:57:23.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 197 (task 518, attempt 0, stage 1.0)
[2025-07-19T19:57:23.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.1.delta.1874cfb6-fdf6-470b-bf41-94acad2367d3.TID521.tmp
[2025-07-19T19:57:23.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 197.0 in stage 1.0 (TID 518). 9253 bytes result sent to driver
[2025-07-19T19:57:23.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a25f874
[2025-07-19T19:57:23.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 526) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6] for update
[2025-07-19T19:57:23.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 197.0 in stage 1.0 (TID 518) in 101 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T19:57:23.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.1.delta.06db1080-d46a-4dea-a8b2-fbb68fa2d5b6.TID520.tmp
[2025-07-19T19:57:23.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 9.0 in stage 1.0 (TID 526)
[2025-07-19T19:57:23.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 198 (task 519, attempt 0, stage 1.0)
[2025-07-19T19:57:23.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 198.0 in stage 1.0 (TID 519). 9259 bytes result sent to driver
[2025-07-19T19:57:23.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 527) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 13.0 in stage 1.0 (TID 527)
[2025-07-19T19:57:23.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 198.0 in stage 1.0 (TID 519) in 100 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T19:57:23.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c12a436
[2025-07-19T19:57:23.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4] for update
[2025-07-19T19:57:23.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.513+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.1.delta.4cde8bf8-a8d8-4cd6-ab88-3dd25ddce034.TID525.tmp
[2025-07-19T19:57:23.515+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@720fafa5
[2025-07-19T19:57:23.516+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.516+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3] for update
[2025-07-19T19:57:23.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.1.delta.41b18b3a-495f-4a3a-ae0d-a1dd2728d3bf.TID524.tmp
[2025-07-19T19:57:23.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@463244be
[2025-07-19T19:57:23.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.1.delta.4448457c-cf60-4882-bd6d-c8f58b8f8b8d.TID523.tmp
[2025-07-19T19:57:23.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1] for update
[2025-07-19T19:57:23.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@639113aa
[2025-07-19T19:57:23.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.1.delta.1874cfb6-fdf6-470b-bf41-94acad2367d3.TID521.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/1.delta
[2025-07-19T19:57:23.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/1.delta
[2025-07-19T19:57:23.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 521, attempt 0, stage 1.0)
[2025-07-19T19:57:23.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.1.delta.06db1080-d46a-4dea-a8b2-fbb68fa2d5b6.TID520.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/1.delta
[2025-07-19T19:57:23.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/1.delta
[2025-07-19T19:57:23.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13] for update
[2025-07-19T19:57:23.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 520, attempt 0, stage 1.0)
[2025-07-19T19:57:23.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.1.delta.c3a42152-3dc6-4855-8978-5edc8675a2ae.TID522.tmp
[2025-07-19T19:57:23.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.1.delta.4cde8bf8-a8d8-4cd6-ab88-3dd25ddce034.TID525.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/1.delta
[2025-07-19T19:57:23.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/1.delta
[2025-07-19T19:57:23.546+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 525, attempt 0, stage 1.0)
[2025-07-19T19:57:23.548+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 0 (task 521, attempt 0, stage 1.0)
[2025-07-19T19:57:23.548+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 521). 6243 bytes result sent to driver
[2025-07-19T19:57:23.548+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 528) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 521) in 119 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T19:57:23.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 21.0 in stage 1.0 (TID 528)
[2025-07-19T19:57:23.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 6 (task 525, attempt 0, stage 1.0)
[2025-07-19T19:57:23.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 6.0 in stage 1.0 (TID 525). 6243 bytes result sent to driver
[2025-07-19T19:57:23.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 529) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 22.0 in stage 1.0 (TID 529)
[2025-07-19T19:57:23.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 525) in 78 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T19:57:23.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f1e4b2
[2025-07-19T19:57:23.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.1.delta.41b18b3a-495f-4a3a-ae0d-a1dd2728d3bf.TID524.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/1.delta
[2025-07-19T19:57:23.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/1.delta
[2025-07-19T19:57:23.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9] for update
[2025-07-19T19:57:23.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 524, attempt 0, stage 1.0)
[2025-07-19T19:57:23.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 199 (task 520, attempt 0, stage 1.0)
[2025-07-19T19:57:23.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 199.0 in stage 1.0 (TID 520). 9320 bytes result sent to driver
[2025-07-19T19:57:23.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 530) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 199.0 in stage 1.0 (TID 520) in 132 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T19:57:23.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 4 (task 524, attempt 0, stage 1.0)
[2025-07-19T19:57:23.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 23.0 in stage 1.0 (TID 530)
[2025-07-19T19:57:23.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 4.0 in stage 1.0 (TID 524). 6243 bytes result sent to driver
[2025-07-19T19:57:23.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.1.delta.c4521320-2763-411f-8938-93ebd8d8937f.TID527.tmp
[2025-07-19T19:57:23.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17cccb79
[2025-07-19T19:57:23.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 531) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 25.0 in stage 1.0 (TID 531)
[2025-07-19T19:57:23.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 524) in 86 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T19:57:23.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22] for update
[2025-07-19T19:57:23.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.1.delta.4448457c-cf60-4882-bd6d-c8f58b8f8b8d.TID523.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/1.delta
[2025-07-19T19:57:23.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/1.delta
[2025-07-19T19:57:23.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 523, attempt 0, stage 1.0)
[2025-07-19T19:57:23.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.1.delta.93437672-61af-4e91-9bfb-a074dadb957b.TID526.tmp
[2025-07-19T19:57:23.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 3 (task 523, attempt 0, stage 1.0)
[2025-07-19T19:57:23.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 3.0 in stage 1.0 (TID 523). 6243 bytes result sent to driver
[2025-07-19T19:57:23.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 532) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 29.0 in stage 1.0 (TID 532)
[2025-07-19T19:57:23.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 523) in 130 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T19:57:23.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@123f296b
[2025-07-19T19:57:23.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21] for update
[2025-07-19T19:57:23.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.1.delta.c3a42152-3dc6-4855-8978-5edc8675a2ae.TID522.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/1.delta
[2025-07-19T19:57:23.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/1.delta
[2025-07-19T19:57:23.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 522, attempt 0, stage 1.0)
[2025-07-19T19:57:23.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.1.delta.59efebe0-db13-44a9-bcba-66a49072aea8.TID529.tmp
[2025-07-19T19:57:23.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@464a9740
[2025-07-19T19:57:23.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23] for update
[2025-07-19T19:57:23.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 1 (task 522, attempt 0, stage 1.0)
[2025-07-19T19:57:23.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 522). 6243 bytes result sent to driver
[2025-07-19T19:57:23.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fdfc0be
[2025-07-19T19:57:23.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 533) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 522) in 145 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T19:57:23.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29] for update
[2025-07-19T19:57:23.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.1.delta.39b95fde-abd0-404f-8060-e7bc256a700c.TID528.tmp
[2025-07-19T19:57:23.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 37.0 in stage 1.0 (TID 533)
[2025-07-19T19:57:23.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.580+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c5bca01
[2025-07-19T19:57:23.582+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25] for update
[2025-07-19T19:57:23.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.1.delta.93437672-61af-4e91-9bfb-a074dadb957b.TID526.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/1.delta
[2025-07-19T19:57:23.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/1.delta
[2025-07-19T19:57:23.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.1.delta.020153f6-4d0c-42dd-8c55-50082cf92855.TID532.tmp
[2025-07-19T19:57:23.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6497e781
[2025-07-19T19:57:23.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 526, attempt 0, stage 1.0)
[2025-07-19T19:57:23.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.1.delta.7096032d-2d50-4b4c-8236-72a90f35dd55.TID530.tmp
[2025-07-19T19:57:23.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37] for update
[2025-07-19T19:57:23.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.1.delta.c4521320-2763-411f-8938-93ebd8d8937f.TID527.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/1.delta
[2025-07-19T19:57:23.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/1.delta
[2025-07-19T19:57:23.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 527, attempt 0, stage 1.0)
[2025-07-19T19:57:23.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 9 (task 526, attempt 0, stage 1.0)
[2025-07-19T19:57:23.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 13 (task 527, attempt 0, stage 1.0)
[2025-07-19T19:57:23.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 9.0 in stage 1.0 (TID 526). 6243 bytes result sent to driver
[2025-07-19T19:57:23.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 13.0 in stage 1.0 (TID 527). 6243 bytes result sent to driver
[2025-07-19T19:57:23.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 534) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 535) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 38.0 in stage 1.0 (TID 534)
[2025-07-19T19:57:23.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 39.0 in stage 1.0 (TID 535)
[2025-07-19T19:57:23.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 526) in 94 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T19:57:23.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 527) in 87 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T19:57:23.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.1.delta.6362f88a-b175-4a5f-92cc-233264abc481.TID531.tmp
[2025-07-19T19:57:23.597+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.1.delta.59efebe0-db13-44a9-bcba-66a49072aea8.TID529.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/1.delta
[2025-07-19T19:57:23.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/1.delta
[2025-07-19T19:57:23.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 529, attempt 0, stage 1.0)
[2025-07-19T19:57:23.600+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.601+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:23.601+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.1.delta.3d9dc317-2bb8-4cc5-aae4-1a96bf3488d9.TID533.tmp
[2025-07-19T19:57:23.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b874407
[2025-07-19T19:57:23.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 22 (task 529, attempt 0, stage 1.0)
[2025-07-19T19:57:23.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39] for update
[2025-07-19T19:57:23.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 22.0 in stage 1.0 (TID 529). 6200 bytes result sent to driver
[2025-07-19T19:57:23.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 536) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 529) in 53 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T19:57:23.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.606+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 43.0 in stage 1.0 (TID 536)
[2025-07-19T19:57:23.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d88cd02
[2025-07-19T19:57:23.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38] for update
[2025-07-19T19:57:23.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ec90c5d
[2025-07-19T19:57:23.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43] for update
[2025-07-19T19:57:23.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.1.delta.39b95fde-abd0-404f-8060-e7bc256a700c.TID528.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/1.delta
[2025-07-19T19:57:23.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/1.delta
[2025-07-19T19:57:23.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 528, attempt 0, stage 1.0)
[2025-07-19T19:57:23.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.1.delta.cc9ffe99-3dfa-444b-8cfc-172aa5d00fe9.TID535.tmp
[2025-07-19T19:57:23.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.1.delta.55b280a9-24a4-4d8a-be3b-b6c3a406a655.TID534.tmp
[2025-07-19T19:57:23.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 21 (task 528, attempt 0, stage 1.0)
[2025-07-19T19:57:23.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 21.0 in stage 1.0 (TID 528). 6243 bytes result sent to driver
[2025-07-19T19:57:23.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.1.delta.020153f6-4d0c-42dd-8c55-50082cf92855.TID532.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/1.delta
[2025-07-19T19:57:23.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/1.delta
[2025-07-19T19:57:23.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 537) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 532, attempt 0, stage 1.0)
[2025-07-19T19:57:23.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 528) in 78 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T19:57:23.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 44.0 in stage 1.0 (TID 537)
[2025-07-19T19:57:23.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.1.delta.f64e420e-5a49-4b3b-8da8-c1eb148cde70.TID536.tmp
[2025-07-19T19:57:23.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 29 (task 532, attempt 0, stage 1.0)
[2025-07-19T19:57:23.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.1.delta.7096032d-2d50-4b4c-8236-72a90f35dd55.TID530.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/1.delta
[2025-07-19T19:57:23.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/1.delta
[2025-07-19T19:57:23.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 29.0 in stage 1.0 (TID 532). 6243 bytes result sent to driver
[2025-07-19T19:57:23.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 530, attempt 0, stage 1.0)
[2025-07-19T19:57:23.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 538) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 45.0 in stage 1.0 (TID 538)
[2025-07-19T19:57:23.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 29.0 in stage 1.0 (TID 532) in 68 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T19:57:23.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 23 (task 530, attempt 0, stage 1.0)
[2025-07-19T19:57:23.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 23.0 in stage 1.0 (TID 530). 6243 bytes result sent to driver
[2025-07-19T19:57:23.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 539) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 50.0 in stage 1.0 (TID 539)
[2025-07-19T19:57:23.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 530) in 80 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T19:57:23.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76c5bc66
[2025-07-19T19:57:23.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44] for update
[2025-07-19T19:57:23.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.1.delta.3d9dc317-2bb8-4cc5-aae4-1a96bf3488d9.TID533.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/1.delta
[2025-07-19T19:57:23.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/1.delta
[2025-07-19T19:57:23.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 533, attempt 0, stage 1.0)
[2025-07-19T19:57:23.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.1.delta.6362f88a-b175-4a5f-92cc-233264abc481.TID531.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/1.delta
[2025-07-19T19:57:23.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/1.delta
[2025-07-19T19:57:23.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 531, attempt 0, stage 1.0)
[2025-07-19T19:57:23.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 25 (task 531, attempt 0, stage 1.0)
[2025-07-19T19:57:23.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 37 (task 533, attempt 0, stage 1.0)
[2025-07-19T19:57:23.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 37.0 in stage 1.0 (TID 533). 6243 bytes result sent to driver
[2025-07-19T19:57:23.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 25.0 in stage 1.0 (TID 531). 6243 bytes result sent to driver
[2025-07-19T19:57:23.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 540) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 533) in 71 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T19:57:23.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d175f2
[2025-07-19T19:57:23.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 53.0 in stage 1.0 (TID 541) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.647+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 52.0 in stage 1.0 (TID 540)
[2025-07-19T19:57:23.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 531) in 91 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T19:57:23.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 53.0 in stage 1.0 (TID 541)
[2025-07-19T19:57:23.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50] for update
[2025-07-19T19:57:23.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.1.delta.226a752f-56a1-47a8-b8a4-9f156bcec8b4.TID537.tmp
[2025-07-19T19:57:23.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.1.delta.cc9ffe99-3dfa-444b-8cfc-172aa5d00fe9.TID535.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/1.delta
[2025-07-19T19:57:23.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/1.delta
[2025-07-19T19:57:23.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.1.delta.55b280a9-24a4-4d8a-be3b-b6c3a406a655.TID534.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/1.delta
[2025-07-19T19:57:23.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/1.delta
[2025-07-19T19:57:23.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 535, attempt 0, stage 1.0)
[2025-07-19T19:57:23.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 534, attempt 0, stage 1.0)
[2025-07-19T19:57:23.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76fc9000
[2025-07-19T19:57:23.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.1.delta.304e1cc7-d9cb-480f-a1c0-260ee9b849bd.TID539.tmp
[2025-07-19T19:57:23.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.1.delta.f64e420e-5a49-4b3b-8da8-c1eb148cde70.TID536.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/1.delta
[2025-07-19T19:57:23.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/1.delta
[2025-07-19T19:57:23.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 536, attempt 0, stage 1.0)
[2025-07-19T19:57:23.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 39 (task 535, attempt 0, stage 1.0)
[2025-07-19T19:57:23.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45] for update
[2025-07-19T19:57:23.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 39.0 in stage 1.0 (TID 535). 6243 bytes result sent to driver
[2025-07-19T19:57:23.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 38 (task 534, attempt 0, stage 1.0)
[2025-07-19T19:57:23.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 56.0 in stage 1.0 (TID 542) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 38.0 in stage 1.0 (TID 534). 6243 bytes result sent to driver
[2025-07-19T19:57:23.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 56.0 in stage 1.0 (TID 542)
[2025-07-19T19:57:23.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 59.0 in stage 1.0 (TID 543) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 39.0 in stage 1.0 (TID 535) in 69 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T19:57:23.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 534) in 70 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T19:57:23.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 59.0 in stage 1.0 (TID 543)
[2025-07-19T19:57:23.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 43 (task 536, attempt 0, stage 1.0)
[2025-07-19T19:57:23.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 43.0 in stage 1.0 (TID 536). 6243 bytes result sent to driver
[2025-07-19T19:57:23.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 61.0 in stage 1.0 (TID 544) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 61.0 in stage 1.0 (TID 544)
[2025-07-19T19:57:23.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@335a21d6
[2025-07-19T19:57:23.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 536) in 66 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T19:57:23.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52] for update
[2025-07-19T19:57:23.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31023515
[2025-07-19T19:57:23.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53] for update
[2025-07-19T19:57:23.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.1.delta.29276fd1-561a-41ce-a9cd-f2cdb99a4654.TID538.tmp
[2025-07-19T19:57:23.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.1.delta.8ce67aa9-cd28-4742-888e-5300c908acaf.TID540.tmp
[2025-07-19T19:57:23.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@162f7d46
[2025-07-19T19:57:23.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.1.delta.5196326c-1d92-44e3-bd38-8040afe5f8e8.TID541.tmp
[2025-07-19T19:57:23.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61] for update
[2025-07-19T19:57:23.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.1.delta.226a752f-56a1-47a8-b8a4-9f156bcec8b4.TID537.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/1.delta
[2025-07-19T19:57:23.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/1.delta
[2025-07-19T19:57:23.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 537, attempt 0, stage 1.0)
[2025-07-19T19:57:23.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.1.delta.304e1cc7-d9cb-480f-a1c0-260ee9b849bd.TID539.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/1.delta
[2025-07-19T19:57:23.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/1.delta
[2025-07-19T19:57:23.693+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 539, attempt 0, stage 1.0)
[2025-07-19T19:57:23.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@930cc29
[2025-07-19T19:57:23.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 44 (task 537, attempt 0, stage 1.0)
[2025-07-19T19:57:23.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56] for update
[2025-07-19T19:57:23.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 44.0 in stage 1.0 (TID 537). 6200 bytes result sent to driver
[2025-07-19T19:57:23.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 65.0 in stage 1.0 (TID 545) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 65.0 in stage 1.0 (TID 545)
[2025-07-19T19:57:23.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 537) in 72 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T19:57:23.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.1.delta.047f2d40-29c2-4fd8-bc47-e8903ac75cc1.TID544.tmp
[2025-07-19T19:57:23.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 50 (task 539, attempt 0, stage 1.0)
[2025-07-19T19:57:23.702+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 50.0 in stage 1.0 (TID 539). 6200 bytes result sent to driver
[2025-07-19T19:57:23.702+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 67.0 in stage 1.0 (TID 546) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.704+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 539) in 68 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T19:57:23.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 67.0 in stage 1.0 (TID 546)
[2025-07-19T19:57:23.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ddf5d0b
[2025-07-19T19:57:23.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59] for update
[2025-07-19T19:57:23.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.1.delta.2e75dacc-a8e8-437b-a098-009128a52eac.TID542.tmp
[2025-07-19T19:57:23.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.1.delta.29276fd1-561a-41ce-a9cd-f2cdb99a4654.TID538.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/1.delta
[2025-07-19T19:57:23.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/1.delta
[2025-07-19T19:57:23.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57e0fe65
[2025-07-19T19:57:23.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 538, attempt 0, stage 1.0)
[2025-07-19T19:57:23.710+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.710+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65] for update
[2025-07-19T19:57:23.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.1.delta.23a169b1-b6ac-44c2-b53a-2b5ee1f23dcd.TID543.tmp
[2025-07-19T19:57:23.712+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 45 (task 538, attempt 0, stage 1.0)
[2025-07-19T19:57:23.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 45.0 in stage 1.0 (TID 538). 6200 bytes result sent to driver
[2025-07-19T19:57:23.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 69.0 in stage 1.0 (TID 547) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e936915
[2025-07-19T19:57:23.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 538) in 85 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T19:57:23.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 69.0 in stage 1.0 (TID 547)
[2025-07-19T19:57:23.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.1.delta.5196326c-1d92-44e3-bd38-8040afe5f8e8.TID541.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/1.delta
[2025-07-19T19:57:23.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/1.delta
[2025-07-19T19:57:23.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67] for update
[2025-07-19T19:57:23.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 541, attempt 0, stage 1.0)
[2025-07-19T19:57:23.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.1.delta.8ce67aa9-cd28-4742-888e-5300c908acaf.TID540.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/1.delta
[2025-07-19T19:57:23.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/1.delta
[2025-07-19T19:57:23.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 53 (task 541, attempt 0, stage 1.0)
[2025-07-19T19:57:23.722+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 540, attempt 0, stage 1.0)
[2025-07-19T19:57:23.722+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 53.0 in stage 1.0 (TID 541). 6200 bytes result sent to driver
[2025-07-19T19:57:23.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 53.0 in stage 1.0 (TID 541) in 74 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T19:57:23.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 70.0 in stage 1.0 (TID 548) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.1.delta.1a821c4e-37ac-4157-9fc0-6a7f5800aab2.TID545.tmp
[2025-07-19T19:57:23.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 70.0 in stage 1.0 (TID 548)
[2025-07-19T19:57:23.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d4423e0
[2025-07-19T19:57:23.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 52 (task 540, attempt 0, stage 1.0)
[2025-07-19T19:57:23.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.1.delta.86b7c3ab-9cc0-4fdf-9b14-ceb328a00b19.TID546.tmp
[2025-07-19T19:57:23.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69] for update
[2025-07-19T19:57:23.729+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 52.0 in stage 1.0 (TID 540). 6200 bytes result sent to driver
[2025-07-19T19:57:23.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 72.0 in stage 1.0 (TID 549) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 540) in 84 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T19:57:23.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 72.0 in stage 1.0 (TID 549)
[2025-07-19T19:57:23.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ae94349
[2025-07-19T19:57:23.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70] for update
[2025-07-19T19:57:23.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.1.delta.047f2d40-29c2-4fd8-bc47-e8903ac75cc1.TID544.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/1.delta
[2025-07-19T19:57:23.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/1.delta
[2025-07-19T19:57:23.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 544, attempt 0, stage 1.0)
[2025-07-19T19:57:23.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c1cf80b
[2025-07-19T19:57:23.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.1.delta.2e75dacc-a8e8-437b-a098-009128a52eac.TID542.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/1.delta
[2025-07-19T19:57:23.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/1.delta
[2025-07-19T19:57:23.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 542, attempt 0, stage 1.0)
[2025-07-19T19:57:23.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.1.delta.6f484aaf-3f6a-41f5-a3e5-feca43ef3477.TID547.tmp
[2025-07-19T19:57:23.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72] for update
[2025-07-19T19:57:23.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.1.delta.4d98da01-c3da-4796-9fe9-94eb0b12d400.TID548.tmp
[2025-07-19T19:57:23.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 61 (task 544, attempt 0, stage 1.0)
[2025-07-19T19:57:23.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 61.0 in stage 1.0 (TID 544). 6243 bytes result sent to driver
[2025-07-19T19:57:23.749+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 56 (task 542, attempt 0, stage 1.0)
[2025-07-19T19:57:23.749+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 56.0 in stage 1.0 (TID 542). 6243 bytes result sent to driver
[2025-07-19T19:57:23.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 75.0 in stage 1.0 (TID 550) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 75.0 in stage 1.0 (TID 550)
[2025-07-19T19:57:23.751+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.1.delta.23a169b1-b6ac-44c2-b53a-2b5ee1f23dcd.TID543.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/1.delta
[2025-07-19T19:57:23.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/1.delta
[2025-07-19T19:57:23.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 77.0 in stage 1.0 (TID 551) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 56.0 in stage 1.0 (TID 542) in 90 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T19:57:23.754+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 61.0 in stage 1.0 (TID 544) in 86 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T19:57:23.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 77.0 in stage 1.0 (TID 551)
[2025-07-19T19:57:23.755+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 543, attempt 0, stage 1.0)
[2025-07-19T19:57:23.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.1.delta.93496abf-eac6-4496-a62f-a8379ad18977.TID549.tmp
[2025-07-19T19:57:23.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.1.delta.1a821c4e-37ac-4157-9fc0-6a7f5800aab2.TID545.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/1.delta
[2025-07-19T19:57:23.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:23.760+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/1.delta
[2025-07-19T19:57:23.761+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 545, attempt 0, stage 1.0)
[2025-07-19T19:57:23.762+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 59 (task 543, attempt 0, stage 1.0)
[2025-07-19T19:57:23.763+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.763+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 59.0 in stage 1.0 (TID 543). 6243 bytes result sent to driver
[2025-07-19T19:57:23.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 78.0 in stage 1.0 (TID 552) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 59.0 in stage 1.0 (TID 543) in 97 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T19:57:23.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 78.0 in stage 1.0 (TID 552)
[2025-07-19T19:57:23.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 65 (task 545, attempt 0, stage 1.0)
[2025-07-19T19:57:23.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 65.0 in stage 1.0 (TID 545). 6243 bytes result sent to driver
[2025-07-19T19:57:23.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@389ec4bd
[2025-07-19T19:57:23.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 81.0 in stage 1.0 (TID 553) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75] for update
[2025-07-19T19:57:23.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 81.0 in stage 1.0 (TID 553)
[2025-07-19T19:57:23.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 65.0 in stage 1.0 (TID 545) in 67 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T19:57:23.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.1.delta.86b7c3ab-9cc0-4fdf-9b14-ceb328a00b19.TID546.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/1.delta
[2025-07-19T19:57:23.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/1.delta
[2025-07-19T19:57:23.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 546, attempt 0, stage 1.0)
[2025-07-19T19:57:23.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 67 (task 546, attempt 0, stage 1.0)
[2025-07-19T19:57:23.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 67.0 in stage 1.0 (TID 546). 6243 bytes result sent to driver
[2025-07-19T19:57:23.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 84.0 in stage 1.0 (TID 554) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6605b4be
[2025-07-19T19:57:23.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 84.0 in stage 1.0 (TID 554)
[2025-07-19T19:57:23.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 67.0 in stage 1.0 (TID 546) in 68 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T19:57:23.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77] for update
[2025-07-19T19:57:23.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.778+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.780+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.1.delta.4d98da01-c3da-4796-9fe9-94eb0b12d400.TID548.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/1.delta
[2025-07-19T19:57:23.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/1.delta
[2025-07-19T19:57:23.782+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 548, attempt 0, stage 1.0)
[2025-07-19T19:57:23.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.1.delta.759d3f16-4cf4-4e4a-b215-262fc52579b4.TID550.tmp
[2025-07-19T19:57:23.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.1.delta.6f484aaf-3f6a-41f5-a3e5-feca43ef3477.TID547.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/1.delta
[2025-07-19T19:57:23.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/1.delta
[2025-07-19T19:57:23.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 547, attempt 0, stage 1.0)
[2025-07-19T19:57:23.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@112d894c
[2025-07-19T19:57:23.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84] for update
[2025-07-19T19:57:23.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 70 (task 548, attempt 0, stage 1.0)
[2025-07-19T19:57:23.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 69 (task 547, attempt 0, stage 1.0)
[2025-07-19T19:57:23.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 70.0 in stage 1.0 (TID 548). 6243 bytes result sent to driver
[2025-07-19T19:57:23.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 69.0 in stage 1.0 (TID 547). 6243 bytes result sent to driver
[2025-07-19T19:57:23.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 85.0 in stage 1.0 (TID 555) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 89.0 in stage 1.0 (TID 556) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 89.0 in stage 1.0 (TID 556)
[2025-07-19T19:57:23.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2578936d
[2025-07-19T19:57:23.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 85.0 in stage 1.0 (TID 555)
[2025-07-19T19:57:23.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 70.0 in stage 1.0 (TID 548) in 61 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T19:57:23.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.1.delta.d7910960-d587-46e6-938d-0e88cd4f3ed2.TID551.tmp
[2025-07-19T19:57:23.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.1.delta.93496abf-eac6-4496-a62f-a8379ad18977.TID549.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/1.delta
[2025-07-19T19:57:23.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/1.delta
[2025-07-19T19:57:23.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78] for update
[2025-07-19T19:57:23.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 69.0 in stage 1.0 (TID 547) in 73 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T19:57:23.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 549, attempt 0, stage 1.0)
[2025-07-19T19:57:23.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 72 (task 549, attempt 0, stage 1.0)
[2025-07-19T19:57:23.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40e00f44
[2025-07-19T19:57:23.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81] for update
[2025-07-19T19:57:23.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.1.delta.ae2fb739-c6b8-4365-84ae-ab7efece1231.TID554.tmp
[2025-07-19T19:57:23.799+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 72.0 in stage 1.0 (TID 549). 6243 bytes result sent to driver
[2025-07-19T19:57:23.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 91.0 in stage 1.0 (TID 557) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 91.0 in stage 1.0 (TID 557)
[2025-07-19T19:57:23.803+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.1.delta.6b49255f-0f2d-46cb-8d48-a37e79c980e7.TID553.tmp
[2025-07-19T19:57:23.803+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 72.0 in stage 1.0 (TID 549) in 73 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T19:57:23.803+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.1.delta.344c0892-3f69-476c-957c-fc1d1933dc8a.TID552.tmp
[2025-07-19T19:57:23.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@461c9ce6
[2025-07-19T19:57:23.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89] for update
[2025-07-19T19:57:23.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@211d10f
[2025-07-19T19:57:23.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85] for update
[2025-07-19T19:57:23.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44cccd64
[2025-07-19T19:57:23.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91] for update
[2025-07-19T19:57:23.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.1.delta.759d3f16-4cf4-4e4a-b215-262fc52579b4.TID550.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/1.delta
[2025-07-19T19:57:23.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/1.delta
[2025-07-19T19:57:23.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 550, attempt 0, stage 1.0)
[2025-07-19T19:57:23.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.1.delta.68241f5d-9720-4cbb-9c34-482802265e1e.TID556.tmp
[2025-07-19T19:57:23.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.1.delta.02a84d41-14e7-4872-aa93-e7b57a9d3515.TID555.tmp
[2025-07-19T19:57:23.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.1.delta.ae2fb739-c6b8-4365-84ae-ab7efece1231.TID554.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/1.delta
[2025-07-19T19:57:23.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/1.delta
[2025-07-19T19:57:23.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 554, attempt 0, stage 1.0)
[2025-07-19T19:57:23.824+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.1.delta.912950a8-28a7-4df4-8775-fba35c0db262.TID557.tmp
[2025-07-19T19:57:23.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 75 (task 550, attempt 0, stage 1.0)
[2025-07-19T19:57:23.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 75.0 in stage 1.0 (TID 550). 6200 bytes result sent to driver
[2025-07-19T19:57:23.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 92.0 in stage 1.0 (TID 558) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 84 (task 554, attempt 0, stage 1.0)
[2025-07-19T19:57:23.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 92.0 in stage 1.0 (TID 558)
[2025-07-19T19:57:23.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 84.0 in stage 1.0 (TID 554). 6200 bytes result sent to driver
[2025-07-19T19:57:23.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 75.0 in stage 1.0 (TID 550) in 78 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T19:57:23.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 84.0 in stage 1.0 (TID 554) in 63 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T19:57:23.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.1.delta.d7910960-d587-46e6-938d-0e88cd4f3ed2.TID551.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/1.delta
[2025-07-19T19:57:23.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/1.delta
[2025-07-19T19:57:23.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 94.0 in stage 1.0 (TID 559) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 94.0 in stage 1.0 (TID 559)
[2025-07-19T19:57:23.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 551, attempt 0, stage 1.0)
[2025-07-19T19:57:23.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.1.delta.6b49255f-0f2d-46cb-8d48-a37e79c980e7.TID553.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/1.delta
[2025-07-19T19:57:23.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/1.delta
[2025-07-19T19:57:23.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 553, attempt 0, stage 1.0)
[2025-07-19T19:57:23.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 77 (task 551, attempt 0, stage 1.0)
[2025-07-19T19:57:23.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 77.0 in stage 1.0 (TID 551). 6200 bytes result sent to driver
[2025-07-19T19:57:23.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fbab613
[2025-07-19T19:57:23.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94] for update
[2025-07-19T19:57:23.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 95.0 in stage 1.0 (TID 560) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 77.0 in stage 1.0 (TID 551) in 91 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T19:57:23.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 95.0 in stage 1.0 (TID 560)
[2025-07-19T19:57:23.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 81 (task 553, attempt 0, stage 1.0)
[2025-07-19T19:57:23.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.1.delta.344c0892-3f69-476c-957c-fc1d1933dc8a.TID552.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/1.delta
[2025-07-19T19:57:23.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/1.delta
[2025-07-19T19:57:23.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 81.0 in stage 1.0 (TID 553). 6200 bytes result sent to driver
[2025-07-19T19:57:23.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 98.0 in stage 1.0 (TID 561) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 98.0 in stage 1.0 (TID 561)
[2025-07-19T19:57:23.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 552, attempt 0, stage 1.0)
[2025-07-19T19:57:23.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@175cff09
[2025-07-19T19:57:23.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92] for update
[2025-07-19T19:57:23.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 81.0 in stage 1.0 (TID 553) in 90 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T19:57:23.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.858+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.1.delta.c37c1212-c0c9-4abd-9934-e254788378ca.TID559.tmp
[2025-07-19T19:57:23.858+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 78 (task 552, attempt 0, stage 1.0)
[2025-07-19T19:57:23.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 78.0 in stage 1.0 (TID 552). 6200 bytes result sent to driver
[2025-07-19T19:57:23.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 101.0 in stage 1.0 (TID 562) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 101.0 in stage 1.0 (TID 562)
[2025-07-19T19:57:23.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 78.0 in stage 1.0 (TID 552) in 97 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T19:57:23.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.1.delta.68241f5d-9720-4cbb-9c34-482802265e1e.TID556.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/1.delta
[2025-07-19T19:57:23.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/1.delta
[2025-07-19T19:57:23.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.1.delta.02a84d41-14e7-4872-aa93-e7b57a9d3515.TID555.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/1.delta
[2025-07-19T19:57:23.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/1.delta
[2025-07-19T19:57:23.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28305fb
[2025-07-19T19:57:23.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.1.delta.912950a8-28a7-4df4-8775-fba35c0db262.TID557.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/1.delta
[2025-07-19T19:57:23.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/1.delta
[2025-07-19T19:57:23.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 555, attempt 0, stage 1.0)
[2025-07-19T19:57:23.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 557, attempt 0, stage 1.0)
[2025-07-19T19:57:23.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95] for update
[2025-07-19T19:57:23.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 556, attempt 0, stage 1.0)
[2025-07-19T19:57:23.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.1.delta.60c09fcd-35b9-43bb-86f9-e16555d4c95d.TID558.tmp
[2025-07-19T19:57:23.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 85 (task 555, attempt 0, stage 1.0)
[2025-07-19T19:57:23.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 91 (task 557, attempt 0, stage 1.0)
[2025-07-19T19:57:23.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 85.0 in stage 1.0 (TID 555). 6286 bytes result sent to driver
[2025-07-19T19:57:23.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 104.0 in stage 1.0 (TID 563) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 91.0 in stage 1.0 (TID 557). 6243 bytes result sent to driver
[2025-07-19T19:57:23.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 85.0 in stage 1.0 (TID 555) in 87 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 107.0 in stage 1.0 (TID 564) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 107.0 in stage 1.0 (TID 564)
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 89 (task 556, attempt 0, stage 1.0)
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 91.0 in stage 1.0 (TID 557) in 72 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 104.0 in stage 1.0 (TID 563)
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 89.0 in stage 1.0 (TID 556). 6243 bytes result sent to driver
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 108.0 in stage 1.0 (TID 565) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.1.delta.b84fdf9e-af42-4838-aa80-28cd005445d5.TID560.tmp
[2025-07-19T19:57:23.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d673f
[2025-07-19T19:57:23.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 89.0 in stage 1.0 (TID 556) in 92 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T19:57:23.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 108.0 in stage 1.0 (TID 565)
[2025-07-19T19:57:23.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101] for update
[2025-07-19T19:57:23.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.876+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c152f91
[2025-07-19T19:57:23.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98] for update
[2025-07-19T19:57:23.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4059f686
[2025-07-19T19:57:23.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.1.delta.744a324b-cc55-4c93-bb0f-70dcc72d119a.TID562.tmp
[2025-07-19T19:57:23.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108] for update
[2025-07-19T19:57:23.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6852fd08
[2025-07-19T19:57:23.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104] for update
[2025-07-19T19:57:23.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.1.delta.482e4e46-5b60-40ea-978d-31b1d45d07ae.TID561.tmp
[2025-07-19T19:57:23.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.1.delta.737698a1-c979-450c-9d65-8719d7dbae28.TID565.tmp
[2025-07-19T19:57:23.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dfcf724
[2025-07-19T19:57:23.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107] for update
[2025-07-19T19:57:23.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.1.delta.c37c1212-c0c9-4abd-9934-e254788378ca.TID559.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/1.delta
[2025-07-19T19:57:23.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/1.delta
[2025-07-19T19:57:23.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 559, attempt 0, stage 1.0)
[2025-07-19T19:57:23.897+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 94 (task 559, attempt 0, stage 1.0)
[2025-07-19T19:57:23.897+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 94.0 in stage 1.0 (TID 559). 6243 bytes result sent to driver
[2025-07-19T19:57:23.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.1.delta.60c09fcd-35b9-43bb-86f9-e16555d4c95d.TID558.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/1.delta
[2025-07-19T19:57:23.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/1.delta
[2025-07-19T19:57:23.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 558, attempt 0, stage 1.0)
[2025-07-19T19:57:23.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.1.delta.3b6374f3-5625-43b5-bda9-4fde1f6becd8.TID563.tmp
[2025-07-19T19:57:23.901+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 115.0 in stage 1.0 (TID 566) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.901+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 115.0 in stage 1.0 (TID 566)
[2025-07-19T19:57:23.902+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 94.0 in stage 1.0 (TID 559) in 70 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T19:57:23.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.1.delta.b84fdf9e-af42-4838-aa80-28cd005445d5.TID560.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/1.delta
[2025-07-19T19:57:23.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/1.delta
[2025-07-19T19:57:23.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 92 (task 558, attempt 0, stage 1.0)
[2025-07-19T19:57:23.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 560, attempt 0, stage 1.0)
[2025-07-19T19:57:23.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 92.0 in stage 1.0 (TID 558). 6243 bytes result sent to driver
[2025-07-19T19:57:23.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.1.delta.8c803c94-cdad-4959-95c8-71c00621dcd3.TID564.tmp
[2025-07-19T19:57:23.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 120.0 in stage 1.0 (TID 567) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 120.0 in stage 1.0 (TID 567)
[2025-07-19T19:57:23.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@590f83a4
[2025-07-19T19:57:23.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 92.0 in stage 1.0 (TID 558) in 80 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T19:57:23.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 95 (task 560, attempt 0, stage 1.0)
[2025-07-19T19:57:23.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115] for update
[2025-07-19T19:57:23.910+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 95.0 in stage 1.0 (TID 560). 6243 bytes result sent to driver
[2025-07-19T19:57:23.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 121.0 in stage 1.0 (TID 568) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 121.0 in stage 1.0 (TID 568)
[2025-07-19T19:57:23.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 95.0 in stage 1.0 (TID 560) in 70 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T19:57:23.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.1.delta.744a324b-cc55-4c93-bb0f-70dcc72d119a.TID562.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/1.delta
[2025-07-19T19:57:23.913+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/1.delta
[2025-07-19T19:57:23.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 562, attempt 0, stage 1.0)
[2025-07-19T19:57:23.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e141b9d
[2025-07-19T19:57:23.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 101 (task 562, attempt 0, stage 1.0)
[2025-07-19T19:57:23.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120] for update
[2025-07-19T19:57:23.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 101.0 in stage 1.0 (TID 562). 6243 bytes result sent to driver
[2025-07-19T19:57:23.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.1.delta.482e4e46-5b60-40ea-978d-31b1d45d07ae.TID561.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/1.delta
[2025-07-19T19:57:23.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/1.delta
[2025-07-19T19:57:23.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 561, attempt 0, stage 1.0)
[2025-07-19T19:57:23.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 101.0 in stage 1.0 (TID 562) in 63 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T19:57:23.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.1.delta.1f270919-52ae-4734-9016-f213e1e625ed.TID566.tmp
[2025-07-19T19:57:23.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 122.0 in stage 1.0 (TID 569) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 122.0 in stage 1.0 (TID 569)
[2025-07-19T19:57:23.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.922+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 98 (task 561, attempt 0, stage 1.0)
[2025-07-19T19:57:23.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 98.0 in stage 1.0 (TID 561). 6243 bytes result sent to driver
[2025-07-19T19:57:23.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 123.0 in stage 1.0 (TID 570) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e521dc5
[2025-07-19T19:57:23.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.1.delta.57869a52-1449-4b10-8bfb-d2c0b99f74f3.TID567.tmp
[2025-07-19T19:57:23.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121] for update
[2025-07-19T19:57:23.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 98.0 in stage 1.0 (TID 561) in 75 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T19:57:23.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 123.0 in stage 1.0 (TID 570)
[2025-07-19T19:57:23.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.1.delta.737698a1-c979-450c-9d65-8719d7dbae28.TID565.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/1.delta
[2025-07-19T19:57:23.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/1.delta
[2025-07-19T19:57:23.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 565, attempt 0, stage 1.0)
[2025-07-19T19:57:23.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68fbc79c
[2025-07-19T19:57:23.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122] for update
[2025-07-19T19:57:23.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 108 (task 565, attempt 0, stage 1.0)
[2025-07-19T19:57:23.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 108.0 in stage 1.0 (TID 565). 6200 bytes result sent to driver
[2025-07-19T19:57:23.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 128.0 in stage 1.0 (TID 571) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.1.delta.c9ab4d0c-2988-43c3-b02f-f2e9086586f9.TID568.tmp
[2025-07-19T19:57:23.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 108.0 in stage 1.0 (TID 565) in 61 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T19:57:23.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 128.0 in stage 1.0 (TID 571)
[2025-07-19T19:57:23.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.1.delta.3b6374f3-5625-43b5-bda9-4fde1f6becd8.TID563.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/1.delta
[2025-07-19T19:57:23.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/1.delta
[2025-07-19T19:57:23.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@742e1928
[2025-07-19T19:57:23.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 563, attempt 0, stage 1.0)
[2025-07-19T19:57:23.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123] for update
[2025-07-19T19:57:23.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.1.delta.e7d13707-e1f0-42b3-a062-b23646ec0211.TID569.tmp
[2025-07-19T19:57:23.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 104 (task 563, attempt 0, stage 1.0)
[2025-07-19T19:57:23.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 104.0 in stage 1.0 (TID 563). 6200 bytes result sent to driver
[2025-07-19T19:57:23.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cdac341
[2025-07-19T19:57:23.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 129.0 in stage 1.0 (TID 572) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 129.0 in stage 1.0 (TID 572)
[2025-07-19T19:57:23.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 104.0 in stage 1.0 (TID 563) in 78 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T19:57:23.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128] for update
[2025-07-19T19:57:23.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.1.delta.1f270919-52ae-4734-9016-f213e1e625ed.TID566.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/1.delta
[2025-07-19T19:57:23.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/1.delta
[2025-07-19T19:57:23.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 566, attempt 0, stage 1.0)
[2025-07-19T19:57:23.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.1.delta.8c803c94-cdad-4959-95c8-71c00621dcd3.TID564.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/1.delta
[2025-07-19T19:57:23.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/1.delta
[2025-07-19T19:57:23.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 564, attempt 0, stage 1.0)
[2025-07-19T19:57:23.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 107 (task 564, attempt 0, stage 1.0)
[2025-07-19T19:57:23.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.1.delta.dc500786-5c6c-45a7-9bc0-57f2720bc7b9.TID570.tmp
[2025-07-19T19:57:23.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 107.0 in stage 1.0 (TID 564). 6200 bytes result sent to driver
[2025-07-19T19:57:23.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 132.0 in stage 1.0 (TID 573) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 132.0 in stage 1.0 (TID 573)
[2025-07-19T19:57:23.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 107.0 in stage 1.0 (TID 564) in 85 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T19:57:23.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 115 (task 566, attempt 0, stage 1.0)
[2025-07-19T19:57:23.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 115.0 in stage 1.0 (TID 566). 6200 bytes result sent to driver
[2025-07-19T19:57:23.959+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 133.0 in stage 1.0 (TID 574) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@574265ea
[2025-07-19T19:57:23.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129] for update
[2025-07-19T19:57:23.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 133.0 in stage 1.0 (TID 574)
[2025-07-19T19:57:23.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 115.0 in stage 1.0 (TID 566) in 59 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T19:57:23.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.1.delta.57869a52-1449-4b10-8bfb-d2c0b99f74f3.TID567.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/1.delta
[2025-07-19T19:57:23.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.1.delta.c3b9ae1c-ed42-4cb8-9850-2a1ff71fb4bb.TID571.tmp
[2025-07-19T19:57:23.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/1.delta
[2025-07-19T19:57:23.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 567, attempt 0, stage 1.0)
[2025-07-19T19:57:23.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35a8e73
[2025-07-19T19:57:23.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.1.delta.5a7d6e94-a63f-421a-ab11-2e277f033c6e.TID572.tmp
[2025-07-19T19:57:23.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132] for update
[2025-07-19T19:57:23.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T19:57:23.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 120 (task 567, attempt 0, stage 1.0)
[2025-07-19T19:57:23.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 120.0 in stage 1.0 (TID 567). 6200 bytes result sent to driver
[2025-07-19T19:57:23.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 120.0 in stage 1.0 (TID 567) in 65 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T19:57:23.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 138.0 in stage 1.0 (TID 575) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 138.0 in stage 1.0 (TID 575)
[2025-07-19T19:57:23.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.1.delta.c9ab4d0c-2988-43c3-b02f-f2e9086586f9.TID568.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/1.delta
[2025-07-19T19:57:23.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/1.delta
[2025-07-19T19:57:23.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 568, attempt 0, stage 1.0)
[2025-07-19T19:57:23.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55accf80
[2025-07-19T19:57:23.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133] for update
[2025-07-19T19:57:23.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 121 (task 568, attempt 0, stage 1.0)
[2025-07-19T19:57:23.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 121.0 in stage 1.0 (TID 568). 6200 bytes result sent to driver
[2025-07-19T19:57:23.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 139.0 in stage 1.0 (TID 576) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 121.0 in stage 1.0 (TID 568) in 68 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T19:57:23.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 139.0 in stage 1.0 (TID 576)
[2025-07-19T19:57:23.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.1.delta.6b8e9b32-1e74-4e55-a873-c0a95a876a2c.TID573.tmp
[2025-07-19T19:57:23.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.1.delta.e7d13707-e1f0-42b3-a062-b23646ec0211.TID569.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/1.delta
[2025-07-19T19:57:23.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/1.delta
[2025-07-19T19:57:23.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 569, attempt 0, stage 1.0)
[2025-07-19T19:57:23.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c028070
[2025-07-19T19:57:23.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138] for update
[2025-07-19T19:57:23.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 122 (task 569, attempt 0, stage 1.0)
[2025-07-19T19:57:23.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 122.0 in stage 1.0 (TID 569). 6243 bytes result sent to driver
[2025-07-19T19:57:23.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 141.0 in stage 1.0 (TID 577) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:23.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 141.0 in stage 1.0 (TID 577)
[2025-07-19T19:57:23.994+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 122.0 in stage 1.0 (TID 569) in 73 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T19:57:23.994+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:23.994+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:23.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:23.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.1.delta.c3b9ae1c-ed42-4cb8-9850-2a1ff71fb4bb.TID571.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/1.delta
[2025-07-19T19:57:23.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/1.delta
[2025-07-19T19:57:23.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1150898f
[2025-07-19T19:57:23.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 571, attempt 0, stage 1.0)
[2025-07-19T19:57:23.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:23.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.1.delta.942a07d7-0d39-4712-b4b3-06bcc1d0dd51.TID574.tmp
[2025-07-19T19:57:23.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139] for update
[2025-07-19T19:57:24.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO DataWritingSparkTask: Committed partition 128 (task 571, attempt 0, stage 1.0)
[2025-07-19T19:57:24.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Finished task 128.0 in stage 1.0 (TID 571). 6243 bytes result sent to driver
[2025-07-19T19:57:24.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Starting task 143.0 in stage 1.0 (TID 578) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO Executor: Running task 143.0 in stage 1.0 (TID 578)
[2025-07-19T19:57:24.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:23 INFO TaskSetManager: Finished task 128.0 in stage 1.0 (TID 571) in 67 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T19:57:24.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.1.delta.dc500786-5c6c-45a7-9bc0-57f2720bc7b9.TID570.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/1.delta
[2025-07-19T19:57:24.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/1.delta
[2025-07-19T19:57:24.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79e93d19
[2025-07-19T19:57:24.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 570, attempt 0, stage 1.0)
[2025-07-19T19:57:24.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.1.delta.f310eeb1-b00c-462d-89fa-ac224cf04181.TID575.tmp
[2025-07-19T19:57:24.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141] for update
[2025-07-19T19:57:24.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 123 (task 570, attempt 0, stage 1.0)
[2025-07-19T19:57:24.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 123.0 in stage 1.0 (TID 570). 6243 bytes result sent to driver
[2025-07-19T19:57:24.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 146.0 in stage 1.0 (TID 579) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.1.delta.5a7d6e94-a63f-421a-ab11-2e277f033c6e.TID572.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/1.delta
[2025-07-19T19:57:24.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 123.0 in stage 1.0 (TID 570) in 85 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T19:57:24.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/1.delta
[2025-07-19T19:57:24.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 146.0 in stage 1.0 (TID 579)
[2025-07-19T19:57:24.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 572, attempt 0, stage 1.0)
[2025-07-19T19:57:24.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.1.delta.e76cd518-cf72-4524-a20a-8d4586ead0c0.TID576.tmp
[2025-07-19T19:57:24.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@771e863b
[2025-07-19T19:57:24.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.014+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143] for update
[2025-07-19T19:57:24.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 129 (task 572, attempt 0, stage 1.0)
[2025-07-19T19:57:24.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.1.delta.c29b55ac-ff06-439e-babf-e1e32172244e.TID577.tmp
[2025-07-19T19:57:24.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.1.delta.6b8e9b32-1e74-4e55-a873-c0a95a876a2c.TID573.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/1.delta
[2025-07-19T19:57:24.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/1.delta
[2025-07-19T19:57:24.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 129.0 in stage 1.0 (TID 572). 6243 bytes result sent to driver
[2025-07-19T19:57:24.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 150.0 in stage 1.0 (TID 580) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 573, attempt 0, stage 1.0)
[2025-07-19T19:57:24.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 150.0 in stage 1.0 (TID 580)
[2025-07-19T19:57:24.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 129.0 in stage 1.0 (TID 572) in 69 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T19:57:24.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 132 (task 573, attempt 0, stage 1.0)
[2025-07-19T19:57:24.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 132.0 in stage 1.0 (TID 573). 6243 bytes result sent to driver
[2025-07-19T19:57:24.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 154.0 in stage 1.0 (TID 581) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 154.0 in stage 1.0 (TID 581)
[2025-07-19T19:57:24.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 132.0 in stage 1.0 (TID 573) in 67 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T19:57:24.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.1.delta.03b8e095-3e4b-4ad8-adbf-2ce6ba7815b4.TID578.tmp
[2025-07-19T19:57:24.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18cd66b7
[2025-07-19T19:57:24.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146] for update
[2025-07-19T19:57:24.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11ece64e
[2025-07-19T19:57:24.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154] for update
[2025-07-19T19:57:24.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.1.delta.942a07d7-0d39-4712-b4b3-06bcc1d0dd51.TID574.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/1.delta
[2025-07-19T19:57:24.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/1.delta
[2025-07-19T19:57:24.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 574, attempt 0, stage 1.0)
[2025-07-19T19:57:24.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.1.delta.f310eeb1-b00c-462d-89fa-ac224cf04181.TID575.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/1.delta
[2025-07-19T19:57:24.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/1.delta
[2025-07-19T19:57:24.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.1.delta.2a8f98bb-8f72-4550-ba1e-fe50b1328a99.TID579.tmp
[2025-07-19T19:57:24.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3abd621d
[2025-07-19T19:57:24.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 133 (task 574, attempt 0, stage 1.0)
[2025-07-19T19:57:24.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 133.0 in stage 1.0 (TID 574). 6243 bytes result sent to driver
[2025-07-19T19:57:24.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150] for update
[2025-07-19T19:57:24.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 575, attempt 0, stage 1.0)
[2025-07-19T19:57:24.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 158.0 in stage 1.0 (TID 582) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 158.0 in stage 1.0 (TID 582)
[2025-07-19T19:57:24.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.1.delta.4b7b75a8-33af-4e35-969c-046f463117fa.TID581.tmp
[2025-07-19T19:57:24.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 133.0 in stage 1.0 (TID 574) in 87 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T19:57:24.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.052+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 138 (task 575, attempt 0, stage 1.0)
[2025-07-19T19:57:24.052+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 138.0 in stage 1.0 (TID 575). 6243 bytes result sent to driver
[2025-07-19T19:57:24.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.1.delta.e76cd518-cf72-4524-a20a-8d4586ead0c0.TID576.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/1.delta
[2025-07-19T19:57:24.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/1.delta
[2025-07-19T19:57:24.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 576, attempt 0, stage 1.0)
[2025-07-19T19:57:24.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 159.0 in stage 1.0 (TID 583) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 159.0 in stage 1.0 (TID 583)
[2025-07-19T19:57:24.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 138.0 in stage 1.0 (TID 575) in 80 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T19:57:24.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.1.delta.c29b55ac-ff06-439e-babf-e1e32172244e.TID577.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/1.delta
[2025-07-19T19:57:24.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/1.delta
[2025-07-19T19:57:24.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 577, attempt 0, stage 1.0)
[2025-07-19T19:57:24.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.1.delta.03b8e095-3e4b-4ad8-adbf-2ce6ba7815b4.TID578.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/1.delta
[2025-07-19T19:57:24.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/1.delta
[2025-07-19T19:57:24.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 578, attempt 0, stage 1.0)
[2025-07-19T19:57:24.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a7e3418
[2025-07-19T19:57:24.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158] for update
[2025-07-19T19:57:24.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.1.delta.669a0a71-86ce-467f-9f63-8d380ce75557.TID580.tmp
[2025-07-19T19:57:24.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 141 (task 577, attempt 0, stage 1.0)
[2025-07-19T19:57:24.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 141.0 in stage 1.0 (TID 577). 6200 bytes result sent to driver
[2025-07-19T19:57:24.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 139 (task 576, attempt 0, stage 1.0)
[2025-07-19T19:57:24.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 143 (task 578, attempt 0, stage 1.0)
[2025-07-19T19:57:24.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 139.0 in stage 1.0 (TID 576). 6243 bytes result sent to driver
[2025-07-19T19:57:24.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 161.0 in stage 1.0 (TID 584) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 163.0 in stage 1.0 (TID 585) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 139.0 in stage 1.0 (TID 576) in 82 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T19:57:24.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b717305
[2025-07-19T19:57:24.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159] for update
[2025-07-19T19:57:24.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 143.0 in stage 1.0 (TID 578). 6200 bytes result sent to driver
[2025-07-19T19:57:24.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 161.0 in stage 1.0 (TID 584)
[2025-07-19T19:57:24.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 163.0 in stage 1.0 (TID 585)
[2025-07-19T19:57:24.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 164.0 in stage 1.0 (TID 586) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 143.0 in stage 1.0 (TID 578) in 64 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T19:57:24.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 164.0 in stage 1.0 (TID 586)
[2025-07-19T19:57:24.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 141.0 in stage 1.0 (TID 577) in 74 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T19:57:24.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.1.delta.96f01b20-5a10-4201-b421-f93b572cbef2.TID583.tmp
[2025-07-19T19:57:24.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.1.delta.cc140820-074a-4cee-a5db-6b3d58db4013.TID582.tmp
[2025-07-19T19:57:24.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ec8b418
[2025-07-19T19:57:24.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161] for update
[2025-07-19T19:57:24.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.1.delta.2a8f98bb-8f72-4550-ba1e-fe50b1328a99.TID579.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/1.delta
[2025-07-19T19:57:24.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/1.delta
[2025-07-19T19:57:24.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 579, attempt 0, stage 1.0)
[2025-07-19T19:57:24.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 146 (task 579, attempt 0, stage 1.0)
[2025-07-19T19:57:24.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3588befd
[2025-07-19T19:57:24.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 146.0 in stage 1.0 (TID 579). 6200 bytes result sent to driver
[2025-07-19T19:57:24.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.1.delta.4b7b75a8-33af-4e35-969c-046f463117fa.TID581.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/1.delta
[2025-07-19T19:57:24.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/1.delta
[2025-07-19T19:57:24.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.1.delta.669a0a71-86ce-467f-9f63-8d380ce75557.TID580.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/1.delta
[2025-07-19T19:57:24.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/1.delta
[2025-07-19T19:57:24.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163] for update
[2025-07-19T19:57:24.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 580, attempt 0, stage 1.0)
[2025-07-19T19:57:24.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.1.delta.67d6c359-bff4-49b3-9b7b-d4e1a2a37920.TID584.tmp
[2025-07-19T19:57:24.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 581, attempt 0, stage 1.0)
[2025-07-19T19:57:24.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 167.0 in stage 1.0 (TID 587) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 146.0 in stage 1.0 (TID 579) in 75 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T19:57:24.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 167.0 in stage 1.0 (TID 587)
[2025-07-19T19:57:24.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 154 (task 581, attempt 0, stage 1.0)
[2025-07-19T19:57:24.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 154.0 in stage 1.0 (TID 581). 6200 bytes result sent to driver
[2025-07-19T19:57:24.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 168.0 in stage 1.0 (TID 588) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 168.0 in stage 1.0 (TID 588)
[2025-07-19T19:57:24.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 150 (task 580, attempt 0, stage 1.0)
[2025-07-19T19:57:24.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 150.0 in stage 1.0 (TID 580). 6200 bytes result sent to driver
[2025-07-19T19:57:24.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 169.0 in stage 1.0 (TID 589) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 154.0 in stage 1.0 (TID 581) in 69 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T19:57:24.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 169.0 in stage 1.0 (TID 589)
[2025-07-19T19:57:24.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 150.0 in stage 1.0 (TID 580) in 74 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T19:57:24.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T19:57:24.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cd2fee7
[2025-07-19T19:57:24.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.1.delta.96f01b20-5a10-4201-b421-f93b572cbef2.TID583.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/1.delta
[2025-07-19T19:57:24.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164] for update
[2025-07-19T19:57:24.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/1.delta
[2025-07-19T19:57:24.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 583, attempt 0, stage 1.0)
[2025-07-19T19:57:24.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.1.delta.9b5b0656-428f-4315-a71b-a793d17062ed.TID585.tmp
[2025-07-19T19:57:24.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 159 (task 583, attempt 0, stage 1.0)
[2025-07-19T19:57:24.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 159.0 in stage 1.0 (TID 583). 6200 bytes result sent to driver
[2025-07-19T19:57:24.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 170.0 in stage 1.0 (TID 590) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 159.0 in stage 1.0 (TID 583) in 49 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T19:57:24.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 170.0 in stage 1.0 (TID 590)
[2025-07-19T19:57:24.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a97ae35
[2025-07-19T19:57:24.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169] for update
[2025-07-19T19:57:24.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.1.delta.336e71e5-3332-49d6-a1db-1dd7cf5c70d1.TID586.tmp
[2025-07-19T19:57:24.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.1.delta.cc140820-074a-4cee-a5db-6b3d58db4013.TID582.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/1.delta
[2025-07-19T19:57:24.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/1.delta
[2025-07-19T19:57:24.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a20974e
[2025-07-19T19:57:24.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 582, attempt 0, stage 1.0)
[2025-07-19T19:57:24.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167] for update
[2025-07-19T19:57:24.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63b3d906
[2025-07-19T19:57:24.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168] for update
[2025-07-19T19:57:24.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.1.delta.06a58ba3-5bb7-41c1-a3ab-1b35d0b417a0.TID589.tmp
[2025-07-19T19:57:24.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.1.delta.67d6c359-bff4-49b3-9b7b-d4e1a2a37920.TID584.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/1.delta
[2025-07-19T19:57:24.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/1.delta
[2025-07-19T19:57:24.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 584, attempt 0, stage 1.0)
[2025-07-19T19:57:24.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 158 (task 582, attempt 0, stage 1.0)
[2025-07-19T19:57:24.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 158.0 in stage 1.0 (TID 582). 6243 bytes result sent to driver
[2025-07-19T19:57:24.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d91a120
[2025-07-19T19:57:24.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 161 (task 584, attempt 0, stage 1.0)
[2025-07-19T19:57:24.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170] for update
[2025-07-19T19:57:24.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 171.0 in stage 1.0 (TID 591) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 171.0 in stage 1.0 (TID 591)
[2025-07-19T19:57:24.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 161.0 in stage 1.0 (TID 584). 6243 bytes result sent to driver
[2025-07-19T19:57:24.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 172.0 in stage 1.0 (TID 592) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 161.0 in stage 1.0 (TID 584) in 71 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T19:57:24.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 172.0 in stage 1.0 (TID 592)
[2025-07-19T19:57:24.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 158.0 in stage 1.0 (TID 582) in 86 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T19:57:24.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.1.delta.21e039a7-7958-4f07-ac79-6492f0e0db42.TID587.tmp
[2025-07-19T19:57:24.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.1.delta.cc00ea23-b572-4e1a-9ee1-be00b22550e4.TID588.tmp
[2025-07-19T19:57:24.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10061464
[2025-07-19T19:57:24.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171] for update
[2025-07-19T19:57:24.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.1.delta.9b5b0656-428f-4315-a71b-a793d17062ed.TID585.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/1.delta
[2025-07-19T19:57:24.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/1.delta
[2025-07-19T19:57:24.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 585, attempt 0, stage 1.0)
[2025-07-19T19:57:24.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18fd4d35
[2025-07-19T19:57:24.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172] for update
[2025-07-19T19:57:24.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.1.delta.1d87f871-3d7e-4cd0-9e6c-de5cbfa8766b.TID590.tmp
[2025-07-19T19:57:24.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 163 (task 585, attempt 0, stage 1.0)
[2025-07-19T19:57:24.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 163.0 in stage 1.0 (TID 585). 6243 bytes result sent to driver
[2025-07-19T19:57:24.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 173.0 in stage 1.0 (TID 593) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 173.0 in stage 1.0 (TID 593)
[2025-07-19T19:57:24.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 163.0 in stage 1.0 (TID 585) in 90 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T19:57:24.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39f4adfa
[2025-07-19T19:57:24.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173] for update
[2025-07-19T19:57:24.156+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.1.delta.336e71e5-3332-49d6-a1db-1dd7cf5c70d1.TID586.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/1.delta
[2025-07-19T19:57:24.158+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/1.delta
[2025-07-19T19:57:24.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.1.delta.8c1dd42f-174f-4669-8c12-5188046d33e2.TID591.tmp
[2025-07-19T19:57:24.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 586, attempt 0, stage 1.0)
[2025-07-19T19:57:24.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 164 (task 586, attempt 0, stage 1.0)
[2025-07-19T19:57:24.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 164.0 in stage 1.0 (TID 586). 6243 bytes result sent to driver
[2025-07-19T19:57:24.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.1.delta.516792de-4e26-4621-84f7-820dd92cbd97.TID592.tmp
[2025-07-19T19:57:24.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 177.0 in stage 1.0 (TID 594) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 164.0 in stage 1.0 (TID 586) in 98 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T19:57:24.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 177.0 in stage 1.0 (TID 594)
[2025-07-19T19:57:24.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.1.delta.bfab11af-0a0a-4e43-b9d8-2b54c5b735ce.TID593.tmp
[2025-07-19T19:57:24.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28412976
[2025-07-19T19:57:24.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.1.delta.21e039a7-7958-4f07-ac79-6492f0e0db42.TID587.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/1.delta
[2025-07-19T19:57:24.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177] for update
[2025-07-19T19:57:24.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/1.delta
[2025-07-19T19:57:24.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 587, attempt 0, stage 1.0)
[2025-07-19T19:57:24.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 167 (task 587, attempt 0, stage 1.0)
[2025-07-19T19:57:24.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 167.0 in stage 1.0 (TID 587). 6243 bytes result sent to driver
[2025-07-19T19:57:24.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 180.0 in stage 1.0 (TID 595) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.1.delta.4ab861b2-40c1-46b6-83ce-d89a61b50402.TID594.tmp
[2025-07-19T19:57:24.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.1.delta.06a58ba3-5bb7-41c1-a3ab-1b35d0b417a0.TID589.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/1.delta
[2025-07-19T19:57:24.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/1.delta
[2025-07-19T19:57:24.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 167.0 in stage 1.0 (TID 587) in 100 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T19:57:24.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 180.0 in stage 1.0 (TID 595)
[2025-07-19T19:57:24.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 589, attempt 0, stage 1.0)
[2025-07-19T19:57:24.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.187+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.187+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 169 (task 589, attempt 0, stage 1.0)
[2025-07-19T19:57:24.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 169.0 in stage 1.0 (TID 589). 6243 bytes result sent to driver
[2025-07-19T19:57:24.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 181.0 in stage 1.0 (TID 596) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 181.0 in stage 1.0 (TID 596)
[2025-07-19T19:57:24.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 169.0 in stage 1.0 (TID 589) in 100 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T19:57:24.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:24.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5818bbfc
[2025-07-19T19:57:24.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180] for update
[2025-07-19T19:57:24.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.1.delta.cc00ea23-b572-4e1a-9ee1-be00b22550e4.TID588.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/1.delta
[2025-07-19T19:57:24.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/1.delta
[2025-07-19T19:57:24.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 588, attempt 0, stage 1.0)
[2025-07-19T19:57:24.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 168 (task 588, attempt 0, stage 1.0)
[2025-07-19T19:57:24.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 168.0 in stage 1.0 (TID 588). 6243 bytes result sent to driver
[2025-07-19T19:57:24.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 186.0 in stage 1.0 (TID 597) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 168.0 in stage 1.0 (TID 588) in 115 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T19:57:24.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 186.0 in stage 1.0 (TID 597)
[2025-07-19T19:57:24.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eede41a
[2025-07-19T19:57:24.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181] for update
[2025-07-19T19:57:24.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.1.delta.16607fd7-267a-4f1a-9b28-0d45a4877f91.TID595.tmp
[2025-07-19T19:57:24.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.1.delta.8c1dd42f-174f-4669-8c12-5188046d33e2.TID591.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/1.delta
[2025-07-19T19:57:24.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/1.delta
[2025-07-19T19:57:24.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 591, attempt 0, stage 1.0)
[2025-07-19T19:57:24.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b157627
[2025-07-19T19:57:24.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.1.delta.516792de-4e26-4621-84f7-820dd92cbd97.TID592.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/1.delta
[2025-07-19T19:57:24.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/1.delta
[2025-07-19T19:57:24.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 592, attempt 0, stage 1.0)
[2025-07-19T19:57:24.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186] for update
[2025-07-19T19:57:24.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.1.delta.1d87f871-3d7e-4cd0-9e6c-de5cbfa8766b.TID590.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/1.delta
[2025-07-19T19:57:24.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/1.delta
[2025-07-19T19:57:24.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 171 (task 591, attempt 0, stage 1.0)
[2025-07-19T19:57:24.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 172 (task 592, attempt 0, stage 1.0)
[2025-07-19T19:57:24.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 590, attempt 0, stage 1.0)
[2025-07-19T19:57:24.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 172.0 in stage 1.0 (TID 592). 6200 bytes result sent to driver
[2025-07-19T19:57:24.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 189.0 in stage 1.0 (TID 598) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 189.0 in stage 1.0 (TID 598)
[2025-07-19T19:57:24.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 172.0 in stage 1.0 (TID 592) in 85 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T19:57:24.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 171.0 in stage 1.0 (TID 591). 6200 bytes result sent to driver
[2025-07-19T19:57:24.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 190.0 in stage 1.0 (TID 599) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 171.0 in stage 1.0 (TID 591) in 89 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T19:57:24.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 190.0 in stage 1.0 (TID 599)
[2025-07-19T19:57:24.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 170 (task 590, attempt 0, stage 1.0)
[2025-07-19T19:57:24.230+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 170.0 in stage 1.0 (TID 590). 6243 bytes result sent to driver
[2025-07-19T19:57:24.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.1.delta.b4388aed-18b6-49d2-9ac4-07cb6307acf7.TID596.tmp
[2025-07-19T19:57:24.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 192.0 in stage 1.0 (TID 600) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 192.0 in stage 1.0 (TID 600)
[2025-07-19T19:57:24.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 170.0 in stage 1.0 (TID 590) in 124 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T19:57:24.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39c14dd5
[2025-07-19T19:57:24.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189] for update
[2025-07-19T19:57:24.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.1.delta.bfab11af-0a0a-4e43-b9d8-2b54c5b735ce.TID593.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/1.delta
[2025-07-19T19:57:24.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/1.delta
[2025-07-19T19:57:24.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 593, attempt 0, stage 1.0)
[2025-07-19T19:57:24.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.1.delta.96b58e36-2234-402d-9a02-28bc4c527ff2.TID597.tmp
[2025-07-19T19:57:24.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 173 (task 593, attempt 0, stage 1.0)
[2025-07-19T19:57:24.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@244d1a18
[2025-07-19T19:57:24.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192] for update
[2025-07-19T19:57:24.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 173.0 in stage 1.0 (TID 593). 6200 bytes result sent to driver
[2025-07-19T19:57:24.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 193.0 in stage 1.0 (TID 601) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 193.0 in stage 1.0 (TID 601)
[2025-07-19T19:57:24.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 173.0 in stage 1.0 (TID 593) in 87 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T19:57:24.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.1.delta.4ab861b2-40c1-46b6-83ce-d89a61b50402.TID594.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/1.delta
[2025-07-19T19:57:24.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/1.delta
[2025-07-19T19:57:24.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 594, attempt 0, stage 1.0)
[2025-07-19T19:57:24.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7059aceb
[2025-07-19T19:57:24.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.1.delta.f6ae498d-9402-4506-9c66-17aac2fa47cc.TID598.tmp
[2025-07-19T19:57:24.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190] for update
[2025-07-19T19:57:24.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 177 (task 594, attempt 0, stage 1.0)
[2025-07-19T19:57:24.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.1.delta.16607fd7-267a-4f1a-9b28-0d45a4877f91.TID595.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/1.delta
[2025-07-19T19:57:24.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/1.delta
[2025-07-19T19:57:24.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 177.0 in stage 1.0 (TID 594). 6200 bytes result sent to driver
[2025-07-19T19:57:24.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 595, attempt 0, stage 1.0)
[2025-07-19T19:57:24.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 195.0 in stage 1.0 (TID 602) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 177.0 in stage 1.0 (TID 594) in 87 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T19:57:24.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.1.delta.94b07ac8-6249-41b6-8f6e-d09eb406779c.TID600.tmp
[2025-07-19T19:57:24.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 195.0 in stage 1.0 (TID 602)
[2025-07-19T19:57:24.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2635fc1
[2025-07-19T19:57:24.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193] for update
[2025-07-19T19:57:24.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 180 (task 595, attempt 0, stage 1.0)
[2025-07-19T19:57:24.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 180.0 in stage 1.0 (TID 595). 6200 bytes result sent to driver
[2025-07-19T19:57:24.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 603) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 0.0 in stage 7.0 (TID 603)
[2025-07-19T19:57:24.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 180.0 in stage 1.0 (TID 595) in 75 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T19:57:24.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.1.delta.031b10d4-93cd-4ad0-bfd7-e411dd7a84ba.TID599.tmp
[2025-07-19T19:57:24.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6744ce13
[2025-07-19T19:57:24.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:24.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195] for update
[2025-07-19T19:57:24.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.1.delta.a79ddc26-c56c-435f-9a6d-b03302c71461.TID601.tmp
[2025-07-19T19:57:24.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.1.delta.b4388aed-18b6-49d2-9ac4-07cb6307acf7.TID596.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/1.delta
[2025-07-19T19:57:24.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/1.delta
[2025-07-19T19:57:24.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58ba02f0
[2025-07-19T19:57:24.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0] for update
[2025-07-19T19:57:24.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 596, attempt 0, stage 1.0)
[2025-07-19T19:57:24.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 181 (task 596, attempt 0, stage 1.0)
[2025-07-19T19:57:24.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 181.0 in stage 1.0 (TID 596). 6243 bytes result sent to driver
[2025-07-19T19:57:24.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.1.delta.96b58e36-2234-402d-9a02-28bc4c527ff2.TID597.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/1.delta
[2025-07-19T19:57:24.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/1.delta
[2025-07-19T19:57:24.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 604) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 181.0 in stage 1.0 (TID 596) in 93 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T19:57:24.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 597, attempt 0, stage 1.0)
[2025-07-19T19:57:24.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 1.0 in stage 7.0 (TID 604)
[2025-07-19T19:57:24.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.1.delta.f6ae498d-9402-4506-9c66-17aac2fa47cc.TID598.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/1.delta
[2025-07-19T19:57:24.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/1.delta
[2025-07-19T19:57:24.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 186 (task 597, attempt 0, stage 1.0)
[2025-07-19T19:57:24.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 186.0 in stage 1.0 (TID 597). 6243 bytes result sent to driver
[2025-07-19T19:57:24.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.1.delta.393787f5-b170-40fb-aad0-8caacc1151d6.TID602.tmp
[2025-07-19T19:57:24.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 598, attempt 0, stage 1.0)
[2025-07-19T19:57:24.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.1.delta.94b07ac8-6249-41b6-8f6e-d09eb406779c.TID600.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/1.delta
[2025-07-19T19:57:24.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@433d05ec
[2025-07-19T19:57:24.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 605) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1] for update
[2025-07-19T19:57:24.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/1.delta
[2025-07-19T19:57:24.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 189 (task 598, attempt 0, stage 1.0)
[2025-07-19T19:57:24.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 186.0 in stage 1.0 (TID 597) in 91 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T19:57:24.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 189.0 in stage 1.0 (TID 598). 6243 bytes result sent to driver
[2025-07-19T19:57:24.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 2.0 in stage 7.0 (TID 605)
[2025-07-19T19:57:24.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodeGenerator: Code generated in 24.868625 ms
[2025-07-19T19:57:24.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 600, attempt 0, stage 1.0)
[2025-07-19T19:57:24.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 606) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 189.0 in stage 1.0 (TID 598) in 82 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T19:57:24.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 3.0 in stage 7.0 (TID 606)
[2025-07-19T19:57:24.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@792d52a4
[2025-07-19T19:57:24.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2] for update
[2025-07-19T19:57:24.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 192 (task 600, attempt 0, stage 1.0)
[2025-07-19T19:57:24.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@696df376
[2025-07-19T19:57:24.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 192.0 in stage 1.0 (TID 600). 6243 bytes result sent to driver
[2025-07-19T19:57:24.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 607) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 4.0 in stage 7.0 (TID 607)
[2025-07-19T19:57:24.330+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 192.0 in stage 1.0 (TID 600) in 80 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T19:57:24.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3] for update
[2025-07-19T19:57:24.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ca43ae5
[2025-07-19T19:57:24.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4] for update
[2025-07-19T19:57:24.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.1.delta.a79ddc26-c56c-435f-9a6d-b03302c71461.TID601.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/1.delta
[2025-07-19T19:57:24.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/1.delta
[2025-07-19T19:57:24.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 601, attempt 0, stage 1.0)
[2025-07-19T19:57:24.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 193 (task 601, attempt 0, stage 1.0)
[2025-07-19T19:57:24.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 193.0 in stage 1.0 (TID 601). 6243 bytes result sent to driver
[2025-07-19T19:57:24.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 608) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 5.0 in stage 7.0 (TID 608)
[2025-07-19T19:57:24.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.1.delta.031b10d4-93cd-4ad0-bfd7-e411dd7a84ba.TID599.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/1.delta
[2025-07-19T19:57:24.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/1.delta
[2025-07-19T19:57:24.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.2.delta.25fd19c3-0057-4950-b50d-cfd751278928.TID604.tmp
[2025-07-19T19:57:24.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 193.0 in stage 1.0 (TID 601) in 89 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T19:57:24.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.2.delta.59c3472c-1bd1-47e4-bc19-65628046530a.TID603.tmp
[2025-07-19T19:57:24.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 599, attempt 0, stage 1.0)
[2025-07-19T19:57:24.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58244a09
[2025-07-19T19:57:24.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.362+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5] for update
[2025-07-19T19:57:24.362+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 190 (task 599, attempt 0, stage 1.0)
[2025-07-19T19:57:24.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 190.0 in stage 1.0 (TID 599). 6243 bytes result sent to driver
[2025-07-19T19:57:24.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 609) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 190.0 in stage 1.0 (TID 599) in 136 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T19:57:24.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 6.0 in stage 7.0 (TID 609)
[2025-07-19T19:57:24.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.2.delta.cbd11a8a-0fb8-4321-b9d5-a81a703d0e24.TID607.tmp
[2025-07-19T19:57:24.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.2.delta.ad35d1db-4d0d-4434-8156-53c644c680db.TID605.tmp
[2025-07-19T19:57:24.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.2.delta.2952d361-278d-4484-abd3-d5308b19a397.TID606.tmp
[2025-07-19T19:57:24.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4dcb736b
[2025-07-19T19:57:24.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.2.delta.45f7ad39-a1f3-4a98-99e1-bc8e2ab400e7.TID608.tmp
[2025-07-19T19:57:24.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6] for update
[2025-07-19T19:57:24.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.1.delta.393787f5-b170-40fb-aad0-8caacc1151d6.TID602.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/1.delta
[2025-07-19T19:57:24.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/1.delta
[2025-07-19T19:57:24.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 602, attempt 0, stage 1.0)
[2025-07-19T19:57:24.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.2.delta.59c3472c-1bd1-47e4-bc19-65628046530a.TID603.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/2.delta
[2025-07-19T19:57:24.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/0/2.delta
[2025-07-19T19:57:24.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T19:57:24.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 195 (task 602, attempt 0, stage 1.0)
[2025-07-19T19:57:24.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 195.0 in stage 1.0 (TID 602). 6243 bytes result sent to driver
[2025-07-19T19:57:24.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 610) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.2.delta.10a839be-b4a9-466c-a7d2-f0475448a3b8.TID609.tmp
[2025-07-19T19:57:24.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 7.0 in stage 7.0 (TID 610)
[2025-07-19T19:57:24.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T19:57:24.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 195.0 in stage 1.0 (TID 602) in 135 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T19:57:24.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-19T19:57:24.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 0.0 in stage 7.0 (TID 603). 5872 bytes result sent to driver
[2025-07-19T19:57:24.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 611) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: ResultStage 1 (start at <unknown>:0) finished in 9.449 s
[2025-07-19T19:57:24.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 603) in 129 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T19:57:24.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T19:57:24.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-07-19T19:57:24.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 8.0 in stage 7.0 (TID 611)
[2025-07-19T19:57:24.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.2.delta.25fd19c3-0057-4950-b50d-cfd751278928.TID604.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/2.delta
[2025-07-19T19:57:24.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/1/2.delta
[2025-07-19T19:57:24.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: Job 2 finished: start at <unknown>:0, took 10.742822 s
[2025-07-19T19:57:24.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T19:57:24.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T19:57:24.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.2.delta.cbd11a8a-0fb8-4321-b9d5-a81a703d0e24.TID607.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/2.delta
[2025-07-19T19:57:24.391+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/4/2.delta
[2025-07-19T19:57:24.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T19:57:24.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Committing epoch 0 for query 609fc205-5186-4889-9ac4-e96d359c0199 in append mode
[2025-07-19T19:57:24.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.2.delta.2952d361-278d-4484-abd3-d5308b19a397.TID606.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/2.delta
[2025-07-19T19:57:24.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/3/2.delta
[2025-07-19T19:57:24.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T19:57:24.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 1.0 in stage 7.0 (TID 604). 5829 bytes result sent to driver
[2025-07-19T19:57:24.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7638b388
[2025-07-19T19:57:24.398+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T19:57:24.398+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T19:57:24.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 4.0 in stage 7.0 (TID 607). 5829 bytes result sent to driver
[2025-07-19T19:57:24.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 612) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 613) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 9.0 in stage 7.0 (TID 612)
[2025-07-19T19:57:24.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 607) in 95 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T19:57:24.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 604) in 116 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T19:57:24.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8] for update
[2025-07-19T19:57:24.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73c13382
[2025-07-19T19:57:24.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.2.delta.ad35d1db-4d0d-4434-8156-53c644c680db.TID605.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/2.delta
[2025-07-19T19:57:24.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/2/2.delta
[2025-07-19T19:57:24.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T19:57:24.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T19:57:24.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 3.0 in stage 7.0 (TID 606). 5829 bytes result sent to driver
[2025-07-19T19:57:24.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9] for update
[2025-07-19T19:57:24.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 614) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 11.0 in stage 7.0 (TID 614)
[2025-07-19T19:57:24.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.2.delta.45f7ad39-a1f3-4a98-99e1-bc8e2ab400e7.TID608.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/2.delta
[2025-07-19T19:57:24.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/5/2.delta
[2025-07-19T19:57:24.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 606) in 106 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T19:57:24.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 10.0 in stage 7.0 (TID 613)
[2025-07-19T19:57:24.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T19:57:24.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T19:57:24.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.2.delta.b33aaf00-49c7-4244-bcd0-f7e3b857c385.TID612.tmp
[2025-07-19T19:57:24.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 2.0 in stage 7.0 (TID 605). 5829 bytes result sent to driver
[2025-07-19T19:57:24.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1997e6b3
[2025-07-19T19:57:24.411+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.2.delta.10a839be-b4a9-466c-a7d2-f0475448a3b8.TID609.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/2.delta
[2025-07-19T19:57:24.411+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/6/2.delta
[2025-07-19T19:57:24.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7] for update
[2025-07-19T19:57:24.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T19:57:24.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 615) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T19:57:24.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 605) in 118 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T19:57:24.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 5.0 in stage 7.0 (TID 608). 5829 bytes result sent to driver
[2025-07-19T19:57:24.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 616) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 12.0 in stage 7.0 (TID 615)
[2025-07-19T19:57:24.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 608) in 91 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T19:57:24.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 13.0 in stage 7.0 (TID 616)
[2025-07-19T19:57:24.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e6188ea
[2025-07-19T19:57:24.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10] for update
[2025-07-19T19:57:24.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T19:57:24.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 6.0 in stage 7.0 (TID 609). 5829 bytes result sent to driver
[2025-07-19T19:57:24.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d5c92eb
[2025-07-19T19:57:24.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Committing streaming append with 118 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 617) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12] for update
[2025-07-19T19:57:24.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40f5b68e
[2025-07-19T19:57:24.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11] for update
[2025-07-19T19:57:24.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 609) in 80 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T19:57:24.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fc3fc6b
[2025-07-19T19:57:24.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 14.0 in stage 7.0 (TID 617)
[2025-07-19T19:57:24.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13] for update
[2025-07-19T19:57:24.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.2.delta.59e6c0fa-90c8-448a-b13d-000640032b72.TID611.tmp
[2025-07-19T19:57:24.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.2.delta.27eaee73-dff1-4bda-a343-5a5cd773daf2.TID610.tmp
[2025-07-19T19:57:24.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:24.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@440f713d
[2025-07-19T19:57:24.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14] for update
[2025-07-19T19:57:24.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.2.delta.3567c38e-b8ca-4fd0-b0a7-6367aac184a9.TID613.tmp
[2025-07-19T19:57:24.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.2.delta.84797733-9749-454b-8c0f-a19f09070e44.TID615.tmp
[2025-07-19T19:57:24.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.2.delta.344b8062-6d65-42f4-91ec-ebcdf0904edb.TID617.tmp
[2025-07-19T19:57:24.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.2.delta.7b8f5d01-0dae-450f-b824-867a47ae83a5.TID614.tmp
[2025-07-19T19:57:24.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.2.delta.3c837651-1e78-47d9-870d-4e2f957b2a5c.TID616.tmp
[2025-07-19T19:57:24.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.2.delta.b33aaf00-49c7-4244-bcd0-f7e3b857c385.TID612.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/2.delta
[2025-07-19T19:57:24.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/9/2.delta
[2025-07-19T19:57:24.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T19:57:24.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T19:57:24.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 9.0 in stage 7.0 (TID 612). 5872 bytes result sent to driver
[2025-07-19T19:57:24.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 618) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 15.0 in stage 7.0 (TID 618)
[2025-07-19T19:57:24.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.2.delta.59e6c0fa-90c8-448a-b13d-000640032b72.TID611.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/2.delta
[2025-07-19T19:57:24.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 612) in 67 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T19:57:24.464+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/8/2.delta
[2025-07-19T19:57:24.466+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dded9e6
[2025-07-19T19:57:24.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T19:57:24.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15] for update
[2025-07-19T19:57:24.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T19:57:24.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 8.0 in stage 7.0 (TID 611). 5872 bytes result sent to driver
[2025-07-19T19:57:24.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.2.delta.27eaee73-dff1-4bda-a343-5a5cd773daf2.TID610.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/2.delta
[2025-07-19T19:57:24.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/7/2.delta
[2025-07-19T19:57:24.476+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.2.delta.3567c38e-b8ca-4fd0-b0a7-6367aac184a9.TID613.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/2.delta
[2025-07-19T19:57:24.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/10/2.delta
[2025-07-19T19:57:24.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 619) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T19:57:24.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T19:57:24.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 16.0 in stage 7.0 (TID 619)
[2025-07-19T19:57:24.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 611) in 94 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T19:57:24.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T19:57:24.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 10.0 in stage 7.0 (TID 613). 5829 bytes result sent to driver
[2025-07-19T19:57:24.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T19:57:24.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 7.0 in stage 7.0 (TID 610). 5872 bytes result sent to driver
[2025-07-19T19:57:24.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:24.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.2.delta.95936908-a1fd-4a88-84d4-ad662e8ecda1.TID618.tmp
[2025-07-19T19:57:24.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.2.delta.7b8f5d01-0dae-450f-b824-867a47ae83a5.TID614.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/2.delta
[2025-07-19T19:57:24.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/11/2.delta
[2025-07-19T19:57:24.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.2.delta.344b8062-6d65-42f4-91ec-ebcdf0904edb.TID617.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/2.delta
[2025-07-19T19:57:24.490+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/14/2.delta
[2025-07-19T19:57:24.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 620) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10bf0a6d
[2025-07-19T19:57:24.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T19:57:24.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T19:57:24.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 610) in 111 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T19:57:24.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16] for update
[2025-07-19T19:57:24.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.2.delta.3c837651-1e78-47d9-870d-4e2f957b2a5c.TID616.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/2.delta
[2025-07-19T19:57:24.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 17.0 in stage 7.0 (TID 620)
[2025-07-19T19:57:24.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/13/2.delta
[2025-07-19T19:57:24.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T19:57:24.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T19:57:24.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 14.0 in stage 7.0 (TID 617). 5872 bytes result sent to driver
[2025-07-19T19:57:24.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.2.delta.84797733-9749-454b-8c0f-a19f09070e44.TID615.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/2.delta
[2025-07-19T19:57:24.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/12/2.delta
[2025-07-19T19:57:24.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T19:57:24.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 11.0 in stage 7.0 (TID 614). 5872 bytes result sent to driver
[2025-07-19T19:57:24.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T19:57:24.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71f6e7e5
[2025-07-19T19:57:24.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 621) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17] for update
[2025-07-19T19:57:24.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 18.0 in stage 7.0 (TID 621)
[2025-07-19T19:57:24.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 13.0 in stage 7.0 (TID 616). 5872 bytes result sent to driver
[2025-07-19T19:57:24.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 622) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 19.0 in stage 7.0 (TID 622)
[2025-07-19T19:57:24.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 617) in 88 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T19:57:24.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 613) in 107 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T19:57:24.513+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T19:57:24.513+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 623) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.514+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 614) in 105 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T19:57:24.514+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 20.0 in stage 7.0 (TID 623)
[2025-07-19T19:57:24.516+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 616) in 96 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T19:57:24.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 624) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 21.0 in stage 7.0 (TID 624)
[2025-07-19T19:57:24.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:24.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T19:57:24.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 12.0 in stage 7.0 (TID 615). 5872 bytes result sent to driver
[2025-07-19T19:57:24.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.2.delta.8d1d5fc8-b704-4fb0-93bc-ef84a36ead4f.TID619.tmp
[2025-07-19T19:57:24.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 625) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 615) in 107 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T19:57:24.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65fafbcd
[2025-07-19T19:57:24.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 22.0 in stage 7.0 (TID 625)
[2025-07-19T19:57:24.526+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.526+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19] for update
[2025-07-19T19:57:24.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f63b3f2
[2025-07-19T19:57:24.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21] for update
[2025-07-19T19:57:24.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cef1723
[2025-07-19T19:57:24.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.2.delta.5e0695b2-7d16-493b-9342-ee17fd2a5e69.TID620.tmp
[2025-07-19T19:57:24.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.2.delta.95936908-a1fd-4a88-84d4-ad662e8ecda1.TID618.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/2.delta
[2025-07-19T19:57:24.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/15/2.delta
[2025-07-19T19:57:24.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20] for update
[2025-07-19T19:57:24.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.2.delta.f268264a-a17e-4903-9ddc-a50a2b2e029f.TID624.tmp
[2025-07-19T19:57:24.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T19:57:24.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T19:57:24.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 15.0 in stage 7.0 (TID 618). 5829 bytes result sent to driver
[2025-07-19T19:57:24.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 626) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17d344e8
[2025-07-19T19:57:24.532+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 23.0 in stage 7.0 (TID 626)
[2025-07-19T19:57:24.532+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.532+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18] for update
[2025-07-19T19:57:24.532+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 618) in 74 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T19:57:24.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43d1d268
[2025-07-19T19:57:24.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22] for update
[2025-07-19T19:57:24.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d01f92c
[2025-07-19T19:57:24.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23] for update
[2025-07-19T19:57:24.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.2.delta.668f63cb-5e8e-4a95-8c08-9965b98e8c36.TID622.tmp
[2025-07-19T19:57:24.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.2.delta.521f8df6-077b-4ef9-8de7-28c238a46709.TID623.tmp
[2025-07-19T19:57:24.547+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.2.delta.9764d8f9-2658-4f0c-96c5-618814caaf37.TID626.tmp
[2025-07-19T19:57:24.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.2.delta.be1982b0-99be-4860-9a17-b5f579a8f951.TID625.tmp
[2025-07-19T19:57:24.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.2.delta.8d1d5fc8-b704-4fb0-93bc-ef84a36ead4f.TID619.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/2.delta
[2025-07-19T19:57:24.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/16/2.delta
[2025-07-19T19:57:24.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.2.delta.41dc7d77-e28a-488d-9a7f-7d021ac3f522.TID621.tmp
[2025-07-19T19:57:24.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T19:57:24.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.2.delta.f268264a-a17e-4903-9ddc-a50a2b2e029f.TID624.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/2.delta
[2025-07-19T19:57:24.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/21/2.delta
[2025-07-19T19:57:24.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T19:57:24.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T19:57:24.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 16.0 in stage 7.0 (TID 619). 5829 bytes result sent to driver
[2025-07-19T19:57:24.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 627) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 24.0 in stage 7.0 (TID 627)
[2025-07-19T19:57:24.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T19:57:24.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 21.0 in stage 7.0 (TID 624). 5829 bytes result sent to driver
[2025-07-19T19:57:24.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 624) in 54 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T19:57:24.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 628) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 25.0 in stage 7.0 (TID 628)
[2025-07-19T19:57:24.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 619) in 88 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T19:57:24.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.2.delta.5e0695b2-7d16-493b-9342-ee17fd2a5e69.TID620.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/2.delta
[2025-07-19T19:57:24.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/17/2.delta
[2025-07-19T19:57:24.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@187bc550
[2025-07-19T19:57:24.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T19:57:24.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24] for update
[2025-07-19T19:57:24.569+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T19:57:24.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 17.0 in stage 7.0 (TID 620). 5829 bytes result sent to driver
[2025-07-19T19:57:24.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 629) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 26.0 in stage 7.0 (TID 629)
[2025-07-19T19:57:24.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 620) in 76 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T19:57:24.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c652756
[2025-07-19T19:57:24.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25] for update
[2025-07-19T19:57:24.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36aba803
[2025-07-19T19:57:24.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26] for update
[2025-07-19T19:57:24.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.2.delta.668f63cb-5e8e-4a95-8c08-9965b98e8c36.TID622.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/2.delta
[2025-07-19T19:57:24.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/19/2.delta
[2025-07-19T19:57:24.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T19:57:24.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T19:57:24.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v88.metadata.json
[2025-07-19T19:57:24.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 19.0 in stage 7.0 (TID 622). 5829 bytes result sent to driver
[2025-07-19T19:57:24.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.2.delta.551efa2e-aa4b-4ce2-95bf-0a93f3a61097.TID627.tmp
[2025-07-19T19:57:24.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 630) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 622) in 78 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T19:57:24.582+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 27.0 in stage 7.0 (TID 630)
[2025-07-19T19:57:24.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.586+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.2.delta.521f8df6-077b-4ef9-8de7-28c238a46709.TID623.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/2.delta
[2025-07-19T19:57:24.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/20/2.delta
[2025-07-19T19:57:24.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.2.delta.be6d523e-9861-46c8-8427-44ba61dfb165.TID628.tmp
[2025-07-19T19:57:24.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a92c65f
[2025-07-19T19:57:24.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.2.delta.c222f49d-6af3-40c6-a1e2-fa4eda088ad3.TID629.tmp
[2025-07-19T19:57:24.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T19:57:24.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27] for update
[2025-07-19T19:57:24.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T19:57:24.600+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 20.0 in stage 7.0 (TID 623). 5915 bytes result sent to driver
[2025-07-19T19:57:24.601+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.2.delta.9764d8f9-2658-4f0c-96c5-618814caaf37.TID626.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/2.delta
[2025-07-19T19:57:24.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.2.delta.be1982b0-99be-4860-9a17-b5f579a8f951.TID625.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/2.delta
[2025-07-19T19:57:24.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/23/2.delta
[2025-07-19T19:57:24.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/22/2.delta
[2025-07-19T19:57:24.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 631) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 28.0 in stage 7.0 (TID 631)
[2025-07-19T19:57:24.606+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 623) in 100 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T19:57:24.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.2.delta.b8a5fbb5-295c-4387-ad36-d9c41fd07f0f.TID630.tmp
[2025-07-19T19:57:24.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.2.delta.41dc7d77-e28a-488d-9a7f-7d021ac3f522.TID621.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/2.delta
[2025-07-19T19:57:24.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/18/2.delta
[2025-07-19T19:57:24.608+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T19:57:24.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T19:57:24.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42987511
[2025-07-19T19:57:24.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T19:57:24.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28] for update
[2025-07-19T19:57:24.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T19:57:24.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 18.0 in stage 7.0 (TID 621). 5872 bytes result sent to driver
[2025-07-19T19:57:24.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 632) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 621) in 118 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T19:57:24.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T19:57:24.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T19:57:24.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 29.0 in stage 7.0 (TID 632)
[2025-07-19T19:57:24.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 22.0 in stage 7.0 (TID 625). 5872 bytes result sent to driver
[2025-07-19T19:57:24.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 23.0 in stage 7.0 (TID 626). 5872 bytes result sent to driver
[2025-07-19T19:57:24.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 633) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 634) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 626) in 85 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T19:57:24.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 31.0 in stage 7.0 (TID 634)
[2025-07-19T19:57:24.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 30.0 in stage 7.0 (TID 633)
[2025-07-19T19:57:24.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 625) in 102 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T19:57:24.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c53bc4d
[2025-07-19T19:57:24.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29] for update
[2025-07-19T19:57:24.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c0afc69
[2025-07-19T19:57:24.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31] for update
[2025-07-19T19:57:24.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62f03b3f
[2025-07-19T19:57:24.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30] for update
[2025-07-19T19:57:24.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SnapshotProducer: Committed snapshot 5492818364931444121 (FastAppend)
[2025-07-19T19:57:24.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.2.delta.3b764e5e-fed2-4b64-90c4-f188bf2faa8d.TID631.tmp
[2025-07-19T19:57:24.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.2.delta.551efa2e-aa4b-4ce2-95bf-0a93f3a61097.TID627.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/2.delta
[2025-07-19T19:57:24.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/24/2.delta
[2025-07-19T19:57:24.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T19:57:24.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.2.delta.946989b5-b7a9-42dd-a63e-15cb2ee3568d.TID632.tmp
[2025-07-19T19:57:24.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T19:57:24.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.2.delta.a039dc60-2126-42f2-890a-7618576e64ea.TID634.tmp
[2025-07-19T19:57:24.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 24.0 in stage 7.0 (TID 627). 5872 bytes result sent to driver
[2025-07-19T19:57:24.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 635) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.2.delta.c222f49d-6af3-40c6-a1e2-fa4eda088ad3.TID629.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/2.delta
[2025-07-19T19:57:24.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/26/2.delta
[2025-07-19T19:57:24.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 32.0 in stage 7.0 (TID 635)
[2025-07-19T19:57:24.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 627) in 75 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T19:57:24.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T19:57:24.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@704027fa
[2025-07-19T19:57:24.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32] for update
[2025-07-19T19:57:24.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.2.delta.082a2b87-dc5f-44b5-a068-fe24d5b91077.TID633.tmp
[2025-07-19T19:57:24.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T19:57:24.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.2.delta.b8a5fbb5-295c-4387-ad36-d9c41fd07f0f.TID630.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/2.delta
[2025-07-19T19:57:24.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 26.0 in stage 7.0 (TID 629). 5872 bytes result sent to driver
[2025-07-19T19:57:24.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/27/2.delta
[2025-07-19T19:57:24.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 636) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T19:57:24.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 33.0 in stage 7.0 (TID 636)
[2025-07-19T19:57:24.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 629) in 75 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T19:57:24.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.2.delta.be6d523e-9861-46c8-8427-44ba61dfb165.TID628.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/2.delta
[2025-07-19T19:57:24.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/25/2.delta
[2025-07-19T19:57:24.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T19:57:24.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@343d6856
[2025-07-19T19:57:24.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T19:57:24.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33] for update
[2025-07-19T19:57:24.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 27.0 in stage 7.0 (TID 630). 5872 bytes result sent to driver
[2025-07-19T19:57:24.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 637) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 630) in 67 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T19:57:24.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 34.0 in stage 7.0 (TID 637)
[2025-07-19T19:57:24.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T19:57:24.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 25.0 in stage 7.0 (TID 628). 5872 bytes result sent to driver
[2025-07-19T19:57:24.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 638) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 35.0 in stage 7.0 (TID 638)
[2025-07-19T19:57:24.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 628) in 94 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T19:57:24.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59b54dc3
[2025-07-19T19:57:24.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34] for update
[2025-07-19T19:57:24.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.2.delta.6abe8451-c04e-47c9-9ccf-747d9de4430f.TID635.tmp
[2025-07-19T19:57:24.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18ab0649
[2025-07-19T19:57:24.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.2.delta.aa34cb0e-fef8-4455-840a-88a00886b303.TID636.tmp
[2025-07-19T19:57:24.661+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.661+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35] for update
[2025-07-19T19:57:24.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.2.delta.3b764e5e-fed2-4b64-90c4-f188bf2faa8d.TID631.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/2.delta
[2025-07-19T19:57:24.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/28/2.delta
[2025-07-19T19:57:24.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T19:57:24.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.2.delta.946989b5-b7a9-42dd-a63e-15cb2ee3568d.TID632.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/2.delta
[2025-07-19T19:57:24.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/29/2.delta
[2025-07-19T19:57:24.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T19:57:24.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=5492818364931444121, sequenceNumber=87, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.26189025S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=118}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=3686}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=174}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=4818}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=382649}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=11911784}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752955029831, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T19:57:24.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Committed in 262 ms
[2025-07-19T19:57:24.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T19:57:24.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752780900000 ms
[2025-07-19T19:57:24.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T19:57:24.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 29.0 in stage 7.0 (TID 632). 5829 bytes result sent to driver
[2025-07-19T19:57:24.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.2.delta.abab0125-290d-442a-a5bf-4b5c5dc11788.TID637.tmp
[2025-07-19T19:57:24.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T19:57:24.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 28.0 in stage 7.0 (TID 631). 5829 bytes result sent to driver
[2025-07-19T19:57:24.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/commits/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/commits/.0.bb91038c-ad5a-4262-8edd-1ac77f1b6946.tmp
[2025-07-19T19:57:24.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 639) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 640) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 36.0 in stage 7.0 (TID 639)
[2025-07-19T19:57:24.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 632) in 78 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T19:57:24.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 37.0 in stage 7.0 (TID 640)
[2025-07-19T19:57:24.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 631) in 89 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T19:57:24.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ef18ef
[2025-07-19T19:57:24.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.2.delta.082a2b87-dc5f-44b5-a068-fe24d5b91077.TID633.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/2.delta
[2025-07-19T19:57:24.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/30/2.delta
[2025-07-19T19:57:24.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36] for update
[2025-07-19T19:57:24.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T19:57:24.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.2.delta.287da929-49cc-43d0-b42f-e735daacaf8d.TID638.tmp
[2025-07-19T19:57:24.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T19:57:24.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 30.0 in stage 7.0 (TID 633). 5786 bytes result sent to driver
[2025-07-19T19:57:24.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13ff7424
[2025-07-19T19:57:24.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 641) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 633) in 85 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T19:57:24.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37] for update
[2025-07-19T19:57:24.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.2.delta.a039dc60-2126-42f2-890a-7618576e64ea.TID634.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/2.delta
[2025-07-19T19:57:24.702+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/31/2.delta
[2025-07-19T19:57:24.702+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 38.0 in stage 7.0 (TID 641)
[2025-07-19T19:57:24.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.2.delta.6abe8451-c04e-47c9-9ccf-747d9de4430f.TID635.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/2.delta
[2025-07-19T19:57:24.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/32/2.delta
[2025-07-19T19:57:24.704+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.704+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T19:57:24.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T19:57:24.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d57ab98
[2025-07-19T19:57:24.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38] for update
[2025-07-19T19:57:24.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T19:57:24.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.2.delta.5fc96918-30d0-400f-bc16-97b1fc1b0c61.TID639.tmp
[2025-07-19T19:57:24.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T19:57:24.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 32.0 in stage 7.0 (TID 635). 5829 bytes result sent to driver
[2025-07-19T19:57:24.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 31.0 in stage 7.0 (TID 634). 5786 bytes result sent to driver
[2025-07-19T19:57:24.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 642) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 643) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 40.0 in stage 7.0 (TID 643)
[2025-07-19T19:57:24.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 635) in 78 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T19:57:24.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 634) in 96 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T19:57:24.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 39.0 in stage 7.0 (TID 642)
[2025-07-19T19:57:24.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.2.delta.68d90b35-3a0a-415a-8952-03a8cc4aff1e.TID640.tmp
[2025-07-19T19:57:24.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:24.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48fbb337
[2025-07-19T19:57:24.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39] for update
[2025-07-19T19:57:24.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62cffd5e
[2025-07-19T19:57:24.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40] for update
[2025-07-19T19:57:24.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.2.delta.aa34cb0e-fef8-4455-840a-88a00886b303.TID636.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/2.delta
[2025-07-19T19:57:24.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/33/2.delta
[2025-07-19T19:57:24.722+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/commits/.0.bb91038c-ad5a-4262-8edd-1ac77f1b6946.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/commits/0
[2025-07-19T19:57:24.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T19:57:24.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.2.delta.13aab921-9122-4773-8c18-a417ba998619.TID641.tmp
[2025-07-19T19:57:24.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.2.delta.abab0125-290d-442a-a5bf-4b5c5dc11788.TID637.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/2.delta
[2025-07-19T19:57:24.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/34/2.delta
[2025-07-19T19:57:24.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T19:57:24.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T19:57:24.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T19:57:24.729+0000] {subprocess.py:93} INFO -   "id" : "609fc205-5186-4889-9ac4-e96d359c0199",
[2025-07-19T19:57:24.729+0000] {subprocess.py:93} INFO -   "runId" : "bba1078e-cb27-476b-a4e5-d0c62f2a2c75",
[2025-07-19T19:57:24.730+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T19:57:24.730+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T19:57:12.076Z",
[2025-07-19T19:57:24.730+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T19:57:24.730+0000] {subprocess.py:93} INFO -   "numInputRows" : 174,
[2025-07-19T19:57:24.730+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:24.730+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 13.76037959667853,
[2025-07-19T19:57:24.730+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T19:57:24.731+0000] {subprocess.py:93} INFO -     "addBatch" : 11614,
[2025-07-19T19:57:24.731+0000] {subprocess.py:93} INFO -     "commitOffsets" : 44,
[2025-07-19T19:57:24.731+0000] {subprocess.py:93} INFO -     "getBatch" : 19,
[2025-07-19T19:57:24.734+0000] {subprocess.py:93} INFO -     "latestOffset" : 415,
[2025-07-19T19:57:24.734+0000] {subprocess.py:93} INFO -     "queryPlanning" : 499,
[2025-07-19T19:57:24.735+0000] {subprocess.py:93} INFO -     "triggerExecution" : 12645,
[2025-07-19T19:57:24.735+0000] {subprocess.py:93} INFO -     "walCommit" : 46
[2025-07-19T19:57:24.737+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:24.738+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T19:57:24.738+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T17:47:20.689Z",
[2025-07-19T19:57:24.739+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T19:35:00.000Z",
[2025-07-19T19:57:24.739+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T16:04:00.000Z",
[2025-07-19T19:57:24.740+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T19:57:24.740+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:24.740+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T19:57:24.740+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T19:57:24.740+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 174,
[2025-07-19T19:57:24.741+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 174,
[2025-07-19T19:57:24.741+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 4011,
[2025-07-19T19:57:24.741+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T19:57:24.741+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 136,
[2025-07-19T19:57:24.741+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 8782,
[2025-07-19T19:57:24.743+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 89456,
[2025-07-19T19:57:24.745+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T19:57:24.746+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T19:57:24.748+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T19:57:24.749+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T19:57:24.749+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T19:57:24.751+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T19:57:24.751+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T19:57:24.752+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 60656
[2025-07-19T19:57:24.752+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:24.752+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:24.753+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T19:57:24.753+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T19:57:24.753+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T19:57:24.753+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T19:57:24.754+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T19:57:24.754+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:24.754+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:24.755+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:24.755+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T19:57:24.755+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T19:57:24.755+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:24.755+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:24.755+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:24.756+0000] {subprocess.py:93} INFO -     "numInputRows" : 174,
[2025-07-19T19:57:24.757+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:24.758+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 13.76037959667853,
[2025-07-19T19:57:24.759+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T19:57:24.759+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T19:57:24.759+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T19:57:24.760+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T19:57:24.760+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:24.761+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:24.762+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T19:57:24.763+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T19:57:24.764+0000] {subprocess.py:93} INFO -     "numOutputRows" : 174
[2025-07-19T19:57:24.765+0000] {subprocess.py:93} INFO -   }
[2025-07-19T19:57:24.765+0000] {subprocess.py:93} INFO - }
[2025-07-19T19:57:24.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.2.delta.6c5f001d-7663-4028-909f-3b2002dbfe64.TID642.tmp
[2025-07-19T19:57:24.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 33.0 in stage 7.0 (TID 636). 5915 bytes result sent to driver
[2025-07-19T19:57:24.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T19:57:24.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 34.0 in stage 7.0 (TID 637). 5872 bytes result sent to driver
[2025-07-19T19:57:24.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 644) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 645) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 636) in 95 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T19:57:24.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 637) in 89 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T19:57:24.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 42.0 in stage 7.0 (TID 645)
[2025-07-19T19:57:24.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 41.0 in stage 7.0 (TID 644)
[2025-07-19T19:57:24.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.2.delta.9c97b99f-94b2-47d2-866a-11d4c6b5add5.TID643.tmp
[2025-07-19T19:57:24.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:24.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.2.delta.287da929-49cc-43d0-b42f-e735daacaf8d.TID638.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/2.delta
[2025-07-19T19:57:24.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/35/2.delta
[2025-07-19T19:57:24.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T19:57:24.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d0d91
[2025-07-19T19:57:24.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.778+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42] for update
[2025-07-19T19:57:24.779+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T19:57:24.780+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 35.0 in stage 7.0 (TID 638). 5872 bytes result sent to driver
[2025-07-19T19:57:24.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/offsets/.1.9a334666-766e-4580-b2ba-47102709098a.tmp
[2025-07-19T19:57:24.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c233e27
[2025-07-19T19:57:24.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.782+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41] for update
[2025-07-19T19:57:24.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 646) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 638) in 95 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T19:57:24.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 43.0 in stage 7.0 (TID 646)
[2025-07-19T19:57:24.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:24.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d65c869
[2025-07-19T19:57:24.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43] for update
[2025-07-19T19:57:24.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.2.delta.5fc96918-30d0-400f-bc16-97b1fc1b0c61.TID639.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/2.delta
[2025-07-19T19:57:24.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/36/2.delta
[2025-07-19T19:57:24.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T19:57:24.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.2.delta.68d90b35-3a0a-415a-8952-03a8cc4aff1e.TID640.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/2.delta
[2025-07-19T19:57:24.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/37/2.delta
[2025-07-19T19:57:24.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.2.delta.c4e432f3-26b3-4e72-98bb-29314b53d246.TID645.tmp
[2025-07-19T19:57:24.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T19:57:24.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T19:57:24.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.2.delta.15f4e712-e0d3-4162-ba54-c214f4ff45ba.TID644.tmp
[2025-07-19T19:57:24.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 36.0 in stage 7.0 (TID 639). 5872 bytes result sent to driver
[2025-07-19T19:57:24.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T19:57:24.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 37.0 in stage 7.0 (TID 640). 5872 bytes result sent to driver
[2025-07-19T19:57:24.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 647) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.2.delta.de842bb8-a3c3-429c-84df-3bc3243bfe50.TID646.tmp
[2025-07-19T19:57:24.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 44.0 in stage 7.0 (TID 647)
[2025-07-19T19:57:24.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 648) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 45.0 in stage 7.0 (TID 648)
[2025-07-19T19:57:24.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 639) in 86 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T19:57:24.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 640) in 83 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T19:57:24.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:24.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58a8c265
[2025-07-19T19:57:24.797+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.798+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44] for update
[2025-07-19T19:57:24.798+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.798+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.799+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:24.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.2.delta.9c97b99f-94b2-47d2-866a-11d4c6b5add5.TID643.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/2.delta
[2025-07-19T19:57:24.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/40/2.delta
[2025-07-19T19:57:24.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9a56963
[2025-07-19T19:57:24.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.2.delta.6c5f001d-7663-4028-909f-3b2002dbfe64.TID642.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/2.delta
[2025-07-19T19:57:24.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/39/2.delta
[2025-07-19T19:57:24.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T19:57:24.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T19:57:24.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45] for update
[2025-07-19T19:57:24.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.803+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T19:57:24.803+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T19:57:24.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 39.0 in stage 7.0 (TID 642). 5872 bytes result sent to driver
[2025-07-19T19:57:24.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 40.0 in stage 7.0 (TID 643). 5872 bytes result sent to driver
[2025-07-19T19:57:24.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 649) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 46.0 in stage 7.0 (TID 649)
[2025-07-19T19:57:24.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.2.delta.03bf8ff4-5a29-49da-a7fb-f7af49de5a10.TID647.tmp
[2025-07-19T19:57:24.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 650) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 643) in 74 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T19:57:24.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 47.0 in stage 7.0 (TID 650)
[2025-07-19T19:57:24.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 642) in 76 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T19:57:24.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@656b5bcc
[2025-07-19T19:57:24.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46] for update
[2025-07-19T19:57:24.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/offsets/.1.9a334666-766e-4580-b2ba-47102709098a.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/offsets/1
[2025-07-19T19:57:24.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752780900000,1752955044737,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T19:57:24.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.2.delta.13aab921-9122-4773-8c18-a417ba998619.TID641.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/2.delta
[2025-07-19T19:57:24.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/38/2.delta
[2025-07-19T19:57:24.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T19:57:24.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a736d11
[2025-07-19T19:57:24.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47] for update
[2025-07-19T19:57:24.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.2.delta.1e159286-31c0-4290-ad45-00791a540571.TID648.tmp
[2025-07-19T19:57:24.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.2.delta.c4e432f3-26b3-4e72-98bb-29314b53d246.TID645.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/2.delta
[2025-07-19T19:57:24.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/42/2.delta
[2025-07-19T19:57:24.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.2.delta.7baaf1a2-7a02-4d61-9f81-ebcfb62a20c4.TID649.tmp
[2025-07-19T19:57:24.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.2.delta.bd9d3178-8a66-4930-96f1-be55be251928.TID650.tmp
[2025-07-19T19:57:24.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.2.delta.de842bb8-a3c3-429c-84df-3bc3243bfe50.TID646.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/2.delta
[2025-07-19T19:57:24.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/43/2.delta
[2025-07-19T19:57:24.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T19:57:24.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T19:57:24.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T19:57:24.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T19:57:24.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T19:57:24.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 38.0 in stage 7.0 (TID 641). 5872 bytes result sent to driver
[2025-07-19T19:57:24.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 42.0 in stage 7.0 (TID 645). 5829 bytes result sent to driver
[2025-07-19T19:57:24.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 43.0 in stage 7.0 (TID 646). 5829 bytes result sent to driver
[2025-07-19T19:57:24.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.2.delta.15f4e712-e0d3-4162-ba54-c214f4ff45ba.TID644.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/2.delta
[2025-07-19T19:57:24.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/41/2.delta
[2025-07-19T19:57:24.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 651) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 641) in 107 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T19:57:24.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T19:57:24.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 48.0 in stage 7.0 (TID 651)
[2025-07-19T19:57:24.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 652) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 653) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 50.0 in stage 7.0 (TID 653)
[2025-07-19T19:57:24.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 645) in 72 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T19:57:24.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 646) in 60 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T19:57:24.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 49.0 in stage 7.0 (TID 652)
[2025-07-19T19:57:24.824+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:24.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T19:57:24.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 41.0 in stage 7.0 (TID 644). 5829 bytes result sent to driver
[2025-07-19T19:57:24.827+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1434163e
[2025-07-19T19:57:24.827+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 654) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.2.delta.03bf8ff4-5a29-49da-a7fb-f7af49de5a10.TID647.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/2.delta
[2025-07-19T19:57:24.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/44/2.delta
[2025-07-19T19:57:24.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 644) in 80 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T19:57:24.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 51.0 in stage 7.0 (TID 654)
[2025-07-19T19:57:24.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50] for update
[2025-07-19T19:57:24.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T19:57:24.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3eca72b3
[2025-07-19T19:57:24.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48] for update
[2025-07-19T19:57:24.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T19:57:24.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ebffeea
[2025-07-19T19:57:24.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 44.0 in stage 7.0 (TID 647). 5829 bytes result sent to driver
[2025-07-19T19:57:24.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 655) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 52.0 in stage 7.0 (TID 655)
[2025-07-19T19:57:24.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 647) in 54 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T19:57:24.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49] for update
[2025-07-19T19:57:24.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.2.delta.1e159286-31c0-4290-ad45-00791a540571.TID648.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/2.delta
[2025-07-19T19:57:24.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/45/2.delta
[2025-07-19T19:57:24.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T19:57:24.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:24.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T19:57:24.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 45.0 in stage 7.0 (TID 648). 5829 bytes result sent to driver
[2025-07-19T19:57:24.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 656) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 648) in 58 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 53.0 in stage 7.0 (TID 656)
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c3ab442
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.2.delta.7cb37cd4-76a9-4ce0-83c8-9144a077cc99.TID653.tmp
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51] for update
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a45be12
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.2.delta.9ff03581-13e5-4d17-9e16-43445f47db7f.TID651.tmp
[2025-07-19T19:57:24.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52] for update
[2025-07-19T19:57:24.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.2.delta.2c573323-f053-4a61-a68a-cdfb5cab13d5.TID652.tmp
[2025-07-19T19:57:24.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76f81f60
[2025-07-19T19:57:24.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53] for update
[2025-07-19T19:57:24.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.2.delta.7baaf1a2-7a02-4d61-9f81-ebcfb62a20c4.TID649.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/2.delta
[2025-07-19T19:57:24.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/46/2.delta
[2025-07-19T19:57:24.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T19:57:24.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.2.delta.bd9d3178-8a66-4930-96f1-be55be251928.TID650.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/2.delta
[2025-07-19T19:57:24.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/47/2.delta
[2025-07-19T19:57:24.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T19:57:24.843+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.843+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T19:57:24.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 46.0 in stage 7.0 (TID 649). 5829 bytes result sent to driver
[2025-07-19T19:57:24.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 657) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 649) in 57 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T19:57:24.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 54.0 in stage 7.0 (TID 657)
[2025-07-19T19:57:24.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T19:57:24.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T19:57:24.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 47.0 in stage 7.0 (TID 650). 5915 bytes result sent to driver
[2025-07-19T19:57:24.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.2.delta.612d2569-9c3b-489a-a4f1-ea5a2df7f961.TID656.tmp
[2025-07-19T19:57:24.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 650) in 70 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T19:57:24.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c5138f7
[2025-07-19T19:57:24.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 658) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 55.0 in stage 7.0 (TID 658)
[2025-07-19T19:57:24.858+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54] for update
[2025-07-19T19:57:24.858+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46fcb846
[2025-07-19T19:57:24.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.2.delta.34f9ef8a-a674-43c5-af8e-902d30ff9423.TID655.tmp
[2025-07-19T19:57:24.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55] for update
[2025-07-19T19:57:24.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.2.delta.214a881c-ff6b-43a0-8765-2dfcb950468c.TID654.tmp
[2025-07-19T19:57:24.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.2.delta.e12ac044-6045-4ddf-b8e6-7976ea163935.TID657.tmp
[2025-07-19T19:57:24.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.2.delta.7cb37cd4-76a9-4ce0-83c8-9144a077cc99.TID653.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/2.delta
[2025-07-19T19:57:24.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/50/2.delta
[2025-07-19T19:57:24.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T19:57:24.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.2.delta.640f7b8c-c61d-415a-925d-981140f3bdbc.TID658.tmp
[2025-07-19T19:57:24.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:24.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T19:57:24.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 50.0 in stage 7.0 (TID 653). 5872 bytes result sent to driver
[2025-07-19T19:57:24.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 659) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 653) in 79 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T19:57:24.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 56.0 in stage 7.0 (TID 659)
[2025-07-19T19:57:24.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.890+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e66ba2
[2025-07-19T19:57:24.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56] for update
[2025-07-19T19:57:24.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.2.delta.9ff03581-13e5-4d17-9e16-43445f47db7f.TID651.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/2.delta
[2025-07-19T19:57:24.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/48/2.delta
[2025-07-19T19:57:24.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T19:57:24.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.2.delta.612d2569-9c3b-489a-a4f1-ea5a2df7f961.TID656.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/2.delta
[2025-07-19T19:57:24.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/53/2.delta
[2025-07-19T19:57:24.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T19:57:24.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T19:57:24.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 48.0 in stage 7.0 (TID 651). 5872 bytes result sent to driver
[2025-07-19T19:57:24.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 660) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T19:57:24.902+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 651) in 96 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T19:57:24.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 57.0 in stage 7.0 (TID 660)
[2025-07-19T19:57:24.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.2.delta.2c573323-f053-4a61-a68a-cdfb5cab13d5.TID652.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/2.delta
[2025-07-19T19:57:24.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 53.0 in stage 7.0 (TID 656). 5872 bytes result sent to driver
[2025-07-19T19:57:24.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 661) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/49/2.delta
[2025-07-19T19:57:24.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 656) in 76 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T19:57:24.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 58.0 in stage 7.0 (TID 661)
[2025-07-19T19:57:24.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T19:57:24.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70fb607a
[2025-07-19T19:57:24.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57] for update
[2025-07-19T19:57:24.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6def0325
[2025-07-19T19:57:24.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.910+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58] for update
[2025-07-19T19:57:24.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.913+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T19:57:24.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 49.0 in stage 7.0 (TID 652). 5872 bytes result sent to driver
[2025-07-19T19:57:24.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.2.delta.4905d4c4-7c82-4bdf-9de3-a43fec756bf9.TID659.tmp
[2025-07-19T19:57:24.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 652) in 106 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T19:57:24.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 662) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 59.0 in stage 7.0 (TID 662)
[2025-07-19T19:57:24.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 209.0 KiB, free 432.8 MiB)
[2025-07-19T19:57:24.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53f77100
[2025-07-19T19:57:24.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.2.delta.34f9ef8a-a674-43c5-af8e-902d30ff9423.TID655.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/2.delta
[2025-07-19T19:57:24.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/52/2.delta
[2025-07-19T19:57:24.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59] for update
[2025-07-19T19:57:24.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T19:57:24.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T19:57:24.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 52.0 in stage 7.0 (TID 655). 5872 bytes result sent to driver
[2025-07-19T19:57:24.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 663) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 655) in 106 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T19:57:24.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 60.0 in stage 7.0 (TID 663)
[2025-07-19T19:57:24.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.2.delta.e12ac044-6045-4ddf-b8e6-7976ea163935.TID657.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/2.delta
[2025-07-19T19:57:24.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/54/2.delta
[2025-07-19T19:57:24.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T19:57:24.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.2.delta.4e3cadad-729c-45e8-b272-a134901d9ecc.TID660.tmp
[2025-07-19T19:57:24.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ebe56b2
[2025-07-19T19:57:24.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.7 MiB)
[2025-07-19T19:57:24.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60] for update
[2025-07-19T19:57:24.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.2.delta.2af75121-594c-435c-9d41-57f99ebc2237.TID661.tmp
[2025-07-19T19:57:24.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T19:57:24.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 54.0 in stage 7.0 (TID 657). 5872 bytes result sent to driver
[2025-07-19T19:57:24.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 664) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 8b44f3d35cfa:44249 (size: 35.4 KiB, free: 434.0 MiB)
[2025-07-19T19:57:24.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 657) in 96 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T19:57:24.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 61.0 in stage 7.0 (TID 664)
[2025-07-19T19:57:24.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkContext: Created broadcast 15 from start at <unknown>:0
[2025-07-19T19:57:24.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@187b5f59
[2025-07-19T19:57:24.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.0 KiB, free 432.7 MiB)
[2025-07-19T19:57:24.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61] for update
[2025-07-19T19:57:24.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 432.7 MiB)
[2025-07-19T19:57:24.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 8b44f3d35cfa:44249 (size: 29.6 KiB, free: 434.0 MiB)
[2025-07-19T19:57:24.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkContext: Created broadcast 16 from start at <unknown>:0
[2025-07-19T19:57:24.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T19:57:24.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T19:57:24.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.2.delta.6c2bf51d-9d71-489b-9b51-b67356f5944e.TID662.tmp
[2025-07-19T19:57:24.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: Registering RDD 33 (start at <unknown>:0) as input to shuffle 4
[2025-07-19T19:57:24.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: Got job 4 (start at <unknown>:0) with 200 output partitions
[2025-07-19T19:57:24.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: Final stage: ResultStage 9 (start at <unknown>:0)
[2025-07-19T19:57:24.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-07-19T19:57:24.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: Missing parents: List()
[2025-07-19T19:57:24.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: Submitting ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0), which has no missing parents
[2025-07-19T19:57:24.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.2.delta.214a881c-ff6b-43a0-8765-2dfcb950468c.TID654.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/2.delta
[2025-07-19T19:57:24.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/51/2.delta
[2025-07-19T19:57:24.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T19:57:24.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T19:57:24.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.2.delta.640f7b8c-c61d-415a-925d-981140f3bdbc.TID658.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/2.delta
[2025-07-19T19:57:24.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/55/2.delta
[2025-07-19T19:57:24.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.2.delta.fafca1ec-110e-4aee-bcd3-a8d145ecc14c.TID663.tmp
[2025-07-19T19:57:24.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T19:57:24.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 51.0 in stage 7.0 (TID 654). 5915 bytes result sent to driver
[2025-07-19T19:57:24.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.2.delta.78fe7e9e-89c4-4b64-8c43-ed405de6fa94.TID664.tmp
[2025-07-19T19:57:24.959+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 665) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 654) in 144 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T19:57:24.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 62.0 in stage 7.0 (TID 665)
[2025-07-19T19:57:24.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T19:57:24.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 55.0 in stage 7.0 (TID 658). 5829 bytes result sent to driver
[2025-07-19T19:57:24.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 32.0 KiB, free 432.7 MiB)
[2025-07-19T19:57:24.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:24.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 666) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 63.0 in stage 7.0 (TID 666)
[2025-07-19T19:57:24.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 658) in 111 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T19:57:24.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 432.6 MiB)
[2025-07-19T19:57:24.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 8b44f3d35cfa:44249 (size: 15.9 KiB, free: 434.0 MiB)
[2025-07-19T19:57:24.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.2.delta.4905d4c4-7c82-4bdf-9de3-a43fec756bf9.TID659.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/2.delta
[2025-07-19T19:57:24.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/56/2.delta
[2025-07-19T19:57:24.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-07-19T19:57:24.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T19:57:24.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSchedulerImpl: Adding task set 9.0 with 200 tasks resource profile 0
[2025-07-19T19:57:24.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6389b9b0
[2025-07-19T19:57:24.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T19:57:24.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:24.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T19:57:24.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62] for update
[2025-07-19T19:57:24.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ad54907
[2025-07-19T19:57:24.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.2.delta.2af75121-594c-435c-9d41-57f99ebc2237.TID661.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/2.delta
[2025-07-19T19:57:24.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:24.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63] for update
[2025-07-19T19:57:24.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/58/2.delta
[2025-07-19T19:57:24.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T19:57:24.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T19:57:24.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 56.0 in stage 7.0 (TID 659). 5829 bytes result sent to driver
[2025-07-19T19:57:24.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:24.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T19:57:24.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 667) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 659) in 100 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T19:57:24.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 64.0 in stage 7.0 (TID 667)
[2025-07-19T19:57:24.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 58.0 in stage 7.0 (TID 661). 5915 bytes result sent to driver
[2025-07-19T19:57:24.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 668) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:24.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.2.delta.6c2bf51d-9d71-489b-9b51-b67356f5944e.TID662.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/2.delta
[2025-07-19T19:57:24.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/59/2.delta
[2025-07-19T19:57:24.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 661) in 92 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T19:57:25.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T19:57:25.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.2.delta.4e3cadad-729c-45e8-b272-a134901d9ecc.TID660.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/2.delta
[2025-07-19T19:57:25.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/57/2.delta
[2025-07-19T19:57:25.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 65.0 in stage 7.0 (TID 668)
[2025-07-19T19:57:25.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T19:57:25.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:25.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T19:57:25.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Committed partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T19:57:25.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b5da7b0
[2025-07-19T19:57:25.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 57.0 in stage 7.0 (TID 660). 5872 bytes result sent to driver
[2025-07-19T19:57:25.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 669) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64] for update
[2025-07-19T19:57:25.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 66.0 in stage 7.0 (TID 669)
[2025-07-19T19:57:25.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 660) in 99 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T19:57:25.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Finished task 59.0 in stage 7.0 (TID 662). 5872 bytes result sent to driver
[2025-07-19T19:57:25.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.2.delta.78fe7e9e-89c4-4b64-8c43-ed405de6fa94.TID664.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/2.delta
[2025-07-19T19:57:25.014+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/61/2.delta
[2025-07-19T19:57:25.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.2.delta.fafca1ec-110e-4aee-bcd3-a8d145ecc14c.TID663.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/2.delta
[2025-07-19T19:57:25.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/60/2.delta
[2025-07-19T19:57:25.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T19:57:25.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 670) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO Executor: Running task 67.0 in stage 7.0 (TID 670)
[2025-07-19T19:57:25.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.2.delta.4e307f79-6ba7-4810-912d-55190dfd2c62.TID666.tmp
[2025-07-19T19:57:25.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 662) in 88 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T19:57:25.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T19:57:25.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46dd7f73
[2025-07-19T19:57:25.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.2.delta.3dc2fbc7-6783-4465-a79a-a1d34284860c.TID665.tmp
[2025-07-19T19:57:25.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65] for update
[2025-07-19T19:57:25.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b88de49
[2025-07-19T19:57:25.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66] for update
[2025-07-19T19:57:25.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T19:57:25.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T19:57:25.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 61.0 in stage 7.0 (TID 664). 5872 bytes result sent to driver
[2025-07-19T19:57:25.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 60.0 in stage 7.0 (TID 663). 5872 bytes result sent to driver
[2025-07-19T19:57:25.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 671) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 672) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 68.0 in stage 7.0 (TID 671)
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 664) in 73 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 663) in 82 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 69.0 in stage 7.0 (TID 672)
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17a7b727
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67] for update
[2025-07-19T19:57:25.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@664b9179
[2025-07-19T19:57:25.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69] for update
[2025-07-19T19:57:25.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c084dad
[2025-07-19T19:57:25.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68] for update
[2025-07-19T19:57:25.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.2.delta.3499d4ea-32a3-4c70-87b1-bfaedff2efb2.TID667.tmp
[2025-07-19T19:57:25.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.2.delta.a41d152e-77f4-4ff9-8e2f-16db524e8c93.TID668.tmp
[2025-07-19T19:57:25.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.2.delta.87c6918b-bb22-4fd9-9e01-e331536b7acf.TID669.tmp
[2025-07-19T19:57:25.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.2.delta.182bd61d-4ff4-4880-89e0-0a107d451238.TID670.tmp
[2025-07-19T19:57:25.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.2.delta.a9090eda-e0d5-40ce-89ba-5861cafcdf9d.TID671.tmp
[2025-07-19T19:57:25.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.2.delta.e96be13a-f363-46fe-b440-bb535f3abf73.TID672.tmp
[2025-07-19T19:57:25.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.2.delta.3499d4ea-32a3-4c70-87b1-bfaedff2efb2.TID667.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/2.delta
[2025-07-19T19:57:25.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/64/2.delta
[2025-07-19T19:57:25.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T19:57:25.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.2.delta.3dc2fbc7-6783-4465-a79a-a1d34284860c.TID665.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/2.delta
[2025-07-19T19:57:25.052+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/62/2.delta
[2025-07-19T19:57:25.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T19:57:25.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.2.delta.4e307f79-6ba7-4810-912d-55190dfd2c62.TID666.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/2.delta
[2025-07-19T19:57:25.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/63/2.delta
[2025-07-19T19:57:25.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T19:57:25.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 64.0 in stage 7.0 (TID 667). 5872 bytes result sent to driver
[2025-07-19T19:57:25.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.2.delta.182bd61d-4ff4-4880-89e0-0a107d451238.TID670.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/2.delta
[2025-07-19T19:57:25.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/67/2.delta
[2025-07-19T19:57:25.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T19:57:25.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 673) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 70.0 in stage 7.0 (TID 673)
[2025-07-19T19:57:25.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T19:57:25.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T19:57:25.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 667) in 75 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T19:57:25.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 62.0 in stage 7.0 (TID 665). 5872 bytes result sent to driver
[2025-07-19T19:57:25.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T19:57:25.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 674) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 71.0 in stage 7.0 (TID 674)
[2025-07-19T19:57:25.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 63.0 in stage 7.0 (TID 666). 5872 bytes result sent to driver
[2025-07-19T19:57:25.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 666) in 94 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T19:57:25.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 675) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 72.0 in stage 7.0 (TID 675)
[2025-07-19T19:57:25.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 665) in 103 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T19:57:25.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.2.delta.a41d152e-77f4-4ff9-8e2f-16db524e8c93.TID668.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/2.delta
[2025-07-19T19:57:25.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/65/2.delta
[2025-07-19T19:57:25.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T19:57:25.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.2.delta.a9090eda-e0d5-40ce-89ba-5861cafcdf9d.TID671.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/2.delta
[2025-07-19T19:57:25.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/68/2.delta
[2025-07-19T19:57:25.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.2.delta.e96be13a-f363-46fe-b440-bb535f3abf73.TID672.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/2.delta
[2025-07-19T19:57:25.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/69/2.delta
[2025-07-19T19:57:25.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 67.0 in stage 7.0 (TID 670). 5786 bytes result sent to driver
[2025-07-19T19:57:25.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@574c17ec
[2025-07-19T19:57:25.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T19:57:25.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T19:57:25.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T19:57:25.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70] for update
[2025-07-19T19:57:25.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:25.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 676) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 73.0 in stage 7.0 (TID 676)
[2025-07-19T19:57:25.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T19:57:25.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 68.0 in stage 7.0 (TID 671). 5829 bytes result sent to driver
[2025-07-19T19:57:25.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 677) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T19:57:25.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 69.0 in stage 7.0 (TID 672). 5786 bytes result sent to driver
[2025-07-19T19:57:25.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 671) in 59 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T19:57:25.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c701562
[2025-07-19T19:57:25.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T19:57:25.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 65.0 in stage 7.0 (TID 668). 5829 bytes result sent to driver
[2025-07-19T19:57:25.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 74.0 in stage 7.0 (TID 677)
[2025-07-19T19:57:25.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 670) in 67 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T19:57:25.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72] for update
[2025-07-19T19:57:25.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 672) in 60 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T19:57:25.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 678) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 75.0 in stage 7.0 (TID 678)
[2025-07-19T19:57:25.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 679) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 668) in 77 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T19:57:25.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 76.0 in stage 7.0 (TID 679)
[2025-07-19T19:57:25.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.2.delta.87c6918b-bb22-4fd9-9e01-e331536b7acf.TID669.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/2.delta
[2025-07-19T19:57:25.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/66/2.delta
[2025-07-19T19:57:25.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T19:57:25.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70cbe910
[2025-07-19T19:57:25.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.2.delta.072d5a15-af09-424d-8655-8e45d27fc2b3.TID673.tmp
[2025-07-19T19:57:25.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75] for update
[2025-07-19T19:57:25.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T19:57:25.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 66.0 in stage 7.0 (TID 669). 5829 bytes result sent to driver
[2025-07-19T19:57:25.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44ac8d17
[2025-07-19T19:57:25.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 680) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 77.0 in stage 7.0 (TID 680)
[2025-07-19T19:57:25.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 669) in 77 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T19:57:25.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71] for update
[2025-07-19T19:57:25.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.2.delta.464bca5a-67e0-4393-b34e-9d31c466d1f8.TID675.tmp
[2025-07-19T19:57:25.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb27b35
[2025-07-19T19:57:25.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74] for update
[2025-07-19T19:57:25.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.2.delta.aadb971c-bea1-4565-988a-10940338a252.TID678.tmp
[2025-07-19T19:57:25.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bd649a7
[2025-07-19T19:57:25.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77] for update
[2025-07-19T19:57:25.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b24a8bd
[2025-07-19T19:57:25.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76] for update
[2025-07-19T19:57:25.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40fa4ce4
[2025-07-19T19:57:25.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73] for update
[2025-07-19T19:57:25.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.2.delta.f068d6d2-5ae9-4c9a-831f-aca988ee76d9.TID674.tmp
[2025-07-19T19:57:25.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.2.delta.0d1279bf-ed48-4898-8399-80eba92838bb.TID677.tmp
[2025-07-19T19:57:25.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.2.delta.b37351f1-55e4-41d9-9128-78edf363a781.TID676.tmp
[2025-07-19T19:57:25.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.2.delta.cd85105d-9e45-4de1-81c1-3e63b0e745d7.TID680.tmp
[2025-07-19T19:57:25.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.2.delta.ea669ed0-347c-4686-ace4-9be9fd9a44b2.TID679.tmp
[2025-07-19T19:57:25.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.2.delta.072d5a15-af09-424d-8655-8e45d27fc2b3.TID673.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/2.delta
[2025-07-19T19:57:25.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/70/2.delta
[2025-07-19T19:57:25.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T19:57:25.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T19:57:25.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 70.0 in stage 7.0 (TID 673). 5829 bytes result sent to driver
[2025-07-19T19:57:25.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 681) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 673) in 50 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T19:57:25.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 78.0 in stage 7.0 (TID 681)
[2025-07-19T19:57:25.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.2.delta.464bca5a-67e0-4393-b34e-9d31c466d1f8.TID675.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/2.delta
[2025-07-19T19:57:25.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/72/2.delta
[2025-07-19T19:57:25.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T19:57:25.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.2.delta.aadb971c-bea1-4565-988a-10940338a252.TID678.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/2.delta
[2025-07-19T19:57:25.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/75/2.delta
[2025-07-19T19:57:25.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T19:57:25.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c734988
[2025-07-19T19:57:25.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78] for update
[2025-07-19T19:57:25.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T19:57:25.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T19:57:25.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 75.0 in stage 7.0 (TID 678). 5915 bytes result sent to driver
[2025-07-19T19:57:25.114+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 682) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.115+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 72.0 in stage 7.0 (TID 675). 5915 bytes result sent to driver
[2025-07-19T19:57:25.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 79.0 in stage 7.0 (TID 682)
[2025-07-19T19:57:25.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 683) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 675) in 59 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T19:57:25.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 80.0 in stage 7.0 (TID 683)
[2025-07-19T19:57:25.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 678) in 51 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T19:57:25.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.2.delta.0d1279bf-ed48-4898-8399-80eba92838bb.TID677.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/2.delta
[2025-07-19T19:57:25.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/74/2.delta
[2025-07-19T19:57:25.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T19:57:25.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c6acb48
[2025-07-19T19:57:25.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79] for update
[2025-07-19T19:57:25.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5506a39
[2025-07-19T19:57:25.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80] for update
[2025-07-19T19:57:25.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.2.delta.cd85105d-9e45-4de1-81c1-3e63b0e745d7.TID680.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/2.delta
[2025-07-19T19:57:25.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/77/2.delta
[2025-07-19T19:57:25.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T19:57:25.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.2.delta.f068d6d2-5ae9-4c9a-831f-aca988ee76d9.TID674.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/2.delta
[2025-07-19T19:57:25.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/71/2.delta
[2025-07-19T19:57:25.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T19:57:25.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T19:57:25.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 74.0 in stage 7.0 (TID 677). 5872 bytes result sent to driver
[2025-07-19T19:57:25.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.2.delta.b37351f1-55e4-41d9-9128-78edf363a781.TID676.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/2.delta
[2025-07-19T19:57:25.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/73/2.delta
[2025-07-19T19:57:25.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 684) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 81.0 in stage 7.0 (TID 684)
[2025-07-19T19:57:25.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 677) in 60 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T19:57:25.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T19:57:25.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 77.0 in stage 7.0 (TID 680). 5872 bytes result sent to driver
[2025-07-19T19:57:25.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T19:57:25.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 685) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 680) in 52 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T19:57:25.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 82.0 in stage 7.0 (TID 685)
[2025-07-19T19:57:25.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T19:57:25.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 71.0 in stage 7.0 (TID 674). 5872 bytes result sent to driver
[2025-07-19T19:57:25.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cf68822
[2025-07-19T19:57:25.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 686) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81] for update
[2025-07-19T19:57:25.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 83.0 in stage 7.0 (TID 686)
[2025-07-19T19:57:25.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.2.delta.836329a4-1171-454d-9f17-b16c797ac204.TID681.tmp
[2025-07-19T19:57:25.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7db1dfe5
[2025-07-19T19:57:25.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82] for update
[2025-07-19T19:57:25.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.2.delta.ea669ed0-347c-4686-ace4-9be9fd9a44b2.TID679.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/2.delta
[2025-07-19T19:57:25.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/76/2.delta
[2025-07-19T19:57:25.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 674) in 75 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T19:57:25.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@346ced66
[2025-07-19T19:57:25.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83] for update
[2025-07-19T19:57:25.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T19:57:25.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T19:57:25.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 73.0 in stage 7.0 (TID 676). 5872 bytes result sent to driver
[2025-07-19T19:57:25.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 687) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 84.0 in stage 7.0 (TID 687)
[2025-07-19T19:57:25.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 676) in 74 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T19:57:25.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T19:57:25.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 76.0 in stage 7.0 (TID 679). 5872 bytes result sent to driver
[2025-07-19T19:57:25.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c6a7b0a
[2025-07-19T19:57:25.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 688) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 85.0 in stage 7.0 (TID 688)
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84] for update
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 679) in 71 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17f1231
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85] for update
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.2.delta.10a1100b-9330-44ca-88bd-b2b03a41613d.TID683.tmp
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.2.delta.f080b481-f0d3-4113-8ea1-7ab07a237440.TID684.tmp
[2025-07-19T19:57:25.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.2.delta.e1faed43-4ed2-4145-8af5-d433cdad3e23.TID685.tmp
[2025-07-19T19:57:25.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.2.delta.f2f7b83c-5e2f-4c07-8e91-7066a6341649.TID682.tmp
[2025-07-19T19:57:25.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.2.delta.bfff6de6-6797-42d5-884d-63e74beee20c.TID688.tmp
[2025-07-19T19:57:25.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.2.delta.281caecf-92f9-431a-ad4c-08745bb356b1.TID687.tmp
[2025-07-19T19:57:25.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.2.delta.0e5fc6e9-0264-41bb-8608-6347f4dbdffc.TID686.tmp
[2025-07-19T19:57:25.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.2.delta.836329a4-1171-454d-9f17-b16c797ac204.TID681.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/2.delta
[2025-07-19T19:57:25.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/78/2.delta
[2025-07-19T19:57:25.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T19:57:25.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.2.delta.f080b481-f0d3-4113-8ea1-7ab07a237440.TID684.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/2.delta
[2025-07-19T19:57:25.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/81/2.delta
[2025-07-19T19:57:25.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.2.delta.f2f7b83c-5e2f-4c07-8e91-7066a6341649.TID682.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/2.delta
[2025-07-19T19:57:25.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/79/2.delta
[2025-07-19T19:57:25.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T19:57:25.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T19:57:25.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.2.delta.bfff6de6-6797-42d5-884d-63e74beee20c.TID688.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/2.delta
[2025-07-19T19:57:25.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/85/2.delta
[2025-07-19T19:57:25.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T19:57:25.187+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T19:57:25.187+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 85.0 in stage 7.0 (TID 688). 5829 bytes result sent to driver
[2025-07-19T19:57:25.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T19:57:25.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.2.delta.0e5fc6e9-0264-41bb-8608-6347f4dbdffc.TID686.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/2.delta
[2025-07-19T19:57:25.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/83/2.delta
[2025-07-19T19:57:25.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 689) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 79.0 in stage 7.0 (TID 682). 5829 bytes result sent to driver
[2025-07-19T19:57:25.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.2.delta.e1faed43-4ed2-4145-8af5-d433cdad3e23.TID685.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/2.delta
[2025-07-19T19:57:25.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/82/2.delta
[2025-07-19T19:57:25.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T19:57:25.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T19:57:25.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 81.0 in stage 7.0 (TID 684). 5829 bytes result sent to driver
[2025-07-19T19:57:25.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 86.0 in stage 7.0 (TID 689)
[2025-07-19T19:57:25.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 690) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 87.0 in stage 7.0 (TID 690)
[2025-07-19T19:57:25.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 691) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.2.delta.10a1100b-9330-44ca-88bd-b2b03a41613d.TID683.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/2.delta
[2025-07-19T19:57:25.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/80/2.delta
[2025-07-19T19:57:25.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 684) in 66 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T19:57:25.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T19:57:25.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 78.0 in stage 7.0 (TID 681). 5872 bytes result sent to driver
[2025-07-19T19:57:25.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 88.0 in stage 7.0 (TID 691)
[2025-07-19T19:57:25.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T19:57:25.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:25.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 682) in 80 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T19:57:25.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T19:57:25.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35272173
[2025-07-19T19:57:25.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86] for update
[2025-07-19T19:57:25.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T19:57:25.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 82.0 in stage 7.0 (TID 685). 5829 bytes result sent to driver
[2025-07-19T19:57:25.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 692) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fd584a6
[2025-07-19T19:57:25.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 688) in 58 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T19:57:25.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 681) in 93 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T19:57:25.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87] for update
[2025-07-19T19:57:25.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 693) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 90.0 in stage 7.0 (TID 693)
[2025-07-19T19:57:25.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 685) in 71 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T19:57:25.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 89.0 in stage 7.0 (TID 692)
[2025-07-19T19:57:25.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b2c14d0
[2025-07-19T19:57:25.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88] for update
[2025-07-19T19:57:25.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T19:57:25.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T19:57:25.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c72869e
[2025-07-19T19:57:25.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 83.0 in stage 7.0 (TID 686). 5829 bytes result sent to driver
[2025-07-19T19:57:25.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 694) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 80.0 in stage 7.0 (TID 683). 5829 bytes result sent to driver
[2025-07-19T19:57:25.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 91.0 in stage 7.0 (TID 694)
[2025-07-19T19:57:25.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 686) in 75 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T19:57:25.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 683) in 90 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T19:57:25.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 695) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 92.0 in stage 7.0 (TID 695)
[2025-07-19T19:57:25.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.2.delta.4be0e48e-6f71-4b78-bb67-a5a5270ebb46.TID689.tmp
[2025-07-19T19:57:25.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90] for update
[2025-07-19T19:57:25.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@355b94bb
[2025-07-19T19:57:25.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.221+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89] for update
[2025-07-19T19:57:25.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.2.delta.50f7e106-dfea-4bc8-8484-d4831742c139.TID691.tmp
[2025-07-19T19:57:25.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.2.delta.35cf54dd-b11e-48f7-9961-c58ac095757c.TID690.tmp
[2025-07-19T19:57:25.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b970bab
[2025-07-19T19:57:25.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.2.delta.281caecf-92f9-431a-ad4c-08745bb356b1.TID687.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/2.delta
[2025-07-19T19:57:25.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/84/2.delta
[2025-07-19T19:57:25.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92] for update
[2025-07-19T19:57:25.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T19:57:25.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ba67416
[2025-07-19T19:57:25.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91] for update
[2025-07-19T19:57:25.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T19:57:25.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.2.delta.a6760f11-cf73-4e18-a992-3b2370abf220.TID693.tmp
[2025-07-19T19:57:25.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 84.0 in stage 7.0 (TID 687). 5829 bytes result sent to driver
[2025-07-19T19:57:25.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 696) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 687) in 90 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T19:57:25.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 93.0 in stage 7.0 (TID 696)
[2025-07-19T19:57:25.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.2.delta.5d0e5f00-3f80-40ba-b377-567fc8d40576.TID692.tmp
[2025-07-19T19:57:25.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18286701
[2025-07-19T19:57:25.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93] for update
[2025-07-19T19:57:25.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.2.delta.31a77e86-4051-4dcf-a943-cf74ae53e431.TID695.tmp
[2025-07-19T19:57:25.235+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.2.delta.ae656027-ca2e-4c37-a8aa-3a57a8ceef2f.TID694.tmp
[2025-07-19T19:57:25.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.2.delta.35cf54dd-b11e-48f7-9961-c58ac095757c.TID690.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/2.delta
[2025-07-19T19:57:25.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/87/2.delta
[2025-07-19T19:57:25.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.2.delta.4cbda099-90fc-4247-810e-5e2f3bbb5797.TID696.tmp
[2025-07-19T19:57:25.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T19:57:25.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T19:57:25.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 87.0 in stage 7.0 (TID 690). 5872 bytes result sent to driver
[2025-07-19T19:57:25.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.2.delta.4be0e48e-6f71-4b78-bb67-a5a5270ebb46.TID689.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/2.delta
[2025-07-19T19:57:25.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/86/2.delta
[2025-07-19T19:57:25.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.2.delta.50f7e106-dfea-4bc8-8484-d4831742c139.TID691.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/2.delta
[2025-07-19T19:57:25.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/88/2.delta
[2025-07-19T19:57:25.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T19:57:25.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T19:57:25.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 697) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 94.0 in stage 7.0 (TID 697)
[2025-07-19T19:57:25.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 690) in 64 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T19:57:25.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T19:57:25.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@349eefda
[2025-07-19T19:57:25.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94] for update
[2025-07-19T19:57:25.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 86.0 in stage 7.0 (TID 689). 5829 bytes result sent to driver
[2025-07-19T19:57:25.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 698) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T19:57:25.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 95.0 in stage 7.0 (TID 698)
[2025-07-19T19:57:25.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.2.delta.a6760f11-cf73-4e18-a992-3b2370abf220.TID693.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/2.delta
[2025-07-19T19:57:25.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/90/2.delta
[2025-07-19T19:57:25.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 88.0 in stage 7.0 (TID 691). 5872 bytes result sent to driver
[2025-07-19T19:57:25.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 689) in 74 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T19:57:25.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 699) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T19:57:25.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 691) in 77 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T19:57:25.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 96.0 in stage 7.0 (TID 699)
[2025-07-19T19:57:25.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.2.delta.31a77e86-4051-4dcf-a943-cf74ae53e431.TID695.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/2.delta
[2025-07-19T19:57:25.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/92/2.delta
[2025-07-19T19:57:25.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b9bd82e
[2025-07-19T19:57:25.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T19:57:25.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95] for update
[2025-07-19T19:57:25.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.2.delta.5d0e5f00-3f80-40ba-b377-567fc8d40576.TID692.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/2.delta
[2025-07-19T19:57:25.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/89/2.delta
[2025-07-19T19:57:25.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T19:57:25.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T19:57:25.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 90.0 in stage 7.0 (TID 693). 5872 bytes result sent to driver
[2025-07-19T19:57:25.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 700) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 97.0 in stage 7.0 (TID 700)
[2025-07-19T19:57:25.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 693) in 76 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T19:57:25.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.2.delta.b2afe1c8-fbb7-49e6-b99b-157613a40622.TID697.tmp
[2025-07-19T19:57:25.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@271aa2ef
[2025-07-19T19:57:25.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.2.delta.ae656027-ca2e-4c37-a8aa-3a57a8ceef2f.TID694.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/2.delta
[2025-07-19T19:57:25.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/91/2.delta
[2025-07-19T19:57:25.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T19:57:25.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97] for update
[2025-07-19T19:57:25.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T19:57:25.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 92.0 in stage 7.0 (TID 695). 5829 bytes result sent to driver
[2025-07-19T19:57:25.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T19:57:25.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 89.0 in stage 7.0 (TID 692). 5872 bytes result sent to driver
[2025-07-19T19:57:25.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 701) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 702) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 98.0 in stage 7.0 (TID 701)
[2025-07-19T19:57:25.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 695) in 73 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T19:57:25.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 692) in 83 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T19:57:25.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:25.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T19:57:25.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36ce0ed6
[2025-07-19T19:57:25.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96] for update
[2025-07-19T19:57:25.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 91.0 in stage 7.0 (TID 694). 5872 bytes result sent to driver
[2025-07-19T19:57:25.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.2.delta.4cbda099-90fc-4247-810e-5e2f3bbb5797.TID696.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/2.delta
[2025-07-19T19:57:25.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/93/2.delta
[2025-07-19T19:57:25.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@498fbf66
[2025-07-19T19:57:25.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 99.0 in stage 7.0 (TID 702)
[2025-07-19T19:57:25.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T19:57:25.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98] for update
[2025-07-19T19:57:25.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41439dc0
[2025-07-19T19:57:25.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99] for update
[2025-07-19T19:57:25.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.2.delta.098f715a-862c-40b2-b8dd-36f235ff1473.TID700.tmp
[2025-07-19T19:57:25.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T19:57:25.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 93.0 in stage 7.0 (TID 696). 5829 bytes result sent to driver
[2025-07-19T19:57:25.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.2.delta.c2362f0e-6b09-4ac3-bf38-0120475a08a2.TID698.tmp
[2025-07-19T19:57:25.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 100.0 in stage 7.0 (TID 703) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 101.0 in stage 7.0 (TID 704) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 694) in 88 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T19:57:25.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 696) in 69 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T19:57:25.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 100.0 in stage 7.0 (TID 703)
[2025-07-19T19:57:25.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 101.0 in stage 7.0 (TID 704)
[2025-07-19T19:57:25.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.2.delta.c7ff1614-4f70-4ef7-b884-71a3dfdec656.TID699.tmp
[2025-07-19T19:57:25.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.2.delta.4dc1ef70-42d7-4589-9b88-02a5d6685a67.TID701.tmp
[2025-07-19T19:57:25.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.2.delta.ecbade22-afe6-4c5f-9700-e02760b4b49c.TID702.tmp
[2025-07-19T19:57:25.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@218f37fc
[2025-07-19T19:57:25.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100] for update
[2025-07-19T19:57:25.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c153339
[2025-07-19T19:57:25.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101] for update
[2025-07-19T19:57:25.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.2.delta.dd9178b6-b11c-49c2-9620-7a341f363efa.TID704.tmp
[2025-07-19T19:57:25.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.2.delta.b2afe1c8-fbb7-49e6-b99b-157613a40622.TID697.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/2.delta
[2025-07-19T19:57:25.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/94/2.delta
[2025-07-19T19:57:25.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T19:57:25.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.2.delta.eef3b9a3-602d-4c0a-a3ab-f40f19e36fc8.TID703.tmp
[2025-07-19T19:57:25.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T19:57:25.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 94.0 in stage 7.0 (TID 697). 5829 bytes result sent to driver
[2025-07-19T19:57:25.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 102.0 in stage 7.0 (TID 705) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 102.0 in stage 7.0 (TID 705)
[2025-07-19T19:57:25.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 697) in 67 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T19:57:25.321+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4640525e
[2025-07-19T19:57:25.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102] for update
[2025-07-19T19:57:25.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.2.delta.4dc1ef70-42d7-4589-9b88-02a5d6685a67.TID701.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/2.delta
[2025-07-19T19:57:25.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/98/2.delta
[2025-07-19T19:57:25.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T19:57:25.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.2.delta.c2362f0e-6b09-4ac3-bf38-0120475a08a2.TID698.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/2.delta
[2025-07-19T19:57:25.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/95/2.delta
[2025-07-19T19:57:25.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T19:57:25.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T19:57:25.330+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.2.delta.098f715a-862c-40b2-b8dd-36f235ff1473.TID700.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/2.delta
[2025-07-19T19:57:25.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 98.0 in stage 7.0 (TID 701). 5829 bytes result sent to driver
[2025-07-19T19:57:25.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/97/2.delta
[2025-07-19T19:57:25.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 103.0 in stage 7.0 (TID 706) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.2.delta.ecbade22-afe6-4c5f-9700-e02760b4b49c.TID702.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/2.delta
[2025-07-19T19:57:25.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/99/2.delta
[2025-07-19T19:57:25.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 701) in 52 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T19:57:25.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T19:57:25.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 103.0 in stage 7.0 (TID 706)
[2025-07-19T19:57:25.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T19:57:25.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 95.0 in stage 7.0 (TID 698). 5829 bytes result sent to driver
[2025-07-19T19:57:25.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T19:57:25.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.2.delta.c7ff1614-4f70-4ef7-b884-71a3dfdec656.TID699.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/2.delta
[2025-07-19T19:57:25.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/96/2.delta
[2025-07-19T19:57:25.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T19:57:25.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63a0635f
[2025-07-19T19:57:25.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103] for update
[2025-07-19T19:57:25.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.2.delta.a54f6352-d0ce-4bd7-858e-0a845e294551.TID705.tmp
[2025-07-19T19:57:25.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 104.0 in stage 7.0 (TID 707) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T19:57:25.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 99.0 in stage 7.0 (TID 702). 5829 bytes result sent to driver
[2025-07-19T19:57:25.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 104.0 in stage 7.0 (TID 707)
[2025-07-19T19:57:25.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 105.0 in stage 7.0 (TID 708) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 698) in 78 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T19:57:25.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 105.0 in stage 7.0 (TID 708)
[2025-07-19T19:57:25.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 702) in 59 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T19:57:25.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T19:57:25.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 97.0 in stage 7.0 (TID 700). 5829 bytes result sent to driver
[2025-07-19T19:57:25.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T19:57:25.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 106.0 in stage 7.0 (TID 709) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 106.0 in stage 7.0 (TID 709)
[2025-07-19T19:57:25.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 700) in 70 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T19:57:25.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:25.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 96.0 in stage 7.0 (TID 699). 5829 bytes result sent to driver
[2025-07-19T19:57:25.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8852be7
[2025-07-19T19:57:25.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104] for update
[2025-07-19T19:57:25.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 107.0 in stage 7.0 (TID 710) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 699) in 78 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T19:57:25.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e1fb5b8
[2025-07-19T19:57:25.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 107.0 in stage 7.0 (TID 710)
[2025-07-19T19:57:25.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105] for update
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.2.delta.eef3b9a3-602d-4c0a-a3ab-f40f19e36fc8.TID703.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/2.delta
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/100/2.delta
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7adf4785
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.2.delta.8e79c83f-8241-4e44-9a03-5c7d9e28deca.TID706.tmp
[2025-07-19T19:57:25.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.2.delta.dd9178b6-b11c-49c2-9620-7a341f363efa.TID704.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/2.delta
[2025-07-19T19:57:25.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/101/2.delta
[2025-07-19T19:57:25.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T19:57:25.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e5e47bc
[2025-07-19T19:57:25.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107] for update
[2025-07-19T19:57:25.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106] for update
[2025-07-19T19:57:25.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T19:57:25.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T19:57:25.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 101.0 in stage 7.0 (TID 704). 5915 bytes result sent to driver
[2025-07-19T19:57:25.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 100.0 in stage 7.0 (TID 703). 5915 bytes result sent to driver
[2025-07-19T19:57:25.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 108.0 in stage 7.0 (TID 711) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 109.0 in stage 7.0 (TID 712) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 108.0 in stage 7.0 (TID 711)
[2025-07-19T19:57:25.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.2.delta.ce74b9a5-0187-44a4-bea3-5c37c6ffe717.TID707.tmp
[2025-07-19T19:57:25.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.2.delta.6332fe96-84e5-4eeb-876f-0c32a2d384a3.TID710.tmp
[2025-07-19T19:57:25.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 100.0 in stage 7.0 (TID 703) in 76 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T19:57:25.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 109.0 in stage 7.0 (TID 712)
[2025-07-19T19:57:25.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 101.0 in stage 7.0 (TID 704) in 75 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T19:57:25.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.2.delta.202493c6-3a28-4a66-872b-b28bee71726e.TID708.tmp
[2025-07-19T19:57:25.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.2.delta.2ce19394-6b65-490e-aa86-751289e449de.TID709.tmp
[2025-07-19T19:57:25.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2196f83c
[2025-07-19T19:57:25.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108] for update
[2025-07-19T19:57:25.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4000cff
[2025-07-19T19:57:25.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109] for update
[2025-07-19T19:57:25.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.2.delta.a54f6352-d0ce-4bd7-858e-0a845e294551.TID705.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/2.delta
[2025-07-19T19:57:25.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/102/2.delta
[2025-07-19T19:57:25.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T19:57:25.394+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T19:57:25.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 102.0 in stage 7.0 (TID 705). 5872 bytes result sent to driver
[2025-07-19T19:57:25.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 110.0 in stage 7.0 (TID 713) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 110.0 in stage 7.0 (TID 713)
[2025-07-19T19:57:25.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 102.0 in stage 7.0 (TID 705) in 80 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T19:57:25.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ebe41e3
[2025-07-19T19:57:25.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110] for update
[2025-07-19T19:57:25.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.2.delta.8cbe1901-918e-4319-9aab-d37cf3566687.TID711.tmp
[2025-07-19T19:57:25.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.2.delta.8e79c83f-8241-4e44-9a03-5c7d9e28deca.TID706.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/2.delta
[2025-07-19T19:57:25.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/103/2.delta
[2025-07-19T19:57:25.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T19:57:25.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T19:57:25.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 103.0 in stage 7.0 (TID 706). 5872 bytes result sent to driver
[2025-07-19T19:57:25.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 111.0 in stage 7.0 (TID 714) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 103.0 in stage 7.0 (TID 706) in 83 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T19:57:25.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 111.0 in stage 7.0 (TID 714)
[2025-07-19T19:57:25.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@85fcb8
[2025-07-19T19:57:25.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111] for update
[2025-07-19T19:57:25.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.2.delta.202493c6-3a28-4a66-872b-b28bee71726e.TID708.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/2.delta
[2025-07-19T19:57:25.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/105/2.delta
[2025-07-19T19:57:25.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T19:57:25.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.2.delta.7d59425f-3977-43e1-b6fc-d651fb0670ba.TID713.tmp
[2025-07-19T19:57:25.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.2.delta.62252f25-7303-4a1a-b049-4bff4b7bc2e5.TID712.tmp
[2025-07-19T19:57:25.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.2.delta.ce74b9a5-0187-44a4-bea3-5c37c6ffe717.TID707.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/2.delta
[2025-07-19T19:57:25.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/104/2.delta
[2025-07-19T19:57:25.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T19:57:25.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T19:57:25.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T19:57:25.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 104.0 in stage 7.0 (TID 707). 5872 bytes result sent to driver
[2025-07-19T19:57:25.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 105.0 in stage 7.0 (TID 708). 5872 bytes result sent to driver
[2025-07-19T19:57:25.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 112.0 in stage 7.0 (TID 715) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.2.delta.6332fe96-84e5-4eeb-876f-0c32a2d384a3.TID710.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/2.delta
[2025-07-19T19:57:25.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/107/2.delta
[2025-07-19T19:57:25.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 112.0 in stage 7.0 (TID 715)
[2025-07-19T19:57:25.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 113.0 in stage 7.0 (TID 716) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 104.0 in stage 7.0 (TID 707) in 95 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T19:57:25.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 113.0 in stage 7.0 (TID 716)
[2025-07-19T19:57:25.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T19:57:25.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 105.0 in stage 7.0 (TID 708) in 94 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T19:57:25.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.2.delta.2ce19394-6b65-490e-aa86-751289e449de.TID709.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/2.delta
[2025-07-19T19:57:25.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/106/2.delta
[2025-07-19T19:57:25.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25ac67c
[2025-07-19T19:57:25.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:25.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T19:57:25.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112] for update
[2025-07-19T19:57:25.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.2.delta.7b9a1529-77bc-4623-94b8-25070860ae77.TID714.tmp
[2025-07-19T19:57:25.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T19:57:25.449+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26547e1f
[2025-07-19T19:57:25.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T19:57:25.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 106.0 in stage 7.0 (TID 709). 5915 bytes result sent to driver
[2025-07-19T19:57:25.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 107.0 in stage 7.0 (TID 710). 5915 bytes result sent to driver
[2025-07-19T19:57:25.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113] for update
[2025-07-19T19:57:25.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 114.0 in stage 7.0 (TID 717) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 114.0 in stage 7.0 (TID 717)
[2025-07-19T19:57:25.465+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 115.0 in stage 7.0 (TID 718) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 106.0 in stage 7.0 (TID 709) in 116 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T19:57:25.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 115.0 in stage 7.0 (TID 718)
[2025-07-19T19:57:25.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 8b44f3d35cfa:44249 in memory (size: 35.4 KiB, free: 434.0 MiB)
[2025-07-19T19:57:25.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 107.0 in stage 7.0 (TID 710) in 114 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T19:57:25.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7671b9c4
[2025-07-19T19:57:25.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114] for update
[2025-07-19T19:57:25.471+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.472+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e069956
[2025-07-19T19:57:25.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.2.delta.2a542365-8d06-45c9-b26b-c575d7d2396f.TID715.tmp
[2025-07-19T19:57:25.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115] for update
[2025-07-19T19:57:25.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 8b44f3d35cfa:44249 in memory (size: 29.6 KiB, free: 434.1 MiB)
[2025-07-19T19:57:25.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.2.delta.f13ec5fd-aee3-4f36-88be-cb86695f1c8c.TID716.tmp
[2025-07-19T19:57:25.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.2.delta.8cbe1901-918e-4319-9aab-d37cf3566687.TID711.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/2.delta
[2025-07-19T19:57:25.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/108/2.delta
[2025-07-19T19:57:25.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T19:57:25.480+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.2.delta.5e99d682-2f64-4a5d-8638-4badc1170470.TID717.tmp
[2025-07-19T19:57:25.480+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T19:57:25.480+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 108.0 in stage 7.0 (TID 711). 5872 bytes result sent to driver
[2025-07-19T19:57:25.480+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.2.delta.08b6bd67-6709-4eae-8ac7-1ee98e68bfa1.TID718.tmp
[2025-07-19T19:57:25.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 116.0 in stage 7.0 (TID 719) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.482+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 116.0 in stage 7.0 (TID 719)
[2025-07-19T19:57:25.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 108.0 in stage 7.0 (TID 711) in 120 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T19:57:25.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.488+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.2.delta.7d59425f-3977-43e1-b6fc-d651fb0670ba.TID713.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/2.delta
[2025-07-19T19:57:25.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/110/2.delta
[2025-07-19T19:57:25.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 8b44f3d35cfa:44249 in memory (size: 29.6 KiB, free: 434.1 MiB)
[2025-07-19T19:57:25.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T19:57:25.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.2.delta.62252f25-7303-4a1a-b049-4bff4b7bc2e5.TID712.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/2.delta
[2025-07-19T19:57:25.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/109/2.delta
[2025-07-19T19:57:25.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T19:57:25.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2008731b
[2025-07-19T19:57:25.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116] for update
[2025-07-19T19:57:25.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T19:57:25.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T19:57:25.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 110.0 in stage 7.0 (TID 713). 5829 bytes result sent to driver
[2025-07-19T19:57:25.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.2.delta.7b9a1529-77bc-4623-94b8-25070860ae77.TID714.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/2.delta
[2025-07-19T19:57:25.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/111/2.delta
[2025-07-19T19:57:25.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 117.0 in stage 7.0 (TID 720) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T19:57:25.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 109.0 in stage 7.0 (TID 712). 5915 bytes result sent to driver
[2025-07-19T19:57:25.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 117.0 in stage 7.0 (TID 720)
[2025-07-19T19:57:25.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 110.0 in stage 7.0 (TID 713) in 104 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T19:57:25.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 118.0 in stage 7.0 (TID 721) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 118.0 in stage 7.0 (TID 721)
[2025-07-19T19:57:25.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@471f0d93
[2025-07-19T19:57:25.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 8b44f3d35cfa:44249 in memory (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T19:57:25.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117] for update
[2025-07-19T19:57:25.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 109.0 in stage 7.0 (TID 712) in 137 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T19:57:25.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T19:57:25.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@598713e3
[2025-07-19T19:57:25.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118] for update
[2025-07-19T19:57:25.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 111.0 in stage 7.0 (TID 714). 5829 bytes result sent to driver
[2025-07-19T19:57:25.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.2.delta.2a542365-8d06-45c9-b26b-c575d7d2396f.TID715.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/2.delta
[2025-07-19T19:57:25.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/112/2.delta
[2025-07-19T19:57:25.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.2.delta.f13ec5fd-aee3-4f36-88be-cb86695f1c8c.TID716.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/2.delta
[2025-07-19T19:57:25.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/113/2.delta
[2025-07-19T19:57:25.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 119.0 in stage 7.0 (TID 722) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T19:57:25.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T19:57:25.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 119.0 in stage 7.0 (TID 722)
[2025-07-19T19:57:25.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.2.delta.0c0021b8-6de1-48e6-9512-f08ffe82df30.TID720.tmp
[2025-07-19T19:57:25.513+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 111.0 in stage 7.0 (TID 714) in 98 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T19:57:25.515+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 8b44f3d35cfa:44249 in memory (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T19:57:25.516+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.2.delta.cea46e65-d491-45db-a37d-2f8330c1a098.TID719.tmp
[2025-07-19T19:57:25.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T19:57:25.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.2.delta.08b6bd67-6709-4eae-8ac7-1ee98e68bfa1.TID718.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/2.delta
[2025-07-19T19:57:25.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/115/2.delta
[2025-07-19T19:57:25.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.2.delta.5e99d682-2f64-4a5d-8638-4badc1170470.TID717.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/2.delta
[2025-07-19T19:57:25.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/114/2.delta
[2025-07-19T19:57:25.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T19:57:25.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T19:57:25.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 112.0 in stage 7.0 (TID 715). 5829 bytes result sent to driver
[2025-07-19T19:57:25.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 120.0 in stage 7.0 (TID 723) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 112.0 in stage 7.0 (TID 715) in 88 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T19:57:25.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T19:57:25.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 120.0 in stage 7.0 (TID 723)
[2025-07-19T19:57:25.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 113.0 in stage 7.0 (TID 716). 5829 bytes result sent to driver
[2025-07-19T19:57:25.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 121.0 in stage 7.0 (TID 724) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.2.delta.aea4c8e0-c7b2-47f1-98cf-0d9624393672.TID721.tmp
[2025-07-19T19:57:25.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 121.0 in stage 7.0 (TID 724)
[2025-07-19T19:57:25.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:25.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@746f3b41
[2025-07-19T19:57:25.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:25.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T19:57:25.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 113.0 in stage 7.0 (TID 716) in 91 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T19:57:25.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 114.0 in stage 7.0 (TID 717). 5829 bytes result sent to driver
[2025-07-19T19:57:25.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119] for update
[2025-07-19T19:57:25.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 114.0 in stage 7.0 (TID 717) in 66 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T19:57:25.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 122.0 in stage 7.0 (TID 725) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 122.0 in stage 7.0 (TID 725)
[2025-07-19T19:57:25.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T19:57:25.532+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 115.0 in stage 7.0 (TID 718). 5829 bytes result sent to driver
[2025-07-19T19:57:25.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f39c45c
[2025-07-19T19:57:25.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121] for update
[2025-07-19T19:57:25.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77dfd9c2
[2025-07-19T19:57:25.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 8b44f3d35cfa:44249 in memory (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T19:57:25.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 123.0 in stage 7.0 (TID 726) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 115.0 in stage 7.0 (TID 718) in 68 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T19:57:25.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 123.0 in stage 7.0 (TID 726)
[2025-07-19T19:57:25.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120] for update
[2025-07-19T19:57:25.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@313cf393
[2025-07-19T19:57:25.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122] for update
[2025-07-19T19:57:25.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 8b44f3d35cfa:44249 in memory (size: 19.3 KiB, free: 434.2 MiB)
[2025-07-19T19:57:25.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:25.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75963e3f
[2025-07-19T19:57:25.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123] for update
[2025-07-19T19:57:25.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.2.delta.4ff4777b-57c2-4cf1-a6bc-b4ceca7509ec.TID722.tmp
[2025-07-19T19:57:25.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.2.delta.f84736a6-8d39-478a-ab9b-e11dc5823260.TID724.tmp
[2025-07-19T19:57:25.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.2.delta.4396b272-0374-4fd3-9f8f-4933ed2e7568.TID725.tmp
[2025-07-19T19:57:25.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 8b44f3d35cfa:44249 in memory (size: 19.9 KiB, free: 434.2 MiB)
[2025-07-19T19:57:25.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.2.delta.a7557742-222c-4903-b3b4-942338f6edf9.TID723.tmp
[2025-07-19T19:57:25.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.2.delta.7274b4b5-f924-4633-a4a5-e703696cfadd.TID726.tmp
[2025-07-19T19:57:25.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.2.delta.0c0021b8-6de1-48e6-9512-f08ffe82df30.TID720.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/2.delta
[2025-07-19T19:57:25.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/117/2.delta
[2025-07-19T19:57:25.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.2.delta.aea4c8e0-c7b2-47f1-98cf-0d9624393672.TID721.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/2.delta
[2025-07-19T19:57:25.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/118/2.delta
[2025-07-19T19:57:25.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 8b44f3d35cfa:44249 in memory (size: 19.7 KiB, free: 434.2 MiB)
[2025-07-19T19:57:25.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T19:57:25.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T19:57:25.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.2.delta.cea46e65-d491-45db-a37d-2f8330c1a098.TID719.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/2.delta
[2025-07-19T19:57:25.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/116/2.delta
[2025-07-19T19:57:25.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T19:57:25.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T19:57:25.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 117.0 in stage 7.0 (TID 720). 5829 bytes result sent to driver
[2025-07-19T19:57:25.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T19:57:25.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 118.0 in stage 7.0 (TID 721). 5829 bytes result sent to driver
[2025-07-19T19:57:25.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 124.0 in stage 7.0 (TID 727) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 125.0 in stage 7.0 (TID 728) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 124.0 in stage 7.0 (TID 727)
[2025-07-19T19:57:25.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 117.0 in stage 7.0 (TID 720) in 60 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T19:57:25.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 125.0 in stage 7.0 (TID 728)
[2025-07-19T19:57:25.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 118.0 in stage 7.0 (TID 721) in 56 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T19:57:25.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T19:57:25.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 116.0 in stage 7.0 (TID 719). 5829 bytes result sent to driver
[2025-07-19T19:57:25.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d198cf2
[2025-07-19T19:57:25.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 126.0 in stage 7.0 (TID 729) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124] for update
[2025-07-19T19:57:25.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 116.0 in stage 7.0 (TID 719) in 82 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T19:57:25.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 126.0 in stage 7.0 (TID 729)
[2025-07-19T19:57:25.569+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@174d307b
[2025-07-19T19:57:25.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125] for update
[2025-07-19T19:57:25.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6938352f
[2025-07-19T19:57:25.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.2.delta.f84736a6-8d39-478a-ab9b-e11dc5823260.TID724.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/2.delta
[2025-07-19T19:57:25.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/121/2.delta
[2025-07-19T19:57:25.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126] for update
[2025-07-19T19:57:25.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T19:57:25.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T19:57:25.577+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 121.0 in stage 7.0 (TID 724). 5829 bytes result sent to driver
[2025-07-19T19:57:25.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 127.0 in stage 7.0 (TID 730) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 121.0 in stage 7.0 (TID 724) in 56 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T19:57:25.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 127.0 in stage 7.0 (TID 730)
[2025-07-19T19:57:25.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.2.delta.4396b272-0374-4fd3-9f8f-4933ed2e7568.TID725.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/2.delta
[2025-07-19T19:57:25.580+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/122/2.delta
[2025-07-19T19:57:25.580+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T19:57:25.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.582+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.582+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb5e233
[2025-07-19T19:57:25.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.2.delta.4ff4777b-57c2-4cf1-a6bc-b4ceca7509ec.TID722.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/2.delta
[2025-07-19T19:57:25.583+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/119/2.delta
[2025-07-19T19:57:25.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.585+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127] for update
[2025-07-19T19:57:25.586+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T19:57:25.586+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.2.delta.cbc07d4d-d31a-409d-9046-54cd1d9cfc55.TID727.tmp
[2025-07-19T19:57:25.586+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.2.delta.59dac68f-3bc9-4921-88b4-ba5a4d4475a7.TID729.tmp
[2025-07-19T19:57:25.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T19:57:25.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 122.0 in stage 7.0 (TID 725). 5829 bytes result sent to driver
[2025-07-19T19:57:25.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T19:57:25.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 119.0 in stage 7.0 (TID 722). 5829 bytes result sent to driver
[2025-07-19T19:57:25.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 128.0 in stage 7.0 (TID 731) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.589+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 129.0 in stage 7.0 (TID 732) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.2.delta.3359d08c-a4b0-4f87-9908-6b969acad107.TID728.tmp
[2025-07-19T19:57:25.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 128.0 in stage 7.0 (TID 731)
[2025-07-19T19:57:25.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 119.0 in stage 7.0 (TID 722) in 75 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T19:57:25.593+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 122.0 in stage 7.0 (TID 725) in 63 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T19:57:25.594+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 129.0 in stage 7.0 (TID 732)
[2025-07-19T19:57:25.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.2.delta.7274b4b5-f924-4633-a4a5-e703696cfadd.TID726.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/2.delta
[2025-07-19T19:57:25.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/123/2.delta
[2025-07-19T19:57:25.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T19:57:25.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21dfcf98
[2025-07-19T19:57:25.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.597+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.597+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128] for update
[2025-07-19T19:57:25.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.2.delta.03320b2a-942b-4879-b6b2-1242039dab48.TID730.tmp
[2025-07-19T19:57:25.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T19:57:25.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 123.0 in stage 7.0 (TID 726). 5829 bytes result sent to driver
[2025-07-19T19:57:25.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 130.0 in stage 7.0 (TID 733) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.600+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 123.0 in stage 7.0 (TID 726) in 68 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T19:57:25.600+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 130.0 in stage 7.0 (TID 733)
[2025-07-19T19:57:25.601+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b9c810b
[2025-07-19T19:57:25.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129] for update
[2025-07-19T19:57:25.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c1589b4
[2025-07-19T19:57:25.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.2.delta.a7557742-222c-4903-b3b4-942338f6edf9.TID723.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/2.delta
[2025-07-19T19:57:25.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/120/2.delta
[2025-07-19T19:57:25.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T19:57:25.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130] for update
[2025-07-19T19:57:25.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.606+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T19:57:25.607+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 120.0 in stage 7.0 (TID 723). 5829 bytes result sent to driver
[2025-07-19T19:57:25.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 131.0 in stage 7.0 (TID 734) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 120.0 in stage 7.0 (TID 723) in 92 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T19:57:25.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 131.0 in stage 7.0 (TID 734)
[2025-07-19T19:57:25.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.2.delta.c62c9ad0-d769-4f6b-8962-bdf0a97dc4f7.TID732.tmp
[2025-07-19T19:57:25.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.2.delta.586e9598-499c-4caf-90b8-4e72d08ad0e9.TID731.tmp
[2025-07-19T19:57:25.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.2.delta.7fdae20d-f1ad-4f7f-bc75-ac7a1816a7b3.TID733.tmp
[2025-07-19T19:57:25.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55cddac3
[2025-07-19T19:57:25.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.2.delta.3359d08c-a4b0-4f87-9908-6b969acad107.TID728.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/2.delta
[2025-07-19T19:57:25.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/125/2.delta
[2025-07-19T19:57:25.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131] for update
[2025-07-19T19:57:25.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T19:57:25.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T19:57:25.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 125.0 in stage 7.0 (TID 728). 5829 bytes result sent to driver
[2025-07-19T19:57:25.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 132.0 in stage 7.0 (TID 735) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.2.delta.03320b2a-942b-4879-b6b2-1242039dab48.TID730.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/2.delta
[2025-07-19T19:57:25.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/127/2.delta
[2025-07-19T19:57:25.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 132.0 in stage 7.0 (TID 735)
[2025-07-19T19:57:25.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 125.0 in stage 7.0 (TID 728) in 68 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T19:57:25.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T19:57:25.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.2.delta.cbc07d4d-d31a-409d-9046-54cd1d9cfc55.TID727.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/2.delta
[2025-07-19T19:57:25.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/124/2.delta
[2025-07-19T19:57:25.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.2.delta.59dac68f-3bc9-4921-88b4-ba5a4d4475a7.TID729.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/2.delta
[2025-07-19T19:57:25.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/126/2.delta
[2025-07-19T19:57:25.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T19:57:25.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 127.0 in stage 7.0 (TID 730). 5829 bytes result sent to driver
[2025-07-19T19:57:25.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T19:57:25.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 133.0 in stage 7.0 (TID 736) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T19:57:25.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.2.delta.222dffae-5622-4eab-a5c7-e8e3cfc67d34.TID734.tmp
[2025-07-19T19:57:25.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T19:57:25.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 126.0 in stage 7.0 (TID 729). 5829 bytes result sent to driver
[2025-07-19T19:57:25.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:25.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T19:57:25.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 124.0 in stage 7.0 (TID 727). 5829 bytes result sent to driver
[2025-07-19T19:57:25.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 134.0 in stage 7.0 (TID 737) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5527a5fb
[2025-07-19T19:57:25.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 134.0 in stage 7.0 (TID 737)
[2025-07-19T19:57:25.647+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 133.0 in stage 7.0 (TID 736)
[2025-07-19T19:57:25.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132] for update
[2025-07-19T19:57:25.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.2.delta.586e9598-499c-4caf-90b8-4e72d08ad0e9.TID731.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/2.delta
[2025-07-19T19:57:25.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/128/2.delta
[2025-07-19T19:57:25.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T19:57:25.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 135.0 in stage 7.0 (TID 738) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.2.delta.c62c9ad0-d769-4f6b-8962-bdf0a97dc4f7.TID732.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/2.delta
[2025-07-19T19:57:25.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/129/2.delta
[2025-07-19T19:57:25.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 124.0 in stage 7.0 (TID 727) in 87 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T19:57:25.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T19:57:25.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 127.0 in stage 7.0 (TID 730) in 72 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T19:57:25.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f81a01a
[2025-07-19T19:57:25.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 126.0 in stage 7.0 (TID 729) in 81 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T19:57:25.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 135.0 in stage 7.0 (TID 738)
[2025-07-19T19:57:25.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133] for update
[2025-07-19T19:57:25.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20ed5e56
[2025-07-19T19:57:25.661+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134] for update
[2025-07-19T19:57:25.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T19:57:25.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.2.delta.7fdae20d-f1ad-4f7f-bc75-ac7a1816a7b3.TID733.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/2.delta
[2025-07-19T19:57:25.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/130/2.delta
[2025-07-19T19:57:25.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T19:57:25.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 128.0 in stage 7.0 (TID 731). 5829 bytes result sent to driver
[2025-07-19T19:57:25.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T19:57:25.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 129.0 in stage 7.0 (TID 732). 5829 bytes result sent to driver
[2025-07-19T19:57:25.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f10b7f4
[2025-07-19T19:57:25.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 136.0 in stage 7.0 (TID 739) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 137.0 in stage 7.0 (TID 740) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 136.0 in stage 7.0 (TID 739)
[2025-07-19T19:57:25.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 129.0 in stage 7.0 (TID 732) in 67 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T19:57:25.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T19:57:25.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 128.0 in stage 7.0 (TID 731) in 68 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T19:57:25.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135] for update
[2025-07-19T19:57:25.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 130.0 in stage 7.0 (TID 733). 5829 bytes result sent to driver
[2025-07-19T19:57:25.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 137.0 in stage 7.0 (TID 740)
[2025-07-19T19:57:25.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 138.0 in stage 7.0 (TID 741) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.668+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30da5225
[2025-07-19T19:57:25.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136] for update
[2025-07-19T19:57:25.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 138.0 in stage 7.0 (TID 741)
[2025-07-19T19:57:25.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 130.0 in stage 7.0 (TID 733) in 62 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T19:57:25.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.2.delta.936bcbed-995e-4de0-888d-3da0b6c3961d.TID735.tmp
[2025-07-19T19:57:25.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.674+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.674+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b8ce874
[2025-07-19T19:57:25.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137] for update
[2025-07-19T19:57:25.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.2.delta.a56289d5-0cf1-4e0b-a5a5-6a8020f3b95d.TID736.tmp
[2025-07-19T19:57:25.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@272c4923
[2025-07-19T19:57:25.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.2.delta.950f0158-01d3-4d03-a50f-b072b617004f.TID737.tmp
[2025-07-19T19:57:25.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138] for update
[2025-07-19T19:57:25.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.2.delta.0d097b94-a618-45df-8074-a1fc1d462a73.TID738.tmp
[2025-07-19T19:57:25.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.2.delta.a34a5c14-68d7-4d19-91ab-fb7e69f1b686.TID739.tmp
[2025-07-19T19:57:25.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.2.delta.222dffae-5622-4eab-a5c7-e8e3cfc67d34.TID734.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/2.delta
[2025-07-19T19:57:25.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/131/2.delta
[2025-07-19T19:57:25.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T19:57:25.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.2.delta.540de283-2608-4e70-828c-16c3f7635878.TID740.tmp
[2025-07-19T19:57:25.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T19:57:25.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 131.0 in stage 7.0 (TID 734). 5829 bytes result sent to driver
[2025-07-19T19:57:25.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 139.0 in stage 7.0 (TID 742) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 139.0 in stage 7.0 (TID 742)
[2025-07-19T19:57:25.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 131.0 in stage 7.0 (TID 734) in 67 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T19:57:25.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.2.delta.4c470f5e-97e4-43a9-9228-205662f20d21.TID741.tmp
[2025-07-19T19:57:25.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cf4dc5
[2025-07-19T19:57:25.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139] for update
[2025-07-19T19:57:25.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.2.delta.936bcbed-995e-4de0-888d-3da0b6c3961d.TID735.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/2.delta
[2025-07-19T19:57:25.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/132/2.delta
[2025-07-19T19:57:25.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T19:57:25.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T19:57:25.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 132.0 in stage 7.0 (TID 735). 5829 bytes result sent to driver
[2025-07-19T19:57:25.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.2.delta.a56289d5-0cf1-4e0b-a5a5-6a8020f3b95d.TID736.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/2.delta
[2025-07-19T19:57:25.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/133/2.delta
[2025-07-19T19:57:25.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 140.0 in stage 7.0 (TID 743) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T19:57:25.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 132.0 in stage 7.0 (TID 735) in 63 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T19:57:25.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 140.0 in stage 7.0 (TID 743)
[2025-07-19T19:57:25.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.2.delta.0d097b94-a618-45df-8074-a1fc1d462a73.TID738.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/2.delta
[2025-07-19T19:57:25.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/135/2.delta
[2025-07-19T19:57:25.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.2.delta.950f0158-01d3-4d03-a50f-b072b617004f.TID737.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/2.delta
[2025-07-19T19:57:25.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/134/2.delta
[2025-07-19T19:57:25.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T19:57:25.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T19:57:25.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.2.delta.779d023d-1e9a-4c11-b9e5-496a289a95f7.TID742.tmp
[2025-07-19T19:57:25.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.697+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T19:57:25.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 133.0 in stage 7.0 (TID 736). 5829 bytes result sent to driver
[2025-07-19T19:57:25.698+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dc70f44
[2025-07-19T19:57:25.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140] for update
[2025-07-19T19:57:25.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 141.0 in stage 7.0 (TID 744) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T19:57:25.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 141.0 in stage 7.0 (TID 744)
[2025-07-19T19:57:25.703+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T19:57:25.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 135.0 in stage 7.0 (TID 738). 5829 bytes result sent to driver
[2025-07-19T19:57:25.705+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 133.0 in stage 7.0 (TID 736) in 63 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T19:57:25.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 134.0 in stage 7.0 (TID 737). 5829 bytes result sent to driver
[2025-07-19T19:57:25.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 142.0 in stage 7.0 (TID 745) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 142.0 in stage 7.0 (TID 745)
[2025-07-19T19:57:25.706+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 143.0 in stage 7.0 (TID 746) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.707+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 134.0 in stage 7.0 (TID 737) in 55 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T19:57:25.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 135.0 in stage 7.0 (TID 738) in 53 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T19:57:25.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 143.0 in stage 7.0 (TID 746)
[2025-07-19T19:57:25.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f1d8549
[2025-07-19T19:57:25.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.710+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.710+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141] for update
[2025-07-19T19:57:25.710+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.2.delta.a34a5c14-68d7-4d19-91ab-fb7e69f1b686.TID739.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/2.delta
[2025-07-19T19:57:25.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/136/2.delta
[2025-07-19T19:57:25.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T19:57:25.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45fae4cd
[2025-07-19T19:57:25.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143] for update
[2025-07-19T19:57:25.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.2.delta.540de283-2608-4e70-828c-16c3f7635878.TID740.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/2.delta
[2025-07-19T19:57:25.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/137/2.delta
[2025-07-19T19:57:25.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T19:57:25.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f10025d
[2025-07-19T19:57:25.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T19:57:25.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 136.0 in stage 7.0 (TID 739). 5829 bytes result sent to driver
[2025-07-19T19:57:25.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142] for update
[2025-07-19T19:57:25.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 144.0 in stage 7.0 (TID 747) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.2.delta.2e6e7bb5-a5ca-4337-b92a-e59238db6d63.TID743.tmp
[2025-07-19T19:57:25.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 136.0 in stage 7.0 (TID 739) in 53 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T19:57:25.722+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T19:57:25.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 144.0 in stage 7.0 (TID 747)
[2025-07-19T19:57:25.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 137.0 in stage 7.0 (TID 740). 5829 bytes result sent to driver
[2025-07-19T19:57:25.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 145.0 in stage 7.0 (TID 748) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.724+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.2.delta.2a96599c-ce71-4115-b39c-34d3701da74b.TID744.tmp
[2025-07-19T19:57:25.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 137.0 in stage 7.0 (TID 740) in 55 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T19:57:25.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 145.0 in stage 7.0 (TID 748)
[2025-07-19T19:57:25.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.2.delta.0620e4df-a908-494c-871f-307ee0e9307a.TID746.tmp
[2025-07-19T19:57:25.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:25.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:25.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@637076ca
[2025-07-19T19:57:25.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145] for update
[2025-07-19T19:57:25.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.2.delta.4c470f5e-97e4-43a9-9228-205662f20d21.TID741.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/2.delta
[2025-07-19T19:57:25.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/138/2.delta
[2025-07-19T19:57:25.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.2.delta.f30663c1-5643-4aed-9680-6362782b6d7c.TID745.tmp
[2025-07-19T19:57:25.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T19:57:25.729+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30a61301
[2025-07-19T19:57:25.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144] for update
[2025-07-19T19:57:25.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T19:57:25.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 138.0 in stage 7.0 (TID 741). 5829 bytes result sent to driver
[2025-07-19T19:57:25.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 146.0 in stage 7.0 (TID 749) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 138.0 in stage 7.0 (TID 741) in 68 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T19:57:25.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 146.0 in stage 7.0 (TID 749)
[2025-07-19T19:57:25.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.2.delta.1ba8b9d1-db91-4b5b-857e-480ddeaa2f4c.TID748.tmp
[2025-07-19T19:57:25.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.2.delta.779d023d-1e9a-4c11-b9e5-496a289a95f7.TID742.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/2.delta
[2025-07-19T19:57:25.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34bdda52
[2025-07-19T19:57:25.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/139/2.delta
[2025-07-19T19:57:25.737+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T19:57:25.737+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146] for update
[2025-07-19T19:57:25.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.2.delta.bb9ad3f6-14f8-45f1-a540-8397cd83d56f.TID747.tmp
[2025-07-19T19:57:25.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T19:57:25.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 139.0 in stage 7.0 (TID 742). 5829 bytes result sent to driver
[2025-07-19T19:57:25.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 147.0 in stage 7.0 (TID 750) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 139.0 in stage 7.0 (TID 742) in 60 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T19:57:25.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 147.0 in stage 7.0 (TID 750)
[2025-07-19T19:57:25.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.2.delta.2a96599c-ce71-4115-b39c-34d3701da74b.TID744.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/2.delta
[2025-07-19T19:57:25.744+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/141/2.delta
[2025-07-19T19:57:25.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T19:57:25.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.2.delta.2e6e7bb5-a5ca-4337-b92a-e59238db6d63.TID743.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/2.delta
[2025-07-19T19:57:25.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/140/2.delta
[2025-07-19T19:57:25.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2880d345
[2025-07-19T19:57:25.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T19:57:25.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147] for update
[2025-07-19T19:57:25.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T19:57:25.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 141.0 in stage 7.0 (TID 744). 5829 bytes result sent to driver
[2025-07-19T19:57:25.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.2.delta.0620e4df-a908-494c-871f-307ee0e9307a.TID746.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/2.delta
[2025-07-19T19:57:25.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/143/2.delta
[2025-07-19T19:57:25.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.2.delta.34644600-6b4d-4b1e-8989-a2783a958542.TID749.tmp
[2025-07-19T19:57:25.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 148.0 in stage 7.0 (TID 751) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 141.0 in stage 7.0 (TID 744) in 49 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T19:57:25.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T19:57:25.752+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 148.0 in stage 7.0 (TID 751)
[2025-07-19T19:57:25.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T19:57:25.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.2.delta.f30663c1-5643-4aed-9680-6362782b6d7c.TID745.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/2.delta
[2025-07-19T19:57:25.754+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/142/2.delta
[2025-07-19T19:57:25.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 140.0 in stage 7.0 (TID 743). 5829 bytes result sent to driver
[2025-07-19T19:57:25.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T19:57:25.757+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 149.0 in stage 7.0 (TID 752) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 140.0 in stage 7.0 (TID 743) in 57 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T19:57:25.759+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 149.0 in stage 7.0 (TID 752)
[2025-07-19T19:57:25.760+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.760+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.764+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T19:57:25.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 142.0 in stage 7.0 (TID 745). 5829 bytes result sent to driver
[2025-07-19T19:57:25.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 150.0 in stage 7.0 (TID 753) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T19:57:25.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5735e447
[2025-07-19T19:57:25.765+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 150.0 in stage 7.0 (TID 753)
[2025-07-19T19:57:25.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 142.0 in stage 7.0 (TID 745) in 55 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T19:57:25.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 143.0 in stage 7.0 (TID 746). 5829 bytes result sent to driver
[2025-07-19T19:57:25.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148] for update
[2025-07-19T19:57:25.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.2.delta.8623ddd4-88bb-460b-a052-fac8f724ac2e.TID750.tmp
[2025-07-19T19:57:25.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 151.0 in stage 7.0 (TID 754) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.766+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ff37c32
[2025-07-19T19:57:25.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 143.0 in stage 7.0 (TID 746) in 59 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T19:57:25.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 151.0 in stage 7.0 (TID 754)
[2025-07-19T19:57:25.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.2.delta.1ba8b9d1-db91-4b5b-857e-480ddeaa2f4c.TID748.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/2.delta
[2025-07-19T19:57:25.768+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/145/2.delta
[2025-07-19T19:57:25.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T19:57:25.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6be1784f
[2025-07-19T19:57:25.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149] for update
[2025-07-19T19:57:25.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150] for update
[2025-07-19T19:57:25.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T19:57:25.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 145.0 in stage 7.0 (TID 748). 5829 bytes result sent to driver
[2025-07-19T19:57:25.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.2.delta.bb9ad3f6-14f8-45f1-a540-8397cd83d56f.TID747.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/2.delta
[2025-07-19T19:57:25.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/144/2.delta
[2025-07-19T19:57:25.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 152.0 in stage 7.0 (TID 755) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T19:57:25.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 145.0 in stage 7.0 (TID 748) in 54 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T19:57:25.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 152.0 in stage 7.0 (TID 755)
[2025-07-19T19:57:25.772+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c06eec0
[2025-07-19T19:57:25.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T19:57:25.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.2.delta.f872bdf1-6400-4f71-9170-49944453f7d7.TID751.tmp
[2025-07-19T19:57:25.774+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151] for update
[2025-07-19T19:57:25.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 144.0 in stage 7.0 (TID 747). 5829 bytes result sent to driver
[2025-07-19T19:57:25.775+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 153.0 in stage 7.0 (TID 756) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 144.0 in stage 7.0 (TID 747) in 62 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T19:57:25.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 153.0 in stage 7.0 (TID 756)
[2025-07-19T19:57:25.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f1040c5
[2025-07-19T19:57:25.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.776+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152] for update
[2025-07-19T19:57:25.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.2.delta.e470c709-543d-4679-9542-358571d12fec.TID753.tmp
[2025-07-19T19:57:25.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15efdb7f
[2025-07-19T19:57:25.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153] for update
[2025-07-19T19:57:25.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.777+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.2.delta.64bb1845-a051-43b4-b514-0cd64a36e117.TID755.tmp
[2025-07-19T19:57:25.780+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.2.delta.b3ebcc94-bcce-435b-9b55-5cd9d306b0c1.TID752.tmp
[2025-07-19T19:57:25.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.2.delta.34644600-6b4d-4b1e-8989-a2783a958542.TID749.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/2.delta
[2025-07-19T19:57:25.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/146/2.delta
[2025-07-19T19:57:25.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.2.delta.1c4a278d-fce6-40cb-aab4-b509482693fe.TID756.tmp
[2025-07-19T19:57:25.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T19:57:25.792+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.2.delta.4479b01c-3da7-4d8a-81cc-8d3478f0f5bb.TID754.tmp
[2025-07-19T19:57:25.802+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T19:57:25.804+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 146.0 in stage 7.0 (TID 749). 5915 bytes result sent to driver
[2025-07-19T19:57:25.806+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 154.0 in stage 7.0 (TID 757) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 146.0 in stage 7.0 (TID 749) in 88 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T19:57:25.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 154.0 in stage 7.0 (TID 757)
[2025-07-19T19:57:25.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.2.delta.8623ddd4-88bb-460b-a052-fac8f724ac2e.TID750.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/2.delta
[2025-07-19T19:57:25.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/147/2.delta
[2025-07-19T19:57:25.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T19:57:25.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T19:57:25.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@579df0fe
[2025-07-19T19:57:25.818+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154] for update
[2025-07-19T19:57:25.820+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 147.0 in stage 7.0 (TID 750). 5872 bytes result sent to driver
[2025-07-19T19:57:25.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 155.0 in stage 7.0 (TID 758) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 155.0 in stage 7.0 (TID 758)
[2025-07-19T19:57:25.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 147.0 in stage 7.0 (TID 750) in 88 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T19:57:25.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59304076
[2025-07-19T19:57:25.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155] for update
[2025-07-19T19:57:25.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.2.delta.685233bc-424d-46fc-bfa7-5c58a0246eea.TID757.tmp
[2025-07-19T19:57:25.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.2.delta.e470c709-543d-4679-9542-358571d12fec.TID753.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/2.delta
[2025-07-19T19:57:25.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/150/2.delta
[2025-07-19T19:57:25.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T19:57:25.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.2.delta.64bb1845-a051-43b4-b514-0cd64a36e117.TID755.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/2.delta
[2025-07-19T19:57:25.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/152/2.delta
[2025-07-19T19:57:25.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T19:57:25.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.2.delta.4479b01c-3da7-4d8a-81cc-8d3478f0f5bb.TID754.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/2.delta
[2025-07-19T19:57:25.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/151/2.delta
[2025-07-19T19:57:25.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T19:57:25.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.2.delta.9d4b845e-a220-4986-b1bd-c5c7fdc69c0d.TID758.tmp
[2025-07-19T19:57:25.841+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T19:57:25.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 150.0 in stage 7.0 (TID 753). 5872 bytes result sent to driver
[2025-07-19T19:57:25.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 156.0 in stage 7.0 (TID 759) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T19:57:25.848+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 156.0 in stage 7.0 (TID 759)
[2025-07-19T19:57:25.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.2.delta.b3ebcc94-bcce-435b-9b55-5cd9d306b0c1.TID752.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/2.delta
[2025-07-19T19:57:25.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/149/2.delta
[2025-07-19T19:57:25.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 150.0 in stage 7.0 (TID 753) in 93 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T19:57:25.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T19:57:25.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.2.delta.f872bdf1-6400-4f71-9170-49944453f7d7.TID751.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/2.delta
[2025-07-19T19:57:25.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/148/2.delta
[2025-07-19T19:57:25.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T19:57:25.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 152.0 in stage 7.0 (TID 755). 5872 bytes result sent to driver
[2025-07-19T19:57:25.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 157.0 in stage 7.0 (TID 760) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 152.0 in stage 7.0 (TID 755) in 85 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T19:57:25.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T19:57:25.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 157.0 in stage 7.0 (TID 760)
[2025-07-19T19:57:25.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 151.0 in stage 7.0 (TID 754). 5872 bytes result sent to driver
[2025-07-19T19:57:25.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.858+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.2.delta.1c4a278d-fce6-40cb-aab4-b509482693fe.TID756.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/2.delta
[2025-07-19T19:57:25.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/153/2.delta
[2025-07-19T19:57:25.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 158.0 in stage 7.0 (TID 761) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4246cb41
[2025-07-19T19:57:25.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 158.0 in stage 7.0 (TID 761)
[2025-07-19T19:57:25.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T19:57:25.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156] for update
[2025-07-19T19:57:25.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 151.0 in stage 7.0 (TID 754) in 96 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T19:57:25.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T19:57:25.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 148.0 in stage 7.0 (TID 751). 5872 bytes result sent to driver
[2025-07-19T19:57:25.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f61a0d3
[2025-07-19T19:57:25.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T19:57:25.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 149.0 in stage 7.0 (TID 752). 5872 bytes result sent to driver
[2025-07-19T19:57:25.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 159.0 in stage 7.0 (TID 762) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 160.0 in stage 7.0 (TID 763) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 160.0 in stage 7.0 (TID 763)
[2025-07-19T19:57:25.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 148.0 in stage 7.0 (TID 751) in 110 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T19:57:25.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 149.0 in stage 7.0 (TID 752) in 108 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T19:57:25.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157] for update
[2025-07-19T19:57:25.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 159.0 in stage 7.0 (TID 762)
[2025-07-19T19:57:25.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16b1903f
[2025-07-19T19:57:25.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158] for update
[2025-07-19T19:57:25.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T19:57:25.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a00e840
[2025-07-19T19:57:25.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159] for update
[2025-07-19T19:57:25.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 153.0 in stage 7.0 (TID 756). 5872 bytes result sent to driver
[2025-07-19T19:57:25.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 161.0 in stage 7.0 (TID 764) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.872+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4eef6d3d
[2025-07-19T19:57:25.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 161.0 in stage 7.0 (TID 764)
[2025-07-19T19:57:25.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160] for update
[2025-07-19T19:57:25.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 153.0 in stage 7.0 (TID 756) in 108 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T19:57:25.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.2.delta.1288e68b-f7ad-4435-bb6a-66809beff7bf.TID759.tmp
[2025-07-19T19:57:25.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6896915c
[2025-07-19T19:57:25.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161] for update
[2025-07-19T19:57:25.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.2.delta.067ccb31-3c2d-4bda-9de8-920e1ec9b66b.TID761.tmp
[2025-07-19T19:57:25.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.2.delta.ac7ddcae-aded-41bf-ba56-5cb2b7b80150.TID760.tmp
[2025-07-19T19:57:25.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.2.delta.50c3cb15-1395-4054-a3d5-6dd369c037e8.TID762.tmp
[2025-07-19T19:57:25.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.2.delta.19652382-ba79-4646-b418-fd442a6a4dac.TID763.tmp
[2025-07-19T19:57:25.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.2.delta.c8f99fd1-17f2-47b3-9519-2121ecbc5aa7.TID764.tmp
[2025-07-19T19:57:25.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.2.delta.685233bc-424d-46fc-bfa7-5c58a0246eea.TID757.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/2.delta
[2025-07-19T19:57:25.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/154/2.delta
[2025-07-19T19:57:25.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T19:57:25.916+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T19:57:25.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 154.0 in stage 7.0 (TID 757). 5872 bytes result sent to driver
[2025-07-19T19:57:25.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 162.0 in stage 7.0 (TID 765) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 154.0 in stage 7.0 (TID 757) in 104 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T19:57:25.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 162.0 in stage 7.0 (TID 765)
[2025-07-19T19:57:25.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4047beaf
[2025-07-19T19:57:25.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.922+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162] for update
[2025-07-19T19:57:25.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.2.delta.9d4b845e-a220-4986-b1bd-c5c7fdc69c0d.TID758.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/2.delta
[2025-07-19T19:57:25.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/155/2.delta
[2025-07-19T19:57:25.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T19:57:25.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.2.delta.34548f65-5869-4f34-b443-6658b3ff5da5.TID765.tmp
[2025-07-19T19:57:25.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T19:57:25.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 155.0 in stage 7.0 (TID 758). 5872 bytes result sent to driver
[2025-07-19T19:57:25.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 163.0 in stage 7.0 (TID 766) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 155.0 in stage 7.0 (TID 758) in 118 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T19:57:25.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 163.0 in stage 7.0 (TID 766)
[2025-07-19T19:57:25.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.2.delta.1288e68b-f7ad-4435-bb6a-66809beff7bf.TID759.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/2.delta
[2025-07-19T19:57:25.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/156/2.delta
[2025-07-19T19:57:25.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T19:57:25.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.2.delta.50c3cb15-1395-4054-a3d5-6dd369c037e8.TID762.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/2.delta
[2025-07-19T19:57:25.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/159/2.delta
[2025-07-19T19:57:25.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T19:57:25.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5649d9f8
[2025-07-19T19:57:25.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163] for update
[2025-07-19T19:57:25.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T19:57:25.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.2.delta.067ccb31-3c2d-4bda-9de8-920e1ec9b66b.TID761.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/2.delta
[2025-07-19T19:57:25.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/158/2.delta
[2025-07-19T19:57:25.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T19:57:25.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 159.0 in stage 7.0 (TID 762). 5872 bytes result sent to driver
[2025-07-19T19:57:25.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T19:57:25.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 156.0 in stage 7.0 (TID 759). 5872 bytes result sent to driver
[2025-07-19T19:57:25.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 164.0 in stage 7.0 (TID 767) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.2.delta.ac7ddcae-aded-41bf-ba56-5cb2b7b80150.TID760.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/2.delta
[2025-07-19T19:57:25.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/157/2.delta
[2025-07-19T19:57:25.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.2.delta.19652382-ba79-4646-b418-fd442a6a4dac.TID763.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/2.delta
[2025-07-19T19:57:25.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/160/2.delta
[2025-07-19T19:57:25.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T19:57:25.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T19:57:25.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 164.0 in stage 7.0 (TID 767)
[2025-07-19T19:57:25.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 165.0 in stage 7.0 (TID 768) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.2.delta.37cbbf83-2215-4c81-b8f8-238d6d892506.TID766.tmp
[2025-07-19T19:57:25.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T19:57:25.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 157.0 in stage 7.0 (TID 760). 5872 bytes result sent to driver
[2025-07-19T19:57:25.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T19:57:25.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 158.0 in stage 7.0 (TID 761). 5872 bytes result sent to driver
[2025-07-19T19:57:25.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ff0c0be
[2025-07-19T19:57:25.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 166.0 in stage 7.0 (TID 769) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164] for update
[2025-07-19T19:57:25.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 165.0 in stage 7.0 (TID 768)
[2025-07-19T19:57:25.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.2.delta.c8f99fd1-17f2-47b3-9519-2121ecbc5aa7.TID764.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/2.delta
[2025-07-19T19:57:25.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/161/2.delta
[2025-07-19T19:57:25.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 166.0 in stage 7.0 (TID 769)
[2025-07-19T19:57:25.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T19:57:25.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 160.0 in stage 7.0 (TID 763). 5872 bytes result sent to driver
[2025-07-19T19:57:25.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T19:57:25.993+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e6d62d6
[2025-07-19T19:57:25.994+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 167.0 in stage 7.0 (TID 770) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:25.994+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:25.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166] for update
[2025-07-19T19:57:25.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:25.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:25.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 159.0 in stage 7.0 (TID 762) in 142 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T19:57:25.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 158.0 in stage 7.0 (TID 761) in 148 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T19:57:25.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 157.0 in stage 7.0 (TID 760) in 150 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T19:57:25.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 156.0 in stage 7.0 (TID 759) in 154 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T19:57:25.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 167.0 in stage 7.0 (TID 770)
[2025-07-19T19:57:25.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:25.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T19:57:25.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 161.0 in stage 7.0 (TID 764). 5872 bytes result sent to driver
[2025-07-19T19:57:26.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.2.delta.34548f65-5869-4f34-b443-6658b3ff5da5.TID765.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/2.delta
[2025-07-19T19:57:26.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/162/2.delta
[2025-07-19T19:57:26.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35e06c6f
[2025-07-19T19:57:26.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T19:57:26.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.002+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165] for update
[2025-07-19T19:57:26.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 168.0 in stage 7.0 (TID 771) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 160.0 in stage 7.0 (TID 763) in 149 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T19:57:26.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 168.0 in stage 7.0 (TID 771)
[2025-07-19T19:57:26.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 169.0 in stage 7.0 (TID 772) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 161.0 in stage 7.0 (TID 764) in 142 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T19:57:26.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO DataWritingSparkTask: Committed partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T19:57:26.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Finished task 162.0 in stage 7.0 (TID 765). 5829 bytes result sent to driver
[2025-07-19T19:57:26.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 169.0 in stage 7.0 (TID 772)
[2025-07-19T19:57:26.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Finished task 162.0 in stage 7.0 (TID 765) in 91 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T19:57:26.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO TaskSetManager: Starting task 170.0 in stage 7.0 (TID 773) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:25 INFO Executor: Running task 170.0 in stage 7.0 (TID 773)
[2025-07-19T19:57:26.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.2.delta.678531b5-2d9c-4f5d-923c-bf33b42dfd4b.TID767.tmp
[2025-07-19T19:57:26.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16066ef
[2025-07-19T19:57:26.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.2.delta.6e1c35f7-0586-4725-b57c-f1115b850d7d.TID769.tmp
[2025-07-19T19:57:26.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168] for update
[2025-07-19T19:57:26.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52c92b50
[2025-07-19T19:57:26.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167] for update
[2025-07-19T19:57:26.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3314de78
[2025-07-19T19:57:26.014+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.014+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170] for update
[2025-07-19T19:57:26.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@192dccb6
[2025-07-19T19:57:26.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169] for update
[2025-07-19T19:57:26.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.2.delta.28352a93-e6d7-40b7-9feb-b18b25701e69.TID768.tmp
[2025-07-19T19:57:26.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.2.delta.37cbbf83-2215-4c81-b8f8-238d6d892506.TID766.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/2.delta
[2025-07-19T19:57:26.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/163/2.delta
[2025-07-19T19:57:26.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T19:57:26.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.2.delta.a077ae5d-ee1a-4b5f-a14f-924cb9673654.TID772.tmp
[2025-07-19T19:57:26.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T19:57:26.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 163.0 in stage 7.0 (TID 766). 5829 bytes result sent to driver
[2025-07-19T19:57:26.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.2.delta.1acc129e-39e4-4916-a76a-4a18f3132904.TID773.tmp
[2025-07-19T19:57:26.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 171.0 in stage 7.0 (TID 774) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.2.delta.2fb79f72-0b35-492f-aee1-65314b4516e8.TID771.tmp
[2025-07-19T19:57:26.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 171.0 in stage 7.0 (TID 774)
[2025-07-19T19:57:26.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.2.delta.678531b5-2d9c-4f5d-923c-bf33b42dfd4b.TID767.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/2.delta
[2025-07-19T19:57:26.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/164/2.delta
[2025-07-19T19:57:26.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 163.0 in stage 7.0 (TID 766) in 90 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T19:57:26.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2300ac94
[2025-07-19T19:57:26.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T19:57:26.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171] for update
[2025-07-19T19:57:26.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.2.delta.4efd480e-38e6-4fc9-9d80-d0f46e0bd0b6.TID770.tmp
[2025-07-19T19:57:26.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T19:57:26.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 164.0 in stage 7.0 (TID 767). 5829 bytes result sent to driver
[2025-07-19T19:57:26.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 172.0 in stage 7.0 (TID 775) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.2.delta.b4d09000-15c3-4b83-a14c-3568241ccb6b.TID774.tmp
[2025-07-19T19:57:26.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.2.delta.6e1c35f7-0586-4725-b57c-f1115b850d7d.TID769.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/2.delta
[2025-07-19T19:57:26.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/166/2.delta
[2025-07-19T19:57:26.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T19:57:26.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T19:57:26.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 166.0 in stage 7.0 (TID 769). 5829 bytes result sent to driver
[2025-07-19T19:57:26.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.2.delta.28352a93-e6d7-40b7-9feb-b18b25701e69.TID768.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/2.delta
[2025-07-19T19:57:26.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/165/2.delta
[2025-07-19T19:57:26.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T19:57:26.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.2.delta.1acc129e-39e4-4916-a76a-4a18f3132904.TID773.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/2.delta
[2025-07-19T19:57:26.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/170/2.delta
[2025-07-19T19:57:26.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 173.0 in stage 7.0 (TID 776) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T19:57:26.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.2.delta.2fb79f72-0b35-492f-aee1-65314b4516e8.TID771.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/2.delta
[2025-07-19T19:57:26.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 172.0 in stage 7.0 (TID 775)
[2025-07-19T19:57:26.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T19:57:26.060+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/168/2.delta
[2025-07-19T19:57:26.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 164.0 in stage 7.0 (TID 767) in 102 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T19:57:26.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 166.0 in stage 7.0 (TID 769) in 67 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T19:57:26.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 173.0 in stage 7.0 (TID 776)
[2025-07-19T19:57:26.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 165.0 in stage 7.0 (TID 768). 5829 bytes result sent to driver
[2025-07-19T19:57:26.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 174.0 in stage 7.0 (TID 777) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 165.0 in stage 7.0 (TID 768) in 74 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T19:57:26.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T19:57:26.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 174.0 in stage 7.0 (TID 777)
[2025-07-19T19:57:26.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65abf7e9
[2025-07-19T19:57:26.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.2.delta.a077ae5d-ee1a-4b5f-a14f-924cb9673654.TID772.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/2.delta
[2025-07-19T19:57:26.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/169/2.delta
[2025-07-19T19:57:26.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T19:57:26.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172] for update
[2025-07-19T19:57:26.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T19:57:26.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74b7db73
[2025-07-19T19:57:26.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.073+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 168.0 in stage 7.0 (TID 771). 5829 bytes result sent to driver
[2025-07-19T19:57:26.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 168.0 in stage 7.0 (TID 771) in 59 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T19:57:26.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 175.0 in stage 7.0 (TID 778) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 175.0 in stage 7.0 (TID 778)
[2025-07-19T19:57:26.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T19:57:26.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173] for update
[2025-07-19T19:57:26.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 169.0 in stage 7.0 (TID 772). 5829 bytes result sent to driver
[2025-07-19T19:57:26.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 176.0 in stage 7.0 (TID 779) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 176.0 in stage 7.0 (TID 779)
[2025-07-19T19:57:26.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 169.0 in stage 7.0 (TID 772) in 60 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T19:57:26.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T19:57:26.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@554ebf9d
[2025-07-19T19:57:26.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174] for update
[2025-07-19T19:57:26.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39a15036
[2025-07-19T19:57:26.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175] for update
[2025-07-19T19:57:26.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c9b422
[2025-07-19T19:57:26.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176] for update
[2025-07-19T19:57:26.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 170.0 in stage 7.0 (TID 773). 5829 bytes result sent to driver
[2025-07-19T19:57:26.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.2.delta.4efd480e-38e6-4fc9-9d80-d0f46e0bd0b6.TID770.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/2.delta
[2025-07-19T19:57:26.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/167/2.delta
[2025-07-19T19:57:26.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T19:57:26.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 177.0 in stage 7.0 (TID 780) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.2.delta.b4d09000-15c3-4b83-a14c-3568241ccb6b.TID774.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/2.delta
[2025-07-19T19:57:26.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/171/2.delta
[2025-07-19T19:57:26.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 170.0 in stage 7.0 (TID 773) in 69 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T19:57:26.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.2.delta.ec913fac-643f-4d08-bf46-8f46e507cf4b.TID775.tmp
[2025-07-19T19:57:26.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T19:57:26.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 177.0 in stage 7.0 (TID 780)
[2025-07-19T19:57:26.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.2.delta.7d031405-f20d-4a68-b4a1-aaa94b6bbc82.TID777.tmp
[2025-07-19T19:57:26.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T19:57:26.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 167.0 in stage 7.0 (TID 770). 5829 bytes result sent to driver
[2025-07-19T19:57:26.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 178.0 in stage 7.0 (TID 781) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 167.0 in stage 7.0 (TID 770) in 86 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T19:57:26.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 178.0 in stage 7.0 (TID 781)
[2025-07-19T19:57:26.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T19:57:26.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.2.delta.21fe0f4f-923c-453f-ba68-e7fa98103eff.TID776.tmp
[2025-07-19T19:57:26.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.2.delta.50a4168e-0c7c-46ca-8a8b-5cf22109474c.TID778.tmp
[2025-07-19T19:57:26.096+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.2.delta.1acc1e06-c4fd-46f2-9024-ea19b231e42b.TID779.tmp
[2025-07-19T19:57:26.096+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b8c75fa
[2025-07-19T19:57:26.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 171.0 in stage 7.0 (TID 774). 5829 bytes result sent to driver
[2025-07-19T19:57:26.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177] for update
[2025-07-19T19:57:26.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 171.0 in stage 7.0 (TID 774) in 58 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T19:57:26.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 179.0 in stage 7.0 (TID 782) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b2157ac
[2025-07-19T19:57:26.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 179.0 in stage 7.0 (TID 782)
[2025-07-19T19:57:26.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178] for update
[2025-07-19T19:57:26.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@548e11f6
[2025-07-19T19:57:26.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179] for update
[2025-07-19T19:57:26.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.2.delta.b4c2e69d-9b1b-46ce-a555-4ccccc489bef.TID781.tmp
[2025-07-19T19:57:26.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.2.delta.c79f9aaa-3a34-45a0-a5a2-2eee29017796.TID780.tmp
[2025-07-19T19:57:26.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.2.delta.d20871b7-22fd-48e6-9cc5-ecddcad9484f.TID782.tmp
[2025-07-19T19:57:26.112+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.2.delta.ec913fac-643f-4d08-bf46-8f46e507cf4b.TID775.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/2.delta
[2025-07-19T19:57:26.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/172/2.delta
[2025-07-19T19:57:26.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T19:57:26.117+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T19:57:26.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.2.delta.7d031405-f20d-4a68-b4a1-aaa94b6bbc82.TID777.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/2.delta
[2025-07-19T19:57:26.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/174/2.delta
[2025-07-19T19:57:26.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T19:57:26.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 172.0 in stage 7.0 (TID 775). 5829 bytes result sent to driver
[2025-07-19T19:57:26.120+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 172.0 in stage 7.0 (TID 775) in 88 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T19:57:26.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.2.delta.50a4168e-0c7c-46ca-8a8b-5cf22109474c.TID778.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/2.delta
[2025-07-19T19:57:26.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/175/2.delta
[2025-07-19T19:57:26.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 180.0 in stage 7.0 (TID 783) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T19:57:26.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 180.0 in stage 7.0 (TID 783)
[2025-07-19T19:57:26.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T19:57:26.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.2.delta.1acc1e06-c4fd-46f2-9024-ea19b231e42b.TID779.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/2.delta
[2025-07-19T19:57:26.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/176/2.delta
[2025-07-19T19:57:26.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cf4f8cc
[2025-07-19T19:57:26.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 174.0 in stage 7.0 (TID 777). 5829 bytes result sent to driver
[2025-07-19T19:57:26.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T19:57:26.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180] for update
[2025-07-19T19:57:26.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 181.0 in stage 7.0 (TID 784) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 181.0 in stage 7.0 (TID 784)
[2025-07-19T19:57:26.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 174.0 in stage 7.0 (TID 777) in 73 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T19:57:26.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T19:57:26.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 175.0 in stage 7.0 (TID 778). 5829 bytes result sent to driver
[2025-07-19T19:57:26.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 182.0 in stage 7.0 (TID 785) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T19:57:26.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 182.0 in stage 7.0 (TID 785)
[2025-07-19T19:57:26.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 175.0 in stage 7.0 (TID 778) in 70 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T19:57:26.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 176.0 in stage 7.0 (TID 779). 5829 bytes result sent to driver
[2025-07-19T19:57:26.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 183.0 in stage 7.0 (TID 786) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 176.0 in stage 7.0 (TID 779) in 70 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T19:57:26.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 183.0 in stage 7.0 (TID 786)
[2025-07-19T19:57:26.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.2.delta.21fe0f4f-923c-453f-ba68-e7fa98103eff.TID776.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/2.delta
[2025-07-19T19:57:26.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/173/2.delta
[2025-07-19T19:57:26.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T19:57:26.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33401cae
[2025-07-19T19:57:26.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182] for update
[2025-07-19T19:57:26.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.2.delta.ad76367a-fab2-4934-8d0a-a0b465db401e.TID783.tmp
[2025-07-19T19:57:26.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T19:57:26.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 173.0 in stage 7.0 (TID 776). 5829 bytes result sent to driver
[2025-07-19T19:57:26.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 184.0 in stage 7.0 (TID 787) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 173.0 in stage 7.0 (TID 776) in 87 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T19:57:26.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19cf13d6
[2025-07-19T19:57:26.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183] for update
[2025-07-19T19:57:26.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.2.delta.d20871b7-22fd-48e6-9cc5-ecddcad9484f.TID782.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/2.delta
[2025-07-19T19:57:26.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/179/2.delta
[2025-07-19T19:57:26.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T19:57:26.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 184.0 in stage 7.0 (TID 787)
[2025-07-19T19:57:26.150+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.2.delta.b4c2e69d-9b1b-46ce-a555-4ccccc489bef.TID781.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/2.delta
[2025-07-19T19:57:26.150+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/178/2.delta
[2025-07-19T19:57:26.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7476f15d
[2025-07-19T19:57:26.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181] for update
[2025-07-19T19:57:26.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T19:57:26.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T19:57:26.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 179.0 in stage 7.0 (TID 782). 5829 bytes result sent to driver
[2025-07-19T19:57:26.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.2.delta.34064346-ff52-4144-998f-54b413726ca4.TID785.tmp
[2025-07-19T19:57:26.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 185.0 in stage 7.0 (TID 788) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 185.0 in stage 7.0 (TID 788)
[2025-07-19T19:57:26.156+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.2.delta.c79f9aaa-3a34-45a0-a5a2-2eee29017796.TID780.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/2.delta
[2025-07-19T19:57:26.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/177/2.delta
[2025-07-19T19:57:26.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 179.0 in stage 7.0 (TID 782) in 68 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T19:57:26.158+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T19:57:26.158+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b0ae197
[2025-07-19T19:57:26.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.2.delta.43a4ccc4-d4d3-4825-b2aa-a32388d52395.TID786.tmp
[2025-07-19T19:57:26.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184] for update
[2025-07-19T19:57:26.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T19:57:26.162+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 178.0 in stage 7.0 (TID 781). 5829 bytes result sent to driver
[2025-07-19T19:57:26.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T19:57:26.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 177.0 in stage 7.0 (TID 780). 5829 bytes result sent to driver
[2025-07-19T19:57:26.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.2.delta.82da374b-866a-4c70-bbba-b6cc8dc0d225.TID784.tmp
[2025-07-19T19:57:26.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11dbd48e
[2025-07-19T19:57:26.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 186.0 in stage 7.0 (TID 789) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 187.0 in stage 7.0 (TID 790) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185] for update
[2025-07-19T19:57:26.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 178.0 in stage 7.0 (TID 781) in 89 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T19:57:26.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 177.0 in stage 7.0 (TID 780) in 95 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T19:57:26.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 186.0 in stage 7.0 (TID 789)
[2025-07-19T19:57:26.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.2.delta.e555989d-fb2d-4811-b66f-66826e2a1e91.TID787.tmp
[2025-07-19T19:57:26.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b20239b
[2025-07-19T19:57:26.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186] for update
[2025-07-19T19:57:26.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 187.0 in stage 7.0 (TID 790)
[2025-07-19T19:57:26.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.2.delta.ad76367a-fab2-4934-8d0a-a0b465db401e.TID783.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/2.delta
[2025-07-19T19:57:26.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/180/2.delta
[2025-07-19T19:57:26.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T19:57:26.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c075513
[2025-07-19T19:57:26.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187] for update
[2025-07-19T19:57:26.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.2.delta.e1361668-2ce3-45b8-80a0-ee234bf62dca.TID789.tmp
[2025-07-19T19:57:26.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T19:57:26.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 180.0 in stage 7.0 (TID 783). 5829 bytes result sent to driver
[2025-07-19T19:57:26.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 188.0 in stage 7.0 (TID 791) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 180.0 in stage 7.0 (TID 783) in 60 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T19:57:26.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 188.0 in stage 7.0 (TID 791)
[2025-07-19T19:57:26.182+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.183+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.2.delta.43a4ccc4-d4d3-4825-b2aa-a32388d52395.TID786.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/2.delta
[2025-07-19T19:57:26.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/183/2.delta
[2025-07-19T19:57:26.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T19:57:26.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19a69da4
[2025-07-19T19:57:26.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.186+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188] for update
[2025-07-19T19:57:26.187+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.2.delta.3c2810e4-68ae-49a2-8ff5-5771fd526243.TID788.tmp
[2025-07-19T19:57:26.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.2.delta.34064346-ff52-4144-998f-54b413726ca4.TID785.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/2.delta
[2025-07-19T19:57:26.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/182/2.delta
[2025-07-19T19:57:26.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.2.delta.82da374b-866a-4c70-bbba-b6cc8dc0d225.TID784.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/2.delta
[2025-07-19T19:57:26.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/181/2.delta
[2025-07-19T19:57:26.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T19:57:26.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T19:57:26.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T19:57:26.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 183.0 in stage 7.0 (TID 786). 5829 bytes result sent to driver
[2025-07-19T19:57:26.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 189.0 in stage 7.0 (TID 792) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.2.delta.e555989d-fb2d-4811-b66f-66826e2a1e91.TID787.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/2.delta
[2025-07-19T19:57:26.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/184/2.delta
[2025-07-19T19:57:26.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 183.0 in stage 7.0 (TID 786) in 66 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T19:57:26.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T19:57:26.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 189.0 in stage 7.0 (TID 792)
[2025-07-19T19:57:26.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T19:57:26.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 181.0 in stage 7.0 (TID 784). 5829 bytes result sent to driver
[2025-07-19T19:57:26.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 190.0 in stage 7.0 (TID 793) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 190.0 in stage 7.0 (TID 793)
[2025-07-19T19:57:26.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 181.0 in stage 7.0 (TID 784) in 70 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T19:57:26.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a24c51f
[2025-07-19T19:57:26.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.211+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189] for update
[2025-07-19T19:57:26.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T19:57:26.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 182.0 in stage 7.0 (TID 785). 5829 bytes result sent to driver
[2025-07-19T19:57:26.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 191.0 in stage 7.0 (TID 794) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 191.0 in stage 7.0 (TID 794)
[2025-07-19T19:57:26.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 182.0 in stage 7.0 (TID 785) in 72 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T19:57:26.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11747aee
[2025-07-19T19:57:26.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.2.delta.91291a1e-9387-42a5-aa11-e4cecb6cbd1d.TID790.tmp
[2025-07-19T19:57:26.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3231a10a
[2025-07-19T19:57:26.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191] for update
[2025-07-19T19:57:26.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T19:57:26.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.2.delta.6d77ab89-0402-4f26-9428-2f1b14b39a71.TID791.tmp
[2025-07-19T19:57:26.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 184.0 in stage 7.0 (TID 787). 5829 bytes result sent to driver
[2025-07-19T19:57:26.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190] for update
[2025-07-19T19:57:26.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 192.0 in stage 7.0 (TID 795) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 184.0 in stage 7.0 (TID 787) in 70 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T19:57:26.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 192.0 in stage 7.0 (TID 795)
[2025-07-19T19:57:26.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.2.delta.0f99b1a9-7f3d-4aee-a47f-a07d142df3b6.TID792.tmp
[2025-07-19T19:57:26.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c398b9c
[2025-07-19T19:57:26.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192] for update
[2025-07-19T19:57:26.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.2.delta.e1361668-2ce3-45b8-80a0-ee234bf62dca.TID789.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/2.delta
[2025-07-19T19:57:26.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/186/2.delta
[2025-07-19T19:57:26.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T19:57:26.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.2.delta.250584ac-e944-486f-8723-645079114813.TID794.tmp
[2025-07-19T19:57:26.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T19:57:26.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 186.0 in stage 7.0 (TID 789). 5829 bytes result sent to driver
[2025-07-19T19:57:26.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 193.0 in stage 7.0 (TID 796) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 186.0 in stage 7.0 (TID 789) in 60 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T19:57:26.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 193.0 in stage 7.0 (TID 796)
[2025-07-19T19:57:26.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.2.delta.ebd62b16-4b6a-49ff-9f1f-e212337db5b7.TID793.tmp
[2025-07-19T19:57:26.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13952893
[2025-07-19T19:57:26.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.228+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193] for update
[2025-07-19T19:57:26.229+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.2.delta.7c74a860-6c34-43f9-aa36-e9c0b2b0b895.TID795.tmp
[2025-07-19T19:57:26.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.2.delta.3c2810e4-68ae-49a2-8ff5-5771fd526243.TID788.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/2.delta
[2025-07-19T19:57:26.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/185/2.delta
[2025-07-19T19:57:26.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T19:57:26.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.2.delta.6d77ab89-0402-4f26-9428-2f1b14b39a71.TID791.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/2.delta
[2025-07-19T19:57:26.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/188/2.delta
[2025-07-19T19:57:26.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T19:57:26.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.2.delta.c1feff13-fd6e-4317-b5a8-8f522b1f206e.TID796.tmp
[2025-07-19T19:57:26.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T19:57:26.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 185.0 in stage 7.0 (TID 788). 5829 bytes result sent to driver
[2025-07-19T19:57:26.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T19:57:26.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 188.0 in stage 7.0 (TID 791). 5829 bytes result sent to driver
[2025-07-19T19:57:26.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 185.0 in stage 7.0 (TID 788) in 93 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T19:57:26.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 194.0 in stage 7.0 (TID 797) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 195.0 in stage 7.0 (TID 798) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 188.0 in stage 7.0 (TID 791) in 63 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T19:57:26.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 195.0 in stage 7.0 (TID 798)
[2025-07-19T19:57:26.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 194.0 in stage 7.0 (TID 797)
[2025-07-19T19:57:26.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.2.delta.91291a1e-9387-42a5-aa11-e4cecb6cbd1d.TID790.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/2.delta
[2025-07-19T19:57:26.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/187/2.delta
[2025-07-19T19:57:26.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T19:57:26.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a4e5649
[2025-07-19T19:57:26.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195] for update
[2025-07-19T19:57:26.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T19:57:26.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 187.0 in stage 7.0 (TID 790). 5829 bytes result sent to driver
[2025-07-19T19:57:26.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 196.0 in stage 7.0 (TID 799) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 187.0 in stage 7.0 (TID 790) in 91 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T19:57:26.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 196.0 in stage 7.0 (TID 799)
[2025-07-19T19:57:26.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.2.delta.250584ac-e944-486f-8723-645079114813.TID794.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/2.delta
[2025-07-19T19:57:26.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@581202f5
[2025-07-19T19:57:26.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/191/2.delta
[2025-07-19T19:57:26.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T19:57:26.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194] for update
[2025-07-19T19:57:26.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63c7d341
[2025-07-19T19:57:26.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196] for update
[2025-07-19T19:57:26.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.2.delta.0f99b1a9-7f3d-4aee-a47f-a07d142df3b6.TID792.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/2.delta
[2025-07-19T19:57:26.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/189/2.delta
[2025-07-19T19:57:26.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T19:57:26.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T19:57:26.269+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 191.0 in stage 7.0 (TID 794). 5786 bytes result sent to driver
[2025-07-19T19:57:26.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 197.0 in stage 7.0 (TID 800) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 197.0 in stage 7.0 (TID 800)
[2025-07-19T19:57:26.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 191.0 in stage 7.0 (TID 794) in 62 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T19:57:26.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e099dce
[2025-07-19T19:57:26.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197] for update
[2025-07-19T19:57:26.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T19:57:26.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 189.0 in stage 7.0 (TID 792). 5829 bytes result sent to driver
[2025-07-19T19:57:26.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 198.0 in stage 7.0 (TID 801) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 189.0 in stage 7.0 (TID 792) in 73 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T19:57:26.277+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 198.0 in stage 7.0 (TID 801)
[2025-07-19T19:57:26.277+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.2.delta.ebd62b16-4b6a-49ff-9f1f-e212337db5b7.TID793.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/2.delta
[2025-07-19T19:57:26.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/190/2.delta
[2025-07-19T19:57:26.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T19:57:26.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.2.delta.a0afd4cb-0534-4f2b-927b-f79093da0cae.TID800.tmp
[2025-07-19T19:57:26.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T19:57:26.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T19:57:26.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47a8d8eb
[2025-07-19T19:57:26.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 190.0 in stage 7.0 (TID 793). 5829 bytes result sent to driver
[2025-07-19T19:57:26.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.2.delta.1deb5005-6c96-43c6-82fe-947b6d7e22df.TID799.tmp
[2025-07-19T19:57:26.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.2.delta.d422bebb-6bb5-4f89-96c1-058c2b2e5dc0.TID797.tmp
[2025-07-19T19:57:26.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.2.delta.147636d3-6176-4598-a448-88de48ab9bf2.TID798.tmp
[2025-07-19T19:57:26.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198] for update
[2025-07-19T19:57:26.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 199.0 in stage 7.0 (TID 802) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 190.0 in stage 7.0 (TID 793) in 80 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T19:57:26.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 199.0 in stage 7.0 (TID 802)
[2025-07-19T19:57:26.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e8c6b71
[2025-07-19T19:57:26.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],b5fdfb25-db44-4f9a-8656-6e80fbb359f7) is active
[2025-07-19T19:57:26.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199] for update
[2025-07-19T19:57:26.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.2.delta.c1feff13-fd6e-4317-b5a8-8f522b1f206e.TID796.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/2.delta
[2025-07-19T19:57:26.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/193/2.delta
[2025-07-19T19:57:26.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.2.delta.7c74a860-6c34-43f9-aa36-e9c0b2b0b895.TID795.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/2.delta
[2025-07-19T19:57:26.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/192/2.delta
[2025-07-19T19:57:26.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.2.delta.2e9d7f90-b2d3-4919-82ff-982ce00e6e97.TID801.tmp
[2025-07-19T19:57:26.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T19:57:26.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T19:57:26.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T19:57:26.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 192.0 in stage 7.0 (TID 795). 5829 bytes result sent to driver
[2025-07-19T19:57:26.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 803) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 0.0 in stage 9.0 (TID 803)
[2025-07-19T19:57:26.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 192.0 in stage 7.0 (TID 795) in 88 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T19:57:26.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T19:57:26.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 193.0 in stage 7.0 (TID 796). 5829 bytes result sent to driver
[2025-07-19T19:57:26.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 804) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 1.0 in stage 9.0 (TID 804)
[2025-07-19T19:57:26.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 193.0 in stage 7.0 (TID 796) in 76 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T19:57:26.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.2.delta.bf2429c1-5717-45d4-b59e-5dca21b30dc0.TID802.tmp
[2025-07-19T19:57:26.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3531012
[2025-07-19T19:57:26.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1] for update
[2025-07-19T19:57:26.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5283f8a7
[2025-07-19T19:57:26.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0] for update
[2025-07-19T19:57:26.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodeGenerator: Code generated in 5.618875 ms
[2025-07-19T19:57:26.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.2.delta.d422bebb-6bb5-4f89-96c1-058c2b2e5dc0.TID797.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/2.delta
[2025-07-19T19:57:26.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/194/2.delta
[2025-07-19T19:57:26.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T19:57:26.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.2.delta.147636d3-6176-4598-a448-88de48ab9bf2.TID798.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/2.delta
[2025-07-19T19:57:26.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/195/2.delta
[2025-07-19T19:57:26.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.2.delta.a0afd4cb-0534-4f2b-927b-f79093da0cae.TID800.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/2.delta
[2025-07-19T19:57:26.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/197/2.delta
[2025-07-19T19:57:26.321+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.2.delta.1deb5005-6c96-43c6-82fe-947b6d7e22df.TID799.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/2.delta
[2025-07-19T19:57:26.321+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/196/2.delta
[2025-07-19T19:57:26.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T19:57:26.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.2.delta.2e9d7f90-b2d3-4919-82ff-982ce00e6e97.TID801.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/2.delta
[2025-07-19T19:57:26.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T19:57:26.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T19:57:26.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T19:57:26.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 194.0 in stage 7.0 (TID 797). 5829 bytes result sent to driver
[2025-07-19T19:57:26.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/198/2.delta
[2025-07-19T19:57:26.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 805) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T19:57:26.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 2.0 in stage 9.0 (TID 805)
[2025-07-19T19:57:26.330+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.2.delta.6f83c63a-f00b-4d01-9c86-466dc791fd3d.TID804.tmp
[2025-07-19T19:57:26.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 194.0 in stage 7.0 (TID 797) in 83 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T19:57:26.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T19:57:26.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 197.0 in stage 7.0 (TID 800). 5829 bytes result sent to driver
[2025-07-19T19:57:26.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:26.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T19:57:26.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 195.0 in stage 7.0 (TID 798). 5829 bytes result sent to driver
[2025-07-19T19:57:26.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 806) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 807) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 195.0 in stage 7.0 (TID 798) in 86 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T19:57:26.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 197.0 in stage 7.0 (TID 800) in 69 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T19:57:26.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T19:57:26.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 198.0 in stage 7.0 (TID 801). 5829 bytes result sent to driver
[2025-07-19T19:57:26.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c26d63b
[2025-07-19T19:57:26.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 4.0 in stage 9.0 (TID 807)
[2025-07-19T19:57:26.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 808) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2] for update
[2025-07-19T19:57:26.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 3.0 in stage 9.0 (TID 806)
[2025-07-19T19:57:26.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 198.0 in stage 7.0 (TID 801) in 64 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T19:57:26.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.2.delta.4f8c7e00-4394-489f-bfb0-6f0cf9d361aa.TID803.tmp
[2025-07-19T19:57:26.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 5.0 in stage 9.0 (TID 808)
[2025-07-19T19:57:26.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T19:57:26.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 196.0 in stage 7.0 (TID 799). 5829 bytes result sent to driver
[2025-07-19T19:57:26.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 809) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 196.0 in stage 7.0 (TID 799) in 80 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T19:57:26.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 6.0 in stage 9.0 (TID 809)
[2025-07-19T19:57:26.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@482fe21
[2025-07-19T19:57:26.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3] for update
[2025-07-19T19:57:26.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4967707e
[2025-07-19T19:57:26.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6] for update
[2025-07-19T19:57:26.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2282fd18
[2025-07-19T19:57:26.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4] for update
[2025-07-19T19:57:26.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a5d965e
[2025-07-19T19:57:26.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.2.delta.999fb5b9-dc23-4e66-8193-230d116c66e8.TID805.tmp
[2025-07-19T19:57:26.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5] for update
[2025-07-19T19:57:26.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.2.delta.39a5e186-b5ac-49bd-9837-8df0667a9623.TID806.tmp
[2025-07-19T19:57:26.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.2.delta.bf2429c1-5717-45d4-b59e-5dca21b30dc0.TID802.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/2.delta
[2025-07-19T19:57:26.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/state/0/199/2.delta
[2025-07-19T19:57:26.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T19:57:26.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.2.delta.2d193d69-c911-4656-a970-b36310185c85.TID809.tmp
[2025-07-19T19:57:26.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.2.delta.e7f187c2-49c5-4e68-8085-6d9a5746d53b.TID807.tmp
[2025-07-19T19:57:26.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.2.delta.40b463f1-b34e-4756-9c89-35c8a5e08b0e.TID808.tmp
[2025-07-19T19:57:26.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T19:57:26.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 199.0 in stage 7.0 (TID 802). 5829 bytes result sent to driver
[2025-07-19T19:57:26.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 810) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 199.0 in stage 7.0 (TID 802) in 78 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T19:57:26.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-19T19:57:26.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 7.0 in stage 9.0 (TID 810)
[2025-07-19T19:57:26.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DAGScheduler: ResultStage 7 (start at <unknown>:0) finished in 3.511 s
[2025-07-19T19:57:26.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@573911bf
[2025-07-19T19:57:26.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T19:57:26.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-07-19T19:57:26.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DAGScheduler: Job 3 finished: start at <unknown>:0, took 3.594931 s
[2025-07-19T19:57:26.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T19:57:26.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO SparkWrite: Committing epoch 1 for query e64be3f7-c229-4a3a-b3cc-de24eff1ecd3 in append mode
[2025-07-19T19:57:26.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7] for update
[2025-07-19T19:57:26.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/.2.delta.6f83c63a-f00b-4d01-9c86-466dc791fd3d.TID804.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/2.delta
[2025-07-19T19:57:26.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/1/2.delta
[2025-07-19T19:57:26.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T19:57:26.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/.2.delta.4f8c7e00-4394-489f-bfb0-6f0cf9d361aa.TID803.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/2.delta
[2025-07-19T19:57:26.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/0/2.delta
[2025-07-19T19:57:26.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T19:57:26.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T19:57:26.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.2.delta.978f7fac-ffe7-4ac5-81b0-a83b118d4428.TID810.tmp
[2025-07-19T19:57:26.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T19:57:26.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T19:57:26.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 0.0 in stage 9.0 (TID 803). 5829 bytes result sent to driver
[2025-07-19T19:57:26.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 1.0 in stage 9.0 (TID 804). 5829 bytes result sent to driver
[2025-07-19T19:57:26.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 8.0 in stage 9.0 (TID 811) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.379+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 8.0 in stage 9.0 (TID 811)
[2025-07-19T19:57:26.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 9.0 in stage 9.0 (TID 812) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 803) in 86 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T19:57:26.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 804) in 83 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T19:57:26.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/.2.delta.999fb5b9-dc23-4e66-8193-230d116c66e8.TID805.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/2.delta
[2025-07-19T19:57:26.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/2/2.delta
[2025-07-19T19:57:26.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T19:57:26.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 9.0 in stage 9.0 (TID 812)
[2025-07-19T19:57:26.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/.2.delta.2d193d69-c911-4656-a970-b36310185c85.TID809.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/2.delta
[2025-07-19T19:57:26.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/6/2.delta
[2025-07-19T19:57:26.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T19:57:26.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@526637b7
[2025-07-19T19:57:26.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T19:57:26.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 2.0 in stage 9.0 (TID 805). 5829 bytes result sent to driver
[2025-07-19T19:57:26.391+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T19:57:26.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8] for update
[2025-07-19T19:57:26.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 6.0 in stage 9.0 (TID 809). 5786 bytes result sent to driver
[2025-07-19T19:57:26.394+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/.2.delta.40b463f1-b34e-4756-9c89-35c8a5e08b0e.TID808.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/2.delta
[2025-07-19T19:57:26.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/5/2.delta
[2025-07-19T19:57:26.397+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13553d56
[2025-07-19T19:57:26.399+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 10.0 in stage 9.0 (TID 813) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 11.0 in stage 9.0 (TID 814) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 10.0 in stage 9.0 (TID 813)
[2025-07-19T19:57:26.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T19:57:26.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9] for update
[2025-07-19T19:57:26.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 11.0 in stage 9.0 (TID 814)
[2025-07-19T19:57:26.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 805) in 67 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T19:57:26.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 809) in 59 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T19:57:26.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T19:57:26.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 5.0 in stage 9.0 (TID 808). 5829 bytes result sent to driver
[2025-07-19T19:57:26.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/.2.delta.39a5e186-b5ac-49bd-9837-8df0667a9623.TID806.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/2.delta
[2025-07-19T19:57:26.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/3/2.delta
[2025-07-19T19:57:26.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:26.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T19:57:26.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68443d4a
[2025-07-19T19:57:26.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 12.0 in stage 9.0 (TID 815) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 12.0 in stage 9.0 (TID 815)
[2025-07-19T19:57:26.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 808) in 67 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T19:57:26.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11] for update
[2025-07-19T19:57:26.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T19:57:26.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/.2.delta.e7f187c2-49c5-4e68-8085-6d9a5746d53b.TID807.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/2.delta
[2025-07-19T19:57:26.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/4/2.delta
[2025-07-19T19:57:26.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 3.0 in stage 9.0 (TID 806). 5829 bytes result sent to driver
[2025-07-19T19:57:26.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T19:57:26.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66ccda78
[2025-07-19T19:57:26.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 13.0 in stage 9.0 (TID 816) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 13.0 in stage 9.0 (TID 816)
[2025-07-19T19:57:26.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10] for update
[2025-07-19T19:57:26.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 806) in 74 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T19:57:26.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.2.delta.b2ee0aa3-f4c8-43d9-84f4-0224dc08a75a.TID811.tmp
[2025-07-19T19:57:26.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@757da5d5
[2025-07-19T19:57:26.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/.2.delta.978f7fac-ffe7-4ac5-81b0-a83b118d4428.TID810.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/2.delta
[2025-07-19T19:57:26.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.2.delta.23346b09-f34a-4027-b10a-2b1c6ae6ce2e.TID812.tmp
[2025-07-19T19:57:26.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/7/2.delta
[2025-07-19T19:57:26.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12] for update
[2025-07-19T19:57:26.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T19:57:26.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T19:57:26.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@711b16e5
[2025-07-19T19:57:26.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13] for update
[2025-07-19T19:57:26.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.2.delta.21e78a3c-4d2e-48b7-8caa-8b5569e79050.TID814.tmp
[2025-07-19T19:57:26.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T19:57:26.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 4.0 in stage 9.0 (TID 807). 5915 bytes result sent to driver
[2025-07-19T19:57:26.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 7.0 in stage 9.0 (TID 810). 5915 bytes result sent to driver
[2025-07-19T19:57:26.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 14.0 in stage 9.0 (TID 817) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 15.0 in stage 9.0 (TID 818) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 15.0 in stage 9.0 (TID 818)
[2025-07-19T19:57:26.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 14.0 in stage 9.0 (TID 817)
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 807) in 89 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 810) in 66 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@275e5138
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14] for update
[2025-07-19T19:57:26.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f11e532
[2025-07-19T19:57:26.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15] for update
[2025-07-19T19:57:26.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.2.delta.be1905b2-d350-4f4a-84a8-bb222a4d6f08.TID813.tmp
[2025-07-19T19:57:26.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.2.delta.3b92bebe-8a2e-4f17-ad0e-b56edb9cf864.TID816.tmp
[2025-07-19T19:57:26.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.2.delta.7cc4b7de-5f97-471a-823f-9a7e79d9e193.TID815.tmp
[2025-07-19T19:57:26.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.2.delta.e83ccf26-3e12-4430-a765-90d43668968a.TID818.tmp
[2025-07-19T19:57:26.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/.2.delta.b2ee0aa3-f4c8-43d9-84f4-0224dc08a75a.TID811.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/2.delta
[2025-07-19T19:57:26.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/8/2.delta
[2025-07-19T19:57:26.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T19:57:26.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.2.delta.97be4051-0524-4985-9aff-4731c0cf7a0c.TID817.tmp
[2025-07-19T19:57:26.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T19:57:26.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 8.0 in stage 9.0 (TID 811). 5872 bytes result sent to driver
[2025-07-19T19:57:26.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/.2.delta.21e78a3c-4d2e-48b7-8caa-8b5569e79050.TID814.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/2.delta
[2025-07-19T19:57:26.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/11/2.delta
[2025-07-19T19:57:26.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T19:57:26.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 16.0 in stage 9.0 (TID 819) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.465+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 16.0 in stage 9.0 (TID 819)
[2025-07-19T19:57:26.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 8.0 in stage 9.0 (TID 811) in 87 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T19:57:26.472+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:26.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5eb9a6f5
[2025-07-19T19:57:26.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16] for update
[2025-07-19T19:57:26.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T19:57:26.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/.2.delta.23346b09-f34a-4027-b10a-2b1c6ae6ce2e.TID812.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/2.delta
[2025-07-19T19:57:26.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/9/2.delta
[2025-07-19T19:57:26.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 11.0 in stage 9.0 (TID 814). 5872 bytes result sent to driver
[2025-07-19T19:57:26.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T19:57:26.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 11.0 in stage 9.0 (TID 814) in 95 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T19:57:26.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 17.0 in stage 9.0 (TID 820) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 17.0 in stage 9.0 (TID 820)
[2025-07-19T19:57:26.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.490+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 8b44f3d35cfa:44249 in memory (size: 15.8 KiB, free: 434.3 MiB)
[2025-07-19T19:57:26.492+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/.2.delta.7cc4b7de-5f97-471a-823f-9a7e79d9e193.TID815.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/2.delta
[2025-07-19T19:57:26.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/12/2.delta
[2025-07-19T19:57:26.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d76196d
[2025-07-19T19:57:26.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17] for update
[2025-07-19T19:57:26.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v89.metadata.json
[2025-07-19T19:57:26.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T19:57:26.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/.2.delta.be1905b2-d350-4f4a-84a8-bb222a4d6f08.TID813.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/2.delta
[2025-07-19T19:57:26.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/10/2.delta
[2025-07-19T19:57:26.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T19:57:26.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/.2.delta.3b92bebe-8a2e-4f17-ad0e-b56edb9cf864.TID816.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/2.delta
[2025-07-19T19:57:26.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/13/2.delta
[2025-07-19T19:57:26.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T19:57:26.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T19:57:26.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.2.delta.671a7449-596c-47d2-a3df-dc1c40e642f3.TID819.tmp
[2025-07-19T19:57:26.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 12.0 in stage 9.0 (TID 815). 5872 bytes result sent to driver
[2025-07-19T19:57:26.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T19:57:26.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.2.delta.ba7e7d20-1143-4a0e-922c-e81f25c0ead4.TID820.tmp
[2025-07-19T19:57:26.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 18.0 in stage 9.0 (TID 821) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 12.0 in stage 9.0 (TID 815) in 109 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T19:57:26.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 10.0 in stage 9.0 (TID 813). 5872 bytes result sent to driver
[2025-07-19T19:57:26.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 18.0 in stage 9.0 (TID 821)
[2025-07-19T19:57:26.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 19.0 in stage 9.0 (TID 822) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 19.0 in stage 9.0 (TID 822)
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 10.0 in stage 9.0 (TID 813) in 115 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43cea02a
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19] for update
[2025-07-19T19:57:26.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T19:57:26.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 13.0 in stage 9.0 (TID 816). 5872 bytes result sent to driver
[2025-07-19T19:57:26.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T19:57:26.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 20.0 in stage 9.0 (TID 823) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 13.0 in stage 9.0 (TID 816) in 109 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T19:57:26.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 20.0 in stage 9.0 (TID 823)
[2025-07-19T19:57:26.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 9.0 in stage 9.0 (TID 812). 5872 bytes result sent to driver
[2025-07-19T19:57:26.517+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b3118fd
[2025-07-19T19:57:26.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.518+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 21.0 in stage 9.0 (TID 824) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 21.0 in stage 9.0 (TID 824)
[2025-07-19T19:57:26.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 9.0 in stage 9.0 (TID 812) in 142 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T19:57:26.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18] for update
[2025-07-19T19:57:26.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6938e1d
[2025-07-19T19:57:26.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/.2.delta.e83ccf26-3e12-4430-a765-90d43668968a.TID818.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/2.delta
[2025-07-19T19:57:26.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20] for update
[2025-07-19T19:57:26.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/15/2.delta
[2025-07-19T19:57:26.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T19:57:26.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/.2.delta.97be4051-0524-4985-9aff-4731c0cf7a0c.TID817.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/2.delta
[2025-07-19T19:57:26.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/14/2.delta
[2025-07-19T19:57:26.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T19:57:26.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T19:57:26.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T19:57:26.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 15.0 in stage 9.0 (TID 818). 5872 bytes result sent to driver
[2025-07-19T19:57:26.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 22.0 in stage 9.0 (TID 825) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 15.0 in stage 9.0 (TID 818) in 114 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T19:57:26.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 22.0 in stage 9.0 (TID 825)
[2025-07-19T19:57:26.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25780fe5
[2025-07-19T19:57:26.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21] for update
[2025-07-19T19:57:26.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.539+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.540+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T19:57:26.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 14.0 in stage 9.0 (TID 817). 5872 bytes result sent to driver
[2025-07-19T19:57:26.541+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@717bf5e8
[2025-07-19T19:57:26.542+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 23.0 in stage 9.0 (TID 826) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22] for update
[2025-07-19T19:57:26.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 14.0 in stage 9.0 (TID 817) in 122 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T19:57:26.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.2.delta.84d0db43-d792-4f34-aa9e-0ae01f1ee694.TID822.tmp
[2025-07-19T19:57:26.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.546+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 23.0 in stage 9.0 (TID 826)
[2025-07-19T19:57:26.547+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.547+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cdd6fc7
[2025-07-19T19:57:26.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.2.delta.95e3a641-e4ce-4a74-bcdc-370fbc642a31.TID821.tmp
[2025-07-19T19:57:26.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23] for update
[2025-07-19T19:57:26.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO SnapshotProducer: Committed snapshot 8994646716895887983 (FastAppend)
[2025-07-19T19:57:26.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.2.delta.bb17e73b-6a2a-49ef-952d-3e59b37165f6.TID823.tmp
[2025-07-19T19:57:26.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.2.delta.f520892d-b9d8-4b1d-877d-1316466ff31b.TID825.tmp
[2025-07-19T19:57:26.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/.2.delta.ba7e7d20-1143-4a0e-922c-e81f25c0ead4.TID820.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/2.delta
[2025-07-19T19:57:26.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/17/2.delta
[2025-07-19T19:57:26.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T19:57:26.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.2.delta.742274c2-85d1-4fcb-ba71-76653bacfa46.TID824.tmp
[2025-07-19T19:57:26.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/.2.delta.671a7449-596c-47d2-a3df-dc1c40e642f3.TID819.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/2.delta
[2025-07-19T19:57:26.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/16/2.delta
[2025-07-19T19:57:26.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T19:57:26.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.2.delta.ce15e2cc-c6c8-44fc-8e45-23f72f1d65f1.TID826.tmp
[2025-07-19T19:57:26.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T19:57:26.570+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T19:57:26.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 17.0 in stage 9.0 (TID 820). 5829 bytes result sent to driver
[2025-07-19T19:57:26.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 16.0 in stage 9.0 (TID 819). 5829 bytes result sent to driver
[2025-07-19T19:57:26.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 24.0 in stage 9.0 (TID 827) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 25.0 in stage 9.0 (TID 828) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 17.0 in stage 9.0 (TID 820) in 89 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T19:57:26.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 16.0 in stage 9.0 (TID 819) in 112 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T19:57:26.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 24.0 in stage 9.0 (TID 827)
[2025-07-19T19:57:26.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 25.0 in stage 9.0 (TID 828)
[2025-07-19T19:57:26.584+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.586+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.586+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:26.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:26.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74ef04e7
[2025-07-19T19:57:26.587+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24] for update
[2025-07-19T19:57:26.588+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b29f74a
[2025-07-19T19:57:26.590+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25] for update
[2025-07-19T19:57:26.591+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.592+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.595+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/.2.delta.84d0db43-d792-4f34-aa9e-0ae01f1ee694.TID822.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/2.delta
[2025-07-19T19:57:26.596+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/19/2.delta
[2025-07-19T19:57:26.597+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T19:57:26.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/.2.delta.95e3a641-e4ce-4a74-bcdc-370fbc642a31.TID821.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/2.delta
[2025-07-19T19:57:26.599+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/18/2.delta
[2025-07-19T19:57:26.602+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.2.delta.cedc142a-b2db-4770-8c23-6163004fd9d6.TID828.tmp
[2025-07-19T19:57:26.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.2.delta.b08d539a-a55e-4f6b-8f9f-eae3b8bdc23d.TID827.tmp
[2025-07-19T19:57:26.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T19:57:26.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T19:57:26.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 19.0 in stage 9.0 (TID 822). 5829 bytes result sent to driver
[2025-07-19T19:57:26.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 26.0 in stage 9.0 (TID 829) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/.2.delta.bb17e73b-6a2a-49ef-952d-3e59b37165f6.TID823.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/2.delta
[2025-07-19T19:57:26.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/20/2.delta
[2025-07-19T19:57:26.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 26.0 in stage 9.0 (TID 829)
[2025-07-19T19:57:26.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 19.0 in stage 9.0 (TID 822) in 113 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T19:57:26.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=8994646716895887983, sequenceNumber=88, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.248209001S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=3672}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=4818}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=10558323}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752955029831, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T19:57:26.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO SparkWrite: Committed in 249 ms
[2025-07-19T19:57:26.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T19:57:26.622+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/.2.delta.f520892d-b9d8-4b1d-877d-1316466ff31b.TID825.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/2.delta
[2025-07-19T19:57:26.623+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/22/2.delta
[2025-07-19T19:57:26.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T19:57:26.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T19:57:26.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T19:57:26.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T19:57:26.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T19:57:26.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 22.0 in stage 9.0 (TID 825). 5829 bytes result sent to driver
[2025-07-19T19:57:26.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 20.0 in stage 9.0 (TID 823). 5829 bytes result sent to driver
[2025-07-19T19:57:26.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 18.0 in stage 9.0 (TID 821). 5829 bytes result sent to driver
[2025-07-19T19:57:26.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 27.0 in stage 9.0 (TID 830) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 27.0 in stage 9.0 (TID 830)
[2025-07-19T19:57:26.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 28.0 in stage 9.0 (TID 831) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 28.0 in stage 9.0 (TID 831)
[2025-07-19T19:57:26.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 29.0 in stage 9.0 (TID 832) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.633+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22aa814
[2025-07-19T19:57:26.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26] for update
[2025-07-19T19:57:26.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 20.0 in stage 9.0 (TID 823) in 116 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T19:57:26.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 29.0 in stage 9.0 (TID 832)
[2025-07-19T19:57:26.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 22.0 in stage 9.0 (TID 825) in 95 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T19:57:26.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.637+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.638+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:26.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 18.0 in stage 9.0 (TID 821) in 126 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T19:57:26.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@502f2306
[2025-07-19T19:57:26.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/.2.delta.742274c2-85d1-4fcb-ba71-76653bacfa46.TID824.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/2.delta
[2025-07-19T19:57:26.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/21/2.delta
[2025-07-19T19:57:26.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T19:57:26.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/.2.delta.ce15e2cc-c6c8-44fc-8e45-23f72f1d65f1.TID826.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/2.delta
[2025-07-19T19:57:26.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/23/2.delta
[2025-07-19T19:57:26.647+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T19:57:26.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dab3e0d
[2025-07-19T19:57:26.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27] for update
[2025-07-19T19:57:26.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28] for update
[2025-07-19T19:57:26.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1655454a
[2025-07-19T19:57:26.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29] for update
[2025-07-19T19:57:26.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.2.delta.8bac0bc2-6e78-4604-9079-4005d2e642c8.TID829.tmp
[2025-07-19T19:57:26.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/commits/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/commits/.1.678a0914-6c9d-4cdb-b00f-38e9a0259af1.tmp
[2025-07-19T19:57:26.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T19:57:26.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 23.0 in stage 9.0 (TID 826). 5829 bytes result sent to driver
[2025-07-19T19:57:26.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 30.0 in stage 9.0 (TID 833) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T19:57:26.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 30.0 in stage 9.0 (TID 833)
[2025-07-19T19:57:26.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 21.0 in stage 9.0 (TID 824). 5829 bytes result sent to driver
[2025-07-19T19:57:26.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 23.0 in stage 9.0 (TID 826) in 106 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T19:57:26.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 31.0 in stage 9.0 (TID 834) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.656+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 31.0 in stage 9.0 (TID 834)
[2025-07-19T19:57:26.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 21.0 in stage 9.0 (TID 824) in 129 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T19:57:26.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24865344
[2025-07-19T19:57:26.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.2.delta.b7203968-e389-4264-8a5b-068c5f3d2cdf.TID830.tmp
[2025-07-19T19:57:26.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31] for update
[2025-07-19T19:57:26.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40d5028e
[2025-07-19T19:57:26.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30] for update
[2025-07-19T19:57:26.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.2.delta.4b2c24a0-3fd8-4787-a5a7-5199cd49742b.TID831.tmp
[2025-07-19T19:57:26.660+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/.2.delta.b08d539a-a55e-4f6b-8f9f-eae3b8bdc23d.TID827.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/2.delta
[2025-07-19T19:57:26.663+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/24/2.delta
[2025-07-19T19:57:26.665+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T19:57:26.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/.2.delta.cedc142a-b2db-4770-8c23-6163004fd9d6.TID828.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/2.delta
[2025-07-19T19:57:26.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/25/2.delta
[2025-07-19T19:57:26.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T19:57:26.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.2.delta.6112cd03-e9ea-452b-8533-0fc6b0db4750.TID833.tmp
[2025-07-19T19:57:26.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T19:57:26.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 25.0 in stage 9.0 (TID 828). 5829 bytes result sent to driver
[2025-07-19T19:57:26.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 32.0 in stage 9.0 (TID 835) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 32.0 in stage 9.0 (TID 835)
[2025-07-19T19:57:26.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 25.0 in stage 9.0 (TID 828) in 97 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T19:57:26.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.2.delta.6bdd19bd-d2f9-4483-8493-1978066fed3e.TID832.tmp
[2025-07-19T19:57:26.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T19:57:26.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 24.0 in stage 9.0 (TID 827). 5829 bytes result sent to driver
[2025-07-19T19:57:26.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 33.0 in stage 9.0 (TID 836) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.679+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 24.0 in stage 9.0 (TID 827) in 106 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T19:57:26.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:26.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32eb9a0
[2025-07-19T19:57:26.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32] for update
[2025-07-19T19:57:26.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 33.0 in stage 9.0 (TID 836)
[2025-07-19T19:57:26.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.2.delta.a96e6b64-10a3-4be6-8f85-5b41690054ce.TID834.tmp
[2025-07-19T19:57:26.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13375e55
[2025-07-19T19:57:26.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33] for update
[2025-07-19T19:57:26.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/commits/.1.678a0914-6c9d-4cdb-b00f-38e9a0259af1.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T19:54:00+00:00/commits/1
[2025-07-19T19:57:26.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T19:57:26.700+0000] {subprocess.py:93} INFO -   "id" : "e64be3f7-c229-4a3a-b3cc-de24eff1ecd3",
[2025-07-19T19:57:26.700+0000] {subprocess.py:93} INFO -   "runId" : "b5fdfb25-db44-4f9a-8656-6e80fbb359f7",
[2025-07-19T19:57:26.700+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T19:57:26.701+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T19:57:22.492Z",
[2025-07-19T19:57:26.701+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T19:57:26.701+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T19:57:26.702+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:26.702+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T19:57:26.702+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T19:57:26.703+0000] {subprocess.py:93} INFO -     "addBatch" : 3969,
[2025-07-19T19:57:26.703+0000] {subprocess.py:93} INFO -     "commitOffsets" : 78,
[2025-07-19T19:57:26.704+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T19:57:26.705+0000] {subprocess.py:93} INFO -     "latestOffset" : 8,
[2025-07-19T19:57:26.706+0000] {subprocess.py:93} INFO -     "queryPlanning" : 61,
[2025-07-19T19:57:26.706+0000] {subprocess.py:93} INFO -     "triggerExecution" : 4202,
[2025-07-19T19:57:26.706+0000] {subprocess.py:93} INFO -     "walCommit" : 80
[2025-07-19T19:57:26.707+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:26.707+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T19:57:26.708+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T19:57:03.000Z"
[2025-07-19T19:57:26.708+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:26.708+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T19:57:26.708+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T19:57:26.708+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 174,
[2025-07-19T19:57:26.709+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T19:57:26.709+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 226,
[2025-07-19T19:57:26.709+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T19:57:26.710+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 102,
[2025-07-19T19:57:26.733+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 11368,
[2025-07-19T19:57:26.805+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 133512,
[2025-07-19T19:57:26.806+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T19:57:26.807+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T19:57:26.809+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T19:57:26.811+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T19:57:26.813+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T19:57:26.815+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T19:57:26.818+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T19:57:26.829+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 57304
[2025-07-19T19:57:26.837+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:26.839+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:26.841+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T19:57:26.841+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T19:57:26.842+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T19:57:26.861+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T19:57:26.862+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:26.863+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:26.863+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:26.863+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T19:57:26.863+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T19:57:26.863+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:26.864+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:26.864+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:26.865+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T19:57:26.865+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T19:57:26.865+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:26.865+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:26.866+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:26.866+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T19:57:26.867+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:26.869+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T19:57:26.871+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T19:57:26.872+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T19:57:26.872+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T19:57:26.873+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T19:57:26.873+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:26.873+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:26.874+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T19:57:26.875+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T19:57:26.875+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T19:57:26.876+0000] {subprocess.py:93} INFO -   }
[2025-07-19T19:57:26.877+0000] {subprocess.py:93} INFO - }
[2025-07-19T19:57:26.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/.2.delta.8bac0bc2-6e78-4604-9079-4005d2e642c8.TID829.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/2.delta
[2025-07-19T19:57:26.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/26/2.delta
[2025-07-19T19:57:26.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.2.delta.87b47e6e-46dc-4da3-8ef3-12495af2ce79.TID835.tmp
[2025-07-19T19:57:26.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T19:57:26.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T19:57:26.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 26.0 in stage 9.0 (TID 829). 5829 bytes result sent to driver
[2025-07-19T19:57:26.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 34.0 in stage 9.0 (TID 837) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 34.0 in stage 9.0 (TID 837)
[2025-07-19T19:57:26.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 26.0 in stage 9.0 (TID 829) in 92 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T19:57:26.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:26.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74684a52
[2025-07-19T19:57:26.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34] for update
[2025-07-19T19:57:26.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/.2.delta.6bdd19bd-d2f9-4483-8493-1978066fed3e.TID832.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/2.delta
[2025-07-19T19:57:26.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/29/2.delta
[2025-07-19T19:57:26.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T19:57:26.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.2.delta.5cb8b200-cead-4520-8161-305e931d2158.TID836.tmp
[2025-07-19T19:57:26.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/.2.delta.6112cd03-e9ea-452b-8533-0fc6b0db4750.TID833.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/2.delta
[2025-07-19T19:57:26.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/30/2.delta
[2025-07-19T19:57:26.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/.2.delta.b7203968-e389-4264-8a5b-068c5f3d2cdf.TID830.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/2.delta
[2025-07-19T19:57:26.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/27/2.delta
[2025-07-19T19:57:26.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T19:57:26.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T19:57:26.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T19:57:26.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 29.0 in stage 9.0 (TID 832). 5829 bytes result sent to driver
[2025-07-19T19:57:26.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/.2.delta.4b2c24a0-3fd8-4787-a5a7-5199cd49742b.TID831.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/2.delta
[2025-07-19T19:57:26.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/28/2.delta
[2025-07-19T19:57:26.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 35.0 in stage 9.0 (TID 838) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T19:57:26.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 29.0 in stage 9.0 (TID 832) in 195 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T19:57:26.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 35.0 in stage 9.0 (TID 838)
[2025-07-19T19:57:26.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T19:57:26.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 30.0 in stage 9.0 (TID 833). 5829 bytes result sent to driver
[2025-07-19T19:57:26.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T19:57:26.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 27.0 in stage 9.0 (TID 830). 5829 bytes result sent to driver
[2025-07-19T19:57:26.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 36.0 in stage 9.0 (TID 839) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 37.0 in stage 9.0 (TID 840) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 37.0 in stage 9.0 (TID 840)
[2025-07-19T19:57:26.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.2.delta.0011b5e9-f1d9-4d67-978f-f876d3753997.TID837.tmp
[2025-07-19T19:57:26.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 30.0 in stage 9.0 (TID 833) in 197 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T19:57:26.897+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 27.0 in stage 9.0 (TID 830) in 217 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T19:57:26.897+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T19:57:26.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44f89d60
[2025-07-19T19:57:26.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35] for update
[2025-07-19T19:57:26.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 36.0 in stage 9.0 (TID 839)
[2025-07-19T19:57:26.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 28.0 in stage 9.0 (TID 831). 5829 bytes result sent to driver
[2025-07-19T19:57:26.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.902+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.902+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d6fcc6
[2025-07-19T19:57:26.902+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:26.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 38.0 in stage 9.0 (TID 841) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 38.0 in stage 9.0 (TID 841)
[2025-07-19T19:57:26.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36] for update
[2025-07-19T19:57:26.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6172b34a
[2025-07-19T19:57:26.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37] for update
[2025-07-19T19:57:26.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 28.0 in stage 9.0 (TID 831) in 251 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T19:57:26.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/.2.delta.a96e6b64-10a3-4be6-8f85-5b41690054ce.TID834.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/2.delta
[2025-07-19T19:57:26.910+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/31/2.delta
[2025-07-19T19:57:26.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T19:57:26.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@265bca35
[2025-07-19T19:57:26.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T19:57:26.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.913+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38] for update
[2025-07-19T19:57:26.913+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.913+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T19:57:26.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 31.0 in stage 9.0 (TID 834). 5829 bytes result sent to driver
[2025-07-19T19:57:26.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.2.delta.24738c69-d429-4aa9-8268-e77c95045e6e.TID839.tmp
[2025-07-19T19:57:26.914+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.2.delta.24d9c7a8-b37f-459c-853b-ffaf9c951d18.TID838.tmp
[2025-07-19T19:57:26.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 39.0 in stage 9.0 (TID 842) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.915+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 39.0 in stage 9.0 (TID 842)
[2025-07-19T19:57:26.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 31.0 in stage 9.0 (TID 834) in 248 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T19:57:26.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71a0c809
[2025-07-19T19:57:26.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.918+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39] for update
[2025-07-19T19:57:26.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.2.delta.74f0c8bf-b3d0-475e-bd45-e127c8520942.TID841.tmp
[2025-07-19T19:57:26.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.2.delta.1e065602-3239-4781-b315-0149ebbee5a4.TID840.tmp
[2025-07-19T19:57:26.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/.2.delta.87b47e6e-46dc-4da3-8ef3-12495af2ce79.TID835.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/2.delta
[2025-07-19T19:57:26.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/32/2.delta
[2025-07-19T19:57:26.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T19:57:26.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/.2.delta.0011b5e9-f1d9-4d67-978f-f876d3753997.TID837.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/2.delta
[2025-07-19T19:57:26.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/34/2.delta
[2025-07-19T19:57:26.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.2.delta.43206a3c-bcf9-4e9d-bfc5-79b6c10c2469.TID842.tmp
[2025-07-19T19:57:26.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T19:57:26.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T19:57:26.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 32.0 in stage 9.0 (TID 835). 5829 bytes result sent to driver
[2025-07-19T19:57:26.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T19:57:26.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 34.0 in stage 9.0 (TID 837). 5829 bytes result sent to driver
[2025-07-19T19:57:26.920+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 40.0 in stage 9.0 (TID 843) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 32.0 in stage 9.0 (TID 835) in 241 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T19:57:26.922+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 40.0 in stage 9.0 (TID 843)
[2025-07-19T19:57:26.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 41.0 in stage 9.0 (TID 844) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 41.0 in stage 9.0 (TID 844)
[2025-07-19T19:57:26.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 34.0 in stage 9.0 (TID 837) in 209 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T19:57:26.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/.2.delta.5cb8b200-cead-4520-8161-305e931d2158.TID836.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/2.delta
[2025-07-19T19:57:26.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/33/2.delta
[2025-07-19T19:57:26.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T19:57:26.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30595664
[2025-07-19T19:57:26.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41] for update
[2025-07-19T19:57:26.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b4fb2af
[2025-07-19T19:57:26.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40] for update
[2025-07-19T19:57:26.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T19:57:26.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 33.0 in stage 9.0 (TID 836). 5829 bytes result sent to driver
[2025-07-19T19:57:26.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 42.0 in stage 9.0 (TID 845) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 42.0 in stage 9.0 (TID 845)
[2025-07-19T19:57:26.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 33.0 in stage 9.0 (TID 836) in 245 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T19:57:26.927+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@209adc22
[2025-07-19T19:57:26.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.928+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42] for update
[2025-07-19T19:57:26.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.929+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.2.delta.f17c5b0f-340d-4803-aed3-50a94feb1597.TID844.tmp
[2025-07-19T19:57:26.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/.2.delta.24d9c7a8-b37f-459c-853b-ffaf9c951d18.TID838.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/2.delta
[2025-07-19T19:57:26.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/35/2.delta
[2025-07-19T19:57:26.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T19:57:26.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/.2.delta.24738c69-d429-4aa9-8268-e77c95045e6e.TID839.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/2.delta
[2025-07-19T19:57:26.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/36/2.delta
[2025-07-19T19:57:26.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T19:57:26.935+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/.2.delta.74f0c8bf-b3d0-475e-bd45-e127c8520942.TID841.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/2.delta
[2025-07-19T19:57:26.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/38/2.delta
[2025-07-19T19:57:26.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T19:57:26.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/.2.delta.1e065602-3239-4781-b315-0149ebbee5a4.TID840.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/2.delta
[2025-07-19T19:57:26.940+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/37/2.delta
[2025-07-19T19:57:26.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T19:57:26.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T19:57:26.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T19:57:26.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 36.0 in stage 9.0 (TID 839). 5829 bytes result sent to driver
[2025-07-19T19:57:26.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T19:57:26.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 35.0 in stage 9.0 (TID 838). 5829 bytes result sent to driver
[2025-07-19T19:57:26.945+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T19:57:26.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 43.0 in stage 9.0 (TID 846) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 43.0 in stage 9.0 (TID 846)
[2025-07-19T19:57:26.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 35.0 in stage 9.0 (TID 838) in 122 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T19:57:26.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/.2.delta.43206a3c-bcf9-4e9d-bfc5-79b6c10c2469.TID842.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/2.delta
[2025-07-19T19:57:26.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/39/2.delta
[2025-07-19T19:57:26.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 38.0 in stage 9.0 (TID 841). 5829 bytes result sent to driver
[2025-07-19T19:57:26.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T19:57:26.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 44.0 in stage 9.0 (TID 847) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 37.0 in stage 9.0 (TID 840). 5829 bytes result sent to driver
[2025-07-19T19:57:26.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.2.delta.7dee813a-c0f8-411b-bded-6f8dab301244.TID845.tmp
[2025-07-19T19:57:26.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 38.0 in stage 9.0 (TID 841) in 98 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T19:57:26.952+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.2.delta.f4cd542b-0c35-4b31-8703-19b6d1a0185a.TID843.tmp
[2025-07-19T19:57:26.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 45.0 in stage 9.0 (TID 848) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 45.0 in stage 9.0 (TID 848)
[2025-07-19T19:57:26.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 46.0 in stage 9.0 (TID 849) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 37.0 in stage 9.0 (TID 840) in 112 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T19:57:26.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 36.0 in stage 9.0 (TID 839) in 112 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T19:57:26.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 44.0 in stage 9.0 (TID 847)
[2025-07-19T19:57:26.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 46.0 in stage 9.0 (TID 849)
[2025-07-19T19:57:26.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36d868ea
[2025-07-19T19:57:26.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.959+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44] for update
[2025-07-19T19:57:26.960+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T19:57:26.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 39.0 in stage 9.0 (TID 842). 5829 bytes result sent to driver
[2025-07-19T19:57:26.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14728d0c
[2025-07-19T19:57:26.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 47.0 in stage 9.0 (TID 850) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 39.0 in stage 9.0 (TID 842) in 56 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T19:57:26.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 47.0 in stage 9.0 (TID 850)
[2025-07-19T19:57:26.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45] for update
[2025-07-19T19:57:26.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13a39d2e
[2025-07-19T19:57:26.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43] for update
[2025-07-19T19:57:26.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35197e7d
[2025-07-19T19:57:26.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47] for update
[2025-07-19T19:57:26.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ae14657
[2025-07-19T19:57:26.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46] for update
[2025-07-19T19:57:26.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.2.delta.8e2e7259-059d-45b1-b702-1aca98747b49.TID847.tmp
[2025-07-19T19:57:26.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.2.delta.a92c1b6a-ae47-47dc-ba3f-832c8d4b4f96.TID850.tmp
[2025-07-19T19:57:26.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.2.delta.c6174fc3-b0ec-4d0b-9fed-6511c33fecee.TID846.tmp
[2025-07-19T19:57:26.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.2.delta.7c6bde8d-fe60-4506-aa1c-cbcdc8da8857.TID848.tmp
[2025-07-19T19:57:26.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/.2.delta.f17c5b0f-340d-4803-aed3-50a94feb1597.TID844.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/2.delta
[2025-07-19T19:57:26.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/41/2.delta
[2025-07-19T19:57:26.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T19:57:26.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/.2.delta.7dee813a-c0f8-411b-bded-6f8dab301244.TID845.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/2.delta
[2025-07-19T19:57:26.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/42/2.delta
[2025-07-19T19:57:26.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T19:57:26.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T19:57:26.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.2.delta.1c1b9469-f399-4381-9278-27d52a8c35b0.TID849.tmp
[2025-07-19T19:57:26.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 41.0 in stage 9.0 (TID 844). 5829 bytes result sent to driver
[2025-07-19T19:57:26.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 48.0 in stage 9.0 (TID 851) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 41.0 in stage 9.0 (TID 844) in 68 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T19:57:26.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 48.0 in stage 9.0 (TID 851)
[2025-07-19T19:57:26.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO DataWritingSparkTask: Committed partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T19:57:26.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@90e2513
[2025-07-19T19:57:26.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Finished task 42.0 in stage 9.0 (TID 845). 5872 bytes result sent to driver
[2025-07-19T19:57:26.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48] for update
[2025-07-19T19:57:26.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Finished task 42.0 in stage 9.0 (TID 845) in 65 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T19:57:26.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO TaskSetManager: Starting task 49.0 in stage 9.0 (TID 852) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:26.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO Executor: Running task 49.0 in stage 9.0 (TID 852)
[2025-07-19T19:57:26.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:26.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:26.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:26.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a7948a1
[2025-07-19T19:57:26.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:26.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49] for update
[2025-07-19T19:57:27.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/.2.delta.f4cd542b-0c35-4b31-8703-19b6d1a0185a.TID843.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/2.delta
[2025-07-19T19:57:27.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/40/2.delta
[2025-07-19T19:57:27.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.2.delta.51a5236e-bc71-4bf1-96a3-2e362ae8a700.TID851.tmp
[2025-07-19T19:57:27.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T19:57:27.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.2.delta.30f33165-f4cd-4535-acd6-efdee71386fe.TID852.tmp
[2025-07-19T19:57:27.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/.2.delta.7c6bde8d-fe60-4506-aa1c-cbcdc8da8857.TID848.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/2.delta
[2025-07-19T19:57:27.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/45/2.delta
[2025-07-19T19:57:27.014+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T19:57:27.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T19:57:27.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 40.0 in stage 9.0 (TID 843). 5829 bytes result sent to driver
[2025-07-19T19:57:27.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 50.0 in stage 9.0 (TID 853) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 40.0 in stage 9.0 (TID 843) in 102 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T19:57:27.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 50.0 in stage 9.0 (TID 853)
[2025-07-19T19:57:27.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/.2.delta.8e2e7259-059d-45b1-b702-1aca98747b49.TID847.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/2.delta
[2025-07-19T19:57:27.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/44/2.delta
[2025-07-19T19:57:27.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T19:57:27.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/.2.delta.a92c1b6a-ae47-47dc-ba3f-832c8d4b4f96.TID850.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/2.delta
[2025-07-19T19:57:27.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/47/2.delta
[2025-07-19T19:57:27.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 45.0 in stage 9.0 (TID 848). 5829 bytes result sent to driver
[2025-07-19T19:57:27.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T19:57:27.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@244f5d36
[2025-07-19T19:57:27.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T19:57:27.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 51.0 in stage 9.0 (TID 854) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 45.0 in stage 9.0 (TID 848) in 79 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T19:57:27.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50] for update
[2025-07-19T19:57:27.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 51.0 in stage 9.0 (TID 854)
[2025-07-19T19:57:27.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T19:57:27.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 47.0 in stage 9.0 (TID 850). 5829 bytes result sent to driver
[2025-07-19T19:57:27.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 47.0 in stage 9.0 (TID 850) in 85 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T19:57:27.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 52.0 in stage 9.0 (TID 855) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/.2.delta.c6174fc3-b0ec-4d0b-9fed-6511c33fecee.TID846.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/2.delta
[2025-07-19T19:57:27.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/43/2.delta
[2025-07-19T19:57:27.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 52.0 in stage 9.0 (TID 855)
[2025-07-19T19:57:27.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T19:57:27.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 44.0 in stage 9.0 (TID 847). 5829 bytes result sent to driver
[2025-07-19T19:57:27.040+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T19:57:27.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T19:57:27.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 44.0 in stage 9.0 (TID 847) in 96 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T19:57:27.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 53.0 in stage 9.0 (TID 856) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 53.0 in stage 9.0 (TID 856)
[2025-07-19T19:57:27.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.050+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72a7e0ae
[2025-07-19T19:57:27.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T19:57:27.055+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 43.0 in stage 9.0 (TID 846). 5829 bytes result sent to driver
[2025-07-19T19:57:27.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/.2.delta.1c1b9469-f399-4381-9278-27d52a8c35b0.TID849.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/2.delta
[2025-07-19T19:57:27.056+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/46/2.delta
[2025-07-19T19:57:27.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 54.0 in stage 9.0 (TID 857) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.057+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52] for update
[2025-07-19T19:57:27.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T19:57:27.059+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 54.0 in stage 9.0 (TID 857)
[2025-07-19T19:57:27.063+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.2.delta.0d2db473-32da-4b9c-960b-ff2e5df2f254.TID853.tmp
[2025-07-19T19:57:27.064+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.065+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.066+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@390c00a6
[2025-07-19T19:57:27.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 43.0 in stage 9.0 (TID 846) in 108 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T19:57:27.067+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.068+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T19:57:27.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54] for update
[2025-07-19T19:57:27.069+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 46.0 in stage 9.0 (TID 849). 5829 bytes result sent to driver
[2025-07-19T19:57:27.070+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a1ab8
[2025-07-19T19:57:27.072+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53] for update
[2025-07-19T19:57:27.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 55.0 in stage 9.0 (TID 858) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.076+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 55.0 in stage 9.0 (TID 858)
[2025-07-19T19:57:27.078+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 46.0 in stage 9.0 (TID 849) in 112 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T19:57:27.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67a1c8be
[2025-07-19T19:57:27.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51] for update
[2025-07-19T19:57:27.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/.2.delta.51a5236e-bc71-4bf1-96a3-2e362ae8a700.TID851.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/2.delta
[2025-07-19T19:57:27.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/48/2.delta
[2025-07-19T19:57:27.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T19:57:27.082+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@335fac39
[2025-07-19T19:57:27.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55] for update
[2025-07-19T19:57:27.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T19:57:27.086+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 48.0 in stage 9.0 (TID 851). 5829 bytes result sent to driver
[2025-07-19T19:57:27.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 48.0 in stage 9.0 (TID 851) in 87 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T19:57:27.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 56.0 in stage 9.0 (TID 859) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.2.delta.a6802abc-f1c7-4ff9-8e74-de8478183bf0.TID855.tmp
[2025-07-19T19:57:27.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 56.0 in stage 9.0 (TID 859)
[2025-07-19T19:57:27.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.2.delta.31dd5101-5979-4adf-8416-25231a8596c2.TID857.tmp
[2025-07-19T19:57:27.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.2.delta.ad82fca5-9d30-416b-8970-875b66510768.TID856.tmp
[2025-07-19T19:57:27.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.2.delta.e9cb30b8-abef-430c-9423-33f60b6e55af.TID854.tmp
[2025-07-19T19:57:27.090+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44f5343
[2025-07-19T19:57:27.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56] for update
[2025-07-19T19:57:27.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.2.delta.3ae47b72-9c3c-4e82-9279-3b1796a6e3cf.TID858.tmp
[2025-07-19T19:57:27.094+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/.2.delta.30f33165-f4cd-4535-acd6-efdee71386fe.TID852.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/2.delta
[2025-07-19T19:57:27.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/49/2.delta
[2025-07-19T19:57:27.096+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T19:57:27.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T19:57:27.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.2.delta.f142768f-b76f-4165-a190-fc292d189858.TID859.tmp
[2025-07-19T19:57:27.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 49.0 in stage 9.0 (TID 852). 5829 bytes result sent to driver
[2025-07-19T19:57:27.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 49.0 in stage 9.0 (TID 852) in 101 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T19:57:27.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 57.0 in stage 9.0 (TID 860) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 57.0 in stage 9.0 (TID 860)
[2025-07-19T19:57:27.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/.2.delta.0d2db473-32da-4b9c-960b-ff2e5df2f254.TID853.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/2.delta
[2025-07-19T19:57:27.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/50/2.delta
[2025-07-19T19:57:27.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T19:57:27.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@191bcf43
[2025-07-19T19:57:27.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57] for update
[2025-07-19T19:57:27.100+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T19:57:27.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 50.0 in stage 9.0 (TID 853). 5915 bytes result sent to driver
[2025-07-19T19:57:27.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 58.0 in stage 9.0 (TID 861) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 50.0 in stage 9.0 (TID 853) in 94 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T19:57:27.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 58.0 in stage 9.0 (TID 861)
[2025-07-19T19:57:27.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@560ee97b
[2025-07-19T19:57:27.111+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.2.delta.5f37de87-6495-40d8-b4a8-a426f3ba0f8d.TID860.tmp
[2025-07-19T19:57:27.112+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.112+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58] for update
[2025-07-19T19:57:27.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/.2.delta.e9cb30b8-abef-430c-9423-33f60b6e55af.TID854.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/2.delta
[2025-07-19T19:57:27.113+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/51/2.delta
[2025-07-19T19:57:27.114+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/.2.delta.ad82fca5-9d30-416b-8970-875b66510768.TID856.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/2.delta
[2025-07-19T19:57:27.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/53/2.delta
[2025-07-19T19:57:27.122+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T19:57:27.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/.2.delta.31dd5101-5979-4adf-8416-25231a8596c2.TID857.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/2.delta
[2025-07-19T19:57:27.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/54/2.delta
[2025-07-19T19:57:27.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/.2.delta.a6802abc-f1c7-4ff9-8e74-de8478183bf0.TID855.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/2.delta
[2025-07-19T19:57:27.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/52/2.delta
[2025-07-19T19:57:27.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T19:57:27.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T19:57:27.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T19:57:27.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T19:57:27.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T19:57:27.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T19:57:27.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 53.0 in stage 9.0 (TID 856). 5872 bytes result sent to driver
[2025-07-19T19:57:27.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 54.0 in stage 9.0 (TID 857). 5872 bytes result sent to driver
[2025-07-19T19:57:27.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 51.0 in stage 9.0 (TID 854). 5872 bytes result sent to driver
[2025-07-19T19:57:27.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 59.0 in stage 9.0 (TID 862) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 60.0 in stage 9.0 (TID 863) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 61.0 in stage 9.0 (TID 864) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 53.0 in stage 9.0 (TID 856) in 89 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T19:57:27.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 54.0 in stage 9.0 (TID 857) in 84 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T19:57:27.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 51.0 in stage 9.0 (TID 854) in 105 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T19:57:27.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 59.0 in stage 9.0 (TID 862)
[2025-07-19T19:57:27.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 60.0 in stage 9.0 (TID 863)
[2025-07-19T19:57:27.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T19:57:27.135+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 52.0 in stage 9.0 (TID 855). 5872 bytes result sent to driver
[2025-07-19T19:57:27.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 62.0 in stage 9.0 (TID 865) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.2.delta.89659d32-bc03-4a33-807c-ca9390a39faf.TID861.tmp
[2025-07-19T19:57:27.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 62.0 in stage 9.0 (TID 865)
[2025-07-19T19:57:27.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 61.0 in stage 9.0 (TID 864)
[2025-07-19T19:57:27.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 52.0 in stage 9.0 (TID 855) in 99 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T19:57:27.141+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/.2.delta.3ae47b72-9c3c-4e82-9279-3b1796a6e3cf.TID858.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/2.delta
[2025-07-19T19:57:27.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/55/2.delta
[2025-07-19T19:57:27.142+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e7ae346
[2025-07-19T19:57:27.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.143+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T19:57:27.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60] for update
[2025-07-19T19:57:27.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5532e0b5
[2025-07-19T19:57:27.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/.2.delta.f142768f-b76f-4165-a190-fc292d189858.TID859.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/2.delta
[2025-07-19T19:57:27.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/56/2.delta
[2025-07-19T19:57:27.150+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61] for update
[2025-07-19T19:57:27.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T19:57:27.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a77a9f8
[2025-07-19T19:57:27.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59] for update
[2025-07-19T19:57:27.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T19:57:27.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 55.0 in stage 9.0 (TID 858). 5872 bytes result sent to driver
[2025-07-19T19:57:27.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 63.0 in stage 9.0 (TID 866) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T19:57:27.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 63.0 in stage 9.0 (TID 866)
[2025-07-19T19:57:27.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 55.0 in stage 9.0 (TID 858) in 99 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T19:57:27.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b3a7fc3
[2025-07-19T19:57:27.158+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62] for update
[2025-07-19T19:57:27.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.2.delta.c8b9d584-ae09-4856-a861-e53cab96b88f.TID863.tmp
[2025-07-19T19:57:27.160+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.164+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T19:57:27.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73ba1d9
[2025-07-19T19:57:27.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63] for update
[2025-07-19T19:57:27.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 56.0 in stage 9.0 (TID 859). 5872 bytes result sent to driver
[2025-07-19T19:57:27.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 56.0 in stage 9.0 (TID 859) in 88 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T19:57:27.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 64.0 in stage 9.0 (TID 867) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 64.0 in stage 9.0 (TID 867)
[2025-07-19T19:57:27.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.2.delta.e90e4117-7dd5-44e2-95b3-126ff8de0460.TID864.tmp
[2025-07-19T19:57:27.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30578a79
[2025-07-19T19:57:27.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64] for update
[2025-07-19T19:57:27.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/.2.delta.5f37de87-6495-40d8-b4a8-a426f3ba0f8d.TID860.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/2.delta
[2025-07-19T19:57:27.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/57/2.delta
[2025-07-19T19:57:27.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T19:57:27.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.2.delta.6697fbcd-f021-4d8c-a18a-8ebdc6fc0ea1.TID862.tmp
[2025-07-19T19:57:27.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T19:57:27.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 57.0 in stage 9.0 (TID 860). 5872 bytes result sent to driver
[2025-07-19T19:57:27.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 65.0 in stage 9.0 (TID 868) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 57.0 in stage 9.0 (TID 860) in 78 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T19:57:27.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 65.0 in stage 9.0 (TID 868)
[2025-07-19T19:57:27.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.2.delta.50777faf-5371-4d62-8ccd-55afe43c5471.TID866.tmp
[2025-07-19T19:57:27.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.2.delta.b2a069a1-8965-40be-b65e-29f2c3bd9eb1.TID865.tmp
[2025-07-19T19:57:27.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1761482b
[2025-07-19T19:57:27.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65] for update
[2025-07-19T19:57:27.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/.2.delta.89659d32-bc03-4a33-807c-ca9390a39faf.TID861.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/2.delta
[2025-07-19T19:57:27.184+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/58/2.delta
[2025-07-19T19:57:27.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T19:57:27.187+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T19:57:27.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 58.0 in stage 9.0 (TID 861). 5872 bytes result sent to driver
[2025-07-19T19:57:27.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 66.0 in stage 9.0 (TID 869) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.2.delta.16a87fda-fd80-4743-ae9f-4def9eaf8524.TID867.tmp
[2025-07-19T19:57:27.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 66.0 in stage 9.0 (TID 869)
[2025-07-19T19:57:27.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.2.delta.2333b3d4-3616-4505-a2b2-2248ca0bd9dd.TID868.tmp
[2025-07-19T19:57:27.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 58.0 in stage 9.0 (TID 861) in 84 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T19:57:27.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@93e6766
[2025-07-19T19:57:27.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66] for update
[2025-07-19T19:57:27.195+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.198+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/.2.delta.c8b9d584-ae09-4856-a861-e53cab96b88f.TID863.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/2.delta
[2025-07-19T19:57:27.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/60/2.delta
[2025-07-19T19:57:27.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T19:57:27.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T19:57:27.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/.2.delta.6697fbcd-f021-4d8c-a18a-8ebdc6fc0ea1.TID862.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/2.delta
[2025-07-19T19:57:27.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/59/2.delta
[2025-07-19T19:57:27.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 60.0 in stage 9.0 (TID 863). 5872 bytes result sent to driver
[2025-07-19T19:57:27.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/.2.delta.e90e4117-7dd5-44e2-95b3-126ff8de0460.TID864.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/2.delta
[2025-07-19T19:57:27.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 67.0 in stage 9.0 (TID 870) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 60.0 in stage 9.0 (TID 863) in 80 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T19:57:27.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/61/2.delta
[2025-07-19T19:57:27.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.2.delta.3d32b33c-9170-4f29-981b-7201613c1471.TID869.tmp
[2025-07-19T19:57:27.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 67.0 in stage 9.0 (TID 870)
[2025-07-19T19:57:27.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T19:57:27.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.212+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:27.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T19:57:27.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T19:57:27.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 59.0 in stage 9.0 (TID 862). 5872 bytes result sent to driver
[2025-07-19T19:57:27.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 68.0 in stage 9.0 (TID 871) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 59.0 in stage 9.0 (TID 862) in 88 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T19:57:27.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f447d23
[2025-07-19T19:57:27.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67] for update
[2025-07-19T19:57:27.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 68.0 in stage 9.0 (TID 871)
[2025-07-19T19:57:27.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/.2.delta.50777faf-5371-4d62-8ccd-55afe43c5471.TID866.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/2.delta
[2025-07-19T19:57:27.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/63/2.delta
[2025-07-19T19:57:27.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T19:57:27.222+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.223+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65c349d8
[2025-07-19T19:57:27.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.225+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68] for update
[2025-07-19T19:57:27.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/.2.delta.b2a069a1-8965-40be-b65e-29f2c3bd9eb1.TID865.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/2.delta
[2025-07-19T19:57:27.231+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/62/2.delta
[2025-07-19T19:57:27.232+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T19:57:27.233+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T19:57:27.234+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T19:57:27.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 61.0 in stage 9.0 (TID 864). 5872 bytes result sent to driver
[2025-07-19T19:57:27.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 63.0 in stage 9.0 (TID 866). 5872 bytes result sent to driver
[2025-07-19T19:57:27.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 69.0 in stage 9.0 (TID 872) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.238+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 61.0 in stage 9.0 (TID 864) in 102 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T19:57:27.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 69.0 in stage 9.0 (TID 872)
[2025-07-19T19:57:27.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 70.0 in stage 9.0 (TID 873) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 70.0 in stage 9.0 (TID 873)
[2025-07-19T19:57:27.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/.2.delta.2333b3d4-3616-4505-a2b2-2248ca0bd9dd.TID868.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/2.delta
[2025-07-19T19:57:27.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/65/2.delta
[2025-07-19T19:57:27.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T19:57:27.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T19:57:27.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 63.0 in stage 9.0 (TID 866) in 84 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T19:57:27.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 62.0 in stage 9.0 (TID 865). 5872 bytes result sent to driver
[2025-07-19T19:57:27.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 71.0 in stage 9.0 (TID 874) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 71.0 in stage 9.0 (TID 874)
[2025-07-19T19:57:27.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d91db0d
[2025-07-19T19:57:27.241+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 62.0 in stage 9.0 (TID 865) in 103 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T19:57:27.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T19:57:27.242+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 65.0 in stage 9.0 (TID 868). 5872 bytes result sent to driver
[2025-07-19T19:57:27.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.243+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70] for update
[2025-07-19T19:57:27.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.2.delta.76fbd000-443c-4c4d-9227-abf4e900c1fd.TID870.tmp
[2025-07-19T19:57:27.244+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.245+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.247+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65869864
[2025-07-19T19:57:27.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69] for update
[2025-07-19T19:57:27.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 72.0 in stage 9.0 (TID 875) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 65.0 in stage 9.0 (TID 868) in 74 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T19:57:27.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 72.0 in stage 9.0 (TID 875)
[2025-07-19T19:57:27.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.251+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cc657e7
[2025-07-19T19:57:27.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71] for update
[2025-07-19T19:57:27.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69f711f4
[2025-07-19T19:57:27.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72] for update
[2025-07-19T19:57:27.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.2.delta.11949d20-bd32-4ac4-a877-e83812f50b4c.TID871.tmp
[2025-07-19T19:57:27.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/.2.delta.3d32b33c-9170-4f29-981b-7201613c1471.TID869.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/2.delta
[2025-07-19T19:57:27.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/66/2.delta
[2025-07-19T19:57:27.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/.2.delta.16a87fda-fd80-4743-ae9f-4def9eaf8524.TID867.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/2.delta
[2025-07-19T19:57:27.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/64/2.delta
[2025-07-19T19:57:27.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T19:57:27.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T19:57:27.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.2.delta.0b690e63-e75e-4991-bc32-880c183b53c3.TID873.tmp
[2025-07-19T19:57:27.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.2.delta.b800362b-8fe3-4f89-9f0a-13bf6895f69b.TID874.tmp
[2025-07-19T19:57:27.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T19:57:27.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T19:57:27.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 66.0 in stage 9.0 (TID 869). 5829 bytes result sent to driver
[2025-07-19T19:57:27.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 64.0 in stage 9.0 (TID 867). 5872 bytes result sent to driver
[2025-07-19T19:57:27.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.2.delta.fb099536-cac1-4770-83bb-ac1dd1bc257e.TID872.tmp
[2025-07-19T19:57:27.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 64.0 in stage 9.0 (TID 867) in 98 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T19:57:27.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 73.0 in stage 9.0 (TID 876) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 74.0 in stage 9.0 (TID 877) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 73.0 in stage 9.0 (TID 876)
[2025-07-19T19:57:27.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 74.0 in stage 9.0 (TID 877)
[2025-07-19T19:57:27.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.2.delta.dbb734be-5b7b-40e4-a28d-8e29b0e965a5.TID875.tmp
[2025-07-19T19:57:27.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 66.0 in stage 9.0 (TID 869) in 66 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T19:57:27.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ea82b27
[2025-07-19T19:57:27.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73] for update
[2025-07-19T19:57:27.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9326b11
[2025-07-19T19:57:27.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74] for update
[2025-07-19T19:57:27.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.2.delta.21144c10-4e79-4380-8091-51dece7a372c.TID876.tmp
[2025-07-19T19:57:27.268+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.2.delta.225ad5a4-5ae1-43a0-8de1-d193dcecac0f.TID877.tmp
[2025-07-19T19:57:27.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/.2.delta.76fbd000-443c-4c4d-9227-abf4e900c1fd.TID870.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/2.delta
[2025-07-19T19:57:27.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/67/2.delta
[2025-07-19T19:57:27.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T19:57:27.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/.2.delta.0b690e63-e75e-4991-bc32-880c183b53c3.TID873.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/2.delta
[2025-07-19T19:57:27.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/70/2.delta
[2025-07-19T19:57:27.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T19:57:27.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/.2.delta.11949d20-bd32-4ac4-a877-e83812f50b4c.TID871.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/2.delta
[2025-07-19T19:57:27.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/68/2.delta
[2025-07-19T19:57:27.278+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T19:57:27.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T19:57:27.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T19:57:27.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 67.0 in stage 9.0 (TID 870). 5829 bytes result sent to driver
[2025-07-19T19:57:27.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/.2.delta.b800362b-8fe3-4f89-9f0a-13bf6895f69b.TID874.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/2.delta
[2025-07-19T19:57:27.283+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/71/2.delta
[2025-07-19T19:57:27.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T19:57:27.286+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 70.0 in stage 9.0 (TID 873). 5829 bytes result sent to driver
[2025-07-19T19:57:27.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/.2.delta.dbb734be-5b7b-40e4-a28d-8e29b0e965a5.TID875.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/2.delta
[2025-07-19T19:57:27.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/72/2.delta
[2025-07-19T19:57:27.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 68.0 in stage 9.0 (TID 871). 5829 bytes result sent to driver
[2025-07-19T19:57:27.288+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 75.0 in stage 9.0 (TID 878) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/.2.delta.fb099536-cac1-4770-83bb-ac1dd1bc257e.TID872.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/2.delta
[2025-07-19T19:57:27.290+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/69/2.delta
[2025-07-19T19:57:27.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 76.0 in stage 9.0 (TID 879) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 75.0 in stage 9.0 (TID 878)
[2025-07-19T19:57:27.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T19:57:27.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 70.0 in stage 9.0 (TID 873) in 52 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T19:57:27.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 76.0 in stage 9.0 (TID 879)
[2025-07-19T19:57:27.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 77.0 in stage 9.0 (TID 880) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T19:57:27.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T19:57:27.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 68.0 in stage 9.0 (TID 871) in 69 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T19:57:27.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 77.0 in stage 9.0 (TID 880)
[2025-07-19T19:57:27.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@541f58f6
[2025-07-19T19:57:27.298+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T19:57:27.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 67.0 in stage 9.0 (TID 870) in 79 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T19:57:27.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75] for update
[2025-07-19T19:57:27.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 71.0 in stage 9.0 (TID 874). 5829 bytes result sent to driver
[2025-07-19T19:57:27.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1db16484
[2025-07-19T19:57:27.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 78.0 in stage 9.0 (TID 881) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T19:57:27.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77] for update
[2025-07-19T19:57:27.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 78.0 in stage 9.0 (TID 881)
[2025-07-19T19:57:27.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 72.0 in stage 9.0 (TID 875). 5829 bytes result sent to driver
[2025-07-19T19:57:27.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 71.0 in stage 9.0 (TID 874) in 55 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T19:57:27.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T19:57:27.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 69.0 in stage 9.0 (TID 872). 5829 bytes result sent to driver
[2025-07-19T19:57:27.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e45fa45
[2025-07-19T19:57:27.305+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 79.0 in stage 9.0 (TID 882) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 79.0 in stage 9.0 (TID 882)
[2025-07-19T19:57:27.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 80.0 in stage 9.0 (TID 883) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76] for update
[2025-07-19T19:57:27.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 72.0 in stage 9.0 (TID 875) in 54 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T19:57:27.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 69.0 in stage 9.0 (TID 872) in 65 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T19:57:27.308+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.2.delta.d5360c9e-9ce3-4bd1-a5a7-e56b880740a3.TID878.tmp
[2025-07-19T19:57:27.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:27.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.2.delta.2a80a490-186e-42ba-8f0a-0cf9125edddf.TID880.tmp
[2025-07-19T19:57:27.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 80.0 in stage 9.0 (TID 883)
[2025-07-19T19:57:27.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:27.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5905aba5
[2025-07-19T19:57:27.311+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78] for update
[2025-07-19T19:57:27.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61f5bd2c
[2025-07-19T19:57:27.312+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79] for update
[2025-07-19T19:57:27.313+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3755d756
[2025-07-19T19:57:27.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80] for update
[2025-07-19T19:57:27.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/.2.delta.21144c10-4e79-4380-8091-51dece7a372c.TID876.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/2.delta
[2025-07-19T19:57:27.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/73/2.delta
[2025-07-19T19:57:27.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T19:57:27.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.2.delta.87001c6b-1773-4d72-8cee-0f065ab9eb5e.TID881.tmp
[2025-07-19T19:57:27.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.2.delta.172fc207-4d17-4e82-975d-e05992773bc5.TID882.tmp
[2025-07-19T19:57:27.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.2.delta.73f4744e-9dc7-4f98-82c5-4666da07beee.TID879.tmp
[2025-07-19T19:57:27.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.2.delta.a4fe3060-ab22-4b71-a4db-7f71a85ba4ad.TID883.tmp
[2025-07-19T19:57:27.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T19:57:27.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 73.0 in stage 9.0 (TID 876). 5829 bytes result sent to driver
[2025-07-19T19:57:27.319+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 81.0 in stage 9.0 (TID 884) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 81.0 in stage 9.0 (TID 884)
[2025-07-19T19:57:27.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 73.0 in stage 9.0 (TID 876) in 52 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T19:57:27.321+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/.2.delta.225ad5a4-5ae1-43a0-8de1-d193dcecac0f.TID877.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/2.delta
[2025-07-19T19:57:27.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/74/2.delta
[2025-07-19T19:57:27.322+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T19:57:27.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a7f5549
[2025-07-19T19:57:27.324+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81] for update
[2025-07-19T19:57:27.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.325+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T19:57:27.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 74.0 in stage 9.0 (TID 877). 5829 bytes result sent to driver
[2025-07-19T19:57:27.326+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 82.0 in stage 9.0 (TID 885) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.327+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 82.0 in stage 9.0 (TID 885)
[2025-07-19T19:57:27.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 74.0 in stage 9.0 (TID 877) in 63 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T19:57:27.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.328+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fc3ff80
[2025-07-19T19:57:27.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.2.delta.6c91c189-692c-45e5-97cb-47c989eb3235.TID884.tmp
[2025-07-19T19:57:27.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82] for update
[2025-07-19T19:57:27.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/.2.delta.d5360c9e-9ce3-4bd1-a5a7-e56b880740a3.TID878.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/2.delta
[2025-07-19T19:57:27.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/75/2.delta
[2025-07-19T19:57:27.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T19:57:27.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/.2.delta.2a80a490-186e-42ba-8f0a-0cf9125edddf.TID880.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/2.delta
[2025-07-19T19:57:27.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/77/2.delta
[2025-07-19T19:57:27.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/.2.delta.87001c6b-1773-4d72-8cee-0f065ab9eb5e.TID881.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/2.delta
[2025-07-19T19:57:27.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/78/2.delta
[2025-07-19T19:57:27.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/.2.delta.73f4744e-9dc7-4f98-82c5-4666da07beee.TID879.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/2.delta
[2025-07-19T19:57:27.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/76/2.delta
[2025-07-19T19:57:27.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T19:57:27.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T19:57:27.335+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T19:57:27.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T19:57:27.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T19:57:27.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 77.0 in stage 9.0 (TID 880). 5786 bytes result sent to driver
[2025-07-19T19:57:27.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 75.0 in stage 9.0 (TID 878). 5829 bytes result sent to driver
[2025-07-19T19:57:27.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 83.0 in stage 9.0 (TID 886) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 83.0 in stage 9.0 (TID 886)
[2025-07-19T19:57:27.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 84.0 in stage 9.0 (TID 887) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 84.0 in stage 9.0 (TID 887)
[2025-07-19T19:57:27.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 75.0 in stage 9.0 (TID 878) in 55 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T19:57:27.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T19:57:27.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 77.0 in stage 9.0 (TID 880) in 54 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T19:57:27.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 78.0 in stage 9.0 (TID 881). 5829 bytes result sent to driver
[2025-07-19T19:57:27.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T19:57:27.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 85.0 in stage 9.0 (TID 888) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 76.0 in stage 9.0 (TID 879). 5829 bytes result sent to driver
[2025-07-19T19:57:27.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 85.0 in stage 9.0 (TID 888)
[2025-07-19T19:57:27.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 86.0 in stage 9.0 (TID 889) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 86.0 in stage 9.0 (TID 889)
[2025-07-19T19:57:27.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.350+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 78.0 in stage 9.0 (TID 881) in 51 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T19:57:27.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 76.0 in stage 9.0 (TID 879) in 59 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T19:57:27.353+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f6c384e
[2025-07-19T19:57:27.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84] for update
[2025-07-19T19:57:27.357+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@601b2359
[2025-07-19T19:57:27.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86] for update
[2025-07-19T19:57:27.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a03c9cb
[2025-07-19T19:57:27.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85] for update
[2025-07-19T19:57:27.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@688bb9e6
[2025-07-19T19:57:27.362+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.362+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83] for update
[2025-07-19T19:57:27.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/.2.delta.a4fe3060-ab22-4b71-a4db-7f71a85ba4ad.TID883.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/2.delta
[2025-07-19T19:57:27.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/80/2.delta
[2025-07-19T19:57:27.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.2.delta.ba1551ad-a76b-4fc4-9039-89ae6e8d37f2.TID885.tmp
[2025-07-19T19:57:27.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T19:57:27.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/.2.delta.172fc207-4d17-4e82-975d-e05992773bc5.TID882.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/2.delta
[2025-07-19T19:57:27.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/79/2.delta
[2025-07-19T19:57:27.365+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T19:57:27.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T19:57:27.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.2.delta.de8f720a-4ebf-4616-8935-8a2f7ac58b09.TID887.tmp
[2025-07-19T19:57:27.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 80.0 in stage 9.0 (TID 883). 5829 bytes result sent to driver
[2025-07-19T19:57:27.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.2.delta.f6b84f6c-a9d4-46e1-978b-685238ae54c3.TID889.tmp
[2025-07-19T19:57:27.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 87.0 in stage 9.0 (TID 890) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T19:57:27.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 80.0 in stage 9.0 (TID 883) in 66 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T19:57:27.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 87.0 in stage 9.0 (TID 890)
[2025-07-19T19:57:27.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 79.0 in stage 9.0 (TID 882). 5786 bytes result sent to driver
[2025-07-19T19:57:27.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 88.0 in stage 9.0 (TID 891) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 79.0 in stage 9.0 (TID 882) in 69 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T19:57:27.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 88.0 in stage 9.0 (TID 891)
[2025-07-19T19:57:27.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.2.delta.2c4cd5a8-39a8-4ceb-b91d-507351a669de.TID888.tmp
[2025-07-19T19:57:27.369+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.2.delta.06df4a71-1ea8-4314-9938-5486dbdb30bf.TID886.tmp
[2025-07-19T19:57:27.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.370+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47df4639
[2025-07-19T19:57:27.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87] for update
[2025-07-19T19:57:27.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b868a2a
[2025-07-19T19:57:27.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88] for update
[2025-07-19T19:57:27.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.373+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/.2.delta.6c91c189-692c-45e5-97cb-47c989eb3235.TID884.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/2.delta
[2025-07-19T19:57:27.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/81/2.delta
[2025-07-19T19:57:27.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T19:57:27.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.2.delta.4f9c0364-f9d5-4816-b568-f9ec7d5b4778.TID891.tmp
[2025-07-19T19:57:27.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T19:57:27.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 81.0 in stage 9.0 (TID 884). 5829 bytes result sent to driver
[2025-07-19T19:57:27.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.2.delta.bc790c6f-11cb-4fe0-9f5c-ee9772c92287.TID890.tmp
[2025-07-19T19:57:27.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 89.0 in stage 9.0 (TID 892) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 81.0 in stage 9.0 (TID 884) in 76 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T19:57:27.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 89.0 in stage 9.0 (TID 892)
[2025-07-19T19:57:27.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36aa6840
[2025-07-19T19:57:27.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89] for update
[2025-07-19T19:57:27.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/.2.delta.de8f720a-4ebf-4616-8935-8a2f7ac58b09.TID887.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/2.delta
[2025-07-19T19:57:27.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/84/2.delta
[2025-07-19T19:57:27.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T19:57:27.394+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/.2.delta.ba1551ad-a76b-4fc4-9039-89ae6e8d37f2.TID885.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/2.delta
[2025-07-19T19:57:27.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/82/2.delta
[2025-07-19T19:57:27.396+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T19:57:27.397+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T19:57:27.397+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.2.delta.be55761e-4e8f-4406-81d9-d00bc23a7376.TID892.tmp
[2025-07-19T19:57:27.397+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 84.0 in stage 9.0 (TID 887). 5829 bytes result sent to driver
[2025-07-19T19:57:27.398+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 90.0 in stage 9.0 (TID 893) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T19:57:27.403+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/.2.delta.f6b84f6c-a9d4-46e1-978b-685238ae54c3.TID889.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/2.delta
[2025-07-19T19:57:27.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/86/2.delta
[2025-07-19T19:57:27.405+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 82.0 in stage 9.0 (TID 885). 5829 bytes result sent to driver
[2025-07-19T19:57:27.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T19:57:27.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 84.0 in stage 9.0 (TID 887) in 66 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T19:57:27.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 82.0 in stage 9.0 (TID 885) in 84 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T19:57:27.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 91.0 in stage 9.0 (TID 894) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 90.0 in stage 9.0 (TID 893)
[2025-07-19T19:57:27.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/.2.delta.06df4a71-1ea8-4314-9938-5486dbdb30bf.TID886.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/2.delta
[2025-07-19T19:57:27.410+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/83/2.delta
[2025-07-19T19:57:27.411+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 91.0 in stage 9.0 (TID 894)
[2025-07-19T19:57:27.411+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T19:57:27.411+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T19:57:27.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T19:57:27.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2faae29
[2025-07-19T19:57:27.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 83.0 in stage 9.0 (TID 886). 5829 bytes result sent to driver
[2025-07-19T19:57:27.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 86.0 in stage 9.0 (TID 889). 5829 bytes result sent to driver
[2025-07-19T19:57:27.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 92.0 in stage 9.0 (TID 895) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91] for update
[2025-07-19T19:57:27.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 93.0 in stage 9.0 (TID 896) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 83.0 in stage 9.0 (TID 886) in 77 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T19:57:27.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 86.0 in stage 9.0 (TID 889) in 74 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T19:57:27.419+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 93.0 in stage 9.0 (TID 896)
[2025-07-19T19:57:27.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@282fe0fa
[2025-07-19T19:57:27.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 92.0 in stage 9.0 (TID 895)
[2025-07-19T19:57:27.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90] for update
[2025-07-19T19:57:27.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fd03533
[2025-07-19T19:57:27.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93] for update
[2025-07-19T19:57:27.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d8816b6
[2025-07-19T19:57:27.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92] for update
[2025-07-19T19:57:27.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/.2.delta.2c4cd5a8-39a8-4ceb-b91d-507351a669de.TID888.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/2.delta
[2025-07-19T19:57:27.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/85/2.delta
[2025-07-19T19:57:27.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T19:57:27.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T19:57:27.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 85.0 in stage 9.0 (TID 888). 5786 bytes result sent to driver
[2025-07-19T19:57:27.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 94.0 in stage 9.0 (TID 897) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.2.delta.965a8ec6-0bcb-4d81-a65d-864310b8834a.TID894.tmp
[2025-07-19T19:57:27.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 94.0 in stage 9.0 (TID 897)
[2025-07-19T19:57:27.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.2.delta.7ae6bcf0-ece2-4a23-878e-60b9740475dd.TID893.tmp
[2025-07-19T19:57:27.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 85.0 in stage 9.0 (TID 888) in 90 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T19:57:27.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/.2.delta.4f9c0364-f9d5-4816-b568-f9ec7d5b4778.TID891.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/2.delta
[2025-07-19T19:57:27.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/88/2.delta
[2025-07-19T19:57:27.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T19:57:27.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a496b20
[2025-07-19T19:57:27.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94] for update
[2025-07-19T19:57:27.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.2.delta.0e6cc001-415a-4b3f-ac4b-473c3fac8dc0.TID896.tmp
[2025-07-19T19:57:27.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/.2.delta.bc790c6f-11cb-4fe0-9f5c-ee9772c92287.TID890.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/2.delta
[2025-07-19T19:57:27.438+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/87/2.delta
[2025-07-19T19:57:27.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T19:57:27.439+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T19:57:27.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.2.delta.1997d542-711c-40ac-9f9d-4baca0b1fa88.TID895.tmp
[2025-07-19T19:57:27.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 88.0 in stage 9.0 (TID 891). 5829 bytes result sent to driver
[2025-07-19T19:57:27.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T19:57:27.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 95.0 in stage 9.0 (TID 898) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 95.0 in stage 9.0 (TID 898)
[2025-07-19T19:57:27.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 87.0 in stage 9.0 (TID 890). 5829 bytes result sent to driver
[2025-07-19T19:57:27.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 88.0 in stage 9.0 (TID 891) in 83 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T19:57:27.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 96.0 in stage 9.0 (TID 899) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b5e8d88
[2025-07-19T19:57:27.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95] for update
[2025-07-19T19:57:27.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 96.0 in stage 9.0 (TID 899)
[2025-07-19T19:57:27.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 87.0 in stage 9.0 (TID 890) in 91 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T19:57:27.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.448+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f8d0a84
[2025-07-19T19:57:27.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96] for update
[2025-07-19T19:57:27.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/.2.delta.be55761e-4e8f-4406-81d9-d00bc23a7376.TID892.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/2.delta
[2025-07-19T19:57:27.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/89/2.delta
[2025-07-19T19:57:27.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.2.delta.e3847be2-3fc4-4a6f-b8d5-841482c7e010.TID897.tmp
[2025-07-19T19:57:27.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T19:57:27.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T19:57:27.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 89.0 in stage 9.0 (TID 892). 5829 bytes result sent to driver
[2025-07-19T19:57:27.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 97.0 in stage 9.0 (TID 900) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 89.0 in stage 9.0 (TID 892) in 75 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T19:57:27.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 97.0 in stage 9.0 (TID 900)
[2025-07-19T19:57:27.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.2.delta.44071394-425d-4e6f-baea-791336b87cf8.TID898.tmp
[2025-07-19T19:57:27.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3174791b
[2025-07-19T19:57:27.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97] for update
[2025-07-19T19:57:27.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.2.delta.3bfed280-bef5-436c-8e9c-b89b1ab321d0.TID899.tmp
[2025-07-19T19:57:27.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/.2.delta.7ae6bcf0-ece2-4a23-878e-60b9740475dd.TID893.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/2.delta
[2025-07-19T19:57:27.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/90/2.delta
[2025-07-19T19:57:27.462+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T19:57:27.465+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.465+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T19:57:27.465+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 90.0 in stage 9.0 (TID 893). 5829 bytes result sent to driver
[2025-07-19T19:57:27.466+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 90.0 in stage 9.0 (TID 893) in 68 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T19:57:27.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 98.0 in stage 9.0 (TID 901) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 98.0 in stage 9.0 (TID 901)
[2025-07-19T19:57:27.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/.2.delta.965a8ec6-0bcb-4d81-a65d-864310b8834a.TID894.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/2.delta
[2025-07-19T19:57:27.470+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/91/2.delta
[2025-07-19T19:57:27.471+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.2.delta.b9e93457-8d9e-4afc-a32a-6fd0eeb94c08.TID900.tmp
[2025-07-19T19:57:27.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78e4fda1
[2025-07-19T19:57:27.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T19:57:27.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98] for update
[2025-07-19T19:57:27.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.567+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T19:57:27.568+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 91.0 in stage 9.0 (TID 894). 5829 bytes result sent to driver
[2025-07-19T19:57:27.569+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 99.0 in stage 9.0 (TID 902) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.572+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 91.0 in stage 9.0 (TID 894) in 163 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T19:57:27.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/.2.delta.0e6cc001-415a-4b3f-ac4b-473c3fac8dc0.TID896.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/2.delta
[2025-07-19T19:57:27.573+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/93/2.delta
[2025-07-19T19:57:27.574+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 99.0 in stage 9.0 (TID 902)
[2025-07-19T19:57:27.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T19:57:27.575+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/.2.delta.e3847be2-3fc4-4a6f-b8d5-841482c7e010.TID897.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/2.delta
[2025-07-19T19:57:27.576+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/94/2.delta
[2025-07-19T19:57:27.578+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.2.delta.663a296e-2fd6-4452-9f1c-dad60e2df8dc.TID901.tmp
[2025-07-19T19:57:27.579+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T19:57:27.580+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.580+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cebce93
[2025-07-19T19:57:27.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99] for update
[2025-07-19T19:57:27.581+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T19:57:27.582+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.586+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 93.0 in stage 9.0 (TID 896). 5829 bytes result sent to driver
[2025-07-19T19:57:27.598+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 100.0 in stage 9.0 (TID 903) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.603+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 100.0 in stage 9.0 (TID 903)
[2025-07-19T19:57:27.604+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 93.0 in stage 9.0 (TID 896) in 166 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T19:57:27.605+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/.2.delta.1997d542-711c-40ac-9f9d-4baca0b1fa88.TID895.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/2.delta
[2025-07-19T19:57:27.608+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/92/2.delta
[2025-07-19T19:57:27.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T19:57:27.609+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T19:57:27.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 94.0 in stage 9.0 (TID 897). 5829 bytes result sent to driver
[2025-07-19T19:57:27.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 101.0 in stage 9.0 (TID 904) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 101.0 in stage 9.0 (TID 904)
[2025-07-19T19:57:27.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 94.0 in stage 9.0 (TID 897) in 156 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T19:57:27.610+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f355380
[2025-07-19T19:57:27.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100] for update
[2025-07-19T19:57:27.611+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1da33a78
[2025-07-19T19:57:27.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101] for update
[2025-07-19T19:57:27.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T19:57:27.613+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 92.0 in stage 9.0 (TID 895). 5786 bytes result sent to driver
[2025-07-19T19:57:27.614+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 102.0 in stage 9.0 (TID 905) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.615+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 102.0 in stage 9.0 (TID 905)
[2025-07-19T19:57:27.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 92.0 in stage 9.0 (TID 895) in 186 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T19:57:27.616+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.617+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.618+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2348a46e
[2025-07-19T19:57:27.619+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.620+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102] for update
[2025-07-19T19:57:27.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.621+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.2.delta.dc0e1d9e-5cf9-4221-bcfe-2b0080666036.TID902.tmp
[2025-07-19T19:57:27.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/.2.delta.44071394-425d-4e6f-baea-791336b87cf8.TID898.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/2.delta
[2025-07-19T19:57:27.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/95/2.delta
[2025-07-19T19:57:27.625+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T19:57:27.626+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.2.delta.a685c0b2-48a6-4b49-a765-ef87cf2aca66.TID904.tmp
[2025-07-19T19:57:27.627+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.2.delta.e7e976ba-bb45-4104-908f-2ab17c5acbfe.TID903.tmp
[2025-07-19T19:57:27.628+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T19:57:27.629+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.2.delta.3a86f1a3-6a9f-4ee5-a874-c7453c9eb3a7.TID905.tmp
[2025-07-19T19:57:27.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 95.0 in stage 9.0 (TID 898). 5829 bytes result sent to driver
[2025-07-19T19:57:27.630+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 103.0 in stage 9.0 (TID 906) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.631+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 103.0 in stage 9.0 (TID 906)
[2025-07-19T19:57:27.632+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 95.0 in stage 9.0 (TID 898) in 180 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T19:57:27.634+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7290e7d1
[2025-07-19T19:57:27.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/.2.delta.b9e93457-8d9e-4afc-a32a-6fd0eeb94c08.TID900.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/2.delta
[2025-07-19T19:57:27.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/97/2.delta
[2025-07-19T19:57:27.635+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103] for update
[2025-07-19T19:57:27.636+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T19:57:27.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/.2.delta.3bfed280-bef5-436c-8e9c-b89b1ab321d0.TID899.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/2.delta
[2025-07-19T19:57:27.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/96/2.delta
[2025-07-19T19:57:27.641+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.642+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T19:57:27.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T19:57:27.644+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/.2.delta.663a296e-2fd6-4452-9f1c-dad60e2df8dc.TID901.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/2.delta
[2025-07-19T19:57:27.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/98/2.delta
[2025-07-19T19:57:27.645+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T19:57:27.646+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 97.0 in stage 9.0 (TID 900). 5829 bytes result sent to driver
[2025-07-19T19:57:27.647+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 104.0 in stage 9.0 (TID 907) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.647+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T19:57:27.648+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 96.0 in stage 9.0 (TID 899). 5829 bytes result sent to driver
[2025-07-19T19:57:27.649+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 105.0 in stage 9.0 (TID 908) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 104.0 in stage 9.0 (TID 907)
[2025-07-19T19:57:27.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 97.0 in stage 9.0 (TID 900) in 177 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T19:57:27.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 105.0 in stage 9.0 (TID 908)
[2025-07-19T19:57:27.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 96.0 in stage 9.0 (TID 899) in 191 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T19:57:27.652+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.653+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.654+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T19:57:27.655+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 98.0 in stage 9.0 (TID 901). 5829 bytes result sent to driver
[2025-07-19T19:57:27.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.2.delta.ba617811-b5d6-4ab8-926e-3a7fcb7c8efc.TID906.tmp
[2025-07-19T19:57:27.657+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4825fd98
[2025-07-19T19:57:27.658+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 106.0 in stage 9.0 (TID 909) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 98.0 in stage 9.0 (TID 901) in 172 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T19:57:27.659+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 106.0 in stage 9.0 (TID 909)
[2025-07-19T19:57:27.661+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.662+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104] for update
[2025-07-19T19:57:27.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.664+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31cfb953
[2025-07-19T19:57:27.666+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.667+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105] for update
[2025-07-19T19:57:27.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a6c1e2d
[2025-07-19T19:57:27.669+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106] for update
[2025-07-19T19:57:27.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/.2.delta.dc0e1d9e-5cf9-4221-bcfe-2b0080666036.TID902.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/2.delta
[2025-07-19T19:57:27.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/99/2.delta
[2025-07-19T19:57:27.670+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T19:57:27.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.671+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T19:57:27.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/.2.delta.e7e976ba-bb45-4104-908f-2ab17c5acbfe.TID903.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/2.delta
[2025-07-19T19:57:27.672+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/100/2.delta
[2025-07-19T19:57:27.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T19:57:27.673+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 99.0 in stage 9.0 (TID 902). 5872 bytes result sent to driver
[2025-07-19T19:57:27.674+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 107.0 in stage 9.0 (TID 910) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.675+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 107.0 in stage 9.0 (TID 910)
[2025-07-19T19:57:27.676+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/.2.delta.3a86f1a3-6a9f-4ee5-a874-c7453c9eb3a7.TID905.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/2.delta
[2025-07-19T19:57:27.677+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/102/2.delta
[2025-07-19T19:57:27.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/.2.delta.a685c0b2-48a6-4b49-a765-ef87cf2aca66.TID904.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/2.delta
[2025-07-19T19:57:27.678+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/101/2.delta
[2025-07-19T19:57:27.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 99.0 in stage 9.0 (TID 902) in 121 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T19:57:27.680+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T19:57:27.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T19:57:27.681+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.2.delta.8bcc716f-1e2e-4448-a0a1-947c65119973.TID908.tmp
[2025-07-19T19:57:27.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T19:57:27.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.682+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 101.0 in stage 9.0 (TID 904). 5829 bytes result sent to driver
[2025-07-19T19:57:27.683+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T19:57:27.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T19:57:27.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 102.0 in stage 9.0 (TID 905). 5829 bytes result sent to driver
[2025-07-19T19:57:27.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 108.0 in stage 9.0 (TID 911) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.684+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 109.0 in stage 9.0 (TID 912) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 108.0 in stage 9.0 (TID 911)
[2025-07-19T19:57:27.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 100.0 in stage 9.0 (TID 903). 5829 bytes result sent to driver
[2025-07-19T19:57:27.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3941e1a1
[2025-07-19T19:57:27.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 109.0 in stage 9.0 (TID 912)
[2025-07-19T19:57:27.685+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107] for update
[2025-07-19T19:57:27.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 101.0 in stage 9.0 (TID 904) in 80 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T19:57:27.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 110.0 in stage 9.0 (TID 913) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.686+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 110.0 in stage 9.0 (TID 913)
[2025-07-19T19:57:27.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 102.0 in stage 9.0 (TID 905) in 70 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T19:57:27.687+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 100.0 in stage 9.0 (TID 903) in 87 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T19:57:27.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.2.delta.0c386c1f-f930-43c5-90f6-bfde7885ae50.TID909.tmp
[2025-07-19T19:57:27.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.2.delta.93ef7a74-4824-43bb-87ca-b7848b887b8f.TID907.tmp
[2025-07-19T19:57:27.688+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68a811ee
[2025-07-19T19:57:27.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.689+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109] for update
[2025-07-19T19:57:27.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.690+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23fa6e46
[2025-07-19T19:57:27.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110] for update
[2025-07-19T19:57:27.691+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c624c97
[2025-07-19T19:57:27.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108] for update
[2025-07-19T19:57:27.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.2.delta.b2fab782-b371-41c8-b238-6798fbf4a687.TID910.tmp
[2025-07-19T19:57:27.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/.2.delta.ba617811-b5d6-4ab8-926e-3a7fcb7c8efc.TID906.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/2.delta
[2025-07-19T19:57:27.692+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/103/2.delta
[2025-07-19T19:57:27.693+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T19:57:27.693+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.2.delta.87c12f61-68bc-49d2-b4df-ec529ccd53e5.TID913.tmp
[2025-07-19T19:57:27.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T19:57:27.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.2.delta.64ccc384-20cd-4a37-aa57-81e72d19d488.TID912.tmp
[2025-07-19T19:57:27.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 103.0 in stage 9.0 (TID 906). 5829 bytes result sent to driver
[2025-07-19T19:57:27.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 111.0 in stage 9.0 (TID 914) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.694+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 103.0 in stage 9.0 (TID 906) in 65 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T19:57:27.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.2.delta.6f233c1a-3226-4197-aedd-43a7d0867837.TID911.tmp
[2025-07-19T19:57:27.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 111.0 in stage 9.0 (TID 914)
[2025-07-19T19:57:27.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/.2.delta.8bcc716f-1e2e-4448-a0a1-947c65119973.TID908.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/2.delta
[2025-07-19T19:57:27.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/105/2.delta
[2025-07-19T19:57:27.695+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ca8e565
[2025-07-19T19:57:27.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T19:57:27.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.696+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111] for update
[2025-07-19T19:57:27.699+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/.2.delta.93ef7a74-4824-43bb-87ca-b7848b887b8f.TID907.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/2.delta
[2025-07-19T19:57:27.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/104/2.delta
[2025-07-19T19:57:27.700+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T19:57:27.701+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T19:57:27.702+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.708+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 105.0 in stage 9.0 (TID 908). 5915 bytes result sent to driver
[2025-07-19T19:57:27.709+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/.2.delta.0c386c1f-f930-43c5-90f6-bfde7885ae50.TID909.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/2.delta
[2025-07-19T19:57:27.711+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/106/2.delta
[2025-07-19T19:57:27.713+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T19:57:27.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 112.0 in stage 9.0 (TID 915) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.714+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 105.0 in stage 9.0 (TID 908) in 78 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T19:57:27.715+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 112.0 in stage 9.0 (TID 915)
[2025-07-19T19:57:27.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.716+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T19:57:27.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54f60f82
[2025-07-19T19:57:27.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 104.0 in stage 9.0 (TID 907). 5872 bytes result sent to driver
[2025-07-19T19:57:27.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T19:57:27.717+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 106.0 in stage 9.0 (TID 909). 5872 bytes result sent to driver
[2025-07-19T19:57:27.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.718+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112] for update
[2025-07-19T19:57:27.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 113.0 in stage 9.0 (TID 916) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 104.0 in stage 9.0 (TID 907) in 85 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T19:57:27.719+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 113.0 in stage 9.0 (TID 916)
[2025-07-19T19:57:27.720+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 106.0 in stage 9.0 (TID 909) in 76 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T19:57:27.721+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/.2.delta.87c12f61-68bc-49d2-b4df-ec529ccd53e5.TID913.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/2.delta
[2025-07-19T19:57:27.722+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/110/2.delta
[2025-07-19T19:57:27.722+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.723+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 114.0 in stage 9.0 (TID 917) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.725+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.726+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T19:57:27.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/.2.delta.b2fab782-b371-41c8-b238-6798fbf4a687.TID910.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/2.delta
[2025-07-19T19:57:27.727+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/107/2.delta
[2025-07-19T19:57:27.728+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 114.0 in stage 9.0 (TID 917)
[2025-07-19T19:57:27.729+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T19:57:27.730+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68408679
[2025-07-19T19:57:27.731+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/.2.delta.6f233c1a-3226-4197-aedd-43a7d0867837.TID911.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/2.delta
[2025-07-19T19:57:27.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/108/2.delta
[2025-07-19T19:57:27.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.732+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113] for update
[2025-07-19T19:57:27.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T19:57:27.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.733+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 110.0 in stage 9.0 (TID 913). 5872 bytes result sent to driver
[2025-07-19T19:57:27.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.734+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.735+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.2.delta.642fdf09-3eef-445e-9707-8089c147edb1.TID915.tmp
[2025-07-19T19:57:27.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T19:57:27.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 115.0 in stage 9.0 (TID 918) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.736+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.2.delta.a74dd864-5331-44bf-8a8a-11c513397806.TID914.tmp
[2025-07-19T19:57:27.737+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 110.0 in stage 9.0 (TID 913) in 64 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T19:57:27.737+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14a3f40c
[2025-07-19T19:57:27.737+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 115.0 in stage 9.0 (TID 918)
[2025-07-19T19:57:27.737+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114] for update
[2025-07-19T19:57:27.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/.2.delta.64ccc384-20cd-4a37-aa57-81e72d19d488.TID912.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/2.delta
[2025-07-19T19:57:27.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/109/2.delta
[2025-07-19T19:57:27.738+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 108.0 in stage 9.0 (TID 911). 5872 bytes result sent to driver
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 107.0 in stage 9.0 (TID 910). 5872 bytes result sent to driver
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 116.0 in stage 9.0 (TID 919) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 117.0 in stage 9.0 (TID 920) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 116.0 in stage 9.0 (TID 919)
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 117.0 in stage 9.0 (TID 920)
[2025-07-19T19:57:27.739+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 108.0 in stage 9.0 (TID 911) in 74 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T19:57:27.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 107.0 in stage 9.0 (TID 910) in 80 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T19:57:27.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.740+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18b34794
[2025-07-19T19:57:27.741+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.2.delta.3a0201ac-9660-4879-adcc-9b1091ab0841.TID916.tmp
[2025-07-19T19:57:27.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T19:57:27.742+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115] for update
[2025-07-19T19:57:27.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 109.0 in stage 9.0 (TID 912). 5872 bytes result sent to driver
[2025-07-19T19:57:27.743+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 118.0 in stage 9.0 (TID 921) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 118.0 in stage 9.0 (TID 921)
[2025-07-19T19:57:27.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f723cab
[2025-07-19T19:57:27.745+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 109.0 in stage 9.0 (TID 912) in 77 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T19:57:27.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117] for update
[2025-07-19T19:57:27.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cbcf7c8
[2025-07-19T19:57:27.746+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116] for update
[2025-07-19T19:57:27.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.2.delta.82e9496c-069d-40a9-8e05-2da3243f31b5.TID920.tmp
[2025-07-19T19:57:27.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b8bd3bd
[2025-07-19T19:57:27.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.747+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118] for update
[2025-07-19T19:57:27.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.2.delta.5fa4d900-6272-4464-8970-3c6e9b20cf0b.TID919.tmp
[2025-07-19T19:57:27.748+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.750+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.2.delta.6ed1afd2-89c2-450c-b66d-b9b2bd74a6e8.TID917.tmp
[2025-07-19T19:57:27.753+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.2.delta.dc47c0c4-edf9-4267-ad6d-f0423bdfc7f2.TID918.tmp
[2025-07-19T19:57:27.756+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.2.delta.ddc36ae0-95ed-4265-b85c-773feead6255.TID921.tmp
[2025-07-19T19:57:27.767+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/.2.delta.642fdf09-3eef-445e-9707-8089c147edb1.TID915.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/2.delta
[2025-07-19T19:57:27.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/112/2.delta
[2025-07-19T19:57:27.769+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T19:57:27.770+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T19:57:27.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 112.0 in stage 9.0 (TID 915). 5829 bytes result sent to driver
[2025-07-19T19:57:27.781+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 119.0 in stage 9.0 (TID 922) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.782+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/.2.delta.a74dd864-5331-44bf-8a8a-11c513397806.TID914.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/2.delta
[2025-07-19T19:57:27.782+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/111/2.delta
[2025-07-19T19:57:27.782+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/.2.delta.82e9496c-069d-40a9-8e05-2da3243f31b5.TID920.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/2.delta
[2025-07-19T19:57:27.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/117/2.delta
[2025-07-19T19:57:27.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 119.0 in stage 9.0 (TID 922)
[2025-07-19T19:57:27.783+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 112.0 in stage 9.0 (TID 915) in 73 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T19:57:27.784+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T19:57:27.785+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 8b44f3d35cfa:44249 in memory (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T19:57:27.786+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T19:57:27.787+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T19:57:27.788+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 117.0 in stage 9.0 (TID 920). 5829 bytes result sent to driver
[2025-07-19T19:57:27.789+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c795439
[2025-07-19T19:57:27.790+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 120.0 in stage 9.0 (TID 923) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.791+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119] for update
[2025-07-19T19:57:27.793+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 117.0 in stage 9.0 (TID 920) in 56 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T19:57:27.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T19:57:27.794+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 120.0 in stage 9.0 (TID 923)
[2025-07-19T19:57:27.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 111.0 in stage 9.0 (TID 914). 5872 bytes result sent to driver
[2025-07-19T19:57:27.795+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 121.0 in stage 9.0 (TID 924) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.796+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 111.0 in stage 9.0 (TID 914) in 108 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T19:57:27.798+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/.2.delta.3a0201ac-9660-4879-adcc-9b1091ab0841.TID916.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/2.delta
[2025-07-19T19:57:27.799+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/113/2.delta
[2025-07-19T19:57:27.799+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:27.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 121.0 in stage 9.0 (TID 924)
[2025-07-19T19:57:27.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T19:57:27.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73f4258c
[2025-07-19T19:57:27.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120] for update
[2025-07-19T19:57:27.800+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/.2.delta.6ed1afd2-89c2-450c-b66d-b9b2bd74a6e8.TID917.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/2.delta
[2025-07-19T19:57:27.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/114/2.delta
[2025-07-19T19:57:27.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T19:57:27.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@852d61c
[2025-07-19T19:57:27.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121] for update
[2025-07-19T19:57:27.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T19:57:27.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 113.0 in stage 9.0 (TID 916). 5829 bytes result sent to driver
[2025-07-19T19:57:27.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 122.0 in stage 9.0 (TID 925) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.801+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 122.0 in stage 9.0 (TID 925)
[2025-07-19T19:57:27.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.2.delta.5ed60320-93e0-4f9a-84c6-4bf65b11d89b.TID922.tmp
[2025-07-19T19:57:27.805+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.807+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/.2.delta.5fa4d900-6272-4464-8970-3c6e9b20cf0b.TID919.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/2.delta
[2025-07-19T19:57:27.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/116/2.delta
[2025-07-19T19:57:27.808+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 113.0 in stage 9.0 (TID 916) in 90 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T19:57:27.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T19:57:27.809+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T19:57:27.810+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 114.0 in stage 9.0 (TID 917). 5829 bytes result sent to driver
[2025-07-19T19:57:27.811+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 123.0 in stage 9.0 (TID 926) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 114.0 in stage 9.0 (TID 917) in 91 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T19:57:27.812+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 123.0 in stage 9.0 (TID 926)
[2025-07-19T19:57:27.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 8b44f3d35cfa:44249 in memory (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T19:57:27.813+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/.2.delta.dc47c0c4-edf9-4267-ad6d-f0423bdfc7f2.TID918.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/2.delta
[2025-07-19T19:57:27.814+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/115/2.delta
[2025-07-19T19:57:27.815+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T19:57:27.816+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T19:57:27.817+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 116.0 in stage 9.0 (TID 919). 5829 bytes result sent to driver
[2025-07-19T19:57:27.819+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 124.0 in stage 9.0 (TID 927) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/.2.delta.ddc36ae0-95ed-4265-b85c-773feead6255.TID921.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/2.delta
[2025-07-19T19:57:27.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/118/2.delta
[2025-07-19T19:57:27.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 124.0 in stage 9.0 (TID 927)
[2025-07-19T19:57:27.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 116.0 in stage 9.0 (TID 919) in 80 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T19:57:27.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T19:57:27.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58e34c2f
[2025-07-19T19:57:27.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.2.delta.2c4b69a9-3682-46ad-b020-b4ac8baab29e.TID924.tmp
[2025-07-19T19:57:27.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122] for update
[2025-07-19T19:57:27.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.2.delta.bedf20be-34d8-43cf-96ae-1a627ee1864c.TID923.tmp
[2025-07-19T19:57:27.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.822+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@418d993a
[2025-07-19T19:57:27.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.823+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124] for update
[2025-07-19T19:57:27.824+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T19:57:27.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T19:57:27.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 118.0 in stage 9.0 (TID 921). 5829 bytes result sent to driver
[2025-07-19T19:57:27.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 115.0 in stage 9.0 (TID 918). 5829 bytes result sent to driver
[2025-07-19T19:57:27.826+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 125.0 in stage 9.0 (TID 928) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.827+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 125.0 in stage 9.0 (TID 928)
[2025-07-19T19:57:27.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 118.0 in stage 9.0 (TID 921) in 84 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T19:57:27.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.828+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 126.0 in stage 9.0 (TID 929) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 115.0 in stage 9.0 (TID 918) in 96 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T19:57:27.829+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 126.0 in stage 9.0 (TID 929)
[2025-07-19T19:57:27.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:27.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.830+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52c22dd6
[2025-07-19T19:57:27.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123] for update
[2025-07-19T19:57:27.831+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26f7853f
[2025-07-19T19:57:27.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.832+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T19:57:27.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.2.delta.9a849dd9-77fb-4b8d-9768-2b71187ceab9.TID925.tmp
[2025-07-19T19:57:27.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.833+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125] for update
[2025-07-19T19:57:27.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.2.delta.ff22280c-532d-4719-97b5-f844b7b96339.TID927.tmp
[2025-07-19T19:57:27.834+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7edaa680
[2025-07-19T19:57:27.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126] for update
[2025-07-19T19:57:27.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/.2.delta.5ed60320-93e0-4f9a-84c6-4bf65b11d89b.TID922.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/2.delta
[2025-07-19T19:57:27.835+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/119/2.delta
[2025-07-19T19:57:27.836+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T19:57:27.837+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.2.delta.c099167f-e8ad-47f0-9f6e-0c742907d6ab.TID929.tmp
[2025-07-19T19:57:27.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T19:57:27.838+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 119.0 in stage 9.0 (TID 922). 5829 bytes result sent to driver
[2025-07-19T19:57:27.839+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 127.0 in stage 9.0 (TID 930) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 119.0 in stage 9.0 (TID 922) in 68 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T19:57:27.840+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 127.0 in stage 9.0 (TID 930)
[2025-07-19T19:57:27.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.2.delta.b73dcdd6-2f30-42f1-96d7-bf2828052c65.TID926.tmp
[2025-07-19T19:57:27.842+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.843+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.843+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5507a999
[2025-07-19T19:57:27.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.844+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127] for update
[2025-07-19T19:57:27.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.2.delta.57c6977d-e08c-41f0-a54c-dbc1bd442b6f.TID928.tmp
[2025-07-19T19:57:27.845+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/.2.delta.bedf20be-34d8-43cf-96ae-1a627ee1864c.TID923.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/2.delta
[2025-07-19T19:57:27.846+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/120/2.delta
[2025-07-19T19:57:27.847+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.849+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T19:57:27.850+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/.2.delta.2c4b69a9-3682-46ad-b020-b4ac8baab29e.TID924.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/2.delta
[2025-07-19T19:57:27.851+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/121/2.delta
[2025-07-19T19:57:27.852+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T19:57:27.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T19:57:27.853+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 120.0 in stage 9.0 (TID 923). 5829 bytes result sent to driver
[2025-07-19T19:57:27.854+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 128.0 in stage 9.0 (TID 931) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.855+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 120.0 in stage 9.0 (TID 923) in 67 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T19:57:27.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 128.0 in stage 9.0 (TID 931)
[2025-07-19T19:57:27.856+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T19:57:27.857+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/.2.delta.9a849dd9-77fb-4b8d-9768-2b71187ceab9.TID925.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/2.delta
[2025-07-19T19:57:27.858+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/122/2.delta
[2025-07-19T19:57:27.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 121.0 in stage 9.0 (TID 924). 5829 bytes result sent to driver
[2025-07-19T19:57:27.859+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.2.delta.96492932-8e0a-46d9-b5e4-acfc64d09acd.TID930.tmp
[2025-07-19T19:57:27.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.860+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T19:57:27.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@576f6eef
[2025-07-19T19:57:27.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 129.0 in stage 9.0 (TID 932) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.861+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128] for update
[2025-07-19T19:57:27.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 121.0 in stage 9.0 (TID 924) in 70 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T19:57:27.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 129.0 in stage 9.0 (TID 932)
[2025-07-19T19:57:27.862+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.863+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.864+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T19:57:27.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 122.0 in stage 9.0 (TID 925). 5829 bytes result sent to driver
[2025-07-19T19:57:27.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63db8cda
[2025-07-19T19:57:27.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 130.0 in stage 9.0 (TID 933) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.865+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129] for update
[2025-07-19T19:57:27.866+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 122.0 in stage 9.0 (TID 925) in 65 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T19:57:27.867+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 130.0 in stage 9.0 (TID 933)
[2025-07-19T19:57:27.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.868+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.869+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53c0a470
[2025-07-19T19:57:27.870+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.2.delta.303124cb-bc59-4895-a772-622f2c472dcd.TID931.tmp
[2025-07-19T19:57:27.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130] for update
[2025-07-19T19:57:27.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/.2.delta.c099167f-e8ad-47f0-9f6e-0c742907d6ab.TID929.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/2.delta
[2025-07-19T19:57:27.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/126/2.delta
[2025-07-19T19:57:27.871+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T19:57:27.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T19:57:27.873+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 126.0 in stage 9.0 (TID 929). 5786 bytes result sent to driver
[2025-07-19T19:57:27.874+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 131.0 in stage 9.0 (TID 934) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 126.0 in stage 9.0 (TID 929) in 55 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T19:57:27.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 131.0 in stage 9.0 (TID 934)
[2025-07-19T19:57:27.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/.2.delta.b73dcdd6-2f30-42f1-96d7-bf2828052c65.TID926.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/2.delta
[2025-07-19T19:57:27.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/123/2.delta
[2025-07-19T19:57:27.875+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T19:57:27.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/.2.delta.57c6977d-e08c-41f0-a54c-dbc1bd442b6f.TID928.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/2.delta
[2025-07-19T19:57:27.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/125/2.delta
[2025-07-19T19:57:27.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/.2.delta.ff22280c-532d-4719-97b5-f844b7b96339.TID927.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/2.delta
[2025-07-19T19:57:27.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T19:57:27.877+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/124/2.delta
[2025-07-19T19:57:27.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T19:57:27.878+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.2.delta.2550d3db-0f3e-4461-9b19-2ea90f9d75eb.TID932.tmp
[2025-07-19T19:57:27.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.879+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.880+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@424e7b63
[2025-07-19T19:57:27.881+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T19:57:27.882+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.883+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131] for update
[2025-07-19T19:57:27.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 123.0 in stage 9.0 (TID 926). 5829 bytes result sent to driver
[2025-07-19T19:57:27.884+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T19:57:27.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 125.0 in stage 9.0 (TID 928). 5829 bytes result sent to driver
[2025-07-19T19:57:27.885+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 132.0 in stage 9.0 (TID 935) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T19:57:27.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 124.0 in stage 9.0 (TID 927). 5829 bytes result sent to driver
[2025-07-19T19:57:27.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 132.0 in stage 9.0 (TID 935)
[2025-07-19T19:57:27.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 133.0 in stage 9.0 (TID 936) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.886+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 134.0 in stage 9.0 (TID 937) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 133.0 in stage 9.0 (TID 936)
[2025-07-19T19:57:27.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 124.0 in stage 9.0 (TID 927) in 72 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T19:57:27.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 125.0 in stage 9.0 (TID 928) in 63 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T19:57:27.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 123.0 in stage 9.0 (TID 926) in 77 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T19:57:27.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 134.0 in stage 9.0 (TID 937)
[2025-07-19T19:57:27.887+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.2.delta.b5d393f5-5c00-4720-8f53-553a56277e4b.TID933.tmp
[2025-07-19T19:57:27.888+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.889+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fba8db9
[2025-07-19T19:57:27.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133] for update
[2025-07-19T19:57:27.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/.2.delta.96492932-8e0a-46d9-b5e4-acfc64d09acd.TID930.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/2.delta
[2025-07-19T19:57:27.891+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/127/2.delta
[2025-07-19T19:57:27.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ae9bd83
[2025-07-19T19:57:27.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T19:57:27.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.892+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132] for update
[2025-07-19T19:57:27.893+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15da0549
[2025-07-19T19:57:27.894+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134] for update
[2025-07-19T19:57:27.895+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.896+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.2.delta.6dcf88e2-b8bb-4c88-a243-931fc4790770.TID934.tmp
[2025-07-19T19:57:27.897+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T19:57:27.898+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 127.0 in stage 9.0 (TID 930). 5829 bytes result sent to driver
[2025-07-19T19:57:27.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 135.0 in stage 9.0 (TID 938) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.899+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 127.0 in stage 9.0 (TID 930) in 52 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T19:57:27.900+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 135.0 in stage 9.0 (TID 938)
[2025-07-19T19:57:27.901+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/.2.delta.303124cb-bc59-4895-a772-622f2c472dcd.TID931.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/2.delta
[2025-07-19T19:57:27.902+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/128/2.delta
[2025-07-19T19:57:27.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.903+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T19:57:27.904+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@640831cd
[2025-07-19T19:57:27.905+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.2.delta.f2ffd4b9-7ad8-4cf9-93c2-28bf73520c09.TID936.tmp
[2025-07-19T19:57:27.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135] for update
[2025-07-19T19:57:27.906+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.907+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T19:57:27.908+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.2.delta.9b958aa4-7937-4625-bc4b-a45b51cc718d.TID935.tmp
[2025-07-19T19:57:27.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 128.0 in stage 9.0 (TID 931). 5829 bytes result sent to driver
[2025-07-19T19:57:27.909+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 136.0 in stage 9.0 (TID 939) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.2.delta.9a65f115-66c8-4164-8415-72e11226e8ba.TID937.tmp
[2025-07-19T19:57:27.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 128.0 in stage 9.0 (TID 931) in 50 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T19:57:27.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 136.0 in stage 9.0 (TID 939)
[2025-07-19T19:57:27.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.911+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23a72536
[2025-07-19T19:57:27.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.2.delta.b72af059-a820-4692-ba3e-d66c059c5e80.TID938.tmp
[2025-07-19T19:57:27.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136] for update
[2025-07-19T19:57:27.912+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.917+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/.2.delta.2550d3db-0f3e-4461-9b19-2ea90f9d75eb.TID932.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/2.delta
[2025-07-19T19:57:27.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/129/2.delta
[2025-07-19T19:57:27.919+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T19:57:27.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T19:57:27.921+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 129.0 in stage 9.0 (TID 932). 5829 bytes result sent to driver
[2025-07-19T19:57:27.922+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 137.0 in stage 9.0 (TID 940) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.923+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 137.0 in stage 9.0 (TID 940)
[2025-07-19T19:57:27.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/.2.delta.b5d393f5-5c00-4720-8f53-553a56277e4b.TID933.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/2.delta
[2025-07-19T19:57:27.924+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/130/2.delta
[2025-07-19T19:57:27.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 129.0 in stage 9.0 (TID 932) in 65 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T19:57:27.925+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T19:57:27.926+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.2.delta.9ed7c76f-9914-4fac-8a92-52273c505a4c.TID939.tmp
[2025-07-19T19:57:27.930+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.931+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/.2.delta.6dcf88e2-b8bb-4c88-a243-931fc4790770.TID934.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/2.delta
[2025-07-19T19:57:27.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.932+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/131/2.delta
[2025-07-19T19:57:27.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T19:57:27.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T19:57:27.933+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 130.0 in stage 9.0 (TID 933). 5829 bytes result sent to driver
[2025-07-19T19:57:27.934+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7444b40a
[2025-07-19T19:57:27.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/.2.delta.f2ffd4b9-7ad8-4cf9-93c2-28bf73520c09.TID936.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/2.delta
[2025-07-19T19:57:27.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/133/2.delta
[2025-07-19T19:57:27.936+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 138.0 in stage 9.0 (TID 941) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.937+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T19:57:27.938+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 130.0 in stage 9.0 (TID 933) in 70 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T19:57:27.939+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137] for update
[2025-07-19T19:57:27.941+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 138.0 in stage 9.0 (TID 941)
[2025-07-19T19:57:27.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T19:57:27.942+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 131.0 in stage 9.0 (TID 934). 5829 bytes result sent to driver
[2025-07-19T19:57:27.943+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.944+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.946+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 139.0 in stage 9.0 (TID 942) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.947+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 131.0 in stage 9.0 (TID 934) in 62 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T19:57:27.948+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 139.0 in stage 9.0 (TID 942)
[2025-07-19T19:57:27.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T19:57:27.949+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.950+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 133.0 in stage 9.0 (TID 936). 5829 bytes result sent to driver
[2025-07-19T19:57:27.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57f6ec53
[2025-07-19T19:57:27.951+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138] for update
[2025-07-19T19:57:27.953+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 140.0 in stage 9.0 (TID 943) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.954+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 133.0 in stage 9.0 (TID 936) in 59 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T19:57:27.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 140.0 in stage 9.0 (TID 943)
[2025-07-19T19:57:27.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.955+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.956+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/.2.delta.b72af059-a820-4692-ba3e-d66c059c5e80.TID938.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/2.delta
[2025-07-19T19:57:27.957+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/135/2.delta
[2025-07-19T19:57:27.958+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bff727
[2025-07-19T19:57:27.959+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.959+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T19:57:27.961+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.962+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140] for update
[2025-07-19T19:57:27.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e43685b
[2025-07-19T19:57:27.963+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T19:57:27.964+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 135.0 in stage 9.0 (TID 938). 5829 bytes result sent to driver
[2025-07-19T19:57:27.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 141.0 in stage 9.0 (TID 944) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.965+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.966+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 135.0 in stage 9.0 (TID 938) in 55 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T19:57:27.967+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 141.0 in stage 9.0 (TID 944)
[2025-07-19T19:57:27.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139] for update
[2025-07-19T19:57:27.968+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.969+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.970+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/.2.delta.9a65f115-66c8-4164-8415-72e11226e8ba.TID937.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/2.delta
[2025-07-19T19:57:27.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/134/2.delta
[2025-07-19T19:57:27.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f09d287
[2025-07-19T19:57:27.971+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T19:57:27.972+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/.2.delta.9b958aa4-7937-4625-bc4b-a45b51cc718d.TID935.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/2.delta
[2025-07-19T19:57:27.973+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/132/2.delta
[2025-07-19T19:57:27.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T19:57:27.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141] for update
[2025-07-19T19:57:27.974+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.2.delta.5b93405a-5550-4dcc-a6da-04536fc09f87.TID940.tmp
[2025-07-19T19:57:27.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T19:57:27.975+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T19:57:27.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 134.0 in stage 9.0 (TID 937). 5829 bytes result sent to driver
[2025-07-19T19:57:27.976+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 132.0 in stage 9.0 (TID 935). 5829 bytes result sent to driver
[2025-07-19T19:57:27.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.2.delta.05d28331-9c82-476c-8e14-1fd3d5932d67.TID941.tmp
[2025-07-19T19:57:27.977+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 142.0 in stage 9.0 (TID 945) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 142.0 in stage 9.0 (TID 945)
[2025-07-19T19:57:27.978+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 143.0 in stage 9.0 (TID 946) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 143.0 in stage 9.0 (TID 946)
[2025-07-19T19:57:27.979+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 134.0 in stage 9.0 (TID 937) in 76 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T19:57:27.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.2.delta.5d73dfa7-8882-4c67-889a-7aa3190cf1ea.TID942.tmp
[2025-07-19T19:57:27.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 132.0 in stage 9.0 (TID 935) in 78 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T19:57:27.980+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.2.delta.21541bfd-db9c-48b5-b2d2-a28f19c10aac.TID943.tmp
[2025-07-19T19:57:27.981+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:27.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c5167a6
[2025-07-19T19:57:27.982+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/.2.delta.9ed7c76f-9914-4fac-8a92-52273c505a4c.TID939.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/2.delta
[2025-07-19T19:57:27.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/136/2.delta
[2025-07-19T19:57:27.983+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T19:57:27.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142] for update
[2025-07-19T19:57:27.984+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.2.delta.a54fecc7-1a96-4b0e-a47b-e1e5262b0587.TID944.tmp
[2025-07-19T19:57:27.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@83be44d
[2025-07-19T19:57:27.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143] for update
[2025-07-19T19:57:27.985+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T19:57:27.986+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 136.0 in stage 9.0 (TID 939). 5829 bytes result sent to driver
[2025-07-19T19:57:27.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 144.0 in stage 9.0 (TID 947) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:27.987+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 136.0 in stage 9.0 (TID 939) in 67 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T19:57:27.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 144.0 in stage 9.0 (TID 947)
[2025-07-19T19:57:27.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:27.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:27.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24321fbd
[2025-07-19T19:57:27.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:27.988+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144] for update
[2025-07-19T19:57:27.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:27.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.2.delta.cf17aac5-43bd-4b14-80b5-2d5bb22d805e.TID946.tmp
[2025-07-19T19:57:27.989+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.2.delta.2bb978e1-6428-416c-8768-5fad3b17cee5.TID945.tmp
[2025-07-19T19:57:27.990+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.2.delta.fa0d0d94-326d-436a-8a30-02c8d300f7cb.TID947.tmp
[2025-07-19T19:57:27.991+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/.2.delta.5d73dfa7-8882-4c67-889a-7aa3190cf1ea.TID942.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/2.delta
[2025-07-19T19:57:27.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/139/2.delta
[2025-07-19T19:57:27.992+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T19:57:27.995+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Committed partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T19:57:27.996+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Finished task 139.0 in stage 9.0 (TID 942). 5829 bytes result sent to driver
[2025-07-19T19:57:27.997+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/.2.delta.05d28331-9c82-476c-8e14-1fd3d5932d67.TID941.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/2.delta
[2025-07-19T19:57:27.998+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/138/2.delta
[2025-07-19T19:57:27.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T19:57:27.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/.2.delta.21541bfd-db9c-48b5-b2d2-a28f19c10aac.TID943.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/2.delta
[2025-07-19T19:57:27.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/140/2.delta
[2025-07-19T19:57:27.999+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Starting task 145.0 in stage 9.0 (TID 948) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO TaskSetManager: Finished task 139.0 in stage 9.0 (TID 942) in 64 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T19:57:28.000+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO Executor: Running task 145.0 in stage 9.0 (TID 948)
[2025-07-19T19:57:28.001+0000] {subprocess.py:93} INFO - 25/07/19 19:57:27 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T19:57:28.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/.2.delta.a54fecc7-1a96-4b0e-a47b-e1e5262b0587.TID944.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/2.delta
[2025-07-19T19:57:28.003+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/141/2.delta
[2025-07-19T19:57:28.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T19:57:28.004+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T19:57:28.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T19:57:28.005+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 140.0 in stage 9.0 (TID 943). 5829 bytes result sent to driver
[2025-07-19T19:57:28.006+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 138.0 in stage 9.0 (TID 941). 5829 bytes result sent to driver
[2025-07-19T19:57:28.007+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.008+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.009+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 146.0 in stage 9.0 (TID 949) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.010+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 146.0 in stage 9.0 (TID 949)
[2025-07-19T19:57:28.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 147.0 in stage 9.0 (TID 950) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.011+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 140.0 in stage 9.0 (TID 943) in 65 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T19:57:28.012+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 138.0 in stage 9.0 (TID 941) in 72 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T19:57:28.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 147.0 in stage 9.0 (TID 950)
[2025-07-19T19:57:28.013+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/.2.delta.5b93405a-5550-4dcc-a6da-04536fc09f87.TID940.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/2.delta
[2025-07-19T19:57:28.015+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/137/2.delta
[2025-07-19T19:57:28.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T19:57:28.016+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25b8ada
[2025-07-19T19:57:28.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T19:57:28.017+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T19:57:28.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 141.0 in stage 9.0 (TID 944). 5829 bytes result sent to driver
[2025-07-19T19:57:28.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145] for update
[2025-07-19T19:57:28.018+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 137.0 in stage 9.0 (TID 940). 5829 bytes result sent to driver
[2025-07-19T19:57:28.019+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c9d695b
[2025-07-19T19:57:28.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146] for update
[2025-07-19T19:57:28.020+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40ba2384
[2025-07-19T19:57:28.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.021+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147] for update
[2025-07-19T19:57:28.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 148.0 in stage 9.0 (TID 951) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 148.0 in stage 9.0 (TID 951)
[2025-07-19T19:57:28.022+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 149.0 in stage 9.0 (TID 952) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 141.0 in stage 9.0 (TID 944) in 69 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T19:57:28.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 137.0 in stage 9.0 (TID 940) in 92 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T19:57:28.023+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 149.0 in stage 9.0 (TID 952)
[2025-07-19T19:57:28.024+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.025+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fd46068
[2025-07-19T19:57:28.026+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148] for update
[2025-07-19T19:57:28.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.027+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14dc49f9
[2025-07-19T19:57:28.028+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149] for update
[2025-07-19T19:57:28.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.029+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.2.delta.d3941064-f4fe-4419-9e59-6560625a5dc5.TID949.tmp
[2025-07-19T19:57:28.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/.2.delta.2bb978e1-6428-416c-8768-5fad3b17cee5.TID945.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/2.delta
[2025-07-19T19:57:28.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/142/2.delta
[2025-07-19T19:57:28.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T19:57:28.030+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.2.delta.9ee5b9ba-53fb-4c80-b7b9-49ea7b491566.TID948.tmp
[2025-07-19T19:57:28.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.2.delta.38a50f49-bd73-46c1-bd7b-5d2af0f2f23e.TID950.tmp
[2025-07-19T19:57:28.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/.2.delta.cf17aac5-43bd-4b14-80b5-2d5bb22d805e.TID946.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/2.delta
[2025-07-19T19:57:28.031+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/143/2.delta
[2025-07-19T19:57:28.032+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T19:57:28.033+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.2.delta.8a8e22f0-9b6f-4d55-812c-66f7849aa95c.TID951.tmp
[2025-07-19T19:57:28.034+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T19:57:28.035+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 142.0 in stage 9.0 (TID 945). 5829 bytes result sent to driver
[2025-07-19T19:57:28.036+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 150.0 in stage 9.0 (TID 953) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.037+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T19:57:28.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 142.0 in stage 9.0 (TID 945) in 80 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T19:57:28.038+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 150.0 in stage 9.0 (TID 953)
[2025-07-19T19:57:28.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 143.0 in stage 9.0 (TID 946). 5829 bytes result sent to driver
[2025-07-19T19:57:28.039+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.2.delta.43a73ab4-63c1-4bcf-a6e7-52631d9b947f.TID952.tmp
[2025-07-19T19:57:28.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 151.0 in stage 9.0 (TID 954) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.041+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 143.0 in stage 9.0 (TID 946) in 81 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T19:57:28.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/.2.delta.fa0d0d94-326d-436a-8a30-02c8d300f7cb.TID947.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/2.delta
[2025-07-19T19:57:28.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/144/2.delta
[2025-07-19T19:57:28.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 151.0 in stage 9.0 (TID 954)
[2025-07-19T19:57:28.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T19:57:28.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.042+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dead2b1
[2025-07-19T19:57:28.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150] for update
[2025-07-19T19:57:28.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.043+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.044+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1098a971
[2025-07-19T19:57:28.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.045+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151] for update
[2025-07-19T19:57:28.046+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T19:57:28.047+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 144.0 in stage 9.0 (TID 947). 5829 bytes result sent to driver
[2025-07-19T19:57:28.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 152.0 in stage 9.0 (TID 955) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 144.0 in stage 9.0 (TID 947) in 76 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T19:57:28.048+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 152.0 in stage 9.0 (TID 955)
[2025-07-19T19:57:28.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.049+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.051+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69d3a792
[2025-07-19T19:57:28.052+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.053+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152] for update
[2025-07-19T19:57:28.054+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.061+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.2.delta.a6d708e6-c067-4137-8803-9e2d436e42d3.TID953.tmp
[2025-07-19T19:57:28.062+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.2.delta.78eeedca-4efb-4477-9b9f-e6f0bf8e157a.TID954.tmp
[2025-07-19T19:57:28.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/.2.delta.38a50f49-bd73-46c1-bd7b-5d2af0f2f23e.TID950.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/2.delta
[2025-07-19T19:57:28.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/147/2.delta
[2025-07-19T19:57:28.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T19:57:28.071+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.2.delta.43708656-8b4c-4b73-8362-1ebbe8294cfe.TID955.tmp
[2025-07-19T19:57:28.074+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/.2.delta.d3941064-f4fe-4419-9e59-6560625a5dc5.TID949.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/2.delta
[2025-07-19T19:57:28.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/146/2.delta
[2025-07-19T19:57:28.075+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T19:57:28.077+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T19:57:28.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/.2.delta.8a8e22f0-9b6f-4d55-812c-66f7849aa95c.TID951.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/2.delta
[2025-07-19T19:57:28.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/148/2.delta
[2025-07-19T19:57:28.079+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 147.0 in stage 9.0 (TID 950). 5829 bytes result sent to driver
[2025-07-19T19:57:28.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 153.0 in stage 9.0 (TID 956) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.080+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T19:57:28.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 147.0 in stage 9.0 (TID 950) in 77 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T19:57:28.081+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T19:57:28.083+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 146.0 in stage 9.0 (TID 949). 5829 bytes result sent to driver
[2025-07-19T19:57:28.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 153.0 in stage 9.0 (TID 956)
[2025-07-19T19:57:28.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 154.0 in stage 9.0 (TID 957) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.084+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 146.0 in stage 9.0 (TID 949) in 79 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T19:57:28.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/.2.delta.9ee5b9ba-53fb-4c80-b7b9-49ea7b491566.TID948.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/2.delta
[2025-07-19T19:57:28.085+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/145/2.delta
[2025-07-19T19:57:28.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 154.0 in stage 9.0 (TID 957)
[2025-07-19T19:57:28.087+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T19:57:28.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.088+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.089+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.091+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:28.092+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/.2.delta.43a73ab4-63c1-4bcf-a6e7-52631d9b947f.TID952.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/2.delta
[2025-07-19T19:57:28.093+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/149/2.delta
[2025-07-19T19:57:28.095+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T19:57:28.096+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T19:57:28.096+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c2a979b
[2025-07-19T19:57:28.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 148.0 in stage 9.0 (TID 951). 5829 bytes result sent to driver
[2025-07-19T19:57:28.097+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.098+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153] for update
[2025-07-19T19:57:28.099+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 155.0 in stage 9.0 (TID 958) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 148.0 in stage 9.0 (TID 951) in 85 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T19:57:28.101+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T19:57:28.102+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 155.0 in stage 9.0 (TID 958)
[2025-07-19T19:57:28.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22b9c4af
[2025-07-19T19:57:28.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 145.0 in stage 9.0 (TID 948). 5829 bytes result sent to driver
[2025-07-19T19:57:28.103+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154] for update
[2025-07-19T19:57:28.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T19:57:28.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 156.0 in stage 9.0 (TID 959) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.104+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 156.0 in stage 9.0 (TID 959)
[2025-07-19T19:57:28.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 145.0 in stage 9.0 (TID 948) in 102 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T19:57:28.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 149.0 in stage 9.0 (TID 952). 5786 bytes result sent to driver
[2025-07-19T19:57:28.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e49a485
[2025-07-19T19:57:28.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 157.0 in stage 9.0 (TID 960) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.105+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 149.0 in stage 9.0 (TID 952) in 88 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T19:57:28.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.106+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155] for update
[2025-07-19T19:57:28.107+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 157.0 in stage 9.0 (TID 960)
[2025-07-19T19:57:28.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.108+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T19:57:28.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/.2.delta.43708656-8b4c-4b73-8362-1ebbe8294cfe.TID955.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/2.delta
[2025-07-19T19:57:28.109+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/152/2.delta
[2025-07-19T19:57:28.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/.2.delta.a6d708e6-c067-4137-8803-9e2d436e42d3.TID953.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/2.delta
[2025-07-19T19:57:28.110+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/150/2.delta
[2025-07-19T19:57:28.115+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.2.delta.80e5cb80-71fc-44c3-aff6-8a2660d3fe14.TID956.tmp
[2025-07-19T19:57:28.116+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T19:57:28.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T19:57:28.118+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.2.delta.ce3e1de2-bf54-4faf-8d58-af6040094c45.TID957.tmp
[2025-07-19T19:57:28.119+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e81bfe2
[2025-07-19T19:57:28.121+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/.2.delta.78eeedca-4efb-4477-9b9f-e6f0bf8e157a.TID954.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/2.delta
[2025-07-19T19:57:28.123+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/151/2.delta
[2025-07-19T19:57:28.124+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156] for update
[2025-07-19T19:57:28.125+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T19:57:28.126+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@755a2a07
[2025-07-19T19:57:28.127+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157] for update
[2025-07-19T19:57:28.128+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T19:57:28.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T19:57:28.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 151.0 in stage 9.0 (TID 954). 5872 bytes result sent to driver
[2025-07-19T19:57:28.129+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T19:57:28.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 150.0 in stage 9.0 (TID 953). 5872 bytes result sent to driver
[2025-07-19T19:57:28.130+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 152.0 in stage 9.0 (TID 955). 5872 bytes result sent to driver
[2025-07-19T19:57:28.131+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 158.0 in stage 9.0 (TID 961) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 159.0 in stage 9.0 (TID 962) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.132+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 160.0 in stage 9.0 (TID 963) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 158.0 in stage 9.0 (TID 961)
[2025-07-19T19:57:28.133+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 150.0 in stage 9.0 (TID 953) in 84 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T19:57:28.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 151.0 in stage 9.0 (TID 954) in 82 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T19:57:28.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 160.0 in stage 9.0 (TID 963)
[2025-07-19T19:57:28.134+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 152.0 in stage 9.0 (TID 955) in 76 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T19:57:28.136+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 159.0 in stage 9.0 (TID 962)
[2025-07-19T19:57:28.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.2.delta.caf49d4b-a61f-43bc-bb09-9ea25d11f679.TID958.tmp
[2025-07-19T19:57:28.137+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.138+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.139+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.140+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.144+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e3a60e7
[2025-07-19T19:57:28.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.145+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.146+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158] for update
[2025-07-19T19:57:28.147+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27e1989f
[2025-07-19T19:57:28.148+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160] for update
[2025-07-19T19:57:28.149+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d4efc5c
[2025-07-19T19:57:28.151+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159] for update
[2025-07-19T19:57:28.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.152+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.2.delta.80e3c98a-6941-491f-b89b-2a6c0615927c.TID959.tmp
[2025-07-19T19:57:28.153+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.2.delta.d597043c-0950-44c8-a3d5-5cec36d1aeaa.TID960.tmp
[2025-07-19T19:57:28.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.2.delta.ae1f3d02-8368-4d97-b380-2c662bba35ca.TID961.tmp
[2025-07-19T19:57:28.154+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.2.delta.d2a4c6e1-b809-4987-a62f-36ab2550be05.TID963.tmp
[2025-07-19T19:57:28.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.2.delta.0c7bc45d-bc7f-49e4-b3d8-b9f2be0567e3.TID962.tmp
[2025-07-19T19:57:28.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/.2.delta.ce3e1de2-bf54-4faf-8d58-af6040094c45.TID957.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/2.delta
[2025-07-19T19:57:28.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/154/2.delta
[2025-07-19T19:57:28.155+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T19:57:28.156+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/.2.delta.80e5cb80-71fc-44c3-aff6-8a2660d3fe14.TID956.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/2.delta
[2025-07-19T19:57:28.156+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/153/2.delta
[2025-07-19T19:57:28.157+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T19:57:28.159+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T19:57:28.161+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T19:57:28.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 154.0 in stage 9.0 (TID 957). 5872 bytes result sent to driver
[2025-07-19T19:57:28.163+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 153.0 in stage 9.0 (TID 956). 5872 bytes result sent to driver
[2025-07-19T19:57:28.165+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 161.0 in stage 9.0 (TID 964) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 162.0 in stage 9.0 (TID 965) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 161.0 in stage 9.0 (TID 964)
[2025-07-19T19:57:28.166+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 162.0 in stage 9.0 (TID 965)
[2025-07-19T19:57:28.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 153.0 in stage 9.0 (TID 956) in 80 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T19:57:28.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 154.0 in stage 9.0 (TID 957) in 78 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T19:57:28.167+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.168+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.169+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.170+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24d4b984
[2025-07-19T19:57:28.171+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162] for update
[2025-07-19T19:57:28.172+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e020ad0
[2025-07-19T19:57:28.173+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.174+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161] for update
[2025-07-19T19:57:28.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.175+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/.2.delta.80e3c98a-6941-491f-b89b-2a6c0615927c.TID959.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/2.delta
[2025-07-19T19:57:28.176+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/156/2.delta
[2025-07-19T19:57:28.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/.2.delta.caf49d4b-a61f-43bc-bb09-9ea25d11f679.TID958.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/2.delta
[2025-07-19T19:57:28.178+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/155/2.delta
[2025-07-19T19:57:28.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T19:57:28.179+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T19:57:28.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T19:57:28.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/.2.delta.0c7bc45d-bc7f-49e4-b3d8-b9f2be0567e3.TID962.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/2.delta
[2025-07-19T19:57:28.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/159/2.delta
[2025-07-19T19:57:28.180+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 156.0 in stage 9.0 (TID 959). 5872 bytes result sent to driver
[2025-07-19T19:57:28.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T19:57:28.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T19:57:28.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 155.0 in stage 9.0 (TID 958). 5872 bytes result sent to driver
[2025-07-19T19:57:28.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 163.0 in stage 9.0 (TID 966) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 164.0 in stage 9.0 (TID 967) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 156.0 in stage 9.0 (TID 959) in 75 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T19:57:28.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 155.0 in stage 9.0 (TID 958) in 80 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T19:57:28.181+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 163.0 in stage 9.0 (TID 966)
[2025-07-19T19:57:28.185+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 164.0 in stage 9.0 (TID 967)
[2025-07-19T19:57:28.188+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.189+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.190+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T19:57:28.191+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.192+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.193+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 159.0 in stage 9.0 (TID 962). 5872 bytes result sent to driver
[2025-07-19T19:57:28.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49cf2870
[2025-07-19T19:57:28.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 165.0 in stage 9.0 (TID 968) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 165.0 in stage 9.0 (TID 968)
[2025-07-19T19:57:28.194+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.195+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164] for update
[2025-07-19T19:57:28.195+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 159.0 in stage 9.0 (TID 962) in 73 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T19:57:28.195+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/.2.delta.d597043c-0950-44c8-a3d5-5cec36d1aeaa.TID960.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/2.delta
[2025-07-19T19:57:28.195+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/157/2.delta
[2025-07-19T19:57:28.196+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T19:57:28.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.197+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.199+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.2.delta.748a5825-3c40-4f39-9392-29c795dbb1e7.TID964.tmp
[2025-07-19T19:57:28.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/.2.delta.ae1f3d02-8368-4d97-b380-2c662bba35ca.TID961.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/2.delta
[2025-07-19T19:57:28.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/158/2.delta
[2025-07-19T19:57:28.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T19:57:28.200+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d50fbdb
[2025-07-19T19:57:28.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163] for update
[2025-07-19T19:57:28.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.2.delta.945b49c9-cbd0-4aaa-b202-14a08571edac.TID965.tmp
[2025-07-19T19:57:28.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/.2.delta.d2a4c6e1-b809-4987-a62f-36ab2550be05.TID963.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/2.delta
[2025-07-19T19:57:28.201+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/160/2.delta
[2025-07-19T19:57:28.202+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T19:57:28.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T19:57:28.203+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12082f04
[2025-07-19T19:57:28.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 157.0 in stage 9.0 (TID 960). 5872 bytes result sent to driver
[2025-07-19T19:57:28.204+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.205+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 166.0 in stage 9.0 (TID 969) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.206+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165] for update
[2025-07-19T19:57:28.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 166.0 in stage 9.0 (TID 969)
[2025-07-19T19:57:28.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 157.0 in stage 9.0 (TID 960) in 99 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T19:57:28.207+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.208+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@337ce5f1
[2025-07-19T19:57:28.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166] for update
[2025-07-19T19:57:28.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T19:57:28.209+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 158.0 in stage 9.0 (TID 961). 5872 bytes result sent to driver
[2025-07-19T19:57:28.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T19:57:28.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 167.0 in stage 9.0 (TID 970) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 158.0 in stage 9.0 (TID 961) in 92 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T19:57:28.210+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 167.0 in stage 9.0 (TID 970)
[2025-07-19T19:57:28.213+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 160.0 in stage 9.0 (TID 963). 5872 bytes result sent to driver
[2025-07-19T19:57:28.214+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 168.0 in stage 9.0 (TID 971) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 168.0 in stage 9.0 (TID 971)
[2025-07-19T19:57:28.215+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 160.0 in stage 9.0 (TID 963) in 93 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T19:57:28.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.216+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1241d9e7
[2025-07-19T19:57:28.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167] for update
[2025-07-19T19:57:28.217+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.2.delta.8f57c76c-5817-4ef3-aea1-fc3c27a98b4c.TID966.tmp
[2025-07-19T19:57:28.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@349bc2ae
[2025-07-19T19:57:28.218+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168] for update
[2025-07-19T19:57:28.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.2.delta.bd9e3d12-0600-40b6-bcc6-6cbdd32b7772.TID967.tmp
[2025-07-19T19:57:28.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.219+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.2.delta.adf08073-bc64-4ad8-93e1-5db742584958.TID968.tmp
[2025-07-19T19:57:28.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.220+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.224+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.2.delta.12008c04-b8bc-451f-8160-aeb0bb427b6b.TID970.tmp
[2025-07-19T19:57:28.226+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.2.delta.58f671c7-f100-4a98-87b2-116ec52dd807.TID971.tmp
[2025-07-19T19:57:28.227+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.2.delta.ea175f9b-29e5-46a7-a445-4aea7f2b69a9.TID969.tmp
[2025-07-19T19:57:28.236+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/.2.delta.945b49c9-cbd0-4aaa-b202-14a08571edac.TID965.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/2.delta
[2025-07-19T19:57:28.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/162/2.delta
[2025-07-19T19:57:28.237+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T19:57:28.239+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/.2.delta.adf08073-bc64-4ad8-93e1-5db742584958.TID968.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/2.delta
[2025-07-19T19:57:28.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/165/2.delta
[2025-07-19T19:57:28.240+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T19:57:28.246+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/.2.delta.748a5825-3c40-4f39-9392-29c795dbb1e7.TID964.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/2.delta
[2025-07-19T19:57:28.248+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/161/2.delta
[2025-07-19T19:57:28.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T19:57:28.249+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T19:57:28.250+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 162.0 in stage 9.0 (TID 965). 5872 bytes result sent to driver
[2025-07-19T19:57:28.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/.2.delta.bd9e3d12-0600-40b6-bcc6-6cbdd32b7772.TID967.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/2.delta
[2025-07-19T19:57:28.252+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/164/2.delta
[2025-07-19T19:57:28.253+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T19:57:28.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 169.0 in stage 9.0 (TID 972) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.254+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 162.0 in stage 9.0 (TID 965) in 90 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T19:57:28.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T19:57:28.255+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 169.0 in stage 9.0 (TID 972)
[2025-07-19T19:57:28.256+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 165.0 in stage 9.0 (TID 968). 5829 bytes result sent to driver
[2025-07-19T19:57:28.257+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T19:57:28.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 170.0 in stage 9.0 (TID 973) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.258+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 170.0 in stage 9.0 (TID 973)
[2025-07-19T19:57:28.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 165.0 in stage 9.0 (TID 968) in 68 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T19:57:28.259+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T19:57:28.260+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 164.0 in stage 9.0 (TID 967). 5829 bytes result sent to driver
[2025-07-19T19:57:28.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/.2.delta.8f57c76c-5817-4ef3-aea1-fc3c27a98b4c.TID966.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/2.delta
[2025-07-19T19:57:28.261+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/163/2.delta
[2025-07-19T19:57:28.262+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 161.0 in stage 9.0 (TID 964). 5872 bytes result sent to driver
[2025-07-19T19:57:28.263+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T19:57:28.264+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 171.0 in stage 9.0 (TID 974) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 172.0 in stage 9.0 (TID 975) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.265+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.266+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 172.0 in stage 9.0 (TID 975)
[2025-07-19T19:57:28.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 164.0 in stage 9.0 (TID 967) in 85 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T19:57:28.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 171.0 in stage 9.0 (TID 974)
[2025-07-19T19:57:28.267+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T19:57:28.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 161.0 in stage 9.0 (TID 964) in 104 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T19:57:28.270+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/.2.delta.58f671c7-f100-4a98-87b2-116ec52dd807.TID971.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/2.delta
[2025-07-19T19:57:28.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/168/2.delta
[2025-07-19T19:57:28.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 163.0 in stage 9.0 (TID 966). 5872 bytes result sent to driver
[2025-07-19T19:57:28.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24f3d95e
[2025-07-19T19:57:28.271+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T19:57:28.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 173.0 in stage 9.0 (TID 976) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.272+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 173.0 in stage 9.0 (TID 976)
[2025-07-19T19:57:28.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169] for update
[2025-07-19T19:57:28.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d204eec
[2025-07-19T19:57:28.273+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172] for update
[2025-07-19T19:57:28.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30dfa8ed
[2025-07-19T19:57:28.274+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 163.0 in stage 9.0 (TID 966) in 96 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T19:57:28.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170] for update
[2025-07-19T19:57:28.275+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T19:57:28.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 168.0 in stage 9.0 (TID 971). 5829 bytes result sent to driver
[2025-07-19T19:57:28.276+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@413f0ae7
[2025-07-19T19:57:28.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.279+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.280+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.281+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173] for update
[2025-07-19T19:57:28.282+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 174.0 in stage 9.0 (TID 977) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.284+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 168.0 in stage 9.0 (TID 971) in 72 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T19:57:28.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 174.0 in stage 9.0 (TID 977)
[2025-07-19T19:57:28.285+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.287+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.289+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.291+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/.2.delta.12008c04-b8bc-451f-8160-aeb0bb427b6b.TID970.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/2.delta
[2025-07-19T19:57:28.292+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/167/2.delta
[2025-07-19T19:57:28.293+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68333047
[2025-07-19T19:57:28.294+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T19:57:28.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171] for update
[2025-07-19T19:57:28.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.2.delta.2b5f7571-117a-4f08-a826-b374531893be.TID972.tmp
[2025-07-19T19:57:28.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.2.delta.0fafadc6-d341-4b28-8d9b-fa9bdf7bd7d8.TID976.tmp
[2025-07-19T19:57:28.295+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/.2.delta.ea175f9b-29e5-46a7-a445-4aea7f2b69a9.TID969.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/2.delta
[2025-07-19T19:57:28.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/166/2.delta
[2025-07-19T19:57:28.296+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T19:57:28.297+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 167.0 in stage 9.0 (TID 970). 5829 bytes result sent to driver
[2025-07-19T19:57:28.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 175.0 in stage 9.0 (TID 978) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e106746
[2025-07-19T19:57:28.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174] for update
[2025-07-19T19:57:28.299+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 175.0 in stage 9.0 (TID 978)
[2025-07-19T19:57:28.300+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.2.delta.6b81ee45-fce1-4dda-8f91-dc9a66b466e1.TID973.tmp
[2025-07-19T19:57:28.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T19:57:28.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 167.0 in stage 9.0 (TID 970) in 93 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T19:57:28.301+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.2.delta.44682f38-670f-41d3-9dd9-ff03894974e7.TID975.tmp
[2025-07-19T19:57:28.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3291cf0d
[2025-07-19T19:57:28.302+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.303+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175] for update
[2025-07-19T19:57:28.304+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.306+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T19:57:28.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 166.0 in stage 9.0 (TID 969). 5829 bytes result sent to driver
[2025-07-19T19:57:28.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 176.0 in stage 9.0 (TID 979) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.307+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 176.0 in stage 9.0 (TID 979)
[2025-07-19T19:57:28.309+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 166.0 in stage 9.0 (TID 969) in 110 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T19:57:28.310+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.314+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.2.delta.4f6a0e8d-f8dc-4c40-8f4c-959043c3094e.TID974.tmp
[2025-07-19T19:57:28.315+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37931b21
[2025-07-19T19:57:28.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.316+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176] for update
[2025-07-19T19:57:28.317+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.318+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.2.delta.c63855ae-fe87-4a7d-b80d-2fb163435a77.TID977.tmp
[2025-07-19T19:57:28.320+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.2.delta.82c4ce71-cb0c-4462-ad2e-d758887d1fc3.TID978.tmp
[2025-07-19T19:57:28.323+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.2.delta.9b636e30-313d-4b24-ba77-97cbc74d3c3e.TID979.tmp
[2025-07-19T19:57:28.329+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/.2.delta.2b5f7571-117a-4f08-a826-b374531893be.TID972.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/2.delta
[2025-07-19T19:57:28.331+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/169/2.delta
[2025-07-19T19:57:28.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T19:57:28.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/.2.delta.44682f38-670f-41d3-9dd9-ff03894974e7.TID975.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/2.delta
[2025-07-19T19:57:28.332+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/172/2.delta
[2025-07-19T19:57:28.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T19:57:28.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/.2.delta.6b81ee45-fce1-4dda-8f91-dc9a66b466e1.TID973.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/2.delta
[2025-07-19T19:57:28.333+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/170/2.delta
[2025-07-19T19:57:28.334+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T19:57:28.336+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T19:57:28.337+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 172.0 in stage 9.0 (TID 975). 5829 bytes result sent to driver
[2025-07-19T19:57:28.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 177.0 in stage 9.0 (TID 980) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T19:57:28.338+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 177.0 in stage 9.0 (TID 980)
[2025-07-19T19:57:28.339+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 169.0 in stage 9.0 (TID 972). 5829 bytes result sent to driver
[2025-07-19T19:57:28.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 172.0 in stage 9.0 (TID 975) in 79 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T19:57:28.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 178.0 in stage 9.0 (TID 981) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.340+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/.2.delta.0fafadc6-d341-4b28-8d9b-fa9bdf7bd7d8.TID976.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/2.delta
[2025-07-19T19:57:28.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/173/2.delta
[2025-07-19T19:57:28.341+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T19:57:28.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 178.0 in stage 9.0 (TID 981)
[2025-07-19T19:57:28.342+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 169.0 in stage 9.0 (TID 972) in 90 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T19:57:28.343+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.344+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@717fb85f
[2025-07-19T19:57:28.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178] for update
[2025-07-19T19:57:28.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60d7ef51
[2025-07-19T19:57:28.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.345+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177] for update
[2025-07-19T19:57:28.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T19:57:28.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T19:57:28.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 170.0 in stage 9.0 (TID 973). 5829 bytes result sent to driver
[2025-07-19T19:57:28.346+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 173.0 in stage 9.0 (TID 976). 5829 bytes result sent to driver
[2025-07-19T19:57:28.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 179.0 in stage 9.0 (TID 982) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 173.0 in stage 9.0 (TID 976) in 81 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T19:57:28.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 179.0 in stage 9.0 (TID 982)
[2025-07-19T19:57:28.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 170.0 in stage 9.0 (TID 973) in 95 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T19:57:28.347+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 180.0 in stage 9.0 (TID 983) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 180.0 in stage 9.0 (TID 983)
[2025-07-19T19:57:28.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/.2.delta.4f6a0e8d-f8dc-4c40-8f4c-959043c3094e.TID974.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/2.delta
[2025-07-19T19:57:28.348+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/171/2.delta
[2025-07-19T19:57:28.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T19:57:28.349+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.351+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.352+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50a51b99
[2025-07-19T19:57:28.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179] for update
[2025-07-19T19:57:28.354+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e20ec16
[2025-07-19T19:57:28.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.355+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180] for update
[2025-07-19T19:57:28.356+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T19:57:28.358+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/.2.delta.c63855ae-fe87-4a7d-b80d-2fb163435a77.TID977.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/2.delta
[2025-07-19T19:57:28.359+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/174/2.delta
[2025-07-19T19:57:28.360+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 171.0 in stage 9.0 (TID 974). 5829 bytes result sent to driver
[2025-07-19T19:57:28.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T19:57:28.361+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 181.0 in stage 9.0 (TID 984) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.362+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 171.0 in stage 9.0 (TID 974) in 98 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T19:57:28.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 181.0 in stage 9.0 (TID 984)
[2025-07-19T19:57:28.363+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/.2.delta.9b636e30-313d-4b24-ba77-97cbc74d3c3e.TID979.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/2.delta
[2025-07-19T19:57:28.364+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/176/2.delta
[2025-07-19T19:57:28.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T19:57:28.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.366+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:28.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T19:57:28.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 174.0 in stage 9.0 (TID 977). 5829 bytes result sent to driver
[2025-07-19T19:57:28.367+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 182.0 in stage 9.0 (TID 985) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.368+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d3f2a5a
[2025-07-19T19:57:28.371+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 174.0 in stage 9.0 (TID 977) in 80 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T19:57:28.372+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.374+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181] for update
[2025-07-19T19:57:28.375+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T19:57:28.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.2.delta.2b5e1a89-d7c4-4572-9407-b7d491174435.TID981.tmp
[2025-07-19T19:57:28.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 182.0 in stage 9.0 (TID 985)
[2025-07-19T19:57:28.376+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 176.0 in stage 9.0 (TID 979). 5829 bytes result sent to driver
[2025-07-19T19:57:28.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.2.delta.fb0cb4d1-8417-4569-aeb3-406d71a89928.TID980.tmp
[2025-07-19T19:57:28.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 183.0 in stage 9.0 (TID 986) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.377+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.2.delta.c76abd1a-515d-403d-8ced-bd5060df53cc.TID982.tmp
[2025-07-19T19:57:28.378+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.380+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 176.0 in stage 9.0 (TID 979) in 58 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T19:57:28.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 183.0 in stage 9.0 (TID 986)
[2025-07-19T19:57:28.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3141a19a
[2025-07-19T19:57:28.381+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182] for update
[2025-07-19T19:57:28.382+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.2.delta.391aa648-8dde-44b2-853a-7672944e8c8b.TID983.tmp
[2025-07-19T19:57:28.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/.2.delta.82c4ce71-cb0c-4462-ad2e-d758887d1fc3.TID978.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/2.delta
[2025-07-19T19:57:28.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/175/2.delta
[2025-07-19T19:57:28.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.383+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.384+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T19:57:28.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.385+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.2.delta.8b96d5d4-50e0-4cab-95a9-5d6267696605.TID984.tmp
[2025-07-19T19:57:28.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T19:57:28.386+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 175.0 in stage 9.0 (TID 978). 5829 bytes result sent to driver
[2025-07-19T19:57:28.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dd7f896
[2025-07-19T19:57:28.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 184.0 in stage 9.0 (TID 987) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.387+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 175.0 in stage 9.0 (TID 978) in 79 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T19:57:28.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 184.0 in stage 9.0 (TID 987)
[2025-07-19T19:57:28.388+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.389+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183] for update
[2025-07-19T19:57:28.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.390+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79dfe2ae
[2025-07-19T19:57:28.392+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.2.delta.44962872-a23e-4e5e-8f91-b26a4fdf6675.TID985.tmp
[2025-07-19T19:57:28.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.393+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184] for update
[2025-07-19T19:57:28.394+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.395+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.2.delta.9c5bf589-de5c-4f6c-a47f-bbdd732da92f.TID986.tmp
[2025-07-19T19:57:28.398+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/.2.delta.fb0cb4d1-8417-4569-aeb3-406d71a89928.TID980.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/2.delta
[2025-07-19T19:57:28.400+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/177/2.delta
[2025-07-19T19:57:28.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T19:57:28.401+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T19:57:28.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 177.0 in stage 9.0 (TID 980). 5829 bytes result sent to driver
[2025-07-19T19:57:28.402+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 185.0 in stage 9.0 (TID 988) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 185.0 in stage 9.0 (TID 988)
[2025-07-19T19:57:28.404+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.2.delta.925ec7c3-c0bd-4489-836c-99334d7b78cf.TID987.tmp
[2025-07-19T19:57:28.406+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 177.0 in stage 9.0 (TID 980) in 67 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T19:57:28.407+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/.2.delta.2b5e1a89-d7c4-4572-9407-b7d491174435.TID981.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/2.delta
[2025-07-19T19:57:28.408+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/178/2.delta
[2025-07-19T19:57:28.409+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T19:57:28.411+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/.2.delta.c76abd1a-515d-403d-8ced-bd5060df53cc.TID982.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/2.delta
[2025-07-19T19:57:28.412+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/179/2.delta
[2025-07-19T19:57:28.413+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T19:57:28.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.414+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T19:57:28.415+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/.2.delta.391aa648-8dde-44b2-853a-7672944e8c8b.TID983.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/2.delta
[2025-07-19T19:57:28.416+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/180/2.delta
[2025-07-19T19:57:28.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a1e0a19
[2025-07-19T19:57:28.417+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T19:57:28.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 178.0 in stage 9.0 (TID 981). 5829 bytes result sent to driver
[2025-07-19T19:57:28.418+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/.2.delta.8b96d5d4-50e0-4cab-95a9-5d6267696605.TID984.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/2.delta
[2025-07-19T19:57:28.420+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/181/2.delta
[2025-07-19T19:57:28.421+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 186.0 in stage 9.0 (TID 989) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.422+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 186.0 in stage 9.0 (TID 989)
[2025-07-19T19:57:28.423+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T19:57:28.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.424+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185] for update
[2025-07-19T19:57:28.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T19:57:28.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 179.0 in stage 9.0 (TID 982). 5829 bytes result sent to driver
[2025-07-19T19:57:28.425+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 178.0 in stage 9.0 (TID 981) in 79 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T19:57:28.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T19:57:28.426+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 180.0 in stage 9.0 (TID 983). 5829 bytes result sent to driver
[2025-07-19T19:57:28.427+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T19:57:28.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 181.0 in stage 9.0 (TID 984). 5829 bytes result sent to driver
[2025-07-19T19:57:28.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 187.0 in stage 9.0 (TID 990) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.428+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 187.0 in stage 9.0 (TID 990)
[2025-07-19T19:57:28.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 188.0 in stage 9.0 (TID 991) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.429+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 189.0 in stage 9.0 (TID 992) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.430+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 179.0 in stage 9.0 (TID 982) in 75 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T19:57:28.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 180.0 in stage 9.0 (TID 983) in 73 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T19:57:28.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/.2.delta.44962872-a23e-4e5e-8f91-b26a4fdf6675.TID985.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/2.delta
[2025-07-19T19:57:28.431+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/182/2.delta
[2025-07-19T19:57:28.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 181.0 in stage 9.0 (TID 984) in 67 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T19:57:28.432+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 189.0 in stage 9.0 (TID 992)
[2025-07-19T19:57:28.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T19:57:28.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T19:57:28.433+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 188.0 in stage 9.0 (TID 991)
[2025-07-19T19:57:28.434+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.435+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17f91ce9
[2025-07-19T19:57:28.436+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186] for update
[2025-07-19T19:57:28.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.437+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.438+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.438+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.440+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@340cefd8
[2025-07-19T19:57:28.441+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187] for update
[2025-07-19T19:57:28.442+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T19:57:28.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a76e5cd
[2025-07-19T19:57:28.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.2.delta.13336e3b-f886-47e6-8337-077a36b3edfb.TID988.tmp
[2025-07-19T19:57:28.443+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189] for update
[2025-07-19T19:57:28.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 182.0 in stage 9.0 (TID 985). 5829 bytes result sent to driver
[2025-07-19T19:57:28.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 190.0 in stage 9.0 (TID 993) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 190.0 in stage 9.0 (TID 993)
[2025-07-19T19:57:28.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 182.0 in stage 9.0 (TID 985) in 71 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T19:57:28.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76170bcd
[2025-07-19T19:57:28.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/.2.delta.9c5bf589-de5c-4f6c-a47f-bbdd732da92f.TID986.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/2.delta
[2025-07-19T19:57:28.444+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/183/2.delta
[2025-07-19T19:57:28.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188] for update
[2025-07-19T19:57:28.445+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T19:57:28.446+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.446+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.446+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.2.delta.72539918-54f9-45f3-aead-ce9af381f25a.TID990.tmp
[2025-07-19T19:57:28.447+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T19:57:28.448+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@718c6f88
[2025-07-19T19:57:28.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 183.0 in stage 9.0 (TID 986). 5829 bytes result sent to driver
[2025-07-19T19:57:28.450+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190] for update
[2025-07-19T19:57:28.451+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 191.0 in stage 9.0 (TID 994) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.452+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 183.0 in stage 9.0 (TID 986) in 76 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T19:57:28.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 191.0 in stage 9.0 (TID 994)
[2025-07-19T19:57:28.453+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/.2.delta.925ec7c3-c0bd-4489-836c-99334d7b78cf.TID987.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/2.delta
[2025-07-19T19:57:28.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/184/2.delta
[2025-07-19T19:57:28.454+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T19:57:28.455+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T19:57:28.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72550537
[2025-07-19T19:57:28.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.2.delta.71ea09ae-d05a-4fe9-a3d9-5f0a5a06d301.TID989.tmp
[2025-07-19T19:57:28.456+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.2.delta.9f722040-124d-4834-8881-0e8cd8cc5fdb.TID992.tmp
[2025-07-19T19:57:28.457+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191] for update
[2025-07-19T19:57:28.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T19:57:28.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 184.0 in stage 9.0 (TID 987). 5829 bytes result sent to driver
[2025-07-19T19:57:28.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 192.0 in stage 9.0 (TID 995) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.458+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 184.0 in stage 9.0 (TID 987) in 72 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T19:57:28.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 192.0 in stage 9.0 (TID 995)
[2025-07-19T19:57:28.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.459+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.2.delta.d106d42b-dc7b-4023-90d8-e1fcc03ee982.TID991.tmp
[2025-07-19T19:57:28.460+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.2.delta.e3bdc8d7-77a7-4410-8728-336303f440d6.TID993.tmp
[2025-07-19T19:57:28.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@312e39ac
[2025-07-19T19:57:28.461+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192] for update
[2025-07-19T19:57:28.463+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.464+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.2.delta.5781d31c-2287-4c07-bd02-ee39b1c0d26a.TID994.tmp
[2025-07-19T19:57:28.467+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/.2.delta.13336e3b-f886-47e6-8337-077a36b3edfb.TID988.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/2.delta
[2025-07-19T19:57:28.468+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/185/2.delta
[2025-07-19T19:57:28.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T19:57:28.469+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.2.delta.24185004-425d-40aa-844f-5f9f3057a56b.TID995.tmp
[2025-07-19T19:57:28.473+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T19:57:28.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 185.0 in stage 9.0 (TID 988). 5829 bytes result sent to driver
[2025-07-19T19:57:28.474+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 193.0 in stage 9.0 (TID 996) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.475+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 193.0 in stage 9.0 (TID 996)
[2025-07-19T19:57:28.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 185.0 in stage 9.0 (TID 988) in 73 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T19:57:28.477+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.478+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.478+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ed4f159
[2025-07-19T19:57:28.479+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.479+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193] for update
[2025-07-19T19:57:28.480+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.483+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/.2.delta.72539918-54f9-45f3-aead-ce9af381f25a.TID990.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/2.delta
[2025-07-19T19:57:28.484+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/187/2.delta
[2025-07-19T19:57:28.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T19:57:28.485+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/.2.delta.d106d42b-dc7b-4023-90d8-e1fcc03ee982.TID991.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/2.delta
[2025-07-19T19:57:28.486+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/188/2.delta
[2025-07-19T19:57:28.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T19:57:28.487+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/.2.delta.9f722040-124d-4834-8881-0e8cd8cc5fdb.TID992.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/2.delta
[2025-07-19T19:57:28.488+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/189/2.delta
[2025-07-19T19:57:28.489+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T19:57:28.490+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T19:57:28.491+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T19:57:28.492+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/.2.delta.71ea09ae-d05a-4fe9-a3d9-5f0a5a06d301.TID989.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/2.delta
[2025-07-19T19:57:28.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/186/2.delta
[2025-07-19T19:57:28.493+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/.2.delta.e3bdc8d7-77a7-4410-8728-336303f440d6.TID993.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/2.delta
[2025-07-19T19:57:28.494+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/190/2.delta
[2025-07-19T19:57:28.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T19:57:28.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T19:57:28.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 188.0 in stage 9.0 (TID 991). 5829 bytes result sent to driver
[2025-07-19T19:57:28.496+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 187.0 in stage 9.0 (TID 990). 5829 bytes result sent to driver
[2025-07-19T19:57:28.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 194.0 in stage 9.0 (TID 997) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.497+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 188.0 in stage 9.0 (TID 991) in 69 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T19:57:28.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T19:57:28.498+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 189.0 in stage 9.0 (TID 992). 5829 bytes result sent to driver
[2025-07-19T19:57:28.499+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 194.0 in stage 9.0 (TID 997)
[2025-07-19T19:57:28.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 195.0 in stage 9.0 (TID 998) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.500+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 196.0 in stage 9.0 (TID 999) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T19:57:28.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 195.0 in stage 9.0 (TID 998)
[2025-07-19T19:57:28.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 190.0 in stage 9.0 (TID 993). 5829 bytes result sent to driver
[2025-07-19T19:57:28.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 196.0 in stage 9.0 (TID 999)
[2025-07-19T19:57:28.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 197.0 in stage 9.0 (TID 1000) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.2.delta.659e3842-e8a0-49c0-af20-c1d5040b929b.TID996.tmp
[2025-07-19T19:57:28.501+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 197.0 in stage 9.0 (TID 1000)
[2025-07-19T19:57:28.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T19:57:28.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 190.0 in stage 9.0 (TID 993) in 66 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T19:57:28.502+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 186.0 in stage 9.0 (TID 989). 5829 bytes result sent to driver
[2025-07-19T19:57:28.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 187.0 in stage 9.0 (TID 990) in 78 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T19:57:28.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 198.0 in stage 9.0 (TID 1001) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 198.0 in stage 9.0 (TID 1001)
[2025-07-19T19:57:28.504+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.505+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 186.0 in stage 9.0 (TID 989) in 82 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T19:57:28.506+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 189.0 in stage 9.0 (TID 992) in 75 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T19:57:28.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.508+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.509+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.510+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b66158f
[2025-07-19T19:57:28.511+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195] for update
[2025-07-19T19:57:28.512+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@788d2b50
[2025-07-19T19:57:28.513+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.514+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.515+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198] for update
[2025-07-19T19:57:28.516+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c60c986
[2025-07-19T19:57:28.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.519+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194] for update
[2025-07-19T19:57:28.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.520+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/.2.delta.24185004-425d-40aa-844f-5f9f3057a56b.TID995.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/2.delta
[2025-07-19T19:57:28.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/192/2.delta
[2025-07-19T19:57:28.521+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/.2.delta.5781d31c-2287-4c07-bd02-ee39b1c0d26a.TID994.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/2.delta
[2025-07-19T19:57:28.522+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/191/2.delta
[2025-07-19T19:57:28.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T19:57:28.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T19:57:28.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c3e4633
[2025-07-19T19:57:28.523+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197] for update
[2025-07-19T19:57:28.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.2.delta.d8e1d546-b535-4d5e-ace2-36034fea586c.TID998.tmp
[2025-07-19T19:57:28.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35546d83
[2025-07-19T19:57:28.524+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.525+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T19:57:28.526+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.527+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196] for update
[2025-07-19T19:57:28.528+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T19:57:28.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 191.0 in stage 9.0 (TID 994). 5829 bytes result sent to driver
[2025-07-19T19:57:28.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.2.delta.70a41889-5fff-4001-8de9-60864c57cbad.TID997.tmp
[2025-07-19T19:57:28.529+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 192.0 in stage 9.0 (TID 995). 5829 bytes result sent to driver
[2025-07-19T19:57:28.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Starting task 199.0 in stage 9.0 (TID 1002) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T19:57:28.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Running task 199.0 in stage 9.0 (TID 1002)
[2025-07-19T19:57:28.530+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.2.delta.721a2d74-aeac-4d35-9c20-1962bb5f69a3.TID1000.tmp
[2025-07-19T19:57:28.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 191.0 in stage 9.0 (TID 994) in 80 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T19:57:28.531+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 192.0 in stage 9.0 (TID 995) in 72 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T19:57:28.532+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.2.delta.1c235f39-2568-4816-ba99-a9156098a7ce.TID1001.tmp
[2025-07-19T19:57:28.533+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T19:57:28.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T19:57:28.534+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45b33a24
[2025-07-19T19:57:28.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],bba1078e-cb27-476b-a4e5-d0c62f2a2c75) is active
[2025-07-19T19:57:28.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199] for update
[2025-07-19T19:57:28.535+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T19:57:28.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/.2.delta.659e3842-e8a0-49c0-af20-c1d5040b929b.TID996.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/2.delta
[2025-07-19T19:57:28.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/193/2.delta
[2025-07-19T19:57:28.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.2.delta.db389ae1-ae37-4d3f-8c20-1d223677e3db.TID999.tmp
[2025-07-19T19:57:28.536+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T19:57:28.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T19:57:28.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 193.0 in stage 9.0 (TID 996). 5829 bytes result sent to driver
[2025-07-19T19:57:28.537+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 193.0 in stage 9.0 (TID 996) in 62 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T19:57:28.538+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.2.delta.b5cf9ada-4e48-4a5e-8846-e2cf00cd220c.TID1002.tmp
[2025-07-19T19:57:28.543+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/.2.delta.70a41889-5fff-4001-8de9-60864c57cbad.TID997.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/2.delta
[2025-07-19T19:57:28.544+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/194/2.delta
[2025-07-19T19:57:28.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T19:57:28.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/.2.delta.721a2d74-aeac-4d35-9c20-1962bb5f69a3.TID1000.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/2.delta
[2025-07-19T19:57:28.545+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/197/2.delta
[2025-07-19T19:57:28.546+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T19:57:28.549+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T19:57:28.550+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T19:57:28.551+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 194.0 in stage 9.0 (TID 997). 5829 bytes result sent to driver
[2025-07-19T19:57:28.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 197.0 in stage 9.0 (TID 1000). 5829 bytes result sent to driver
[2025-07-19T19:57:28.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 194.0 in stage 9.0 (TID 997) in 59 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T19:57:28.552+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 197.0 in stage 9.0 (TID 1000) in 55 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T19:57:28.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/.2.delta.d8e1d546-b535-4d5e-ace2-36034fea586c.TID998.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/2.delta
[2025-07-19T19:57:28.553+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/195/2.delta
[2025-07-19T19:57:28.554+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T19:57:28.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/.2.delta.1c235f39-2568-4816-ba99-a9156098a7ce.TID1001.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/2.delta
[2025-07-19T19:57:28.555+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/198/2.delta
[2025-07-19T19:57:28.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T19:57:28.556+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T19:57:28.557+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 195.0 in stage 9.0 (TID 998). 5829 bytes result sent to driver
[2025-07-19T19:57:28.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 195.0 in stage 9.0 (TID 998) in 65 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T19:57:28.558+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/.2.delta.db389ae1-ae37-4d3f-8c20-1d223677e3db.TID999.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/2.delta
[2025-07-19T19:57:28.559+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/196/2.delta
[2025-07-19T19:57:28.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T19:57:28.560+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 198.0 in stage 9.0 (TID 1001). 5829 bytes result sent to driver
[2025-07-19T19:57:28.561+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T19:57:28.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 198.0 in stage 9.0 (TID 1001) in 63 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T19:57:28.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/.2.delta.b5cf9ada-4e48-4a5e-8846-e2cf00cd220c.TID1002.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/2.delta
[2025-07-19T19:57:28.562+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/state/0/199/2.delta
[2025-07-19T19:57:28.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T19:57:28.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T19:57:28.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 196.0 in stage 9.0 (TID 999). 5829 bytes result sent to driver
[2025-07-19T19:57:28.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DataWritingSparkTask: Committed partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T19:57:28.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO Executor: Finished task 199.0 in stage 9.0 (TID 1002). 5829 bytes result sent to driver
[2025-07-19T19:57:28.563+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 196.0 in stage 9.0 (TID 999) in 71 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T19:57:28.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSetManager: Finished task 199.0 in stage 9.0 (TID 1002) in 47 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T19:57:28.564+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-19T19:57:28.565+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DAGScheduler: ResultStage 9 (start at <unknown>:0) finished in 3.604 s
[2025-07-19T19:57:28.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T19:57:28.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-07-19T19:57:28.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO DAGScheduler: Job 4 finished: start at <unknown>:0, took 3.622438 s
[2025-07-19T19:57:28.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T19:57:28.566+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO SparkWrite: Committing epoch 1 for query 609fc205-5186-4889-9ac4-e96d359c0199 in append mode
[2025-07-19T19:57:28.571+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T19:57:28.612+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v89.metadata.json
[2025-07-19T19:57:28.624+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO SnapshotProducer: Committed snapshot 1759828668938613019 (FastAppend)
[2025-07-19T19:57:28.639+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=1759828668938613019, sequenceNumber=88, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.065402416S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=3686}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=4818}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=11911784}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752955029831, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T19:57:28.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO SparkWrite: Committed in 65 ms
[2025-07-19T19:57:28.640+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T19:57:28.643+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/commits/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/commits/.1.a73a3777-60a4-43ff-9c2d-29bc98f8968a.tmp
[2025-07-19T19:57:28.650+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/commits/.1.a73a3777-60a4-43ff-9c2d-29bc98f8968a.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T19:54:00+00:00/commits/1
[2025-07-19T19:57:28.651+0000] {subprocess.py:93} INFO - 25/07/19 19:57:28 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T19:57:28.651+0000] {subprocess.py:93} INFO -   "id" : "609fc205-5186-4889-9ac4-e96d359c0199",
[2025-07-19T19:57:28.652+0000] {subprocess.py:93} INFO -   "runId" : "bba1078e-cb27-476b-a4e5-d0c62f2a2c75",
[2025-07-19T19:57:28.652+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T19:57:28.652+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T19:57:24.726Z",
[2025-07-19T19:57:28.652+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T19:57:28.652+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T19:57:28.652+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:28.652+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T19:57:28.653+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T19:57:28.653+0000] {subprocess.py:93} INFO -     "addBatch" : 3781,
[2025-07-19T19:57:28.653+0000] {subprocess.py:93} INFO -     "commitOffsets" : 13,
[2025-07-19T19:57:28.653+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T19:57:28.653+0000] {subprocess.py:93} INFO -     "latestOffset" : 10,
[2025-07-19T19:57:28.653+0000] {subprocess.py:93} INFO -     "queryPlanning" : 64,
[2025-07-19T19:57:28.654+0000] {subprocess.py:93} INFO -     "triggerExecution" : 3924,
[2025-07-19T19:57:28.654+0000] {subprocess.py:93} INFO -     "walCommit" : 50
[2025-07-19T19:57:28.654+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:28.654+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T19:57:28.654+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T19:35:00.000Z"
[2025-07-19T19:57:28.654+0000] {subprocess.py:93} INFO -   },
[2025-07-19T19:57:28.654+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T19:57:28.654+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 174,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 223,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 101,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 13003,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 133272,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T19:57:28.655+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 57464
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T19:57:28.656+0000] {subprocess.py:93} INFO -         "0" : 174
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -       }
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -     },
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -     }
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO -   }
[2025-07-19T19:57:28.657+0000] {subprocess.py:93} INFO - }
[2025-07-19T19:57:30.495+0000] {subprocess.py:93} INFO - 25/07/19 19:57:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:57:37.058+0000] {subprocess.py:93} INFO - 25/07/19 19:57:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:57:38.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:38 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:57:40.503+0000] {subprocess.py:93} INFO - 25/07/19 19:57:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:57:46.821+0000] {subprocess.py:93} INFO - 25/07/19 19:57:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:57:48.771+0000] {subprocess.py:93} INFO - 25/07/19 19:57:48 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:57:50.507+0000] {subprocess.py:93} INFO - 25/07/19 19:57:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:57:56.825+0000] {subprocess.py:93} INFO - 25/07/19 19:57:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:57:58.773+0000] {subprocess.py:93} INFO - 25/07/19 19:57:58 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:58:00.511+0000] {subprocess.py:93} INFO - 25/07/19 19:58:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:58:06.838+0000] {subprocess.py:93} INFO - 25/07/19 19:58:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:58:08.787+0000] {subprocess.py:93} INFO - 25/07/19 19:58:08 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:58:10.514+0000] {subprocess.py:93} INFO - 25/07/19 19:58:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T19:58:12.355+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2, groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T19:58:12.356+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2, groupId=spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T19:58:12.360+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO Metrics: Metrics scheduler closed
[2025-07-19T19:58:12.360+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T19:58:12.360+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO Metrics: Metrics reporters closed
[2025-07-19T19:58:12.364+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-274861a1-883f-41ad-8dc4-f47ac8da5465-785387780-executor-2 unregistered
[2025-07-19T19:58:12.365+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3, groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T19:58:12.365+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3, groupId=spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T19:58:12.366+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO Metrics: Metrics scheduler closed
[2025-07-19T19:58:12.366+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T19:58:12.366+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO Metrics: Metrics reporters closed
[2025-07-19T19:58:12.367+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-85c517c6-d51c-4205-bd46-21b6509874fe-1763357858-executor-3 unregistered
[2025-07-19T19:58:12.367+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1, groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T19:58:12.367+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1, groupId=spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T19:58:12.368+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO Metrics: Metrics scheduler closed
[2025-07-19T19:58:12.369+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T19:58:12.369+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO Metrics: Metrics reporters closed
[2025-07-19T19:58:12.369+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-f93668cb-ba7a-4ec0-b21f-59cf7d3370ec--1984111485-executor-1 unregistered
[2025-07-19T19:58:12.371+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO SparkContext: Invoking stop() from shutdown hook
[2025-07-19T19:58:12.371+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-19T19:58:12.380+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO SparkUI: Stopped Spark web UI at http://8b44f3d35cfa:4041
[2025-07-19T19:58:12.389+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-19T19:58:12.405+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO MemoryStore: MemoryStore cleared
[2025-07-19T19:58:12.406+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO BlockManager: BlockManager stopped
[2025-07-19T19:58:12.409+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-19T19:58:12.410+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-19T19:58:12.418+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO SparkContext: Successfully stopped SparkContext
[2025-07-19T19:58:12.418+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ShutdownHookManager: Shutdown hook called
[2025-07-19T19:58:12.418+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-c6bf89c9-78cb-41ad-9d12-ab8ef8e6d52a/pyspark-fd8185e4-8a03-4ddc-bd50-bcbad340cf03
[2025-07-19T19:58:12.419+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-e0dd4e08-eb30-4033-b7a1-52349406b62d
[2025-07-19T19:58:12.420+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-c6bf89c9-78cb-41ad-9d12-ab8ef8e6d52a
[2025-07-19T19:58:12.435+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2025-07-19T19:58:12.436+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2025-07-19T19:58:12.436+0000] {subprocess.py:93} INFO - 25/07/19 19:58:12 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2025-07-19T19:58:12.886+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-19T19:58:12.930+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=restaurant_pipeline, task_id=stream_to_bronze, execution_date=20250719T195400, start_date=20250719T195707, end_date=20250719T195812
[2025-07-19T19:58:12.963+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-19T19:58:12.999+0000] {taskinstance.py:2778} INFO - 1 downstream tasks scheduled from follow-on schedule check
