[2025-07-19T22:09:41.855+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T22:06:00+00:00 [queued]>
[2025-07-19T22:09:41.865+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T22:06:00+00:00 [queued]>
[2025-07-19T22:09:41.865+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2025-07-19T22:09:41.875+0000] {taskinstance.py:1382} INFO - Executing <Task(BashOperator): stream_to_bronze> on 2025-07-19 22:06:00+00:00
[2025-07-19T22:09:41.879+0000] {standard_task_runner.py:57} INFO - Started process 5063 to run task
[2025-07-19T22:09:41.884+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'restaurant_pipeline', 'stream_to_bronze', 'scheduled__2025-07-19T22:06:00+00:00', '--job-id', '1283', '--raw', '--subdir', 'DAGS_FOLDER/restaurant_pipeline.py', '--cfg-path', '/tmp/tmp95j4jk5v']
[2025-07-19T22:09:41.887+0000] {standard_task_runner.py:85} INFO - Job 1283: Subtask stream_to_bronze
[2025-07-19T22:09:41.925+0000] {task_command.py:416} INFO - Running <TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T22:06:00+00:00 [running]> on host e3f5d8fc4eef
[2025-07-19T22:09:41.978+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='moran' AIRFLOW_CTX_DAG_ID='restaurant_pipeline' AIRFLOW_CTX_TASK_ID='stream_to_bronze' AIRFLOW_CTX_EXECUTION_DATE='2025-07-19T22:06:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T22:06:00+00:00'
[2025-07-19T22:09:41.978+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-07-19T22:09:41.979+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', "docker exec -e AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T22:06:00+00:00' spark-iceberg spark-submit /home/iceberg/spark/stream_to_bronze.py"]
[2025-07-19T22:09:41.986+0000] {subprocess.py:86} INFO - Output:
[2025-07-19T22:09:44.246+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SparkContext: Running Spark version 3.5.6
[2025-07-19T22:09:44.249+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T22:09:44.250+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SparkContext: Java version 17.0.15
[2025-07-19T22:09:44.268+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO ResourceUtils: ==============================================================
[2025-07-19T22:09:44.268+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-19T22:09:44.268+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO ResourceUtils: ==============================================================
[2025-07-19T22:09:44.268+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SparkContext: Submitted application: StreamToBronze
[2025-07-19T22:09:44.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-19T22:09:44.288+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO ResourceProfile: Limiting resource is cpu
[2025-07-19T22:09:44.289+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-19T22:09:44.336+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SecurityManager: Changing view acls to: root,spark
[2025-07-19T22:09:44.336+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SecurityManager: Changing modify acls to: root,spark
[2025-07-19T22:09:44.337+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SecurityManager: Changing view acls groups to:
[2025-07-19T22:09:44.337+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SecurityManager: Changing modify acls groups to:
[2025-07-19T22:09:44.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
[2025-07-19T22:09:44.384+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-19T22:09:44.606+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO Utils: Successfully started service 'sparkDriver' on port 39259.
[2025-07-19T22:09:44.626+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SparkEnv: Registering MapOutputTracker
[2025-07-19T22:09:44.653+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-19T22:09:44.671+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-19T22:09:44.672+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-19T22:09:44.675+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-19T22:09:44.690+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3984fbe8-7fb2-42b3-8519-1a168c1c8635
[2025-07-19T22:09:44.699+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-19T22:09:44.711+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-19T22:09:44.789+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-19T22:09:44.831+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-07-19T22:09:44.837+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-07-19T22:09:44.919+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO Executor: Starting executor ID driver on host 8b44f3d35cfa
[2025-07-19T22:09:44.919+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T22:09:44.920+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO Executor: Java version 17.0.15
[2025-07-19T22:09:44.925+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-19T22:09:44.925+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7024c97 for default.
[2025-07-19T22:09:44.942+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37751.
[2025-07-19T22:09:44.943+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO NettyBlockTransferService: Server created on 8b44f3d35cfa:37751
[2025-07-19T22:09:44.944+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-19T22:09:44.961+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 8b44f3d35cfa, 37751, None)
[2025-07-19T22:09:44.976+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO BlockManagerMasterEndpoint: Registering block manager 8b44f3d35cfa:37751 with 434.4 MiB RAM, BlockManagerId(driver, 8b44f3d35cfa, 37751, None)
[2025-07-19T22:09:44.977+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 8b44f3d35cfa, 37751, None)
[2025-07-19T22:09:44.978+0000] {subprocess.py:93} INFO - 25/07/19 22:09:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 8b44f3d35cfa, 37751, None)
[2025-07-19T22:09:45.300+0000] {subprocess.py:93} INFO - 25/07/19 22:09:45 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-19T22:09:45.306+0000] {subprocess.py:93} INFO - 25/07/19 22:09:45 INFO SharedState: Warehouse path is 'file:/app/spark-warehouse'.
[2025-07-19T22:09:47.209+0000] {subprocess.py:93} INFO - 25/07/19 22:09:47 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-07-19T22:09:47.218+0000] {subprocess.py:93} INFO - 25/07/19 22:09:47 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-07-19T22:09:47.219+0000] {subprocess.py:93} INFO - 25/07/19 22:09:47 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-07-19T22:09:48.035+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:48.046+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-07-19T22:09:48.096+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00 resolved to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00.
[2025-07-19T22:09:48.096+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T22:09:48.141+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/metadata using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/.metadata.d20fb193-8f7a-4b37-ac10-cfae82d75f91.tmp
[2025-07-19T22:09:48.270+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/.metadata.d20fb193-8f7a-4b37-ac10-cfae82d75f91.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/metadata
[2025-07-19T22:09:48.302+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Starting [id = 7b068dbd-ce57-48ee-985f-2e8eff7153ac, runId = c4540072-4f24-4872-808b-e7ac78480bd8]. Use file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00 to store the query checkpoint.
[2025-07-19T22:09:48.310+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@bd5b169] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@55e907a9]
[2025-07-19T22:09:48.343+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T22:09:48.344+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T22:09:48.344+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T22:09:48.347+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T22:09:48.455+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:48.464+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00 resolved to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00.
[2025-07-19T22:09:48.465+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T22:09:48.485+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/metadata using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/.metadata.58cec22f-1672-4f32-b1de-ce0b9ce06052.tmp
[2025-07-19T22:09:48.573+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/.metadata.58cec22f-1672-4f32-b1de-ce0b9ce06052.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/metadata
[2025-07-19T22:09:48.591+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Starting [id = 76699ab7-445a-4f4e-a8af-51ec24e5ea93, runId = 002fa0f1-bd40-4ea7-9304-5ec9b41c6781]. Use file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00 to store the query checkpoint.
[2025-07-19T22:09:48.593+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@5b3aa4a1] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@55fd406e]
[2025-07-19T22:09:48.599+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T22:09:48.600+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T22:09:48.600+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T22:09:48.601+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T22:09:48.657+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T22:09:48.657+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T22:09:48.657+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T22:09:48.658+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T22:09:48.658+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T22:09:48.659+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T22:09:48.659+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T22:09:48.659+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T22:09:48.660+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T22:09:48.660+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T22:09:48.660+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T22:09:48.660+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T22:09:48.660+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T22:09:48.660+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T22:09:48.660+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T22:09:48.661+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T22:09:48.661+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T22:09:48.661+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T22:09:48.661+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T22:09:48.661+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T22:09:48.662+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T22:09:48.662+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T22:09:48.662+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T22:09:48.662+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T22:09:48.662+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T22:09:48.663+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T22:09:48.663+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T22:09:48.663+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T22:09:48.663+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T22:09:48.664+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T22:09:48.664+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T22:09:48.664+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T22:09:48.664+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T22:09:48.665+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T22:09:48.665+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T22:09:48.665+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T22:09:48.665+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T22:09:48.665+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T22:09:48.665+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T22:09:48.665+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T22:09:48.666+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T22:09:48.666+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T22:09:48.666+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T22:09:48.666+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T22:09:48.666+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T22:09:48.666+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T22:09:48.667+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T22:09:48.667+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T22:09:48.667+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T22:09:48.667+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T22:09:48.667+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T22:09:48.667+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T22:09:48.668+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T22:09:48.668+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T22:09:48.669+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T22:09:48.669+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T22:09:48.670+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T22:09:48.670+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T22:09:48.670+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T22:09:48.670+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T22:09:48.671+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T22:09:48.671+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T22:09:48.671+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T22:09:48.671+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T22:09:48.671+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T22:09:48.671+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T22:09:48.672+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T22:09:48.672+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T22:09:48.672+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T22:09:48.672+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T22:09:48.673+0000] {subprocess.py:93} INFO - 
[2025-07-19T22:09:48.673+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T22:09:48.673+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T22:09:48.673+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T22:09:48.673+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T22:09:48.673+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T22:09:48.673+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T22:09:48.674+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T22:09:48.674+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T22:09:48.674+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T22:09:48.674+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T22:09:48.675+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T22:09:48.675+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T22:09:48.675+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T22:09:48.675+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T22:09:48.676+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T22:09:48.676+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T22:09:48.676+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T22:09:48.676+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T22:09:48.677+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T22:09:48.677+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T22:09:48.677+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T22:09:48.677+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T22:09:48.678+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T22:09:48.678+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T22:09:48.678+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T22:09:48.678+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T22:09:48.678+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T22:09:48.678+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T22:09:48.679+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T22:09:48.679+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T22:09:48.679+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T22:09:48.679+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T22:09:48.679+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T22:09:48.679+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T22:09:48.680+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T22:09:48.680+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T22:09:48.680+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T22:09:48.680+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T22:09:48.680+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T22:09:48.680+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T22:09:48.681+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T22:09:48.681+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T22:09:48.682+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T22:09:48.682+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T22:09:48.682+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T22:09:48.683+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T22:09:48.683+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T22:09:48.683+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T22:09:48.684+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T22:09:48.684+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T22:09:48.684+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T22:09:48.685+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T22:09:48.687+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T22:09:48.687+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T22:09:48.688+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T22:09:48.688+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T22:09:48.688+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T22:09:48.688+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T22:09:48.690+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T22:09:48.691+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T22:09:48.692+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T22:09:48.692+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T22:09:48.693+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T22:09:48.693+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T22:09:48.693+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T22:09:48.694+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T22:09:48.694+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T22:09:48.695+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T22:09:48.695+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T22:09:48.696+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T22:09:48.697+0000] {subprocess.py:93} INFO - 
[2025-07-19T22:09:48.708+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:48.718+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00 resolved to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00.
[2025-07-19T22:09:48.719+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T22:09:48.729+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T22:09:48.730+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T22:09:48.731+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T22:09:48.732+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T22:09:48.733+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AppInfoParser: Kafka startTimeMs: 1752962988728
[2025-07-19T22:09:48.734+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/metadata using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/.metadata.ee960fc8-11e6-40f2-9a98-37a8364f1c31.tmp
[2025-07-19T22:09:48.735+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T22:09:48.735+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T22:09:48.735+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AppInfoParser: Kafka startTimeMs: 1752962988729
[2025-07-19T22:09:48.838+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/.metadata.ee960fc8-11e6-40f2-9a98-37a8364f1c31.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/metadata
[2025-07-19T22:09:48.856+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Starting [id = 46c08399-34b2-49a9-aadd-060519c28563, runId = 9b56af61-c478-4de4-bf3d-6c85462edb9c]. Use file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00 to store the query checkpoint.
[2025-07-19T22:09:48.856+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@48a7809b] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@46606627]
[2025-07-19T22:09:48.859+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T22:09:48.859+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T22:09:48.859+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T22:09:48.859+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T22:09:48.892+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T22:09:48.895+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T22:09:48.896+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T22:09:48.896+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T22:09:48.897+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T22:09:48.898+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T22:09:48.898+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T22:09:48.898+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T22:09:48.898+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T22:09:48.898+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T22:09:48.898+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T22:09:48.898+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T22:09:48.898+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T22:09:48.899+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T22:09:48.899+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T22:09:48.899+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T22:09:48.899+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T22:09:48.899+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T22:09:48.899+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T22:09:48.900+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T22:09:48.901+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T22:09:48.901+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T22:09:48.901+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T22:09:48.901+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T22:09:48.901+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T22:09:48.901+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T22:09:48.901+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T22:09:48.902+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T22:09:48.902+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T22:09:48.902+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T22:09:48.902+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T22:09:48.902+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T22:09:48.902+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T22:09:48.902+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T22:09:48.902+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T22:09:48.902+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T22:09:48.903+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T22:09:48.904+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T22:09:48.905+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T22:09:48.905+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T22:09:48.905+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T22:09:48.906+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T22:09:48.906+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T22:09:48.906+0000] {subprocess.py:93} INFO - 
[2025-07-19T22:09:48.906+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T22:09:48.906+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T22:09:48.906+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T22:09:48.906+0000] {subprocess.py:93} INFO - 25/07/19 22:09:48 INFO AppInfoParser: Kafka startTimeMs: 1752962988886
[2025-07-19T22:09:49.061+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/sources/0/.0.3fb24a7c-a2d0-4a06-8dba-f893a230c455.tmp
[2025-07-19T22:09:49.061+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/sources/0/.0.1d7583fe-3c99-44f2-b2a9-13202a90bbc7.tmp
[2025-07-19T22:09:49.062+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/sources/0/.0.c0267b3a-7601-47b6-8187-794ce44bfd2a.tmp
[2025-07-19T22:09:49.165+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/sources/0/.0.3fb24a7c-a2d0-4a06-8dba-f893a230c455.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/sources/0/0
[2025-07-19T22:09:49.166+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/sources/0/.0.c0267b3a-7601-47b6-8187-794ce44bfd2a.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/sources/0/0
[2025-07-19T22:09:49.167+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO KafkaMicroBatchStream: Initial offsets: {"reservations":{"0":0}}
[2025-07-19T22:09:49.167+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO KafkaMicroBatchStream: Initial offsets: {"feedback":{"0":0}}
[2025-07-19T22:09:49.168+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/sources/0/.0.1d7583fe-3c99-44f2-b2a9-13202a90bbc7.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/sources/0/0
[2025-07-19T22:09:49.168+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO KafkaMicroBatchStream: Initial offsets: {"checkins":{"0":0}}
[2025-07-19T22:09:49.193+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/offsets/.0.51e4924a-ae6b-4861-ab4a-e283cbada70e.tmp
[2025-07-19T22:09:49.194+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/offsets/.0.5f758c1f-2295-4ec3-85ee-b2d5a5738fd1.tmp
[2025-07-19T22:09:49.194+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/offsets/.0.a1d3d093-be9f-4185-ba44-f2a07c93a9da.tmp
[2025-07-19T22:09:49.329+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/offsets/.0.51e4924a-ae6b-4861-ab4a-e283cbada70e.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/offsets/0
[2025-07-19T22:09:49.331+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752962989174,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T22:09:49.333+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/offsets/.0.a1d3d093-be9f-4185-ba44-f2a07c93a9da.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/offsets/0
[2025-07-19T22:09:49.336+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/offsets/.0.5f758c1f-2295-4ec3-85ee-b2d5a5738fd1.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/offsets/0
[2025-07-19T22:09:49.336+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752962989174,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T22:09:49.337+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752962989174,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T22:09:49.597+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:49.597+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:49.597+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:49.597+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:49.598+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:49.598+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:49.599+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:49.600+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:49.600+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:49.904+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO CodeGenerator: Code generated in 100.951792 ms
[2025-07-19T22:09:49.923+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:49.923+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:49.923+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:49.973+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:49.974+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:49.974+0000] {subprocess.py:93} INFO - 25/07/19 22:09:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.026+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:50.027+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:50.027+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:50.027+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:50.027+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:50.027+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:50.039+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.040+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:50.041+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:50.042+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:50.042+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.043+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.044+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.055+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.058+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.084+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:50.085+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:50.086+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T22:09:50.086+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:50.086+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:50.086+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:09:50.086+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:50.086+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:50.086+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:09:50.109+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.116+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.116+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.118+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.121+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.122+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T22:09:50.224+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO CodeGenerator: Code generated in 24.275292 ms
[2025-07-19T22:09:50.227+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO CodeGenerator: Code generated in 27.458833 ms
[2025-07-19T22:09:50.302+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO CodeGenerator: Code generated in 71.259875 ms
[2025-07-19T22:09:50.595+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T22:09:50.595+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T22:09:50.604+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T22:09:50.657+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T22:09:50.658+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T22:09:50.659+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T22:09:50.659+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 8b44f3d35cfa:37751 (size: 35.4 KiB, free: 434.4 MiB)
[2025-07-19T22:09:50.664+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 8b44f3d35cfa:37751 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T22:09:50.665+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Created broadcast 2 from start at <unknown>:0
[2025-07-19T22:09:50.666+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 8b44f3d35cfa:37751 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T22:09:50.667+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Created broadcast 0 from start at <unknown>:0
[2025-07-19T22:09:50.667+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Created broadcast 1 from start at <unknown>:0
[2025-07-19T22:09:50.687+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T22:09:50.687+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T22:09:50.690+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T22:09:50.709+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.6 MiB)
[2025-07-19T22:09:50.709+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.5 MiB)
[2025-07-19T22:09:50.710+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 8b44f3d35cfa:37751 (size: 29.6 KiB, free: 434.3 MiB)
[2025-07-19T22:09:50.716+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.5 MiB)
[2025-07-19T22:09:50.716+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Created broadcast 5 from start at <unknown>:0
[2025-07-19T22:09:50.717+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 8b44f3d35cfa:37751 (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T22:09:50.717+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 8b44f3d35cfa:37751 (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T22:09:50.717+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Created broadcast 3 from start at <unknown>:0
[2025-07-19T22:09:50.717+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Created broadcast 4 from start at <unknown>:0
[2025-07-19T22:09:50.717+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T22:09:50.717+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T22:09:50.717+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T22:09:50.734+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T22:09:50.735+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T22:09:50.736+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T22:09:50.745+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Registering RDD 15 (start at <unknown>:0) as input to shuffle 1
[2025-07-19T22:09:50.749+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Got job 2 (start at <unknown>:0) with 200 output partitions
[2025-07-19T22:09:50.750+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Final stage: ResultStage 1 (start at <unknown>:0)
[2025-07-19T22:09:50.750+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
[2025-07-19T22:09:50.752+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
[2025-07-19T22:09:50.755+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[15] at start at <unknown>:0), which has no missing parents
[2025-07-19T22:09:50.774+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 35.8 KiB, free 433.5 MiB)
[2025-07-19T22:09:50.791+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.5 MiB)
[2025-07-19T22:09:50.792+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 8b44f3d35cfa:37751 (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T22:09:50.792+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-07-19T22:09:50.802+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[15] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T22:09:50.803+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-07-19T22:09:50.837+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Registering RDD 17 (start at <unknown>:0) as input to shuffle 0
[2025-07-19T22:09:50.839+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Got job 1 (start at <unknown>:0) with 200 output partitions
[2025-07-19T22:09:50.840+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Final stage: ResultStage 3 (start at <unknown>:0)
[2025-07-19T22:09:50.840+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-07-19T22:09:50.841+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
[2025-07-19T22:09:50.841+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at start at <unknown>:0), which has no missing parents
[2025-07-19T22:09:50.849+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.8 KiB, free 433.4 MiB)
[2025-07-19T22:09:50.852+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 433.4 MiB)
[2025-07-19T22:09:50.854+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 8b44f3d35cfa:37751 (size: 14.7 KiB, free: 434.2 MiB)
[2025-07-19T22:09:50.855+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-07-19T22:09:50.856+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T22:09:50.857+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-07-19T22:09:50.870+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9923 bytes)
[2025-07-19T22:09:50.879+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Registering RDD 16 (start at <unknown>:0) as input to shuffle 2
[2025-07-19T22:09:50.882+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 200 output partitions
[2025-07-19T22:09:50.883+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Final stage: ResultStage 5 (start at <unknown>:0)
[2025-07-19T22:09:50.886+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-07-19T22:09:50.888+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
[2025-07-19T22:09:50.889+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[16] at start at <unknown>:0), which has no missing parents
[2025-07-19T22:09:50.889+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9928 bytes)
[2025-07-19T22:09:50.892+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 32.3 KiB, free 433.4 MiB)
[2025-07-19T22:09:50.893+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 433.4 MiB)
[2025-07-19T22:09:50.894+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 8b44f3d35cfa:37751 (size: 14.0 KiB, free: 434.2 MiB)
[2025-07-19T22:09:50.895+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-19T22:09:50.895+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
[2025-07-19T22:09:50.898+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-07-19T22:09:50.898+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[16] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T22:09:50.899+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-19T22:09:50.899+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9925 bytes)
[2025-07-19T22:09:50.901+0000] {subprocess.py:93} INFO - 25/07/19 22:09:50 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)
[2025-07-19T22:09:51.019+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 15.619291 ms
[2025-07-19T22:09:51.022+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 20.367625 ms
[2025-07-19T22:09:51.028+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 17.203334 ms
[2025-07-19T22:09:51.029+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 34.800791 ms
[2025-07-19T22:09:51.035+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 14.652458 ms
[2025-07-19T22:09:51.044+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 8.016708 ms
[2025-07-19T22:09:51.056+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 25.896959 ms
[2025-07-19T22:09:51.058+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 8.97075 ms
[2025-07-19T22:09:51.073+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 8.766709 ms
[2025-07-19T22:09:51.097+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reservations-0 fromOffset=0 untilOffset=276, for query queryId=7b068dbd-ce57-48ee-985f-2e8eff7153ac batchId=0 taskId=1 partitionId=0
[2025-07-19T22:09:51.098+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=feedback-0 fromOffset=0 untilOffset=276, for query queryId=46c08399-34b2-49a9-aadd-060519c28563 batchId=0 taskId=2 partitionId=0
[2025-07-19T22:09:51.099+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 14.12 ms
[2025-07-19T22:09:51.101+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=checkins-0 fromOffset=0 untilOffset=276, for query queryId=76699ab7-445a-4f4e-a8af-51ec24e5ea93 batchId=0 taskId=0 partitionId=0
[2025-07-19T22:09:51.136+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 12.393125 ms
[2025-07-19T22:09:51.166+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO CodeGenerator: Code generated in 15.832667 ms
[2025-07-19T22:09:51.214+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T22:09:51.216+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T22:09:51.219+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T22:09:51.219+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T22:09:51.220+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T22:09:51.221+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T22:09:51.221+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T22:09:51.222+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T22:09:51.223+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1
[2025-07-19T22:09:51.224+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T22:09:51.225+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T22:09:51.226+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T22:09:51.227+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T22:09:51.229+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T22:09:51.231+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T22:09:51.234+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T22:09:51.236+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T22:09:51.238+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor
[2025-07-19T22:09:51.239+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T22:09:51.244+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T22:09:51.245+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T22:09:51.246+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T22:09:51.247+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T22:09:51.249+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T22:09:51.250+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T22:09:51.251+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T22:09:51.254+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T22:09:51.256+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T22:09:51.257+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T22:09:51.258+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T22:09:51.259+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T22:09:51.259+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T22:09:51.260+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T22:09:51.261+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T22:09:51.261+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T22:09:51.262+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T22:09:51.263+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T22:09:51.264+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T22:09:51.266+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T22:09:51.268+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T22:09:51.269+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T22:09:51.272+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T22:09:51.273+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T22:09:51.274+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T22:09:51.274+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T22:09:51.275+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T22:09:51.275+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T22:09:51.276+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T22:09:51.276+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T22:09:51.277+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T22:09:51.277+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T22:09:51.277+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T22:09:51.277+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T22:09:51.278+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T22:09:51.278+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T22:09:51.278+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T22:09:51.279+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T22:09:51.279+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T22:09:51.280+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T22:09:51.281+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T22:09:51.283+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T22:09:51.284+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T22:09:51.284+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T22:09:51.285+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T22:09:51.286+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T22:09:51.286+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T22:09:51.287+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T22:09:51.287+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T22:09:51.287+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T22:09:51.288+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T22:09:51.290+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T22:09:51.291+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T22:09:51.291+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T22:09:51.292+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T22:09:51.292+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T22:09:51.292+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T22:09:51.293+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T22:09:51.293+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T22:09:51.293+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T22:09:51.294+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T22:09:51.294+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T22:09:51.295+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T22:09:51.295+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T22:09:51.295+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T22:09:51.296+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T22:09:51.296+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T22:09:51.297+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T22:09:51.297+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T22:09:51.299+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T22:09:51.299+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T22:09:51.300+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T22:09:51.300+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T22:09:51.301+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T22:09:51.301+0000] {subprocess.py:93} INFO - 
[2025-07-19T22:09:51.302+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T22:09:51.302+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T22:09:51.302+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T22:09:51.302+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T22:09:51.302+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T22:09:51.302+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T22:09:51.302+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T22:09:51.303+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T22:09:51.303+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3
[2025-07-19T22:09:51.303+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T22:09:51.303+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T22:09:51.303+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T22:09:51.304+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T22:09:51.304+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T22:09:51.304+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T22:09:51.304+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T22:09:51.304+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T22:09:51.304+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor
[2025-07-19T22:09:51.305+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T22:09:51.307+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T22:09:51.307+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T22:09:51.307+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T22:09:51.308+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T22:09:51.308+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T22:09:51.308+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T22:09:51.308+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T22:09:51.308+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T22:09:51.308+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T22:09:51.309+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T22:09:51.309+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T22:09:51.309+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T22:09:51.309+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T22:09:51.309+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T22:09:51.309+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T22:09:51.309+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T22:09:51.309+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T22:09:51.309+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T22:09:51.310+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T22:09:51.311+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T22:09:51.312+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T22:09:51.312+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T22:09:51.312+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T22:09:51.312+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T22:09:51.313+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T22:09:51.313+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T22:09:51.313+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T22:09:51.314+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T22:09:51.314+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T22:09:51.314+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T22:09:51.315+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T22:09:51.315+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T22:09:51.316+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T22:09:51.317+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T22:09:51.317+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T22:09:51.318+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T22:09:51.318+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T22:09:51.318+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T22:09:51.318+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T22:09:51.319+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T22:09:51.319+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T22:09:51.319+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T22:09:51.320+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T22:09:51.320+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T22:09:51.320+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T22:09:51.320+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T22:09:51.321+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T22:09:51.321+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T22:09:51.321+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T22:09:51.321+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T22:09:51.321+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T22:09:51.322+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T22:09:51.322+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T22:09:51.323+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T22:09:51.323+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T22:09:51.323+0000] {subprocess.py:93} INFO - 
[2025-07-19T22:09:51.324+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T22:09:51.324+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T22:09:51.325+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T22:09:51.325+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T22:09:51.325+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T22:09:51.325+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T22:09:51.326+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T22:09:51.326+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T22:09:51.327+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2
[2025-07-19T22:09:51.327+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T22:09:51.327+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T22:09:51.328+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T22:09:51.328+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T22:09:51.328+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T22:09:51.328+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T22:09:51.328+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T22:09:51.328+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T22:09:51.328+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor
[2025-07-19T22:09:51.329+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T22:09:51.329+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T22:09:51.329+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T22:09:51.329+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T22:09:51.329+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T22:09:51.329+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T22:09:51.330+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T22:09:51.333+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T22:09:51.334+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T22:09:51.336+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T22:09:51.337+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T22:09:51.338+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T22:09:51.338+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T22:09:51.339+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T22:09:51.339+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T22:09:51.340+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T22:09:51.340+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T22:09:51.342+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T22:09:51.342+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T22:09:51.343+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T22:09:51.343+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T22:09:51.344+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T22:09:51.346+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T22:09:51.346+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T22:09:51.347+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T22:09:51.347+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T22:09:51.348+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T22:09:51.349+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T22:09:51.351+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T22:09:51.352+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T22:09:51.353+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T22:09:51.354+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T22:09:51.354+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T22:09:51.355+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T22:09:51.356+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T22:09:51.356+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T22:09:51.357+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T22:09:51.358+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T22:09:51.358+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T22:09:51.358+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T22:09:51.358+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T22:09:51.358+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T22:09:51.359+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T22:09:51.359+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T22:09:51.359+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T22:09:51.359+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T22:09:51.359+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T22:09:51.360+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T22:09:51.360+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T22:09:51.360+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T22:09:51.360+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T22:09:51.361+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T22:09:51.361+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T22:09:51.362+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T22:09:51.362+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T22:09:51.362+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T22:09:51.363+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T22:09:51.363+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T22:09:51.363+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T22:09:51.364+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T22:09:51.365+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T22:09:51.365+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T22:09:51.366+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T22:09:51.366+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T22:09:51.366+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T22:09:51.366+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T22:09:51.366+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T22:09:51.366+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T22:09:51.367+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T22:09:51.367+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T22:09:51.367+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T22:09:51.367+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T22:09:51.368+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T22:09:51.368+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T22:09:51.368+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T22:09:51.368+0000] {subprocess.py:93} INFO - 
[2025-07-19T22:09:51.368+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T22:09:51.369+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T22:09:51.369+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO AppInfoParser: Kafka startTimeMs: 1752962991296
[2025-07-19T22:09:51.369+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T22:09:51.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T22:09:51.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO AppInfoParser: Kafka startTimeMs: 1752962991297
[2025-07-19T22:09:51.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T22:09:51.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T22:09:51.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO AppInfoParser: Kafka startTimeMs: 1752962991297
[2025-07-19T22:09:51.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1, groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor] Assigned to partition(s): feedback-0
[2025-07-19T22:09:51.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3, groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor] Assigned to partition(s): checkins-0
[2025-07-19T22:09:51.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2, groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor] Assigned to partition(s): reservations-0
[2025-07-19T22:09:51.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2, groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor] Seeking to offset 0 for partition reservations-0
[2025-07-19T22:09:51.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3, groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor] Seeking to offset 0 for partition checkins-0
[2025-07-19T22:09:51.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1, groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor] Seeking to offset 0 for partition feedback-0
[2025-07-19T22:09:51.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2, groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T22:09:51.372+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1, groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T22:09:51.372+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3, groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T22:09:51.390+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1, groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor] Seeking to earliest offset of partition feedback-0
[2025-07-19T22:09:51.391+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2, groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor] Seeking to earliest offset of partition reservations-0
[2025-07-19T22:09:51.392+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3, groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor] Seeking to earliest offset of partition checkins-0
[2025-07-19T22:09:51.899+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2, groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T22:09:51.900+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1, groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T22:09:51.901+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3, groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T22:09:51.902+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1, groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor] Seeking to latest offset of partition feedback-0
[2025-07-19T22:09:51.902+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2, groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor] Seeking to latest offset of partition reservations-0
[2025-07-19T22:09:51.903+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3, groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor] Seeking to latest offset of partition checkins-0
[2025-07-19T22:09:51.903+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1, groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=276, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T22:09:51.903+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2, groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=276, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T22:09:51.903+0000] {subprocess.py:93} INFO - 25/07/19 22:09:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3, groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=276, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T22:09:52.232+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO KafkaDataConsumer: From Kafka topicPartition=feedback-0 groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor read 276 records through 1 polls (polled  out 276 records), taking 585371667 nanos, during time span of 926939375 nanos.
[2025-07-19T22:09:52.233+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO KafkaDataConsumer: From Kafka topicPartition=reservations-0 groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor read 276 records through 1 polls (polled  out 276 records), taking 585403876 nanos, during time span of 926686959 nanos.
[2025-07-19T22:09:52.233+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO KafkaDataConsumer: From Kafka topicPartition=checkins-0 groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor read 276 records through 1 polls (polled  out 276 records), taking 586418126 nanos, during time span of 926887918 nanos.
[2025-07-19T22:09:52.246+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2642 bytes result sent to driver
[2025-07-19T22:09:52.247+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 2642 bytes result sent to driver
[2025-07-19T22:09:52.247+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 2642 bytes result sent to driver
[2025-07-19T22:09:52.256+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 1364 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T22:09:52.256+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-19T22:09:52.256+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 1378 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T22:09:52.256+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-07-19T22:09:52.257+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1398 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T22:09:52.257+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-19T22:09:52.260+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: ShuffleMapStage 4 (start at <unknown>:0) finished in 1.381 s
[2025-07-19T22:09:52.260+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T22:09:52.260+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ShuffleMapStage 2)
[2025-07-19T22:09:52.262+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 5, ResultStage 3)
[2025-07-19T22:09:52.262+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: failed: Set()
[2025-07-19T22:09:52.264+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: Submitting ResultStage 5 (StateStoreRDD[22] at start at <unknown>:0), which has no missing parents
[2025-07-19T22:09:52.311+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 38.8 KiB, free 433.3 MiB)
[2025-07-19T22:09:52.312+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 433.3 MiB)
[2025-07-19T22:09:52.313+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 8b44f3d35cfa:37751 (size: 19.3 KiB, free: 434.1 MiB)
[2025-07-19T22:09:52.313+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-07-19T22:09:52.316+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 5 (StateStoreRDD[22] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T22:09:52.317+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSchedulerImpl: Adding task set 5.0 with 200 tasks resource profile 0
[2025-07-19T22:09:52.322+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: ShuffleMapStage 2 (start at <unknown>:0) finished in 1.476 s
[2025-07-19T22:09:52.323+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T22:09:52.323+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ResultStage 5)
[2025-07-19T22:09:52.324+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 3)
[2025-07-19T22:09:52.327+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: failed: Set()
[2025-07-19T22:09:52.336+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (8b44f3d35cfa, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:52.345+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 4) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:52.348+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: Submitting ResultStage 3 (StateStoreRDD[21] at start at <unknown>:0), which has no missing parents
[2025-07-19T22:09:52.354+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 5) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:52.354+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 6) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:52.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 7) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:52.358+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 8) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:52.359+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 9) (8b44f3d35cfa, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:52.361+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 10) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:52.363+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Running task 1.0 in stage 5.0 (TID 4)
[2025-07-19T22:09:52.365+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
[2025-07-19T22:09:52.366+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Running task 4.0 in stage 5.0 (TID 7)
[2025-07-19T22:09:52.366+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Running task 3.0 in stage 5.0 (TID 6)
[2025-07-19T22:09:52.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Running task 2.0 in stage 5.0 (TID 5)
[2025-07-19T22:09:52.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Running task 8.0 in stage 5.0 (TID 9)
[2025-07-19T22:09:52.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Running task 7.0 in stage 5.0 (TID 8)
[2025-07-19T22:09:52.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO Executor: Running task 9.0 in stage 5.0 (TID 10)
[2025-07-19T22:09:52.404+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:52.407+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:52.409+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:52.409+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:52.411+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:52.412+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T22:09:52.414+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2025-07-19T22:09:52.416+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:52.418+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T22:09:52.419+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:52.420+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T22:09:52.423+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T22:09:52.424+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T22:09:52.425+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
[2025-07-19T22:09:52.426+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:52.428+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 23 ms
[2025-07-19T22:09:52.429+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 39.6 KiB, free 433.3 MiB)
[2025-07-19T22:09:52.429+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 433.2 MiB)
[2025-07-19T22:09:52.430+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: State Store maintenance task started
[2025-07-19T22:09:52.431+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 8b44f3d35cfa:37751 (size: 19.6 KiB, free: 434.1 MiB)
[2025-07-19T22:09:52.433+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-07-19T22:09:52.434+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 3 (StateStoreRDD[21] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T22:09:52.437+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 200 tasks resource profile 0
[2025-07-19T22:09:52.437+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: ShuffleMapStage 0 (start at <unknown>:0) finished in 1.663 s
[2025-07-19T22:09:52.438+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T22:09:52.438+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: running: Set(ResultStage 5, ResultStage 3)
[2025-07-19T22:09:52.438+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
[2025-07-19T22:09:52.438+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: failed: Set()
[2025-07-19T22:09:52.438+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: Submitting ResultStage 1 (StateStoreRDD[23] at start at <unknown>:0), which has no missing parents
[2025-07-19T22:09:52.446+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78ebf1ad
[2025-07-19T22:09:52.446+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:52.457+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3] for update
[2025-07-19T22:09:52.516+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/.schema.b9b3b290-b2d9-4231-9d5f-9223d4001b4b.TID3.tmp
[2025-07-19T22:09:52.537+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodeGenerator: Code generated in 37.656625 ms
[2025-07-19T22:09:52.556+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 40.1 KiB, free 433.2 MiB)
[2025-07-19T22:09:52.557+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 433.2 MiB)
[2025-07-19T22:09:52.558+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 8b44f3d35cfa:37751 (size: 19.9 KiB, free: 434.1 MiB)
[2025-07-19T22:09:52.559+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1611
[2025-07-19T22:09:52.560+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 1 (StateStoreRDD[23] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T22:09:52.562+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 200 tasks resource profile 0
[2025-07-19T22:09:52.573+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodeGenerator: Code generated in 8.16575 ms
[2025-07-19T22:09:52.635+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/.schema.b9b3b290-b2d9-4231-9d5f-9223d4001b4b.TID3.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/schema
[2025-07-19T22:09:52.638+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3176f287
[2025-07-19T22:09:52.640+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:52.641+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0] for update
[2025-07-19T22:09:52.657+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e077daf
[2025-07-19T22:09:52.659+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:52.660+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4] for update
[2025-07-19T22:09:52.674+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71895b4d
[2025-07-19T22:09:52.683+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:52.683+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7] for update
[2025-07-19T22:09:52.686+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7968acd5
[2025-07-19T22:09:52.688+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:52.688+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8] for update
[2025-07-19T22:09:52.703+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62bd039
[2025-07-19T22:09:52.723+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:52.724+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2] for update
[2025-07-19T22:09:52.729+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61412588
[2025-07-19T22:09:52.730+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:52.736+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9] for update
[2025-07-19T22:09:52.737+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:52.738+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:52.738+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:52.739+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:52.739+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:52.739+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:52.740+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:52.740+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b559971
[2025-07-19T22:09:52.742+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:52.742+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1] for update
[2025-07-19T22:09:52.743+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:52.969+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.1.delta.016a44ab-64b5-4d23-abba-e48c425740c5.TID9.tmp
[2025-07-19T22:09:52.971+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.1.delta.5bad0d63-b06c-42f2-8256-e80069b47808.TID5.tmp
[2025-07-19T22:09:52.978+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.1.delta.e3ab7a9c-b671-4752-9e81-a2a4fa269f27.TID10.tmp
[2025-07-19T22:09:52.980+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.1.delta.38c1d1b3-2d43-45b5-9894-a38d195efa59.TID7.tmp
[2025-07-19T22:09:52.983+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.1.delta.087ed086-8ece-419a-b07b-75f90b35631e.TID4.tmp
[2025-07-19T22:09:52.984+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.1.delta.4462c016-052a-4850-8be1-e1cc73e3c13d.TID3.tmp
[2025-07-19T22:09:52.985+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.1.delta.59300234-e2f5-4b3b-b4bf-8a069281d27b.TID8.tmp
[2025-07-19T22:09:52.987+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CodeGenerator: Code generated in 7.144584 ms
[2025-07-19T22:09:52.988+0000] {subprocess.py:93} INFO - 25/07/19 22:09:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.1.delta.5ae2ff39-0794-4d56-9d72-796dc6a6c1bd.TID6.tmp
[2025-07-19T22:09:53.132+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.1.delta.4462c016-052a-4850-8be1-e1cc73e3c13d.TID3.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/1.delta
[2025-07-19T22:09:53.133+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/1.delta
[2025-07-19T22:09:53.137+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.1.delta.5ae2ff39-0794-4d56-9d72-796dc6a6c1bd.TID6.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/1.delta
[2025-07-19T22:09:53.138+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/1.delta
[2025-07-19T22:09:53.139+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.1.delta.5bad0d63-b06c-42f2-8256-e80069b47808.TID5.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/1.delta
[2025-07-19T22:09:53.141+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/1.delta
[2025-07-19T22:09:53.142+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.1.delta.087ed086-8ece-419a-b07b-75f90b35631e.TID4.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/1.delta
[2025-07-19T22:09:53.143+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/1.delta
[2025-07-19T22:09:53.150+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.1.delta.38c1d1b3-2d43-45b5-9894-a38d195efa59.TID7.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/1.delta
[2025-07-19T22:09:53.152+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.1.delta.016a44ab-64b5-4d23-abba-e48c425740c5.TID9.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/1.delta
[2025-07-19T22:09:53.152+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/1.delta
[2025-07-19T22:09:53.153+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/1.delta
[2025-07-19T22:09:53.159+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.1.delta.e3ab7a9c-b671-4752-9e81-a2a4fa269f27.TID10.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/1.delta
[2025-07-19T22:09:53.160+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/1.delta
[2025-07-19T22:09:53.176+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 3, attempt 0, stage 5.0)
[2025-07-19T22:09:53.177+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 6, attempt 0, stage 5.0)
[2025-07-19T22:09:53.178+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.1.delta.59300234-e2f5-4b3b-b4bf-8a069281d27b.TID8.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/1.delta
[2025-07-19T22:09:53.180+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/1.delta
[2025-07-19T22:09:53.182+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 4, attempt 0, stage 5.0)
[2025-07-19T22:09:53.183+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 9, attempt 0, stage 5.0)
[2025-07-19T22:09:53.184+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 8, attempt 0, stage 5.0)
[2025-07-19T22:09:53.186+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 7, attempt 0, stage 5.0)
[2025-07-19T22:09:53.189+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 5, attempt 0, stage 5.0)
[2025-07-19T22:09:53.189+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 10, attempt 0, stage 5.0)
[2025-07-19T22:09:53.286+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 8b44f3d35cfa:37751 in memory (size: 14.7 KiB, free: 434.1 MiB)
[2025-07-19T22:09:53.293+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 8b44f3d35cfa:37751 in memory (size: 14.0 KiB, free: 434.1 MiB)
[2025-07-19T22:09:53.297+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 8b44f3d35cfa:37751 in memory (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T22:09:53.628+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 8 (task 9, attempt 0, stage 5.0)
[2025-07-19T22:09:53.629+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 4 (task 7, attempt 0, stage 5.0)
[2025-07-19T22:09:53.631+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 0 (task 3, attempt 0, stage 5.0)
[2025-07-19T22:09:53.633+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 3 (task 6, attempt 0, stage 5.0)
[2025-07-19T22:09:53.633+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 7 (task 8, attempt 0, stage 5.0)
[2025-07-19T22:09:53.634+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 9 (task 10, attempt 0, stage 5.0)
[2025-07-19T22:09:53.634+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 1 (task 4, attempt 0, stage 5.0)
[2025-07-19T22:09:53.635+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 2 (task 5, attempt 0, stage 5.0)
[2025-07-19T22:09:53.636+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 3.0 in stage 5.0 (TID 6). 9203 bytes result sent to driver
[2025-07-19T22:09:53.637+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 7.0 in stage 5.0 (TID 8). 9147 bytes result sent to driver
[2025-07-19T22:09:53.641+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 2.0 in stage 5.0 (TID 5). 9197 bytes result sent to driver
[2025-07-19T22:09:53.643+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 1.0 in stage 5.0 (TID 4). 9212 bytes result sent to driver
[2025-07-19T22:09:53.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 4.0 in stage 5.0 (TID 7). 9203 bytes result sent to driver
[2025-07-19T22:09:53.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 9212 bytes result sent to driver
[2025-07-19T22:09:53.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 9.0 in stage 5.0 (TID 10). 9215 bytes result sent to driver
[2025-07-19T22:09:53.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 8.0 in stage 5.0 (TID 9). 9207 bytes result sent to driver
[2025-07-19T22:09:53.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 11) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.645+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 12) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.646+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 10.0 in stage 5.0 (TID 11)
[2025-07-19T22:09:53.646+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 13) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.646+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 11.0 in stage 5.0 (TID 12)
[2025-07-19T22:09:53.647+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 14) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.647+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 15) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.647+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 16) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.647+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 13.0 in stage 5.0 (TID 14)
[2025-07-19T22:09:53.647+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 15.0 in stage 5.0 (TID 16)
[2025-07-19T22:09:53.647+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 14.0 in stage 5.0 (TID 15)
[2025-07-19T22:09:53.648+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 12.0 in stage 5.0 (TID 13)
[2025-07-19T22:09:53.657+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 17) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.660+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 18) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.661+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 5) in 1332 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T22:09:53.662+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 7) in 1333 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T22:09:53.663+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 18.0 in stage 5.0 (TID 18)
[2025-07-19T22:09:53.663+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 16.0 in stage 5.0 (TID 17)
[2025-07-19T22:09:53.664+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 1340 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T22:09:53.665+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 6) in 1339 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T22:09:53.668+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 8) in 1340 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T22:09:53.672+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 10) in 1339 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T22:09:53.674+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 4) in 1340 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T22:09:53.675+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.675+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:09:53.676+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 9) in 1340 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T22:09:53.676+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.676+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:09:53.677+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.678+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:53.679+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.680+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.683+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:53.684+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:53.690+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.692+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:53.693+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.694+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:53.695+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@748abd5c
[2025-07-19T22:09:53.696+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:53.697+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.698+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11] for update
[2025-07-19T22:09:53.701+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:53.704+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:53.706+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35e920a
[2025-07-19T22:09:53.706+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:53.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15] for update
[2025-07-19T22:09:53.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:53.708+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@600ac739
[2025-07-19T22:09:53.709+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:53.709+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10] for update
[2025-07-19T22:09:53.709+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.1.delta.3044647b-bfc8-443f-b0b1-d970a6431dbb.TID12.tmp
[2025-07-19T22:09:53.716+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.1.delta.41837a14-4207-4bf7-bebb-362b97201b30.TID16.tmp
[2025-07-19T22:09:53.724+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:53.726+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3143aa5d
[2025-07-19T22:09:53.726+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:53.731+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12] for update
[2025-07-19T22:09:53.742+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:53.748+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@155ea365
[2025-07-19T22:09:53.751+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:53.752+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18] for update
[2025-07-19T22:09:53.760+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.1.delta.80f76060-3ccf-40d5-b526-f7390742dc21.TID13.tmp
[2025-07-19T22:09:53.761+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.1.delta.f4682221-6efa-4219-8114-74d3d549f95d.TID11.tmp
[2025-07-19T22:09:53.762+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:53.777+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@423980d9
[2025-07-19T22:09:53.779+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:53.782+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13] for update
[2025-07-19T22:09:53.786+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:53.795+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.1.delta.41837a14-4207-4bf7-bebb-362b97201b30.TID16.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/1.delta
[2025-07-19T22:09:53.799+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/1.delta
[2025-07-19T22:09:53.803+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 16, attempt 0, stage 5.0)
[2025-07-19T22:09:53.804+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5465ea21
[2025-07-19T22:09:53.804+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:53.804+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14] for update
[2025-07-19T22:09:53.810+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.1.delta.0a743cef-e458-4463-aa7b-6edbe8bf944f.TID18.tmp
[2025-07-19T22:09:53.811+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:53.822+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66652a33
[2025-07-19T22:09:53.824+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:53.828+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16] for update
[2025-07-19T22:09:53.836+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.1.delta.2f34fd92-fd96-4456-b560-93f3e9637380.TID14.tmp
[2025-07-19T22:09:53.840+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.1.delta.868dd750-ff00-4c29-9a88-d90996f843bb.TID15.tmp
[2025-07-19T22:09:53.841+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:53.842+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.1.delta.3044647b-bfc8-443f-b0b1-d970a6431dbb.TID12.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/1.delta
[2025-07-19T22:09:53.842+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/1.delta
[2025-07-19T22:09:53.844+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 12, attempt 0, stage 5.0)
[2025-07-19T22:09:53.874+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.1.delta.c213f696-3229-49d6-a615-37842442a380.TID17.tmp
[2025-07-19T22:09:53.877+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 15 (task 16, attempt 0, stage 5.0)
[2025-07-19T22:09:53.880+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 15.0 in stage 5.0 (TID 16). 9156 bytes result sent to driver
[2025-07-19T22:09:53.885+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.1.delta.80f76060-3ccf-40d5-b526-f7390742dc21.TID13.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/1.delta
[2025-07-19T22:09:53.889+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/1.delta
[2025-07-19T22:09:53.890+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 19) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.890+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 13, attempt 0, stage 5.0)
[2025-07-19T22:09:53.900+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 20.0 in stage 5.0 (TID 19)
[2025-07-19T22:09:53.913+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 16) in 264 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T22:09:53.919+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.1.delta.f4682221-6efa-4219-8114-74d3d549f95d.TID11.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/1.delta
[2025-07-19T22:09:53.920+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/1.delta
[2025-07-19T22:09:53.923+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 11, attempt 0, stage 5.0)
[2025-07-19T22:09:53.926+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.927+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:09:53.935+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 11 (task 12, attempt 0, stage 5.0)
[2025-07-19T22:09:53.943+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 11.0 in stage 5.0 (TID 12). 9148 bytes result sent to driver
[2025-07-19T22:09:53.943+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 20) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.946+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 12) in 306 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T22:09:53.948+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2403a9e
[2025-07-19T22:09:53.948+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:53.949+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20] for update
[2025-07-19T22:09:53.956+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.1.delta.0a743cef-e458-4463-aa7b-6edbe8bf944f.TID18.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/1.delta
[2025-07-19T22:09:53.957+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/1.delta
[2025-07-19T22:09:53.958+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 22.0 in stage 5.0 (TID 20)
[2025-07-19T22:09:53.958+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 18, attempt 0, stage 5.0)
[2025-07-19T22:09:53.960+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.1.delta.2f34fd92-fd96-4456-b560-93f3e9637380.TID14.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/1.delta
[2025-07-19T22:09:53.960+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/1.delta
[2025-07-19T22:09:53.962+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 14, attempt 0, stage 5.0)
[2025-07-19T22:09:53.966+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:53.968+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.1.delta.868dd750-ff00-4c29-9a88-d90996f843bb.TID15.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/1.delta
[2025-07-19T22:09:53.970+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/1.delta
[2025-07-19T22:09:53.970+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 15, attempt 0, stage 5.0)
[2025-07-19T22:09:53.975+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 12 (task 13, attempt 0, stage 5.0)
[2025-07-19T22:09:53.976+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 10 (task 11, attempt 0, stage 5.0)
[2025-07-19T22:09:53.977+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 12.0 in stage 5.0 (TID 13). 9173 bytes result sent to driver
[2025-07-19T22:09:53.980+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 21) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.981+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 10.0 in stage 5.0 (TID 11). 9156 bytes result sent to driver
[2025-07-19T22:09:53.982+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 23.0 in stage 5.0 (TID 21)
[2025-07-19T22:09:53.986+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 13) in 346 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T22:09:53.993+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.1.delta.c213f696-3229-49d6-a615-37842442a380.TID17.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/1.delta
[2025-07-19T22:09:53.994+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/1.delta
[2025-07-19T22:09:53.994+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 17, attempt 0, stage 5.0)
[2025-07-19T22:09:53.996+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO DataWritingSparkTask: Committed partition 13 (task 14, attempt 0, stage 5.0)
[2025-07-19T22:09:53.996+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 22) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:53.996+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 11) in 360 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T22:09:53.996+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Running task 26.0 in stage 5.0 (TID 22)
[2025-07-19T22:09:53.997+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:53.997+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:53.997+0000] {subprocess.py:93} INFO - 25/07/19 22:09:53 INFO Executor: Finished task 13.0 in stage 5.0 (TID 14). 9171 bytes result sent to driver
[2025-07-19T22:09:54.005+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.006+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 23) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.007+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 27.0 in stage 5.0 (TID 23)
[2025-07-19T22:09:54.007+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 14) in 368 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T22:09:54.008+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 14 (task 15, attempt 0, stage 5.0)
[2025-07-19T22:09:54.009+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
[2025-07-19T22:09:54.017+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 18 (task 18, attempt 0, stage 5.0)
[2025-07-19T22:09:54.018+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.019+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.020+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 18.0 in stage 5.0 (TID 18). 9155 bytes result sent to driver
[2025-07-19T22:09:54.020+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 14.0 in stage 5.0 (TID 15). 9149 bytes result sent to driver
[2025-07-19T22:09:54.020+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 24) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.025+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 28.0 in stage 5.0 (TID 24)
[2025-07-19T22:09:54.025+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.1.delta.41a62eb5-583d-4c94-add0-7e9ffa10f892.TID19.tmp
[2025-07-19T22:09:54.025+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 18) in 366 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T22:09:54.026+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.026+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:54.028+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 25) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.030+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b9f8aa0
[2025-07-19T22:09:54.033+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 30.0 in stage 5.0 (TID 25)
[2025-07-19T22:09:54.036+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.037+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23] for update
[2025-07-19T22:09:54.038+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 15) in 393 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T22:09:54.040+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.041+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.048+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 16 (task 17, attempt 0, stage 5.0)
[2025-07-19T22:09:54.049+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58859d73
[2025-07-19T22:09:54.052+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.053+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 16.0 in stage 5.0 (TID 17). 9183 bytes result sent to driver
[2025-07-19T22:09:54.053+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.054+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 17) in 405 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T22:09:54.056+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27] for update
[2025-07-19T22:09:54.057+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 26) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.058+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.060+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.062+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 31.0 in stage 5.0 (TID 26)
[2025-07-19T22:09:54.062+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b38b740
[2025-07-19T22:09:54.063+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.064+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.067+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.070+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.072+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26] for update
[2025-07-19T22:09:54.076+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.1.delta.427743bc-eb73-483d-b1f8-10d2139d0967.TID21.tmp
[2025-07-19T22:09:54.077+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@748c9fe7
[2025-07-19T22:09:54.078+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.078+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.078+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22] for update
[2025-07-19T22:09:54.090+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.096+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.1.delta.d326c459-38e5-440d-873d-3b10aca20fa7.TID23.tmp
[2025-07-19T22:09:54.101+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@268a016a
[2025-07-19T22:09:54.105+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.108+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31] for update
[2025-07-19T22:09:54.109+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.123+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@250fdec2
[2025-07-19T22:09:54.127+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.130+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.1.delta.17d5508a-d62b-4332-a5d0-46d80c05c4ec.TID22.tmp
[2025-07-19T22:09:54.132+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30] for update
[2025-07-19T22:09:54.135+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.1.delta.21e635d1-30f6-4d86-bf43-45a1facbafe7.TID20.tmp
[2025-07-19T22:09:54.137+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.140+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.1.delta.ab2730d9-d2c3-4872-a187-3f4c1d7aef6a.TID26.tmp
[2025-07-19T22:09:54.141+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.1.delta.41a62eb5-583d-4c94-add0-7e9ffa10f892.TID19.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/1.delta
[2025-07-19T22:09:54.142+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/1.delta
[2025-07-19T22:09:54.143+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 19, attempt 0, stage 5.0)
[2025-07-19T22:09:54.159+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60e921d5
[2025-07-19T22:09:54.162+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.1.delta.4f006446-4943-4a18-bda7-96ae85e95250.TID25.tmp
[2025-07-19T22:09:54.165+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.166+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28] for update
[2025-07-19T22:09:54.177+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.192+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.1.delta.d326c459-38e5-440d-873d-3b10aca20fa7.TID23.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/1.delta
[2025-07-19T22:09:54.195+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/1.delta
[2025-07-19T22:09:54.195+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.1.delta.9423dec6-cd30-4ba5-a222-7ec5a6b77644.TID24.tmp
[2025-07-19T22:09:54.196+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 23, attempt 0, stage 5.0)
[2025-07-19T22:09:54.198+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.1.delta.21e635d1-30f6-4d86-bf43-45a1facbafe7.TID20.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/1.delta
[2025-07-19T22:09:54.203+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/1.delta
[2025-07-19T22:09:54.203+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 20, attempt 0, stage 5.0)
[2025-07-19T22:09:54.203+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.1.delta.427743bc-eb73-483d-b1f8-10d2139d0967.TID21.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/1.delta
[2025-07-19T22:09:54.204+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/1.delta
[2025-07-19T22:09:54.206+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 21, attempt 0, stage 5.0)
[2025-07-19T22:09:54.209+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 20 (task 19, attempt 0, stage 5.0)
[2025-07-19T22:09:54.216+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 20.0 in stage 5.0 (TID 19). 9151 bytes result sent to driver
[2025-07-19T22:09:54.227+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 27) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.230+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.1.delta.ab2730d9-d2c3-4872-a187-3f4c1d7aef6a.TID26.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/1.delta
[2025-07-19T22:09:54.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/1.delta
[2025-07-19T22:09:54.236+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 19) in 333 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T22:09:54.237+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 33.0 in stage 5.0 (TID 27)
[2025-07-19T22:09:54.241+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.1.delta.17d5508a-d62b-4332-a5d0-46d80c05c4ec.TID22.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/1.delta
[2025-07-19T22:09:54.242+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/1.delta
[2025-07-19T22:09:54.243+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 26, attempt 0, stage 5.0)
[2025-07-19T22:09:54.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 22, attempt 0, stage 5.0)
[2025-07-19T22:09:54.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e7cd0cd
[2025-07-19T22:09:54.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.245+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33] for update
[2025-07-19T22:09:54.248+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.253+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.1.delta.4f006446-4943-4a18-bda7-96ae85e95250.TID25.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/1.delta
[2025-07-19T22:09:54.253+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/1.delta
[2025-07-19T22:09:54.258+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 25, attempt 0, stage 5.0)
[2025-07-19T22:09:54.259+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 22 (task 20, attempt 0, stage 5.0)
[2025-07-19T22:09:54.263+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 23 (task 21, attempt 0, stage 5.0)
[2025-07-19T22:09:54.269+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 22.0 in stage 5.0 (TID 20). 9105 bytes result sent to driver
[2025-07-19T22:09:54.273+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 27 (task 23, attempt 0, stage 5.0)
[2025-07-19T22:09:54.275+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 28) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.276+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.1.delta.ca5c4d2c-3ec7-47db-9802-bdec3264ff14.TID27.tmp
[2025-07-19T22:09:54.276+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 20) in 326 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T22:09:54.277+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 23.0 in stage 5.0 (TID 21). 9170 bytes result sent to driver
[2025-07-19T22:09:54.277+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 35.0 in stage 5.0 (TID 28)
[2025-07-19T22:09:54.281+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 29) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 37.0 in stage 5.0 (TID 29)
[2025-07-19T22:09:54.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 27.0 in stage 5.0 (TID 23). 9155 bytes result sent to driver
[2025-07-19T22:09:54.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 21) in 296 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T22:09:54.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.283+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 30) (8b44f3d35cfa, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.283+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.1.delta.9423dec6-cd30-4ba5-a222-7ec5a6b77644.TID24.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/1.delta
[2025-07-19T22:09:54.283+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/1.delta
[2025-07-19T22:09:54.283+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 24, attempt 0, stage 5.0)
[2025-07-19T22:09:54.284+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 38.0 in stage 5.0 (TID 30)
[2025-07-19T22:09:54.284+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 26 (task 22, attempt 0, stage 5.0)
[2025-07-19T22:09:54.302+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.304+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:09:54.307+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 26.0 in stage 5.0 (TID 22). 9202 bytes result sent to driver
[2025-07-19T22:09:54.310+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 31) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.311+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3273d882
[2025-07-19T22:09:54.313+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 22) in 315 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T22:09:54.315+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.316+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35] for update
[2025-07-19T22:09:54.320+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 23) in 314 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T22:09:54.327+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.329+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T22:09:54.329+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 39.0 in stage 5.0 (TID 31)
[2025-07-19T22:09:54.330+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 31 (task 26, attempt 0, stage 5.0)
[2025-07-19T22:09:54.336+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.337+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f129d44
[2025-07-19T22:09:54.337+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 31.0 in stage 5.0 (TID 26). 9167 bytes result sent to driver
[2025-07-19T22:09:54.337+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38] for update
[2025-07-19T22:09:54.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 32) (8b44f3d35cfa, executor driver, partition 40, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 40.0 in stage 5.0 (TID 32)
[2025-07-19T22:09:54.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 26) in 288 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T22:09:54.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.355+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.356+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:09:54.356+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a73892d
[2025-07-19T22:09:54.356+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 30 (task 25, attempt 0, stage 5.0)
[2025-07-19T22:09:54.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37] for update
[2025-07-19T22:09:54.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 30.0 in stage 5.0 (TID 25). 9162 bytes result sent to driver
[2025-07-19T22:09:54.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.1.delta.f751c298-0694-4779-85d2-891c3817b844.TID28.tmp
[2025-07-19T22:09:54.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 33) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.359+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 41.0 in stage 5.0 (TID 33)
[2025-07-19T22:09:54.360+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.1.delta.b05cbbea-96e6-47ad-96f8-423f406aae4c.TID30.tmp
[2025-07-19T22:09:54.364+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 25) in 332 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T22:09:54.366+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d373e97
[2025-07-19T22:09:54.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40] for update
[2025-07-19T22:09:54.373+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.1.delta.ca5c4d2c-3ec7-47db-9802-bdec3264ff14.TID27.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/1.delta
[2025-07-19T22:09:54.375+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.376+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/1.delta
[2025-07-19T22:09:54.377+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 27, attempt 0, stage 5.0)
[2025-07-19T22:09:54.378+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.378+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.379+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.388+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1629ba12
[2025-07-19T22:09:54.392+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.1.delta.95fe87cb-ef04-47cc-8785-565e73f843c5.TID32.tmp
[2025-07-19T22:09:54.394+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.1.delta.a1364ef0-e8c9-4888-b2f2-ebed8aced072.TID29.tmp
[2025-07-19T22:09:54.395+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.397+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 28 (task 24, attempt 0, stage 5.0)
[2025-07-19T22:09:54.397+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39] for update
[2025-07-19T22:09:54.413+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 28.0 in stage 5.0 (TID 24). 9167 bytes result sent to driver
[2025-07-19T22:09:54.413+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.414+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 33 (task 27, attempt 0, stage 5.0)
[2025-07-19T22:09:54.428+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 34) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.432+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 33.0 in stage 5.0 (TID 27). 9199 bytes result sent to driver
[2025-07-19T22:09:54.440+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d7422ea
[2025-07-19T22:09:54.441+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.442+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 35) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.444+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41] for update
[2025-07-19T22:09:54.448+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 42.0 in stage 5.0 (TID 34)
[2025-07-19T22:09:54.450+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 43.0 in stage 5.0 (TID 35)
[2025-07-19T22:09:54.451+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.454+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:54.455+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 27) in 216 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T22:09:54.455+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 24) in 416 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T22:09:54.456+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e88f603
[2025-07-19T22:09:54.457+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.457+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42] for update
[2025-07-19T22:09:54.465+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.467+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.470+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.474+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.477+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.1.delta.f751c298-0694-4779-85d2-891c3817b844.TID28.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/1.delta
[2025-07-19T22:09:54.477+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/1.delta
[2025-07-19T22:09:54.478+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 28, attempt 0, stage 5.0)
[2025-07-19T22:09:54.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55209eea
[2025-07-19T22:09:54.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.1.delta.095652fc-1ca3-4017-915f-58cecd3e4862.TID31.tmp
[2025-07-19T22:09:54.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43] for update
[2025-07-19T22:09:54.480+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.1.delta.77cdb61f-4bae-4070-bd0a-ba5b5fd2ca86.TID34.tmp
[2025-07-19T22:09:54.480+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.1.delta.a5dce8b5-3365-49b9-a78a-25e94eedb0a7.TID33.tmp
[2025-07-19T22:09:54.480+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.493+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.1.delta.b05cbbea-96e6-47ad-96f8-423f406aae4c.TID30.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/1.delta
[2025-07-19T22:09:54.494+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/1.delta
[2025-07-19T22:09:54.504+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 30, attempt 0, stage 5.0)
[2025-07-19T22:09:54.509+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.1.delta.a1364ef0-e8c9-4888-b2f2-ebed8aced072.TID29.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/1.delta
[2025-07-19T22:09:54.512+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/1.delta
[2025-07-19T22:09:54.519+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 29, attempt 0, stage 5.0)
[2025-07-19T22:09:54.528+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.1.delta.6faae0a1-c9cf-4b78-abef-7e41a039180a.TID35.tmp
[2025-07-19T22:09:54.534+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.1.delta.95fe87cb-ef04-47cc-8785-565e73f843c5.TID32.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/1.delta
[2025-07-19T22:09:54.538+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/1.delta
[2025-07-19T22:09:54.540+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 35 (task 28, attempt 0, stage 5.0)
[2025-07-19T22:09:54.545+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 32, attempt 0, stage 5.0)
[2025-07-19T22:09:54.548+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 35.0 in stage 5.0 (TID 28). 9147 bytes result sent to driver
[2025-07-19T22:09:54.549+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 36) (8b44f3d35cfa, executor driver, partition 44, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.553+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 28) in 278 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T22:09:54.554+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 44.0 in stage 5.0 (TID 36)
[2025-07-19T22:09:54.554+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.554+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:54.565+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 38 (task 30, attempt 0, stage 5.0)
[2025-07-19T22:09:54.569+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a541070
[2025-07-19T22:09:54.573+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 37 (task 29, attempt 0, stage 5.0)
[2025-07-19T22:09:54.574+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.575+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44] for update
[2025-07-19T22:09:54.576+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 37.0 in stage 5.0 (TID 29). 9175 bytes result sent to driver
[2025-07-19T22:09:54.577+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 29) in 293 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T22:09:54.578+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 38.0 in stage 5.0 (TID 30). 9161 bytes result sent to driver
[2025-07-19T22:09:54.579+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 37) (8b44f3d35cfa, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.582+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 45.0 in stage 5.0 (TID 37)
[2025-07-19T22:09:54.584+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 38) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.586+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 30) in 290 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T22:09:54.587+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 46.0 in stage 5.0 (TID 38)
[2025-07-19T22:09:54.588+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.1.delta.77cdb61f-4bae-4070-bd0a-ba5b5fd2ca86.TID34.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/1.delta
[2025-07-19T22:09:54.591+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/1.delta
[2025-07-19T22:09:54.594+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.595+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:54.596+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 34, attempt 0, stage 5.0)
[2025-07-19T22:09:54.603+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 40 (task 32, attempt 0, stage 5.0)
[2025-07-19T22:09:54.604+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.606+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.609+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.1.delta.095652fc-1ca3-4017-915f-58cecd3e4862.TID31.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/1.delta
[2025-07-19T22:09:54.609+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/1.delta
[2025-07-19T22:09:54.612+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 40.0 in stage 5.0 (TID 32). 9151 bytes result sent to driver
[2025-07-19T22:09:54.614+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 32) in 259 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T22:09:54.615+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15946c9
[2025-07-19T22:09:54.620+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.621+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 39) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.621+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 47.0 in stage 5.0 (TID 39)
[2025-07-19T22:09:54.622+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.1.delta.a5dce8b5-3365-49b9-a78a-25e94eedb0a7.TID33.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/1.delta
[2025-07-19T22:09:54.623+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/1.delta
[2025-07-19T22:09:54.624+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.625+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 31, attempt 0, stage 5.0)
[2025-07-19T22:09:54.626+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45] for update
[2025-07-19T22:09:54.627+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 33, attempt 0, stage 5.0)
[2025-07-19T22:09:54.627+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.628+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:09:54.629+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.630+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.1.delta.5f859a80-50b7-49ee-a90c-0c8e47306039.TID36.tmp
[2025-07-19T22:09:54.633+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c34646b
[2025-07-19T22:09:54.634+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.634+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46] for update
[2025-07-19T22:09:54.639+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.1.delta.43bfe23f-2c18-4d69-93c3-f4b1c29b9a25.TID37.tmp
[2025-07-19T22:09:54.640+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.1.delta.6faae0a1-c9cf-4b78-abef-7e41a039180a.TID35.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/1.delta
[2025-07-19T22:09:54.641+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/1.delta
[2025-07-19T22:09:54.643+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 35, attempt 0, stage 5.0)
[2025-07-19T22:09:54.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.658+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@643a0e69
[2025-07-19T22:09:54.659+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.661+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47] for update
[2025-07-19T22:09:54.664+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 39 (task 31, attempt 0, stage 5.0)
[2025-07-19T22:09:54.676+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 39.0 in stage 5.0 (TID 31). 9160 bytes result sent to driver
[2025-07-19T22:09:54.677+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 40) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.677+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.680+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 48.0 in stage 5.0 (TID 40)
[2025-07-19T22:09:54.685+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 31) in 364 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T22:09:54.685+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.1.delta.40884f59-eba3-4509-890f-bafbb126f0ac.TID38.tmp
[2025-07-19T22:09:54.686+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 41 (task 33, attempt 0, stage 5.0)
[2025-07-19T22:09:54.688+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 42 (task 34, attempt 0, stage 5.0)
[2025-07-19T22:09:54.695+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 42.0 in stage 5.0 (TID 34). 9159 bytes result sent to driver
[2025-07-19T22:09:54.696+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 41.0 in stage 5.0 (TID 33). 9172 bytes result sent to driver
[2025-07-19T22:09:54.696+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.701+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:09:54.702+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.1.delta.c53d0846-7d74-490e-b5de-3c5d552748b0.TID39.tmp
[2025-07-19T22:09:54.702+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 43 (task 35, attempt 0, stage 5.0)
[2025-07-19T22:09:54.702+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 50.0 in stage 5.0 (TID 41) (8b44f3d35cfa, executor driver, partition 50, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.709+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 34) in 298 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T22:09:54.713+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 43.0 in stage 5.0 (TID 35). 9179 bytes result sent to driver
[2025-07-19T22:09:54.714+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 50.0 in stage 5.0 (TID 41)
[2025-07-19T22:09:54.721+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.1.delta.5f859a80-50b7-49ee-a90c-0c8e47306039.TID36.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/1.delta
[2025-07-19T22:09:54.722+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/1.delta
[2025-07-19T22:09:54.723+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 51.0 in stage 5.0 (TID 42) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.723+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f79c2f3
[2025-07-19T22:09:54.723+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 36, attempt 0, stage 5.0)
[2025-07-19T22:09:54.724+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.725+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48] for update
[2025-07-19T22:09:54.735+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 52.0 in stage 5.0 (TID 43) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.740+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 33) in 373 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T22:09:54.742+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.743+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 35) in 308 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T22:09:54.743+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 52.0 in stage 5.0 (TID 43)
[2025-07-19T22:09:54.744+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 51.0 in stage 5.0 (TID 42)
[2025-07-19T22:09:54.745+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.746+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.750+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.753+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:54.755+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.755+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:09:54.756+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@906567f
[2025-07-19T22:09:54.757+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.757+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51] for update
[2025-07-19T22:09:54.758+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.758+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.1.delta.43bfe23f-2c18-4d69-93c3-f4b1c29b9a25.TID37.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/1.delta
[2025-07-19T22:09:54.760+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/1.delta
[2025-07-19T22:09:54.768+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 37, attempt 0, stage 5.0)
[2025-07-19T22:09:54.772+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.1.delta.40884f59-eba3-4509-890f-bafbb126f0ac.TID38.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/1.delta
[2025-07-19T22:09:54.773+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.1.delta.723c100f-8f4f-4792-a419-0ac8204a88bf.TID40.tmp
[2025-07-19T22:09:54.776+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/1.delta
[2025-07-19T22:09:54.776+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a8f6b30
[2025-07-19T22:09:54.776+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 38, attempt 0, stage 5.0)
[2025-07-19T22:09:54.776+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.777+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50] for update
[2025-07-19T22:09:54.777+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.780+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@701211ef
[2025-07-19T22:09:54.787+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.790+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52] for update
[2025-07-19T22:09:54.791+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 44 (task 36, attempt 0, stage 5.0)
[2025-07-19T22:09:54.792+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 44.0 in stage 5.0 (TID 36). 9147 bytes result sent to driver
[2025-07-19T22:09:54.793+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.1.delta.4f6daaf4-fbd9-4fa0-81c3-c6d117391620.TID42.tmp
[2025-07-19T22:09:54.793+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 54.0 in stage 5.0 (TID 44) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.793+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.794+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 54.0 in stage 5.0 (TID 44)
[2025-07-19T22:09:54.807+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 36) in 261 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T22:09:54.808+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.1.delta.c53d0846-7d74-490e-b5de-3c5d552748b0.TID39.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/1.delta
[2025-07-19T22:09:54.808+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/1.delta
[2025-07-19T22:09:54.810+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 39, attempt 0, stage 5.0)
[2025-07-19T22:09:54.812+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.816+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:54.817+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.1.delta.ad23027e-3753-4ce6-aac9-edd97cf0b1d3.TID41.tmp
[2025-07-19T22:09:54.834+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.1.delta.d3e1ac34-cc5e-4e56-aafa-6bc8aa8afa3b.TID43.tmp
[2025-07-19T22:09:54.839+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d3b7b37
[2025-07-19T22:09:54.843+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.845+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54] for update
[2025-07-19T22:09:54.847+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 46 (task 38, attempt 0, stage 5.0)
[2025-07-19T22:09:54.849+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 46.0 in stage 5.0 (TID 38). 9172 bytes result sent to driver
[2025-07-19T22:09:54.852+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 55.0 in stage 5.0 (TID 45) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.853+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.859+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 38) in 275 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T22:09:54.864+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 55.0 in stage 5.0 (TID 45)
[2025-07-19T22:09:54.868+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 45 (task 37, attempt 0, stage 5.0)
[2025-07-19T22:09:54.869+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.870+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 45.0 in stage 5.0 (TID 37). 9149 bytes result sent to driver
[2025-07-19T22:09:54.871+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.873+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 56.0 in stage 5.0 (TID 46) (8b44f3d35cfa, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.873+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 56.0 in stage 5.0 (TID 46)
[2025-07-19T22:09:54.873+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 37) in 291 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T22:09:54.874+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fb965bf
[2025-07-19T22:09:54.875+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.877+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55] for update
[2025-07-19T22:09:54.877+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 47 (task 39, attempt 0, stage 5.0)
[2025-07-19T22:09:54.884+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.887+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T22:09:54.889+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.895+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 47.0 in stage 5.0 (TID 39). 9201 bytes result sent to driver
[2025-07-19T22:09:54.897+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 57.0 in stage 5.0 (TID 47) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.899+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.1.delta.723c100f-8f4f-4792-a419-0ac8204a88bf.TID40.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/1.delta
[2025-07-19T22:09:54.903+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/1.delta
[2025-07-19T22:09:54.907+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 57.0 in stage 5.0 (TID 47)
[2025-07-19T22:09:54.908+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.1.delta.ba0085d3-f4c4-4a9e-83c1-3054248245f5.TID44.tmp
[2025-07-19T22:09:54.910+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 39) in 299 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T22:09:54.911+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 40, attempt 0, stage 5.0)
[2025-07-19T22:09:54.912+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.912+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.924+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.1.delta.4f6daaf4-fbd9-4fa0-81c3-c6d117391620.TID42.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/1.delta
[2025-07-19T22:09:54.926+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f71713d
[2025-07-19T22:09:54.928+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/1.delta
[2025-07-19T22:09:54.930+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.932+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56] for update
[2025-07-19T22:09:54.936+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 42, attempt 0, stage 5.0)
[2025-07-19T22:09:54.946+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.1.delta.8eed47e8-1c3b-4780-b1d4-aa32d62062ea.TID45.tmp
[2025-07-19T22:09:54.948+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.1.delta.ad23027e-3753-4ce6-aac9-edd97cf0b1d3.TID41.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/1.delta
[2025-07-19T22:09:54.948+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/1.delta
[2025-07-19T22:09:54.948+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3300c5ea
[2025-07-19T22:09:54.949+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 41, attempt 0, stage 5.0)
[2025-07-19T22:09:54.949+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:54.949+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57] for update
[2025-07-19T22:09:54.953+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.957+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.1.delta.d3e1ac34-cc5e-4e56-aafa-6bc8aa8afa3b.TID43.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/1.delta
[2025-07-19T22:09:54.958+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/1.delta
[2025-07-19T22:09:54.959+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 43, attempt 0, stage 5.0)
[2025-07-19T22:09:54.959+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:54.960+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 48 (task 40, attempt 0, stage 5.0)
[2025-07-19T22:09:54.969+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Finished task 48.0 in stage 5.0 (TID 40). 9160 bytes result sent to driver
[2025-07-19T22:09:54.974+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Starting task 58.0 in stage 5.0 (TID 48) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:54.978+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO Executor: Running task 58.0 in stage 5.0 (TID 48)
[2025-07-19T22:09:54.979+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 40) in 303 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T22:09:54.982+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:54.983+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:54.984+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.1.delta.b0eaa013-6015-471b-959f-530d768606a8.TID46.tmp
[2025-07-19T22:09:54.988+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.1.delta.4be668c5-a27c-4b21-901e-580714e1d508.TID47.tmp
[2025-07-19T22:09:55.000+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5faa2624
[2025-07-19T22:09:55.001+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.002+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58] for update
[2025-07-19T22:09:55.003+0000] {subprocess.py:93} INFO - 25/07/19 22:09:54 INFO DataWritingSparkTask: Committed partition 51 (task 42, attempt 0, stage 5.0)
[2025-07-19T22:09:55.003+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 50 (task 41, attempt 0, stage 5.0)
[2025-07-19T22:09:55.004+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 51.0 in stage 5.0 (TID 42). 9149 bytes result sent to driver
[2025-07-19T22:09:55.007+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 50.0 in stage 5.0 (TID 41). 9159 bytes result sent to driver
[2025-07-19T22:09:55.009+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 59.0 in stage 5.0 (TID 49) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.009+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.010+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 60.0 in stage 5.0 (TID 50) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.012+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 59.0 in stage 5.0 (TID 49)
[2025-07-19T22:09:55.014+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 51.0 in stage 5.0 (TID 42) in 294 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T22:09:55.018+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.022+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 50.0 in stage 5.0 (TID 41) in 316 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T22:09:55.022+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 60.0 in stage 5.0 (TID 50)
[2025-07-19T22:09:55.022+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.023+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.1.delta.ba0085d3-f4c4-4a9e-83c1-3054248245f5.TID44.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/1.delta
[2025-07-19T22:09:55.023+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/1.delta
[2025-07-19T22:09:55.023+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 52 (task 43, attempt 0, stage 5.0)
[2025-07-19T22:09:55.023+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 44, attempt 0, stage 5.0)
[2025-07-19T22:09:55.023+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 52.0 in stage 5.0 (TID 43). 9214 bytes result sent to driver
[2025-07-19T22:09:55.027+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 62.0 in stage 5.0 (TID 51) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.028+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.028+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:55.029+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78f77185
[2025-07-19T22:09:55.036+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.040+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59] for update
[2025-07-19T22:09:55.040+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 52.0 in stage 5.0 (TID 43) in 303 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T22:09:55.041+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 62.0 in stage 5.0 (TID 51)
[2025-07-19T22:09:55.041+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.041+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.1.delta.5afd4cc1-6962-4426-812e-7dc7dc7cbd06.TID48.tmp
[2025-07-19T22:09:55.045+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.045+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:09:55.059+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f78f71b
[2025-07-19T22:09:55.060+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.063+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60] for update
[2025-07-19T22:09:55.075+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.077+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.1.delta.8eed47e8-1c3b-4780-b1d4-aa32d62062ea.TID45.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/1.delta
[2025-07-19T22:09:55.078+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/1.delta
[2025-07-19T22:09:55.079+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 45, attempt 0, stage 5.0)
[2025-07-19T22:09:55.081+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26d84422
[2025-07-19T22:09:55.086+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.087+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62] for update
[2025-07-19T22:09:55.090+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.1.delta.cbfa5d54-5eed-4375-a2cc-e5a510ed7235.TID49.tmp
[2025-07-19T22:09:55.092+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.1.delta.a66a2bef-e12a-4bae-aa52-46dc818f92aa.TID50.tmp
[2025-07-19T22:09:55.107+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 54 (task 44, attempt 0, stage 5.0)
[2025-07-19T22:09:55.108+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 54.0 in stage 5.0 (TID 44). 9163 bytes result sent to driver
[2025-07-19T22:09:55.109+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.114+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.1.delta.4be668c5-a27c-4b21-901e-580714e1d508.TID47.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/1.delta
[2025-07-19T22:09:55.121+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/1.delta
[2025-07-19T22:09:55.123+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.1.delta.b0eaa013-6015-471b-959f-530d768606a8.TID46.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/1.delta
[2025-07-19T22:09:55.124+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/1.delta
[2025-07-19T22:09:55.126+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 63.0 in stage 5.0 (TID 52) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.127+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 46, attempt 0, stage 5.0)
[2025-07-19T22:09:55.127+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 47, attempt 0, stage 5.0)
[2025-07-19T22:09:55.127+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 54.0 in stage 5.0 (TID 44) in 329 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T22:09:55.128+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 63.0 in stage 5.0 (TID 52)
[2025-07-19T22:09:55.135+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.137+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.146+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.1.delta.80324417-c784-4481-908f-3724dbd4b7bf.TID51.tmp
[2025-07-19T22:09:55.150+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ea5f6bc
[2025-07-19T22:09:55.153+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.153+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63] for update
[2025-07-19T22:09:55.157+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.158+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 55 (task 45, attempt 0, stage 5.0)
[2025-07-19T22:09:55.158+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 55.0 in stage 5.0 (TID 45). 9151 bytes result sent to driver
[2025-07-19T22:09:55.160+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 65.0 in stage 5.0 (TID 53) (8b44f3d35cfa, executor driver, partition 65, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.163+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 65.0 in stage 5.0 (TID 53)
[2025-07-19T22:09:55.164+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 55.0 in stage 5.0 (TID 45) in 322 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T22:09:55.166+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.1.delta.5afd4cc1-6962-4426-812e-7dc7dc7cbd06.TID48.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/1.delta
[2025-07-19T22:09:55.167+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/1.delta
[2025-07-19T22:09:55.168+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 48, attempt 0, stage 5.0)
[2025-07-19T22:09:55.171+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.172+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:55.188+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23638fb8
[2025-07-19T22:09:55.196+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.198+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65] for update
[2025-07-19T22:09:55.201+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.1.delta.f582134b-1dcb-45e0-b1dc-5ad42fe08929.TID52.tmp
[2025-07-19T22:09:55.202+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 56 (task 46, attempt 0, stage 5.0)
[2025-07-19T22:09:55.203+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 57 (task 47, attempt 0, stage 5.0)
[2025-07-19T22:09:55.206+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 56.0 in stage 5.0 (TID 46). 9151 bytes result sent to driver
[2025-07-19T22:09:55.207+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 66.0 in stage 5.0 (TID 54) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.208+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 66.0 in stage 5.0 (TID 54)
[2025-07-19T22:09:55.210+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 56.0 in stage 5.0 (TID 46) in 351 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T22:09:55.212+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.213+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.213+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 57.0 in stage 5.0 (TID 47). 9149 bytes result sent to driver
[2025-07-19T22:09:55.214+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.214+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 67.0 in stage 5.0 (TID 55) (8b44f3d35cfa, executor driver, partition 67, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.214+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 67.0 in stage 5.0 (TID 55)
[2025-07-19T22:09:55.221+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30250e2d
[2025-07-19T22:09:55.223+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.224+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66] for update
[2025-07-19T22:09:55.225+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 57.0 in stage 5.0 (TID 47) in 331 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T22:09:55.226+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.1.delta.cbfa5d54-5eed-4375-a2cc-e5a510ed7235.TID49.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/1.delta
[2025-07-19T22:09:55.229+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/1.delta
[2025-07-19T22:09:55.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 49, attempt 0, stage 5.0)
[2025-07-19T22:09:55.239+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.241+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T22:09:55.243+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 58 (task 48, attempt 0, stage 5.0)
[2025-07-19T22:09:55.246+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.1.delta.80362e44-5628-4008-ad3a-72ec9bb2bc18.TID53.tmp
[2025-07-19T22:09:55.248+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 58.0 in stage 5.0 (TID 48). 9183 bytes result sent to driver
[2025-07-19T22:09:55.252+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 68.0 in stage 5.0 (TID 56) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.253+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 68.0 in stage 5.0 (TID 56)
[2025-07-19T22:09:55.254+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 58.0 in stage 5.0 (TID 48) in 274 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T22:09:55.255+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.1.delta.a66a2bef-e12a-4bae-aa52-46dc818f92aa.TID50.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/1.delta
[2025-07-19T22:09:55.255+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/1.delta
[2025-07-19T22:09:55.255+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 50, attempt 0, stage 5.0)
[2025-07-19T22:09:55.256+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45e6b208
[2025-07-19T22:09:55.257+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.257+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.258+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.258+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67] for update
[2025-07-19T22:09:55.264+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.271+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 59 (task 49, attempt 0, stage 5.0)
[2025-07-19T22:09:55.272+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.1.delta.bc3b07b7-b570-4cf3-b271-df55ae9b24ad.TID54.tmp
[2025-07-19T22:09:55.273+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@370254f3
[2025-07-19T22:09:55.273+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.1.delta.80324417-c784-4481-908f-3724dbd4b7bf.TID51.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/1.delta
[2025-07-19T22:09:55.273+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/1.delta
[2025-07-19T22:09:55.273+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 51, attempt 0, stage 5.0)
[2025-07-19T22:09:55.274+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.274+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68] for update
[2025-07-19T22:09:55.274+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 59.0 in stage 5.0 (TID 49). 9161 bytes result sent to driver
[2025-07-19T22:09:55.279+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.1.delta.b677b88c-f978-49cd-ac38-e82d1e4b91de.TID55.tmp
[2025-07-19T22:09:55.285+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 71.0 in stage 5.0 (TID 57) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.285+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 71.0 in stage 5.0 (TID 57)
[2025-07-19T22:09:55.286+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.286+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 59.0 in stage 5.0 (TID 49) in 281 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T22:09:55.287+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.288+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:55.293+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 60 (task 50, attempt 0, stage 5.0)
[2025-07-19T22:09:55.294+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 60.0 in stage 5.0 (TID 50). 9169 bytes result sent to driver
[2025-07-19T22:09:55.294+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.1.delta.973c383d-1bc6-466e-aef8-58a1d0f0089b.TID56.tmp
[2025-07-19T22:09:55.295+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 72.0 in stage 5.0 (TID 58) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.298+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 72.0 in stage 5.0 (TID 58)
[2025-07-19T22:09:55.299+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 60.0 in stage 5.0 (TID 50) in 290 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T22:09:55.303+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@576e1de7
[2025-07-19T22:09:55.306+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.306+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71] for update
[2025-07-19T22:09:55.307+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.307+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:55.308+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.315+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c2b9c30
[2025-07-19T22:09:55.317+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.319+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72] for update
[2025-07-19T22:09:55.320+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.1.delta.f582134b-1dcb-45e0-b1dc-5ad42fe08929.TID52.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/1.delta
[2025-07-19T22:09:55.321+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/1.delta
[2025-07-19T22:09:55.325+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 52, attempt 0, stage 5.0)
[2025-07-19T22:09:55.327+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.331+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.1.delta.e8df01eb-1198-4af7-abd5-52d4cf2dbcbf.TID57.tmp
[2025-07-19T22:09:55.332+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 62 (task 51, attempt 0, stage 5.0)
[2025-07-19T22:09:55.339+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.1.delta.80362e44-5628-4008-ad3a-72ec9bb2bc18.TID53.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/1.delta
[2025-07-19T22:09:55.343+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/1.delta
[2025-07-19T22:09:55.344+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 53, attempt 0, stage 5.0)
[2025-07-19T22:09:55.346+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 62.0 in stage 5.0 (TID 51). 9186 bytes result sent to driver
[2025-07-19T22:09:55.350+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 74.0 in stage 5.0 (TID 59) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.353+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 74.0 in stage 5.0 (TID 59)
[2025-07-19T22:09:55.354+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 62.0 in stage 5.0 (TID 51) in 332 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T22:09:55.360+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.1.delta.b8860a6e-8228-4e16-bca6-116e1b0569f7.TID58.tmp
[2025-07-19T22:09:55.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.374+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T22:09:55.389+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.1.delta.bc3b07b7-b570-4cf3-b271-df55ae9b24ad.TID54.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/1.delta
[2025-07-19T22:09:55.390+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.1.delta.b677b88c-f978-49cd-ac38-e82d1e4b91de.TID55.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/1.delta
[2025-07-19T22:09:55.391+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/1.delta
[2025-07-19T22:09:55.391+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/1.delta
[2025-07-19T22:09:55.392+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 54, attempt 0, stage 5.0)
[2025-07-19T22:09:55.393+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 63 (task 52, attempt 0, stage 5.0)
[2025-07-19T22:09:55.394+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 55, attempt 0, stage 5.0)
[2025-07-19T22:09:55.402+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 63.0 in stage 5.0 (TID 52). 9202 bytes result sent to driver
[2025-07-19T22:09:55.404+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a068af8
[2025-07-19T22:09:55.404+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.1.delta.973c383d-1bc6-466e-aef8-58a1d0f0089b.TID56.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/1.delta
[2025-07-19T22:09:55.405+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 75.0 in stage 5.0 (TID 60) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.406+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.406+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74] for update
[2025-07-19T22:09:55.407+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/1.delta
[2025-07-19T22:09:55.407+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 56, attempt 0, stage 5.0)
[2025-07-19T22:09:55.407+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 75.0 in stage 5.0 (TID 60)
[2025-07-19T22:09:55.410+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 63.0 in stage 5.0 (TID 52) in 293 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T22:09:55.422+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 65 (task 53, attempt 0, stage 5.0)
[2025-07-19T22:09:55.423+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.1.delta.e8df01eb-1198-4af7-abd5-52d4cf2dbcbf.TID57.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/1.delta
[2025-07-19T22:09:55.425+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/1.delta
[2025-07-19T22:09:55.425+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 65.0 in stage 5.0 (TID 53). 9163 bytes result sent to driver
[2025-07-19T22:09:55.426+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 76.0 in stage 5.0 (TID 61) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.428+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.428+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 57, attempt 0, stage 5.0)
[2025-07-19T22:09:55.430+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 76.0 in stage 5.0 (TID 61)
[2025-07-19T22:09:55.432+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.432+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.433+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 65.0 in stage 5.0 (TID 53) in 268 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T22:09:55.434+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.436+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:09:55.440+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 67 (task 55, attempt 0, stage 5.0)
[2025-07-19T22:09:55.440+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 66 (task 54, attempt 0, stage 5.0)
[2025-07-19T22:09:55.442+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@786030b3
[2025-07-19T22:09:55.443+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.443+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 66.0 in stage 5.0 (TID 54). 9141 bytes result sent to driver
[2025-07-19T22:09:55.447+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75] for update
[2025-07-19T22:09:55.453+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 67.0 in stage 5.0 (TID 55). 9159 bytes result sent to driver
[2025-07-19T22:09:55.454+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 77.0 in stage 5.0 (TID 62) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.455+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.455+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 78.0 in stage 5.0 (TID 63) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.456+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 66.0 in stage 5.0 (TID 54) in 253 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T22:09:55.457+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 78.0 in stage 5.0 (TID 63)
[2025-07-19T22:09:55.457+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 77.0 in stage 5.0 (TID 62)
[2025-07-19T22:09:55.458+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 67.0 in stage 5.0 (TID 55) in 242 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T22:09:55.459+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.1.delta.3da9fd15-4370-4cd6-9c59-599b29ad07e1.TID59.tmp
[2025-07-19T22:09:55.466+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 68 (task 56, attempt 0, stage 5.0)
[2025-07-19T22:09:55.468+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 68.0 in stage 5.0 (TID 56). 9161 bytes result sent to driver
[2025-07-19T22:09:55.471+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.472+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:55.474+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 79.0 in stage 5.0 (TID 64) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.475+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 68.0 in stage 5.0 (TID 56) in 219 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T22:09:55.476+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 79.0 in stage 5.0 (TID 64)
[2025-07-19T22:09:55.476+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.1.delta.86252327-8dfb-4f73-8643-8019c48d04d2.TID60.tmp
[2025-07-19T22:09:55.476+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31a4b834
[2025-07-19T22:09:55.477+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.478+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76] for update
[2025-07-19T22:09:55.478+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 71 (task 57, attempt 0, stage 5.0)
[2025-07-19T22:09:55.480+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b87ed3d
[2025-07-19T22:09:55.480+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 71.0 in stage 5.0 (TID 57). 9173 bytes result sent to driver
[2025-07-19T22:09:55.480+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.1.delta.b8860a6e-8228-4e16-bca6-116e1b0569f7.TID58.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/1.delta
[2025-07-19T22:09:55.480+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/1.delta
[2025-07-19T22:09:55.484+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.1.delta.3bb51f31-0825-4a90-91fb-788af8f0dd3f.TID61.tmp
[2025-07-19T22:09:55.487+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 58, attempt 0, stage 5.0)
[2025-07-19T22:09:55.488+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.488+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78] for update
[2025-07-19T22:09:55.488+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 71.0 in stage 5.0 (TID 57) in 209 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T22:09:55.494+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 80.0 in stage 5.0 (TID 65) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.504+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 80.0 in stage 5.0 (TID 65)
[2025-07-19T22:09:55.505+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.506+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@169ebba1
[2025-07-19T22:09:55.507+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.508+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.508+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.509+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79] for update
[2025-07-19T22:09:55.515+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39153501
[2025-07-19T22:09:55.517+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.518+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77] for update
[2025-07-19T22:09:55.523+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.527+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.1.delta.c02c44c2-0c69-4d5a-b7f2-68b8b27ed8a3.TID63.tmp
[2025-07-19T22:09:55.531+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.538+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65c81bcd
[2025-07-19T22:09:55.539+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.539+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80] for update
[2025-07-19T22:09:55.539+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.539+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 72 (task 58, attempt 0, stage 5.0)
[2025-07-19T22:09:55.549+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.1.delta.fc286ef4-579e-4073-b351-92d75942d6d4.TID64.tmp
[2025-07-19T22:09:55.553+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.1.delta.3da9fd15-4370-4cd6-9c59-599b29ad07e1.TID59.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/1.delta
[2025-07-19T22:09:55.556+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/1.delta
[2025-07-19T22:09:55.557+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 72.0 in stage 5.0 (TID 58). 9204 bytes result sent to driver
[2025-07-19T22:09:55.558+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 59, attempt 0, stage 5.0)
[2025-07-19T22:09:55.562+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 82.0 in stage 5.0 (TID 66) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.565+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 72.0 in stage 5.0 (TID 58) in 254 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T22:09:55.566+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.1.delta.86252327-8dfb-4f73-8643-8019c48d04d2.TID60.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/1.delta
[2025-07-19T22:09:55.569+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/1.delta
[2025-07-19T22:09:55.572+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 60, attempt 0, stage 5.0)
[2025-07-19T22:09:55.573+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 82.0 in stage 5.0 (TID 66)
[2025-07-19T22:09:55.574+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.1.delta.1ae2d153-2a27-416f-8d31-870ece6d6af7.TID62.tmp
[2025-07-19T22:09:55.576+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.577+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.578+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.1.delta.3bb51f31-0825-4a90-91fb-788af8f0dd3f.TID61.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/1.delta
[2025-07-19T22:09:55.579+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/1.delta
[2025-07-19T22:09:55.583+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.1.delta.b09f2977-fb72-40a7-9935-96589df786e0.TID65.tmp
[2025-07-19T22:09:55.586+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 61, attempt 0, stage 5.0)
[2025-07-19T22:09:55.587+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dee945d
[2025-07-19T22:09:55.587+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.587+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82] for update
[2025-07-19T22:09:55.594+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.611+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.1.delta.c02c44c2-0c69-4d5a-b7f2-68b8b27ed8a3.TID63.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/1.delta
[2025-07-19T22:09:55.624+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/1.delta
[2025-07-19T22:09:55.627+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 75 (task 60, attempt 0, stage 5.0)
[2025-07-19T22:09:55.629+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 75.0 in stage 5.0 (TID 60). 9177 bytes result sent to driver
[2025-07-19T22:09:55.632+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 74 (task 59, attempt 0, stage 5.0)
[2025-07-19T22:09:55.634+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 63, attempt 0, stage 5.0)
[2025-07-19T22:09:55.637+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 74.0 in stage 5.0 (TID 59). 9155 bytes result sent to driver
[2025-07-19T22:09:55.639+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 83.0 in stage 5.0 (TID 67) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.642+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 84.0 in stage 5.0 (TID 68) (8b44f3d35cfa, executor driver, partition 84, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 83.0 in stage 5.0 (TID 67)
[2025-07-19T22:09:55.647+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 75.0 in stage 5.0 (TID 60) in 217 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T22:09:55.650+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 84.0 in stage 5.0 (TID 68)
[2025-07-19T22:09:55.656+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 74.0 in stage 5.0 (TID 59) in 269 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T22:09:55.658+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.662+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.665+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.1.delta.fc286ef4-579e-4073-b351-92d75942d6d4.TID64.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/1.delta
[2025-07-19T22:09:55.669+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/1.delta
[2025-07-19T22:09:55.670+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.670+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 64, attempt 0, stage 5.0)
[2025-07-19T22:09:55.671+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.1.delta.27458321-6789-4f53-9aeb-2acbcbafa3fe.TID66.tmp
[2025-07-19T22:09:55.672+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e75b91e
[2025-07-19T22:09:55.673+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.674+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83] for update
[2025-07-19T22:09:55.678+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2025-07-19T22:09:55.678+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.678+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 76 (task 61, attempt 0, stage 5.0)
[2025-07-19T22:09:55.681+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 76.0 in stage 5.0 (TID 61). 9169 bytes result sent to driver
[2025-07-19T22:09:55.682+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.1.delta.1ae2d153-2a27-416f-8d31-870ece6d6af7.TID62.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/1.delta
[2025-07-19T22:09:55.686+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 78 (task 63, attempt 0, stage 5.0)
[2025-07-19T22:09:55.687+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@670bbf28
[2025-07-19T22:09:55.687+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/1.delta
[2025-07-19T22:09:55.688+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.688+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 85.0 in stage 5.0 (TID 69) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.689+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84] for update
[2025-07-19T22:09:55.689+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 76.0 in stage 5.0 (TID 61) in 245 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T22:09:55.690+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 62, attempt 0, stage 5.0)
[2025-07-19T22:09:55.690+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 85.0 in stage 5.0 (TID 69)
[2025-07-19T22:09:55.690+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.691+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:55.691+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.1.delta.22320d47-1005-40e4-9719-33966cdbb9b1.TID67.tmp
[2025-07-19T22:09:55.703+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 78.0 in stage 5.0 (TID 63). 9171 bytes result sent to driver
[2025-07-19T22:09:55.703+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 86.0 in stage 5.0 (TID 70) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.704+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 86.0 in stage 5.0 (TID 70)
[2025-07-19T22:09:55.724+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.726+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 78.0 in stage 5.0 (TID 63) in 270 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T22:09:55.734+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c55768c
[2025-07-19T22:09:55.735+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.736+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85] for update
[2025-07-19T22:09:55.737+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.738+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.739+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 79 (task 64, attempt 0, stage 5.0)
[2025-07-19T22:09:55.739+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.740+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 79.0 in stage 5.0 (TID 64). 9151 bytes result sent to driver
[2025-07-19T22:09:55.742+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 87.0 in stage 5.0 (TID 71) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.745+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 87.0 in stage 5.0 (TID 71)
[2025-07-19T22:09:55.746+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.1.delta.b09f2977-fb72-40a7-9935-96589df786e0.TID65.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/1.delta
[2025-07-19T22:09:55.746+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/1.delta
[2025-07-19T22:09:55.750+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.1.delta.0fe8b78a-e68e-44f9-bfcf-d8d6abd20456.TID68.tmp
[2025-07-19T22:09:55.751+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.1.delta.27458321-6789-4f53-9aeb-2acbcbafa3fe.TID66.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/1.delta
[2025-07-19T22:09:55.754+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 79.0 in stage 5.0 (TID 64) in 286 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T22:09:55.755+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/1.delta
[2025-07-19T22:09:55.755+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40a6a91c
[2025-07-19T22:09:55.755+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 66, attempt 0, stage 5.0)
[2025-07-19T22:09:55.756+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.756+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86] for update
[2025-07-19T22:09:55.757+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 65, attempt 0, stage 5.0)
[2025-07-19T22:09:55.760+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.761+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.761+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:09:55.764+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.1.delta.24fdad63-4b22-4f3e-a60e-f0ebbf941030.TID69.tmp
[2025-07-19T22:09:55.773+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 77 (task 62, attempt 0, stage 5.0)
[2025-07-19T22:09:55.774+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 77.0 in stage 5.0 (TID 62). 9174 bytes result sent to driver
[2025-07-19T22:09:55.777+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34d86250
[2025-07-19T22:09:55.778+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.779+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87] for update
[2025-07-19T22:09:55.779+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.1.delta.054c82fc-10f8-4b7f-a2ff-3c373fa74dde.TID70.tmp
[2025-07-19T22:09:55.784+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 88.0 in stage 5.0 (TID 72) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.787+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 77.0 in stage 5.0 (TID 62) in 340 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T22:09:55.797+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 88.0 in stage 5.0 (TID 72)
[2025-07-19T22:09:55.798+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.805+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.1.delta.22320d47-1005-40e4-9719-33966cdbb9b1.TID67.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/1.delta
[2025-07-19T22:09:55.807+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/1.delta
[2025-07-19T22:09:55.809+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.809+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:55.810+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.1.delta.188a4c39-dafa-4dda-9ca7-da8e10303c3a.TID71.tmp
[2025-07-19T22:09:55.812+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 67, attempt 0, stage 5.0)
[2025-07-19T22:09:55.814+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 80 (task 65, attempt 0, stage 5.0)
[2025-07-19T22:09:55.824+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 80.0 in stage 5.0 (TID 65). 9204 bytes result sent to driver
[2025-07-19T22:09:55.831+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 90.0 in stage 5.0 (TID 73) (8b44f3d35cfa, executor driver, partition 90, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.834+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@232dc02b
[2025-07-19T22:09:55.836+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.839+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 90.0 in stage 5.0 (TID 73)
[2025-07-19T22:09:55.839+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88] for update
[2025-07-19T22:09:55.842+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 82 (task 66, attempt 0, stage 5.0)
[2025-07-19T22:09:55.846+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.847+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 82.0 in stage 5.0 (TID 66). 9147 bytes result sent to driver
[2025-07-19T22:09:55.847+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.848+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:55.848+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 94.0 in stage 5.0 (TID 74) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.848+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 94.0 in stage 5.0 (TID 74)
[2025-07-19T22:09:55.853+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 82.0 in stage 5.0 (TID 66) in 303 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T22:09:55.856+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22aa2618
[2025-07-19T22:09:55.859+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.860+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:55.861+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.1.delta.0fe8b78a-e68e-44f9-bfcf-d8d6abd20456.TID68.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/1.delta
[2025-07-19T22:09:55.862+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/1.delta
[2025-07-19T22:09:55.863+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.864+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90] for update
[2025-07-19T22:09:55.864+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 80.0 in stage 5.0 (TID 65) in 370 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T22:09:55.865+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 68, attempt 0, stage 5.0)
[2025-07-19T22:09:55.867+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.867+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.1.delta.f578c140-e155-44c9-9ae2-10f3321083cf.TID72.tmp
[2025-07-19T22:09:55.870+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.1.delta.24fdad63-4b22-4f3e-a60e-f0ebbf941030.TID69.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/1.delta
[2025-07-19T22:09:55.871+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/1.delta
[2025-07-19T22:09:55.877+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b6b1093
[2025-07-19T22:09:55.877+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.877+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94] for update
[2025-07-19T22:09:55.880+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.1.delta.db7aecd7-983f-4e0d-97fc-614078109aab.TID73.tmp
[2025-07-19T22:09:55.882+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 83 (task 67, attempt 0, stage 5.0)
[2025-07-19T22:09:55.885+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 69, attempt 0, stage 5.0)
[2025-07-19T22:09:55.885+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 83.0 in stage 5.0 (TID 67). 9161 bytes result sent to driver
[2025-07-19T22:09:55.885+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.890+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 84 (task 68, attempt 0, stage 5.0)
[2025-07-19T22:09:55.891+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 84.0 in stage 5.0 (TID 68). 9153 bytes result sent to driver
[2025-07-19T22:09:55.891+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 83.0 in stage 5.0 (TID 67) in 277 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T22:09:55.893+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.1.delta.188a4c39-dafa-4dda-9ca7-da8e10303c3a.TID71.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/1.delta
[2025-07-19T22:09:55.896+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/1.delta
[2025-07-19T22:09:55.898+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 95.0 in stage 5.0 (TID 75) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.899+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 71, attempt 0, stage 5.0)
[2025-07-19T22:09:55.900+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 95.0 in stage 5.0 (TID 75)
[2025-07-19T22:09:55.902+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 96.0 in stage 5.0 (TID 76) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.906+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.1.delta.054c82fc-10f8-4b7f-a2ff-3c373fa74dde.TID70.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/1.delta
[2025-07-19T22:09:55.907+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/1.delta
[2025-07-19T22:09:55.909+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 84.0 in stage 5.0 (TID 68) in 292 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T22:09:55.913+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 70, attempt 0, stage 5.0)
[2025-07-19T22:09:55.915+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.917+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:55.922+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 96.0 in stage 5.0 (TID 76)
[2025-07-19T22:09:55.924+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.925+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:55.927+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70ab437d
[2025-07-19T22:09:55.928+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.928+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95] for update
[2025-07-19T22:09:55.932+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:55.934+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.1.delta.aa02bc40-1359-4353-a3c0-2a32bf50ec5f.TID74.tmp
[2025-07-19T22:09:55.936+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 85 (task 69, attempt 0, stage 5.0)
[2025-07-19T22:09:55.942+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 85.0 in stage 5.0 (TID 69). 9171 bytes result sent to driver
[2025-07-19T22:09:55.943+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 97.0 in stage 5.0 (TID 77) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:55.949+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 97.0 in stage 5.0 (TID 77)
[2025-07-19T22:09:55.950+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 85.0 in stage 5.0 (TID 69) in 288 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T22:09:55.958+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65be9b54
[2025-07-19T22:09:55.966+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:55.973+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96] for update
[2025-07-19T22:09:55.977+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 87 (task 71, attempt 0, stage 5.0)
[2025-07-19T22:09:55.978+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:55.987+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.1.delta.db7aecd7-983f-4e0d-97fc-614078109aab.TID73.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/1.delta
[2025-07-19T22:09:55.993+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/1.delta
[2025-07-19T22:09:55.995+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 73, attempt 0, stage 5.0)
[2025-07-19T22:09:55.996+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:55.998+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 87.0 in stage 5.0 (TID 71). 9155 bytes result sent to driver
[2025-07-19T22:09:55.999+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Committed partition 86 (task 70, attempt 0, stage 5.0)
[2025-07-19T22:09:56.000+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Finished task 86.0 in stage 5.0 (TID 70). 9203 bytes result sent to driver
[2025-07-19T22:09:56.001+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 99.0 in stage 5.0 (TID 78) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.001+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Starting task 100.0 in stage 5.0 (TID 79) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.002+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.006+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.1.delta.f578c140-e155-44c9-9ae2-10f3321083cf.TID72.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/1.delta
[2025-07-19T22:09:56.008+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/1.delta
[2025-07-19T22:09:56.009+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 86.0 in stage 5.0 (TID 70) in 267 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T22:09:56.010+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 99.0 in stage 5.0 (TID 78)
[2025-07-19T22:09:56.010+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 72, attempt 0, stage 5.0)
[2025-07-19T22:09:56.012+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO TaskSetManager: Finished task 87.0 in stage 5.0 (TID 71) in 233 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T22:09:56.012+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO Executor: Running task 100.0 in stage 5.0 (TID 79)
[2025-07-19T22:09:56.013+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.1.delta.8fc56b46-c6b5-43dc-92a5-8d99131464f2.TID75.tmp
[2025-07-19T22:09:56.013+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.014+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:56.015+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.019+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.021+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fdb0b29
[2025-07-19T22:09:56.021+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.022+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97] for update
[2025-07-19T22:09:56.023+0000] {subprocess.py:93} INFO - 25/07/19 22:09:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.024+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f7c3a19
[2025-07-19T22:09:56.026+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.1.delta.b4fe251d-de7d-40bb-ac01-69f0ee632553.TID76.tmp
[2025-07-19T22:09:56.026+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.026+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100] for update
[2025-07-19T22:09:56.026+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.037+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.1.delta.70f94e63-8161-4396-9889-988a2c15e59d.TID77.tmp
[2025-07-19T22:09:56.042+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@526e7915
[2025-07-19T22:09:56.043+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.046+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99] for update
[2025-07-19T22:09:56.053+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 90 (task 73, attempt 0, stage 5.0)
[2025-07-19T22:09:56.055+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.057+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 88 (task 72, attempt 0, stage 5.0)
[2025-07-19T22:09:56.059+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 90.0 in stage 5.0 (TID 73). 9161 bytes result sent to driver
[2025-07-19T22:09:56.061+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 101.0 in stage 5.0 (TID 80) (8b44f3d35cfa, executor driver, partition 101, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.062+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 101.0 in stage 5.0 (TID 80)
[2025-07-19T22:09:56.063+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 88.0 in stage 5.0 (TID 72). 9161 bytes result sent to driver
[2025-07-19T22:09:56.066+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 90.0 in stage 5.0 (TID 73) in 218 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T22:09:56.069+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 103.0 in stage 5.0 (TID 81) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.070+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 103.0 in stage 5.0 (TID 81)
[2025-07-19T22:09:56.070+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.1.delta.aa02bc40-1359-4353-a3c0-2a32bf50ec5f.TID74.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/1.delta
[2025-07-19T22:09:56.071+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/1.delta
[2025-07-19T22:09:56.072+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 88.0 in stage 5.0 (TID 72) in 277 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T22:09:56.072+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.079+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.081+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 74, attempt 0, stage 5.0)
[2025-07-19T22:09:56.083+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.084+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:56.085+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.1.delta.b87f2521-c789-4ba6-a76b-bdf16537a25f.TID78.tmp
[2025-07-19T22:09:56.089+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.1.delta.e7dd0742-8d9f-43f8-9441-3f5dc28cf892.TID79.tmp
[2025-07-19T22:09:56.094+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40f74341
[2025-07-19T22:09:56.096+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.098+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101] for update
[2025-07-19T22:09:56.101+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.103+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35d78925
[2025-07-19T22:09:56.103+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.106+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103] for update
[2025-07-19T22:09:56.107+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.109+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.1.delta.b4fe251d-de7d-40bb-ac01-69f0ee632553.TID76.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/1.delta
[2025-07-19T22:09:56.112+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/1.delta
[2025-07-19T22:09:56.117+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 76, attempt 0, stage 5.0)
[2025-07-19T22:09:56.120+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.1.delta.2ef9ff09-8065-4042-a772-e5ba642e0e93.TID80.tmp
[2025-07-19T22:09:56.121+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.1.delta.8fc56b46-c6b5-43dc-92a5-8d99131464f2.TID75.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/1.delta
[2025-07-19T22:09:56.125+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/1.delta
[2025-07-19T22:09:56.127+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 75, attempt 0, stage 5.0)
[2025-07-19T22:09:56.128+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 94 (task 74, attempt 0, stage 5.0)
[2025-07-19T22:09:56.129+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 94.0 in stage 5.0 (TID 74). 9211 bytes result sent to driver
[2025-07-19T22:09:56.130+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 104.0 in stage 5.0 (TID 82) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.135+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 104.0 in stage 5.0 (TID 82)
[2025-07-19T22:09:56.137+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 94.0 in stage 5.0 (TID 74) in 289 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T22:09:56.141+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.1.delta.413655e6-2046-4d02-8d53-1d5135dc6792.TID81.tmp
[2025-07-19T22:09:56.145+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.1.delta.70f94e63-8161-4396-9889-988a2c15e59d.TID77.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/1.delta
[2025-07-19T22:09:56.146+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/1.delta
[2025-07-19T22:09:56.147+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.148+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.153+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 77, attempt 0, stage 5.0)
[2025-07-19T22:09:56.163+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 95 (task 75, attempt 0, stage 5.0)
[2025-07-19T22:09:56.166+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 96 (task 76, attempt 0, stage 5.0)
[2025-07-19T22:09:56.167+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 96.0 in stage 5.0 (TID 76). 9169 bytes result sent to driver
[2025-07-19T22:09:56.167+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 95.0 in stage 5.0 (TID 75). 9155 bytes result sent to driver
[2025-07-19T22:09:56.167+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 105.0 in stage 5.0 (TID 83) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.168+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 106.0 in stage 5.0 (TID 84) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.168+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 96.0 in stage 5.0 (TID 76) in 267 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T22:09:56.168+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 95.0 in stage 5.0 (TID 75) in 272 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T22:09:56.169+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 105.0 in stage 5.0 (TID 83)
[2025-07-19T22:09:56.171+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 106.0 in stage 5.0 (TID 84)
[2025-07-19T22:09:56.174+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.175+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:56.177+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@393ebd1e
[2025-07-19T22:09:56.181+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.182+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104] for update
[2025-07-19T22:09:56.182+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.1.delta.e7dd0742-8d9f-43f8-9441-3f5dc28cf892.TID79.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/1.delta
[2025-07-19T22:09:56.182+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/1.delta
[2025-07-19T22:09:56.182+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 79, attempt 0, stage 5.0)
[2025-07-19T22:09:56.184+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.192+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1861e217
[2025-07-19T22:09:56.193+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.1.delta.b87f2521-c789-4ba6-a76b-bdf16537a25f.TID78.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/1.delta
[2025-07-19T22:09:56.194+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/1.delta
[2025-07-19T22:09:56.199+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.200+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.1.delta.edcf718c-f6d3-4aac-8d2a-3500d0fa0cfc.TID82.tmp
[2025-07-19T22:09:56.200+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105] for update
[2025-07-19T22:09:56.203+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.204+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 78, attempt 0, stage 5.0)
[2025-07-19T22:09:56.206+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.207+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.212+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.1.delta.2ef9ff09-8065-4042-a772-e5ba642e0e93.TID80.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/1.delta
[2025-07-19T22:09:56.213+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/1.delta
[2025-07-19T22:09:56.215+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 97 (task 77, attempt 0, stage 5.0)
[2025-07-19T22:09:56.216+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 97.0 in stage 5.0 (TID 77). 9140 bytes result sent to driver
[2025-07-19T22:09:56.217+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 80, attempt 0, stage 5.0)
[2025-07-19T22:09:56.218+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 100 (task 79, attempt 0, stage 5.0)
[2025-07-19T22:09:56.230+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 100.0 in stage 5.0 (TID 79). 9205 bytes result sent to driver
[2025-07-19T22:09:56.232+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 107.0 in stage 5.0 (TID 85) (8b44f3d35cfa, executor driver, partition 107, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.232+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 107.0 in stage 5.0 (TID 85)
[2025-07-19T22:09:56.233+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69f7bd3
[2025-07-19T22:09:56.233+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.1.delta.413655e6-2046-4d02-8d53-1d5135dc6792.TID81.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/1.delta
[2025-07-19T22:09:56.233+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 108.0 in stage 5.0 (TID 86) (8b44f3d35cfa, executor driver, partition 108, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.233+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/1.delta
[2025-07-19T22:09:56.233+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 108.0 in stage 5.0 (TID 86)
[2025-07-19T22:09:56.233+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 81, attempt 0, stage 5.0)
[2025-07-19T22:09:56.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 100.0 in stage 5.0 (TID 79) in 263 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T22:09:56.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106] for update
[2025-07-19T22:09:56.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.235+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 97.0 in stage 5.0 (TID 77) in 292 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T22:09:56.236+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.1.delta.82e3ba87-09fd-4e85-8b60-d484bf79c8dd.TID83.tmp
[2025-07-19T22:09:56.246+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74c186bf
[2025-07-19T22:09:56.247+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.247+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107] for update
[2025-07-19T22:09:56.250+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.255+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@240079a0
[2025-07-19T22:09:56.256+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.256+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108] for update
[2025-07-19T22:09:56.261+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 101 (task 80, attempt 0, stage 5.0)
[2025-07-19T22:09:56.263+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.1.delta.cb97804d-35d2-41c5-afd6-4587b89f7969.TID84.tmp
[2025-07-19T22:09:56.268+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 101.0 in stage 5.0 (TID 80). 9161 bytes result sent to driver
[2025-07-19T22:09:56.269+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.270+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 109.0 in stage 5.0 (TID 87) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.270+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 101.0 in stage 5.0 (TID 80) in 220 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T22:09:56.271+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 109.0 in stage 5.0 (TID 87)
[2025-07-19T22:09:56.273+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.274+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:56.275+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.1.delta.e2b61f89-cddc-4476-b61b-e29930d8abe2.TID85.tmp
[2025-07-19T22:09:56.278+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 103 (task 81, attempt 0, stage 5.0)
[2025-07-19T22:09:56.279+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 99 (task 78, attempt 0, stage 5.0)
[2025-07-19T22:09:56.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 99.0 in stage 5.0 (TID 78). 9157 bytes result sent to driver
[2025-07-19T22:09:56.285+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13e3e2d8
[2025-07-19T22:09:56.286+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 110.0 in stage 5.0 (TID 88) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.290+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 99.0 in stage 5.0 (TID 78) in 317 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T22:09:56.292+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.293+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109] for update
[2025-07-19T22:09:56.294+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 103.0 in stage 5.0 (TID 81). 9190 bytes result sent to driver
[2025-07-19T22:09:56.294+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 110.0 in stage 5.0 (TID 88)
[2025-07-19T22:09:56.295+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 111.0 in stage 5.0 (TID 89) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.295+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.1.delta.236070fd-0e7c-465f-8fd3-e70145ee843c.TID86.tmp
[2025-07-19T22:09:56.296+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 103.0 in stage 5.0 (TID 81) in 239 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T22:09:56.297+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 111.0 in stage 5.0 (TID 89)
[2025-07-19T22:09:56.300+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.301+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.1.delta.edcf718c-f6d3-4aac-8d2a-3500d0fa0cfc.TID82.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/1.delta
[2025-07-19T22:09:56.302+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/1.delta
[2025-07-19T22:09:56.303+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 82, attempt 0, stage 5.0)
[2025-07-19T22:09:56.305+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.306+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:09:56.306+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.307+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.309+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.1.delta.6be96003-d52c-4139-a82a-ad743f1ee77a.TID87.tmp
[2025-07-19T22:09:56.309+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.1.delta.82e3ba87-09fd-4e85-8b60-d484bf79c8dd.TID83.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/1.delta
[2025-07-19T22:09:56.311+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/1.delta
[2025-07-19T22:09:56.311+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 83, attempt 0, stage 5.0)
[2025-07-19T22:09:56.320+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d0a6820
[2025-07-19T22:09:56.321+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.321+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110] for update
[2025-07-19T22:09:56.321+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.336+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63fbbd7e
[2025-07-19T22:09:56.337+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111] for update
[2025-07-19T22:09:56.338+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.344+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 104 (task 82, attempt 0, stage 5.0)
[2025-07-19T22:09:56.346+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 104.0 in stage 5.0 (TID 82). 9159 bytes result sent to driver
[2025-07-19T22:09:56.349+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 112.0 in stage 5.0 (TID 90) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.350+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 112.0 in stage 5.0 (TID 90)
[2025-07-19T22:09:56.354+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 104.0 in stage 5.0 (TID 82) in 220 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T22:09:56.355+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.1.delta.6a5b2777-0862-41f4-844c-17179e4a6b5b.TID88.tmp
[2025-07-19T22:09:56.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.367+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.1.delta.cb97804d-35d2-41c5-afd6-4587b89f7969.TID84.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/1.delta
[2025-07-19T22:09:56.368+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/1.delta
[2025-07-19T22:09:56.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 84, attempt 0, stage 5.0)
[2025-07-19T22:09:56.374+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 105 (task 83, attempt 0, stage 5.0)
[2025-07-19T22:09:56.376+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5db49ec1
[2025-07-19T22:09:56.377+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.377+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112] for update
[2025-07-19T22:09:56.377+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.1.delta.95db4194-acc1-49c0-a2bd-b6aa93561819.TID89.tmp
[2025-07-19T22:09:56.382+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 105.0 in stage 5.0 (TID 83). 9147 bytes result sent to driver
[2025-07-19T22:09:56.383+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 113.0 in stage 5.0 (TID 91) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.386+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 113.0 in stage 5.0 (TID 91)
[2025-07-19T22:09:56.387+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.1.delta.236070fd-0e7c-465f-8fd3-e70145ee843c.TID86.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/1.delta
[2025-07-19T22:09:56.391+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.1.delta.e2b61f89-cddc-4476-b61b-e29930d8abe2.TID85.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/1.delta
[2025-07-19T22:09:56.393+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/1.delta
[2025-07-19T22:09:56.394+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/1.delta
[2025-07-19T22:09:56.394+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 105.0 in stage 5.0 (TID 83) in 213 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T22:09:56.395+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 86, attempt 0, stage 5.0)
[2025-07-19T22:09:56.398+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 85, attempt 0, stage 5.0)
[2025-07-19T22:09:56.402+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.402+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.402+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.403+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.1.delta.6be96003-d52c-4139-a82a-ad743f1ee77a.TID87.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/1.delta
[2025-07-19T22:09:56.403+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/1.delta
[2025-07-19T22:09:56.403+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 87, attempt 0, stage 5.0)
[2025-07-19T22:09:56.417+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4821b079
[2025-07-19T22:09:56.420+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.423+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113] for update
[2025-07-19T22:09:56.425+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 106 (task 84, attempt 0, stage 5.0)
[2025-07-19T22:09:56.426+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.1.delta.2c349e98-b9c6-4a22-8c5c-00c3a3061d19.TID90.tmp
[2025-07-19T22:09:56.459+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 106.0 in stage 5.0 (TID 84). 9198 bytes result sent to driver
[2025-07-19T22:09:56.470+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.474+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 114.0 in stage 5.0 (TID 92) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 106.0 in stage 5.0 (TID 84) in 315 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T22:09:56.489+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 114.0 in stage 5.0 (TID 92)
[2025-07-19T22:09:56.510+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 107 (task 85, attempt 0, stage 5.0)
[2025-07-19T22:09:56.542+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 107.0 in stage 5.0 (TID 85). 9149 bytes result sent to driver
[2025-07-19T22:09:56.562+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.1.delta.810c6004-0da7-416b-8208-ee9fe4eecf69.TID91.tmp
[2025-07-19T22:09:56.567+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 108 (task 86, attempt 0, stage 5.0)
[2025-07-19T22:09:56.569+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 115.0 in stage 5.0 (TID 93) (8b44f3d35cfa, executor driver, partition 115, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.571+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 107.0 in stage 5.0 (TID 85) in 338 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T22:09:56.573+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 108.0 in stage 5.0 (TID 86). 9139 bytes result sent to driver
[2025-07-19T22:09:56.574+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 116.0 in stage 5.0 (TID 94) (8b44f3d35cfa, executor driver, partition 116, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.578+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 115.0 in stage 5.0 (TID 93)
[2025-07-19T22:09:56.580+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 116.0 in stage 5.0 (TID 94)
[2025-07-19T22:09:56.592+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 108.0 in stage 5.0 (TID 86) in 353 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T22:09:56.593+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.595+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:56.596+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.602+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:56.603+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.606+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.606+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 109 (task 87, attempt 0, stage 5.0)
[2025-07-19T22:09:56.608+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 109.0 in stage 5.0 (TID 87). 9159 bytes result sent to driver
[2025-07-19T22:09:56.611+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.1.delta.6a5b2777-0862-41f4-844c-17179e4a6b5b.TID88.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/1.delta
[2025-07-19T22:09:56.613+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/1.delta
[2025-07-19T22:09:56.617+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 117.0 in stage 5.0 (TID 95) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.621+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.1.delta.95db4194-acc1-49c0-a2bd-b6aa93561819.TID89.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/1.delta
[2025-07-19T22:09:56.624+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/1.delta
[2025-07-19T22:09:56.625+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 117.0 in stage 5.0 (TID 95)
[2025-07-19T22:09:56.626+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 109.0 in stage 5.0 (TID 87) in 345 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T22:09:56.627+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 89, attempt 0, stage 5.0)
[2025-07-19T22:09:56.627+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3383e101
[2025-07-19T22:09:56.628+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.628+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115] for update
[2025-07-19T22:09:56.628+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 88, attempt 0, stage 5.0)
[2025-07-19T22:09:56.628+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.628+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.628+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.629+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b2c3671
[2025-07-19T22:09:56.629+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.629+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114] for update
[2025-07-19T22:09:56.632+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.642+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65328341
[2025-07-19T22:09:56.643+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.650+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116] for update
[2025-07-19T22:09:56.660+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.1.delta.b6759be6-fe1b-4c8c-8000-fa3c1171b15d.TID93.tmp
[2025-07-19T22:09:56.664+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.666+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.1.delta.2c349e98-b9c6-4a22-8c5c-00c3a3061d19.TID90.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/1.delta
[2025-07-19T22:09:56.667+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/1.delta
[2025-07-19T22:09:56.667+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 90, attempt 0, stage 5.0)
[2025-07-19T22:09:56.667+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 111 (task 89, attempt 0, stage 5.0)
[2025-07-19T22:09:56.668+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.1.delta.8243e350-fa74-4710-b593-a04a894b4968.TID92.tmp
[2025-07-19T22:09:56.674+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 111.0 in stage 5.0 (TID 89). 9215 bytes result sent to driver
[2025-07-19T22:09:56.676+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73aa26d3
[2025-07-19T22:09:56.677+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 118.0 in stage 5.0 (TID 96) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.684+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.685+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117] for update
[2025-07-19T22:09:56.689+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 118.0 in stage 5.0 (TID 96)
[2025-07-19T22:09:56.690+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 111.0 in stage 5.0 (TID 89) in 397 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T22:09:56.691+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 110 (task 88, attempt 0, stage 5.0)
[2025-07-19T22:09:56.693+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.1.delta.1631425b-fe64-416c-890b-264a51fa17fb.TID94.tmp
[2025-07-19T22:09:56.694+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.695+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.696+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.697+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 110.0 in stage 5.0 (TID 88). 9155 bytes result sent to driver
[2025-07-19T22:09:56.698+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 119.0 in stage 5.0 (TID 97) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.699+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 119.0 in stage 5.0 (TID 97)
[2025-07-19T22:09:56.701+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 110.0 in stage 5.0 (TID 88) in 421 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T22:09:56.714+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.715+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.715+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7076951e
[2025-07-19T22:09:56.716+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.719+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118] for update
[2025-07-19T22:09:56.720+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.721+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 112 (task 90, attempt 0, stage 5.0)
[2025-07-19T22:09:56.739+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 112.0 in stage 5.0 (TID 90). 9208 bytes result sent to driver
[2025-07-19T22:09:56.740+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 120.0 in stage 5.0 (TID 98) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.740+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 120.0 in stage 5.0 (TID 98)
[2025-07-19T22:09:56.740+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 112.0 in stage 5.0 (TID 90) in 394 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T22:09:56.743+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2644af42
[2025-07-19T22:09:56.744+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.748+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119] for update
[2025-07-19T22:09:56.748+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.750+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.751+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.1.delta.810c6004-0da7-416b-8208-ee9fe4eecf69.TID91.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/1.delta
[2025-07-19T22:09:56.752+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/1.delta
[2025-07-19T22:09:56.752+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.1.delta.b7e40f14-d974-448b-9559-4641ff64c26f.TID95.tmp
[2025-07-19T22:09:56.753+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 91, attempt 0, stage 5.0)
[2025-07-19T22:09:56.755+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.1.delta.03b5a35d-ec59-4d50-8505-17f2ee863af0.TID96.tmp
[2025-07-19T22:09:56.764+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.772+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e9c67af
[2025-07-19T22:09:56.774+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.774+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120] for update
[2025-07-19T22:09:56.778+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.798+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 113 (task 91, attempt 0, stage 5.0)
[2025-07-19T22:09:56.799+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 113.0 in stage 5.0 (TID 91). 9200 bytes result sent to driver
[2025-07-19T22:09:56.801+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.1.delta.8243e350-fa74-4710-b593-a04a894b4968.TID92.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/1.delta
[2025-07-19T22:09:56.801+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/1.delta
[2025-07-19T22:09:56.802+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.1.delta.b6759be6-fe1b-4c8c-8000-fa3c1171b15d.TID93.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/1.delta
[2025-07-19T22:09:56.802+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/1.delta
[2025-07-19T22:09:56.803+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 92, attempt 0, stage 5.0)
[2025-07-19T22:09:56.803+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 121.0 in stage 5.0 (TID 99) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.804+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 93, attempt 0, stage 5.0)
[2025-07-19T22:09:56.805+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 121.0 in stage 5.0 (TID 99)
[2025-07-19T22:09:56.807+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 113.0 in stage 5.0 (TID 91) in 429 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T22:09:56.814+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.1.delta.46fcc61e-1cec-49a4-a46d-7fd5ed7184c0.TID97.tmp
[2025-07-19T22:09:56.819+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.831+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:09:56.832+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.1.delta.c7a38c7b-ec2d-4770-8897-b91a2c6d1119.TID98.tmp
[2025-07-19T22:09:56.834+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@aea1933
[2025-07-19T22:09:56.835+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.836+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121] for update
[2025-07-19T22:09:56.841+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.1.delta.1631425b-fe64-416c-890b-264a51fa17fb.TID94.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/1.delta
[2025-07-19T22:09:56.843+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/1.delta
[2025-07-19T22:09:56.844+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 94, attempt 0, stage 5.0)
[2025-07-19T22:09:56.848+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.855+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 115 (task 93, attempt 0, stage 5.0)
[2025-07-19T22:09:56.860+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 114 (task 92, attempt 0, stage 5.0)
[2025-07-19T22:09:56.862+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 115.0 in stage 5.0 (TID 93). 9157 bytes result sent to driver
[2025-07-19T22:09:56.863+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 122.0 in stage 5.0 (TID 100) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.865+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 122.0 in stage 5.0 (TID 100)
[2025-07-19T22:09:56.867+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 114.0 in stage 5.0 (TID 92). 9210 bytes result sent to driver
[2025-07-19T22:09:56.869+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 115.0 in stage 5.0 (TID 93) in 302 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T22:09:56.873+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 125.0 in stage 5.0 (TID 101) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.874+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.1.delta.2449df0c-cf77-4e03-a730-88ed5b8b7ac8.TID99.tmp
[2025-07-19T22:09:56.875+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 125.0 in stage 5.0 (TID 101)
[2025-07-19T22:09:56.882+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.1.delta.03b5a35d-ec59-4d50-8505-17f2ee863af0.TID96.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/1.delta
[2025-07-19T22:09:56.883+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/1.delta
[2025-07-19T22:09:56.886+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 96, attempt 0, stage 5.0)
[2025-07-19T22:09:56.888+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 114.0 in stage 5.0 (TID 92) in 422 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T22:09:56.892+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.893+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:56.895+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.1.delta.46fcc61e-1cec-49a4-a46d-7fd5ed7184c0.TID97.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/1.delta
[2025-07-19T22:09:56.898+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/1.delta
[2025-07-19T22:09:56.899+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 97, attempt 0, stage 5.0)
[2025-07-19T22:09:56.900+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 116 (task 94, attempt 0, stage 5.0)
[2025-07-19T22:09:56.900+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.1.delta.b7e40f14-d974-448b-9559-4641ff64c26f.TID95.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/1.delta
[2025-07-19T22:09:56.903+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/1.delta
[2025-07-19T22:09:56.904+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 116.0 in stage 5.0 (TID 94). 9153 bytes result sent to driver
[2025-07-19T22:09:56.904+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 95, attempt 0, stage 5.0)
[2025-07-19T22:09:56.904+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 126.0 in stage 5.0 (TID 102) (8b44f3d35cfa, executor driver, partition 126, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.905+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 116.0 in stage 5.0 (TID 94) in 332 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T22:09:56.905+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 126.0 in stage 5.0 (TID 102)
[2025-07-19T22:09:56.911+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bdf2245
[2025-07-19T22:09:56.912+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.1.delta.c7a38c7b-ec2d-4770-8897-b91a2c6d1119.TID98.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/1.delta
[2025-07-19T22:09:56.913+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/1.delta
[2025-07-19T22:09:56.914+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.915+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T22:09:56.916+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 98, attempt 0, stage 5.0)
[2025-07-19T22:09:56.918+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.919+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122] for update
[2025-07-19T22:09:56.923+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.925+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.927+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.928+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 117 (task 95, attempt 0, stage 5.0)
[2025-07-19T22:09:56.929+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 117.0 in stage 5.0 (TID 95). 9161 bytes result sent to driver
[2025-07-19T22:09:56.930+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f082319
[2025-07-19T22:09:56.930+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 128.0 in stage 5.0 (TID 103) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.930+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 128.0 in stage 5.0 (TID 103)
[2025-07-19T22:09:56.931+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.931+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125] for update
[2025-07-19T22:09:56.931+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 117.0 in stage 5.0 (TID 95) in 323 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T22:09:56.931+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 118 (task 96, attempt 0, stage 5.0)
[2025-07-19T22:09:56.931+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.938+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 118.0 in stage 5.0 (TID 96). 9198 bytes result sent to driver
[2025-07-19T22:09:56.939+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.939+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.939+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 129.0 in stage 5.0 (TID 104) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.939+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@531c85dc
[2025-07-19T22:09:56.939+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 129.0 in stage 5.0 (TID 104)
[2025-07-19T22:09:56.939+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.940+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126] for update
[2025-07-19T22:09:56.940+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 120 (task 98, attempt 0, stage 5.0)
[2025-07-19T22:09:56.949+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 118.0 in stage 5.0 (TID 96) in 272 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T22:09:56.952+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 120.0 in stage 5.0 (TID 98). 9211 bytes result sent to driver
[2025-07-19T22:09:56.952+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.1.delta.3b2afd50-e630-44a7-910e-e091151243c1.TID100.tmp
[2025-07-19T22:09:56.953+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.953+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:56.953+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.958+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Starting task 130.0 in stage 5.0 (TID 105) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:56.959+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Running task 130.0 in stage 5.0 (TID 105)
[2025-07-19T22:09:56.959+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4018eda9
[2025-07-19T22:09:56.963+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:56.964+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128] for update
[2025-07-19T22:09:56.966+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO TaskSetManager: Finished task 120.0 in stage 5.0 (TID 98) in 220 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T22:09:56.966+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:56.968+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:56.972+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T22:09:56.975+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.1.delta.a98e2767-e3fb-4b09-b96a-6397f064a92a.TID102.tmp
[2025-07-19T22:09:56.976+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.1.delta.25a3702a-ab73-4f61-8ab2-1c4b0088b059.TID101.tmp
[2025-07-19T22:09:56.977+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.1.delta.2449df0c-cf77-4e03-a730-88ed5b8b7ac8.TID99.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/1.delta
[2025-07-19T22:09:56.979+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/1.delta
[2025-07-19T22:09:57.007+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 99, attempt 0, stage 5.0)
[2025-07-19T22:09:57.008+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO DataWritingSparkTask: Committed partition 119 (task 97, attempt 0, stage 5.0)
[2025-07-19T22:09:57.008+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO Executor: Finished task 119.0 in stage 5.0 (TID 97). 9151 bytes result sent to driver
[2025-07-19T22:09:57.008+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e48f2df
[2025-07-19T22:09:57.008+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.009+0000] {subprocess.py:93} INFO - 25/07/19 22:09:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129] for update
[2025-07-19T22:09:57.029+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 131.0 in stage 5.0 (TID 106) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.033+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 131.0 in stage 5.0 (TID 106)
[2025-07-19T22:09:57.036+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 119.0 in stage 5.0 (TID 97) in 325 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T22:09:57.048+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.1.delta.967294fd-548f-4d18-a0aa-fe3eb0e4e3e1.TID103.tmp
[2025-07-19T22:09:57.049+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.049+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:57.057+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f9bb721
[2025-07-19T22:09:57.059+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.064+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.067+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 121 (task 99, attempt 0, stage 5.0)
[2025-07-19T22:09:57.072+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130] for update
[2025-07-19T22:09:57.074+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.1.delta.3b2afd50-e630-44a7-910e-e091151243c1.TID100.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/1.delta
[2025-07-19T22:09:57.076+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/1.delta
[2025-07-19T22:09:57.077+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 100, attempt 0, stage 5.0)
[2025-07-19T22:09:57.081+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 121.0 in stage 5.0 (TID 99). 9194 bytes result sent to driver
[2025-07-19T22:09:57.082+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 133.0 in stage 5.0 (TID 107) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.085+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 121.0 in stage 5.0 (TID 99) in 285 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T22:09:57.087+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 133.0 in stage 5.0 (TID 107)
[2025-07-19T22:09:57.089+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.090+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:57.090+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.097+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.1.delta.02ace9f8-f7b6-4a24-ad1e-b98afd402f17.TID104.tmp
[2025-07-19T22:09:57.105+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.1.delta.a98e2767-e3fb-4b09-b96a-6397f064a92a.TID102.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/1.delta
[2025-07-19T22:09:57.109+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.1.delta.25a3702a-ab73-4f61-8ab2-1c4b0088b059.TID101.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/1.delta
[2025-07-19T22:09:57.109+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/1.delta
[2025-07-19T22:09:57.109+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a536b07
[2025-07-19T22:09:57.110+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/1.delta
[2025-07-19T22:09:57.110+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.110+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131] for update
[2025-07-19T22:09:57.119+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.119+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.1.delta.001a3d25-d5b1-4975-8efa-8621e53746e0.TID105.tmp
[2025-07-19T22:09:57.121+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 101, attempt 0, stage 5.0)
[2025-07-19T22:09:57.121+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 102, attempt 0, stage 5.0)
[2025-07-19T22:09:57.121+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bacb09c
[2025-07-19T22:09:57.126+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.127+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133] for update
[2025-07-19T22:09:57.136+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.145+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.1.delta.0112b6e2-d8f3-42cd-89ea-f192a11f9156.TID106.tmp
[2025-07-19T22:09:57.149+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 122 (task 100, attempt 0, stage 5.0)
[2025-07-19T22:09:57.150+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 126 (task 102, attempt 0, stage 5.0)
[2025-07-19T22:09:57.159+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 126.0 in stage 5.0 (TID 102). 9162 bytes result sent to driver
[2025-07-19T22:09:57.163+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.1.delta.9e379f1f-4d6a-48eb-a3e1-43a7f06c6e1f.TID107.tmp
[2025-07-19T22:09:57.165+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 122.0 in stage 5.0 (TID 100). 9152 bytes result sent to driver
[2025-07-19T22:09:57.166+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 134.0 in stage 5.0 (TID 108) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.169+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 135.0 in stage 5.0 (TID 109) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.170+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 134.0 in stage 5.0 (TID 108)
[2025-07-19T22:09:57.170+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 135.0 in stage 5.0 (TID 109)
[2025-07-19T22:09:57.171+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 126.0 in stage 5.0 (TID 102) in 264 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T22:09:57.172+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.173+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.175+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 122.0 in stage 5.0 (TID 100) in 306 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T22:09:57.177+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.178+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.178+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@705a6dea
[2025-07-19T22:09:57.181+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.1.delta.02ace9f8-f7b6-4a24-ad1e-b98afd402f17.TID104.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/1.delta
[2025-07-19T22:09:57.182+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/1.delta
[2025-07-19T22:09:57.183+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.185+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135] for update
[2025-07-19T22:09:57.186+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 104, attempt 0, stage 5.0)
[2025-07-19T22:09:57.187+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.1.delta.967294fd-548f-4d18-a0aa-fe3eb0e4e3e1.TID103.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/1.delta
[2025-07-19T22:09:57.187+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/1.delta
[2025-07-19T22:09:57.187+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 103, attempt 0, stage 5.0)
[2025-07-19T22:09:57.187+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.188+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ca29069
[2025-07-19T22:09:57.195+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.195+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134] for update
[2025-07-19T22:09:57.200+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 125 (task 101, attempt 0, stage 5.0)
[2025-07-19T22:09:57.204+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 125.0 in stage 5.0 (TID 101). 9171 bytes result sent to driver
[2025-07-19T22:09:57.207+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 137.0 in stage 5.0 (TID 110) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.209+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.212+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.1.delta.001a3d25-d5b1-4975-8efa-8621e53746e0.TID105.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/1.delta
[2025-07-19T22:09:57.213+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/1.delta
[2025-07-19T22:09:57.215+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 105, attempt 0, stage 5.0)
[2025-07-19T22:09:57.216+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 137.0 in stage 5.0 (TID 110)
[2025-07-19T22:09:57.219+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.221+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:57.222+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 125.0 in stage 5.0 (TID 101) in 351 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T22:09:57.229+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.1.delta.3e3dd97d-1be9-4282-840c-84cd4b9d4130.TID109.tmp
[2025-07-19T22:09:57.230+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.1.delta.d69e11ab-34b1-414f-a98e-eae62f9e154f.TID108.tmp
[2025-07-19T22:09:57.235+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6be36b33
[2025-07-19T22:09:57.236+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.1.delta.0112b6e2-d8f3-42cd-89ea-f192a11f9156.TID106.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/1.delta
[2025-07-19T22:09:57.239+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/1.delta
[2025-07-19T22:09:57.241+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.242+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137] for update
[2025-07-19T22:09:57.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 106, attempt 0, stage 5.0)
[2025-07-19T22:09:57.245+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.252+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 129 (task 104, attempt 0, stage 5.0)
[2025-07-19T22:09:57.253+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 129.0 in stage 5.0 (TID 104). 9162 bytes result sent to driver
[2025-07-19T22:09:57.254+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 139.0 in stage 5.0 (TID 111) (8b44f3d35cfa, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.254+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 139.0 in stage 5.0 (TID 111)
[2025-07-19T22:09:57.256+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 128 (task 103, attempt 0, stage 5.0)
[2025-07-19T22:09:57.257+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 128.0 in stage 5.0 (TID 103). 9175 bytes result sent to driver
[2025-07-19T22:09:57.258+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.260+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 141.0 in stage 5.0 (TID 112) (8b44f3d35cfa, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.261+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.1.delta.9e379f1f-4d6a-48eb-a3e1-43a7f06c6e1f.TID107.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/1.delta
[2025-07-19T22:09:57.264+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/1.delta
[2025-07-19T22:09:57.268+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.1.delta.c4dd6117-86c2-4b0c-a665-f298e2516b3a.TID110.tmp
[2025-07-19T22:09:57.270+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 129.0 in stage 5.0 (TID 104) in 320 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T22:09:57.270+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 130 (task 105, attempt 0, stage 5.0)
[2025-07-19T22:09:57.273+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 130.0 in stage 5.0 (TID 105). 9174 bytes result sent to driver
[2025-07-19T22:09:57.274+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 107, attempt 0, stage 5.0)
[2025-07-19T22:09:57.276+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 142.0 in stage 5.0 (TID 113) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.278+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 130.0 in stage 5.0 (TID 105) in 304 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T22:09:57.278+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 141.0 in stage 5.0 (TID 112)
[2025-07-19T22:09:57.278+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 142.0 in stage 5.0 (TID 113)
[2025-07-19T22:09:57.280+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 131 (task 106, attempt 0, stage 5.0)
[2025-07-19T22:09:57.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 128.0 in stage 5.0 (TID 103) in 343 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T22:09:57.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 131.0 in stage 5.0 (TID 106). 9152 bytes result sent to driver
[2025-07-19T22:09:57.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:57.283+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 143.0 in stage 5.0 (TID 114) (8b44f3d35cfa, executor driver, partition 143, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.283+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 143.0 in stage 5.0 (TID 114)
[2025-07-19T22:09:57.283+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
[2025-07-19T22:09:57.283+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 131.0 in stage 5.0 (TID 106) in 260 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T22:09:57.284+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T22:09:57.284+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.287+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.291+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e492920
[2025-07-19T22:09:57.292+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.297+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142] for update
[2025-07-19T22:09:57.299+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 133 (task 107, attempt 0, stage 5.0)
[2025-07-19T22:09:57.300+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 133.0 in stage 5.0 (TID 107). 9173 bytes result sent to driver
[2025-07-19T22:09:57.301+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.303+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 144.0 in stage 5.0 (TID 115) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.306+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 133.0 in stage 5.0 (TID 107) in 220 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T22:09:57.306+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 144.0 in stage 5.0 (TID 115)
[2025-07-19T22:09:57.308+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@269dc5f4
[2025-07-19T22:09:57.309+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.309+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143] for update
[2025-07-19T22:09:57.310+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.312+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.312+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.312+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.1.delta.c4dd6117-86c2-4b0c-a665-f298e2516b3a.TID110.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/1.delta
[2025-07-19T22:09:57.313+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/1.delta
[2025-07-19T22:09:57.326+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.1.delta.0f0bde8a-76b5-4348-8d13-79474851c7b6.TID113.tmp
[2025-07-19T22:09:57.344+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.1.delta.3e3dd97d-1be9-4282-840c-84cd4b9d4130.TID109.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/1.delta
[2025-07-19T22:09:57.352+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/1.delta
[2025-07-19T22:09:57.354+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.1.delta.d69e11ab-34b1-414f-a98e-eae62f9e154f.TID108.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/1.delta
[2025-07-19T22:09:57.355+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/1.delta
[2025-07-19T22:09:57.356+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73f24aa9
[2025-07-19T22:09:57.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 110, attempt 0, stage 5.0)
[2025-07-19T22:09:57.358+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 109, attempt 0, stage 5.0)
[2025-07-19T22:09:57.359+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 108, attempt 0, stage 5.0)
[2025-07-19T22:09:57.360+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.361+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144] for update
[2025-07-19T22:09:57.363+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.1.delta.99a2a9f0-c3b5-48b2-8a90-44ded4be67d2.TID114.tmp
[2025-07-19T22:09:57.363+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.365+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5287f0c1
[2025-07-19T22:09:57.365+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.1.delta.0f7839f1-a808-497f-a825-791b2223f270.TID115.tmp
[2025-07-19T22:09:57.366+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.370+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141] for update
[2025-07-19T22:09:57.375+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 137 (task 110, attempt 0, stage 5.0)
[2025-07-19T22:09:57.376+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 137.0 in stage 5.0 (TID 110). 9164 bytes result sent to driver
[2025-07-19T22:09:57.377+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 145.0 in stage 5.0 (TID 116) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.382+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 137.0 in stage 5.0 (TID 110) in 178 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T22:09:57.384+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43454fc5
[2025-07-19T22:09:57.385+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 145.0 in stage 5.0 (TID 116)
[2025-07-19T22:09:57.386+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.386+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139] for update
[2025-07-19T22:09:57.386+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.398+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.399+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.400+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:57.400+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 134 (task 108, attempt 0, stage 5.0)
[2025-07-19T22:09:57.400+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 134.0 in stage 5.0 (TID 108). 9162 bytes result sent to driver
[2025-07-19T22:09:57.401+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 135 (task 109, attempt 0, stage 5.0)
[2025-07-19T22:09:57.401+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 135.0 in stage 5.0 (TID 109). 9164 bytes result sent to driver
[2025-07-19T22:09:57.402+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 146.0 in stage 5.0 (TID 117) (8b44f3d35cfa, executor driver, partition 146, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.402+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 147.0 in stage 5.0 (TID 118) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.404+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68636d17
[2025-07-19T22:09:57.404+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.404+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145] for update
[2025-07-19T22:09:57.405+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 146.0 in stage 5.0 (TID 117)
[2025-07-19T22:09:57.406+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 134.0 in stage 5.0 (TID 108) in 248 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T22:09:57.406+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 135.0 in stage 5.0 (TID 109) in 246 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T22:09:57.407+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.407+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.407+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.410+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 147.0 in stage 5.0 (TID 118)
[2025-07-19T22:09:57.419+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.1.delta.32260f89-1172-410c-81f9-4b00cef1a13c.TID111.tmp
[2025-07-19T22:09:57.421+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.1.delta.b6bfa8cf-40b6-4bda-a894-be844f419d91.TID112.tmp
[2025-07-19T22:09:57.421+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.422+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.426+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.1.delta.0f0bde8a-76b5-4348-8d13-79474851c7b6.TID113.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/1.delta
[2025-07-19T22:09:57.426+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/1.delta
[2025-07-19T22:09:57.427+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 113, attempt 0, stage 5.0)
[2025-07-19T22:09:57.434+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73d1aa93
[2025-07-19T22:09:57.436+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.1.delta.e2560370-a54e-4146-98b0-3859aff9c731.TID116.tmp
[2025-07-19T22:09:57.436+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.437+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146] for update
[2025-07-19T22:09:57.438+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.453+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a833dc6
[2025-07-19T22:09:57.454+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.454+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 142 (task 113, attempt 0, stage 5.0)
[2025-07-19T22:09:57.455+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147] for update
[2025-07-19T22:09:57.456+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.1.delta.7461671c-971a-4a4a-8067-e2a3d777fc31.TID117.tmp
[2025-07-19T22:09:57.457+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.1.delta.0f7839f1-a808-497f-a825-791b2223f270.TID115.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/1.delta
[2025-07-19T22:09:57.457+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/1.delta
[2025-07-19T22:09:57.458+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 115, attempt 0, stage 5.0)
[2025-07-19T22:09:57.458+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.1.delta.99a2a9f0-c3b5-48b2-8a90-44ded4be67d2.TID114.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/1.delta
[2025-07-19T22:09:57.459+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/1.delta
[2025-07-19T22:09:57.460+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 142.0 in stage 5.0 (TID 113). 9164 bytes result sent to driver
[2025-07-19T22:09:57.461+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 148.0 in stage 5.0 (TID 119) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.462+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 114, attempt 0, stage 5.0)
[2025-07-19T22:09:57.465+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 148.0 in stage 5.0 (TID 119)
[2025-07-19T22:09:57.466+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 142.0 in stage 5.0 (TID 113) in 201 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T22:09:57.466+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.466+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.466+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.476+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7eb065a9
[2025-07-19T22:09:57.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.491+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148] for update
[2025-07-19T22:09:57.491+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.1.delta.81cfd965-cc15-412b-a806-8bcfc3fa33f2.TID118.tmp
[2025-07-19T22:09:57.491+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.496+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 143 (task 114, attempt 0, stage 5.0)
[2025-07-19T22:09:57.497+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 143.0 in stage 5.0 (TID 114). 9169 bytes result sent to driver
[2025-07-19T22:09:57.498+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 149.0 in stage 5.0 (TID 120) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.498+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 149.0 in stage 5.0 (TID 120)
[2025-07-19T22:09:57.498+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 144 (task 115, attempt 0, stage 5.0)
[2025-07-19T22:09:57.498+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 143.0 in stage 5.0 (TID 114) in 222 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T22:09:57.498+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 144.0 in stage 5.0 (TID 115). 9152 bytes result sent to driver
[2025-07-19T22:09:57.499+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.499+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.507+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 150.0 in stage 5.0 (TID 121) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.512+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.1.delta.32260f89-1172-410c-81f9-4b00cef1a13c.TID111.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/1.delta
[2025-07-19T22:09:57.517+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/1.delta
[2025-07-19T22:09:57.518+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 111, attempt 0, stage 5.0)
[2025-07-19T22:09:57.519+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ed1ed83
[2025-07-19T22:09:57.520+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 144.0 in stage 5.0 (TID 115) in 212 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T22:09:57.521+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 150.0 in stage 5.0 (TID 121)
[2025-07-19T22:09:57.522+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.523+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149] for update
[2025-07-19T22:09:57.523+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.1.delta.d8cccc7a-c8ea-425b-b735-9981e36df06c.TID119.tmp
[2025-07-19T22:09:57.524+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.524+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.526+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:57.530+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.1.delta.b6bfa8cf-40b6-4bda-a894-be844f419d91.TID112.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/1.delta
[2025-07-19T22:09:57.535+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.1.delta.d932c2b8-3c82-4e9f-863b-82927e037b93.TID120.tmp
[2025-07-19T22:09:57.535+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.1.delta.e2560370-a54e-4146-98b0-3859aff9c731.TID116.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/1.delta
[2025-07-19T22:09:57.535+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/1.delta
[2025-07-19T22:09:57.535+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/1.delta
[2025-07-19T22:09:57.536+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52a2d37d
[2025-07-19T22:09:57.536+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 116, attempt 0, stage 5.0)
[2025-07-19T22:09:57.536+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 112, attempt 0, stage 5.0)
[2025-07-19T22:09:57.536+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.537+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150] for update
[2025-07-19T22:09:57.545+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.548+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 139 (task 111, attempt 0, stage 5.0)
[2025-07-19T22:09:57.549+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 139.0 in stage 5.0 (TID 111). 9168 bytes result sent to driver
[2025-07-19T22:09:57.561+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.1.delta.7461671c-971a-4a4a-8067-e2a3d777fc31.TID117.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/1.delta
[2025-07-19T22:09:57.562+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/1.delta
[2025-07-19T22:09:57.563+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 117, attempt 0, stage 5.0)
[2025-07-19T22:09:57.564+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 151.0 in stage 5.0 (TID 122) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.567+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 139.0 in stage 5.0 (TID 111) in 317 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T22:09:57.570+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 151.0 in stage 5.0 (TID 122)
[2025-07-19T22:09:57.571+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.1.delta.e2220981-ff67-469c-97b7-e6417d2683ea.TID121.tmp
[2025-07-19T22:09:57.572+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.1.delta.81cfd965-cc15-412b-a806-8bcfc3fa33f2.TID118.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/1.delta
[2025-07-19T22:09:57.573+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/1.delta
[2025-07-19T22:09:57.575+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 118, attempt 0, stage 5.0)
[2025-07-19T22:09:57.578+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.580+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.592+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.1.delta.d8cccc7a-c8ea-425b-b735-9981e36df06c.TID119.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/1.delta
[2025-07-19T22:09:57.592+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/1.delta
[2025-07-19T22:09:57.592+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 119, attempt 0, stage 5.0)
[2025-07-19T22:09:57.594+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3703bc8a
[2025-07-19T22:09:57.595+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 141 (task 112, attempt 0, stage 5.0)
[2025-07-19T22:09:57.598+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 145 (task 116, attempt 0, stage 5.0)
[2025-07-19T22:09:57.598+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.598+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151] for update
[2025-07-19T22:09:57.604+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 145.0 in stage 5.0 (TID 116). 9168 bytes result sent to driver
[2025-07-19T22:09:57.605+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 145.0 in stage 5.0 (TID 116) in 227 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T22:09:57.605+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 141.0 in stage 5.0 (TID 112). 9189 bytes result sent to driver
[2025-07-19T22:09:57.607+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 153.0 in stage 5.0 (TID 123) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.609+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 154.0 in stage 5.0 (TID 124) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.610+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 153.0 in stage 5.0 (TID 123)
[2025-07-19T22:09:57.611+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 154.0 in stage 5.0 (TID 124)
[2025-07-19T22:09:57.612+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 141.0 in stage 5.0 (TID 112) in 355 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T22:09:57.612+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.1.delta.d932c2b8-3c82-4e9f-863b-82927e037b93.TID120.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/1.delta
[2025-07-19T22:09:57.613+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/1.delta
[2025-07-19T22:09:57.616+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.619+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.623+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 120, attempt 0, stage 5.0)
[2025-07-19T22:09:57.624+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2025-07-19T22:09:57.624+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.624+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:57.633+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 146 (task 117, attempt 0, stage 5.0)
[2025-07-19T22:09:57.635+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 147 (task 118, attempt 0, stage 5.0)
[2025-07-19T22:09:57.637+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 147.0 in stage 5.0 (TID 118). 9156 bytes result sent to driver
[2025-07-19T22:09:57.637+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 156.0 in stage 5.0 (TID 125) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.637+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 156.0 in stage 5.0 (TID 125)
[2025-07-19T22:09:57.638+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 146.0 in stage 5.0 (TID 117). 9189 bytes result sent to driver
[2025-07-19T22:09:57.639+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 157.0 in stage 5.0 (TID 126) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.643+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 157.0 in stage 5.0 (TID 126)
[2025-07-19T22:09:57.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31bb20df
[2025-07-19T22:09:57.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 147.0 in stage 5.0 (TID 118) in 243 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T22:09:57.645+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 146.0 in stage 5.0 (TID 117) in 245 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T22:09:57.647+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.649+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153] for update
[2025-07-19T22:09:57.650+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.650+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.1.delta.fdbd14db-4088-4114-8cff-f0b8bc3faac9.TID122.tmp
[2025-07-19T22:09:57.651+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:09:57.654+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.656+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:09:57.657+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 148 (task 119, attempt 0, stage 5.0)
[2025-07-19T22:09:57.668+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.676+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 148.0 in stage 5.0 (TID 119). 9204 bytes result sent to driver
[2025-07-19T22:09:57.677+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 158.0 in stage 5.0 (TID 127) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.677+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12913e93
[2025-07-19T22:09:57.677+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 158.0 in stage 5.0 (TID 127)
[2025-07-19T22:09:57.678+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 148.0 in stage 5.0 (TID 119) in 203 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T22:09:57.679+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.682+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154] for update
[2025-07-19T22:09:57.687+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.690+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:09:57.692+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.1.delta.e2220981-ff67-469c-97b7-e6417d2683ea.TID121.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/1.delta
[2025-07-19T22:09:57.694+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/1.delta
[2025-07-19T22:09:57.697+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 121, attempt 0, stage 5.0)
[2025-07-19T22:09:57.698+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.699+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 149 (task 120, attempt 0, stage 5.0)
[2025-07-19T22:09:57.700+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 149.0 in stage 5.0 (TID 120). 9162 bytes result sent to driver
[2025-07-19T22:09:57.704+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 159.0 in stage 5.0 (TID 128) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.706+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@560eeada
[2025-07-19T22:09:57.706+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.706+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157] for update
[2025-07-19T22:09:57.706+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 149.0 in stage 5.0 (TID 120) in 190 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T22:09:57.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 159.0 in stage 5.0 (TID 128)
[2025-07-19T22:09:57.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.1.delta.99416df5-6b3c-4e01-b480-57734e81eb41.TID123.tmp
[2025-07-19T22:09:57.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.1.delta.e72d6111-6be0-4989-a34a-d03c5d408ef5.TID124.tmp
[2025-07-19T22:09:57.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29d1781f
[2025-07-19T22:09:57.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.707+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156] for update
[2025-07-19T22:09:57.713+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.1.delta.cb3d0526-e1a2-4417-9aa8-df13e883299f.TID126.tmp
[2025-07-19T22:09:57.725+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d6a7c3
[2025-07-19T22:09:57.725+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.726+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159] for update
[2025-07-19T22:09:57.727+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 150 (task 121, attempt 0, stage 5.0)
[2025-07-19T22:09:57.728+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.730+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.731+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 150.0 in stage 5.0 (TID 121). 9175 bytes result sent to driver
[2025-07-19T22:09:57.733+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 150.0 in stage 5.0 (TID 121) in 221 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T22:09:57.736+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 162.0 in stage 5.0 (TID 129) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.738+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 162.0 in stage 5.0 (TID 129)
[2025-07-19T22:09:57.739+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.740+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61bba8ea
[2025-07-19T22:09:57.742+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:09:57.743+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.746+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158] for update
[2025-07-19T22:09:57.747+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.750+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.1.delta.2960fbf6-8427-46e1-973c-0a57db52f617.TID128.tmp
[2025-07-19T22:09:57.756+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.1.delta.48243082-d945-4556-ae7d-46f027b64c26.TID125.tmp
[2025-07-19T22:09:57.757+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.1.delta.fdbd14db-4088-4114-8cff-f0b8bc3faac9.TID122.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/1.delta
[2025-07-19T22:09:57.760+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/1.delta
[2025-07-19T22:09:57.762+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 122, attempt 0, stage 5.0)
[2025-07-19T22:09:57.762+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f59776a
[2025-07-19T22:09:57.763+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.768+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162] for update
[2025-07-19T22:09:57.773+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.775+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.1.delta.085eff11-1d38-43a7-a2ae-8c34599275ca.TID127.tmp
[2025-07-19T22:09:57.788+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.1.delta.99416df5-6b3c-4e01-b480-57734e81eb41.TID123.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/1.delta
[2025-07-19T22:09:57.788+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/1.delta
[2025-07-19T22:09:57.789+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 123, attempt 0, stage 5.0)
[2025-07-19T22:09:57.796+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.1.delta.e72d6111-6be0-4989-a34a-d03c5d408ef5.TID124.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/1.delta
[2025-07-19T22:09:57.797+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/1.delta
[2025-07-19T22:09:57.798+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.1.delta.770c08de-344d-474c-85b8-f18f7890b760.TID129.tmp
[2025-07-19T22:09:57.799+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 124, attempt 0, stage 5.0)
[2025-07-19T22:09:57.806+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.1.delta.cb3d0526-e1a2-4417-9aa8-df13e883299f.TID126.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/1.delta
[2025-07-19T22:09:57.807+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 151 (task 122, attempt 0, stage 5.0)
[2025-07-19T22:09:57.814+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 153 (task 123, attempt 0, stage 5.0)
[2025-07-19T22:09:57.815+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/1.delta
[2025-07-19T22:09:57.817+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 126, attempt 0, stage 5.0)
[2025-07-19T22:09:57.818+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 151.0 in stage 5.0 (TID 122). 9176 bytes result sent to driver
[2025-07-19T22:09:57.820+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 153.0 in stage 5.0 (TID 123). 9166 bytes result sent to driver
[2025-07-19T22:09:57.821+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 165.0 in stage 5.0 (TID 130) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.824+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 165.0 in stage 5.0 (TID 130)
[2025-07-19T22:09:57.825+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 151.0 in stage 5.0 (TID 122) in 255 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T22:09:57.825+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 167.0 in stage 5.0 (TID 131) (8b44f3d35cfa, executor driver, partition 167, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.826+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 167.0 in stage 5.0 (TID 131)
[2025-07-19T22:09:57.827+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 153.0 in stage 5.0 (TID 123) in 222 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T22:09:57.828+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.830+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.832+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.833+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.833+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 154 (task 124, attempt 0, stage 5.0)
[2025-07-19T22:09:57.836+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 154.0 in stage 5.0 (TID 124). 9160 bytes result sent to driver
[2025-07-19T22:09:57.837+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.1.delta.48243082-d945-4556-ae7d-46f027b64c26.TID125.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/1.delta
[2025-07-19T22:09:57.839+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/1.delta
[2025-07-19T22:09:57.840+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 125, attempt 0, stage 5.0)
[2025-07-19T22:09:57.840+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 168.0 in stage 5.0 (TID 132) (8b44f3d35cfa, executor driver, partition 168, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.840+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 168.0 in stage 5.0 (TID 132)
[2025-07-19T22:09:57.841+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 154.0 in stage 5.0 (TID 124) in 232 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T22:09:57.846+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.1.delta.085eff11-1d38-43a7-a2ae-8c34599275ca.TID127.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/1.delta
[2025-07-19T22:09:57.850+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/1.delta
[2025-07-19T22:09:57.850+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.1.delta.2960fbf6-8427-46e1-973c-0a57db52f617.TID128.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/1.delta
[2025-07-19T22:09:57.850+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/1.delta
[2025-07-19T22:09:57.852+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a9e0745
[2025-07-19T22:09:57.852+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 128, attempt 0, stage 5.0)
[2025-07-19T22:09:57.853+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.853+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 127, attempt 0, stage 5.0)
[2025-07-19T22:09:57.854+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167] for update
[2025-07-19T22:09:57.854+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.855+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T22:09:57.856+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.856+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 157 (task 126, attempt 0, stage 5.0)
[2025-07-19T22:09:57.856+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.1.delta.770c08de-344d-474c-85b8-f18f7890b760.TID129.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/1.delta
[2025-07-19T22:09:57.858+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/1.delta
[2025-07-19T22:09:57.858+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 129, attempt 0, stage 5.0)
[2025-07-19T22:09:57.864+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 157.0 in stage 5.0 (TID 126). 9210 bytes result sent to driver
[2025-07-19T22:09:57.867+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a6fb01e
[2025-07-19T22:09:57.869+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.874+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 169.0 in stage 5.0 (TID 133) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.875+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165] for update
[2025-07-19T22:09:57.877+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 169.0 in stage 5.0 (TID 133)
[2025-07-19T22:09:57.878+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79c85416
[2025-07-19T22:09:57.879+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.880+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.881+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 157.0 in stage 5.0 (TID 126) in 239 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T22:09:57.881+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168] for update
[2025-07-19T22:09:57.882+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.1.delta.2b5f7bc2-cb35-44fc-847c-f9c21715390d.TID131.tmp
[2025-07-19T22:09:57.885+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.887+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.888+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 158 (task 127, attempt 0, stage 5.0)
[2025-07-19T22:09:57.888+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.889+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 159 (task 128, attempt 0, stage 5.0)
[2025-07-19T22:09:57.889+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 158.0 in stage 5.0 (TID 127). 9165 bytes result sent to driver
[2025-07-19T22:09:57.891+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 158.0 in stage 5.0 (TID 127) in 227 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T22:09:57.892+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 159.0 in stage 5.0 (TID 128). 9165 bytes result sent to driver
[2025-07-19T22:09:57.897+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 170.0 in stage 5.0 (TID 134) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.901+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 170.0 in stage 5.0 (TID 134)
[2025-07-19T22:09:57.905+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25d9bb95
[2025-07-19T22:09:57.906+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 171.0 in stage 5.0 (TID 135) (8b44f3d35cfa, executor driver, partition 171, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.906+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.907+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.909+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.910+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169] for update
[2025-07-19T22:09:57.911+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 162 (task 129, attempt 0, stage 5.0)
[2025-07-19T22:09:57.912+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 171.0 in stage 5.0 (TID 135)
[2025-07-19T22:09:57.913+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 156 (task 125, attempt 0, stage 5.0)
[2025-07-19T22:09:57.914+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 159.0 in stage 5.0 (TID 128) in 233 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T22:09:57.915+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 162.0 in stage 5.0 (TID 129). 9191 bytes result sent to driver
[2025-07-19T22:09:57.919+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.920+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 172.0 in stage 5.0 (TID 136) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.922+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 156.0 in stage 5.0 (TID 125). 9166 bytes result sent to driver
[2025-07-19T22:09:57.922+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 172.0 in stage 5.0 (TID 136)
[2025-07-19T22:09:57.923+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 173.0 in stage 5.0 (TID 137) (8b44f3d35cfa, executor driver, partition 173, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:57.923+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.1.delta.bc71a449-c9cb-4f19-967c-11d7693c9bc8.TID132.tmp
[2025-07-19T22:09:57.924+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 162.0 in stage 5.0 (TID 129) in 193 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T22:09:57.924+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.928+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 173.0 in stage 5.0 (TID 137)
[2025-07-19T22:09:57.932+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:57.933+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a185de8
[2025-07-19T22:09:57.938+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 156.0 in stage 5.0 (TID 125) in 290 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T22:09:57.939+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.941+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170] for update
[2025-07-19T22:09:57.943+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.1.delta.4bc33a58-3981-4fc1-8d67-81b52b2cd987.TID130.tmp
[2025-07-19T22:09:57.943+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.944+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T22:09:57.945+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.946+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:57.947+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:57.947+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.1.delta.2ff12212-432b-4ce5-b5d4-76a05ba75e77.TID133.tmp
[2025-07-19T22:09:57.948+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@142fe2b8
[2025-07-19T22:09:57.950+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.952+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172] for update
[2025-07-19T22:09:57.954+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.1.delta.d27d0ab8-48f0-4c9b-b12d-98d2853a15c4.TID134.tmp
[2025-07-19T22:09:57.957+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.958+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77226b80
[2025-07-19T22:09:57.959+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.959+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173] for update
[2025-07-19T22:09:57.960+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.961+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.1.delta.2b5f7bc2-cb35-44fc-847c-f9c21715390d.TID131.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/1.delta
[2025-07-19T22:09:57.962+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/1.delta
[2025-07-19T22:09:57.962+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 131, attempt 0, stage 5.0)
[2025-07-19T22:09:57.967+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20fec1d6
[2025-07-19T22:09:57.969+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:57.969+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171] for update
[2025-07-19T22:09:57.974+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.1.delta.918d34ba-18cb-4c49-a49f-3325e56d454b.TID136.tmp
[2025-07-19T22:09:57.975+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.1.delta.c54c6f05-91b6-45a6-a4a0-32fc7cd1ec08.TID137.tmp
[2025-07-19T22:09:57.985+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:57.994+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.1.delta.12cf26a1-f981-4031-8928-32d8f0584ef3.TID135.tmp
[2025-07-19T22:09:57.997+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO DataWritingSparkTask: Committed partition 167 (task 131, attempt 0, stage 5.0)
[2025-07-19T22:09:58.000+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Finished task 167.0 in stage 5.0 (TID 131). 9162 bytes result sent to driver
[2025-07-19T22:09:58.001+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Starting task 174.0 in stage 5.0 (TID 138) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.001+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO TaskSetManager: Finished task 167.0 in stage 5.0 (TID 131) in 175 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T22:09:58.002+0000] {subprocess.py:93} INFO - 25/07/19 22:09:57 INFO Executor: Running task 174.0 in stage 5.0 (TID 138)
[2025-07-19T22:09:58.004+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.004+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.010+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.1.delta.bc71a449-c9cb-4f19-967c-11d7693c9bc8.TID132.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/1.delta
[2025-07-19T22:09:58.011+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/1.delta
[2025-07-19T22:09:58.012+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 132, attempt 0, stage 5.0)
[2025-07-19T22:09:58.013+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@488a62d1
[2025-07-19T22:09:58.014+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.015+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174] for update
[2025-07-19T22:09:58.015+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.1.delta.4bc33a58-3981-4fc1-8d67-81b52b2cd987.TID130.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/1.delta
[2025-07-19T22:09:58.015+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/1.delta
[2025-07-19T22:09:58.016+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 130, attempt 0, stage 5.0)
[2025-07-19T22:09:58.016+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.016+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.1.delta.2ff12212-432b-4ce5-b5d4-76a05ba75e77.TID133.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/1.delta
[2025-07-19T22:09:58.016+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/1.delta
[2025-07-19T22:09:58.032+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.1.delta.d27d0ab8-48f0-4c9b-b12d-98d2853a15c4.TID134.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/1.delta
[2025-07-19T22:09:58.033+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 133, attempt 0, stage 5.0)
[2025-07-19T22:09:58.034+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/1.delta
[2025-07-19T22:09:58.036+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 134, attempt 0, stage 5.0)
[2025-07-19T22:09:58.043+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.1.delta.b6c2c4d5-cc7f-40bd-804b-989d19ea7315.TID138.tmp
[2025-07-19T22:09:58.054+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 168 (task 132, attempt 0, stage 5.0)
[2025-07-19T22:09:58.055+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 168.0 in stage 5.0 (TID 132). 9167 bytes result sent to driver
[2025-07-19T22:09:58.056+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 175.0 in stage 5.0 (TID 139) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.057+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 175.0 in stage 5.0 (TID 139)
[2025-07-19T22:09:58.058+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 165 (task 130, attempt 0, stage 5.0)
[2025-07-19T22:09:58.059+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 168.0 in stage 5.0 (TID 132) in 214 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T22:09:58.060+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 165.0 in stage 5.0 (TID 130). 9152 bytes result sent to driver
[2025-07-19T22:09:58.061+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.062+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 177.0 in stage 5.0 (TID 140) (8b44f3d35cfa, executor driver, partition 177, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.067+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 177.0 in stage 5.0 (TID 140)
[2025-07-19T22:09:58.068+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 170 (task 134, attempt 0, stage 5.0)
[2025-07-19T22:09:58.069+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 165.0 in stage 5.0 (TID 130) in 239 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T22:09:58.071+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.1.delta.918d34ba-18cb-4c49-a49f-3325e56d454b.TID136.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/1.delta
[2025-07-19T22:09:58.073+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/1.delta
[2025-07-19T22:09:58.075+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.076+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.077+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 170.0 in stage 5.0 (TID 134). 9154 bytes result sent to driver
[2025-07-19T22:09:58.078+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T22:09:58.080+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 178.0 in stage 5.0 (TID 141) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.083+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 178.0 in stage 5.0 (TID 141)
[2025-07-19T22:09:58.092+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 170.0 in stage 5.0 (TID 134) in 170 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T22:09:58.095+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.1.delta.c54c6f05-91b6-45a6-a4a0-32fc7cd1ec08.TID137.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/1.delta
[2025-07-19T22:09:58.102+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 136, attempt 0, stage 5.0)
[2025-07-19T22:09:58.107+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/1.delta
[2025-07-19T22:09:58.111+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 137, attempt 0, stage 5.0)
[2025-07-19T22:09:58.112+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.115+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:58.116+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b0cdfcd
[2025-07-19T22:09:58.119+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.120+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177] for update
[2025-07-19T22:09:58.122+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.123+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.1.delta.12cf26a1-f981-4031-8928-32d8f0584ef3.TID135.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/1.delta
[2025-07-19T22:09:58.123+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/1.delta
[2025-07-19T22:09:58.126+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 135, attempt 0, stage 5.0)
[2025-07-19T22:09:58.128+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 169 (task 133, attempt 0, stage 5.0)
[2025-07-19T22:09:58.130+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 169.0 in stage 5.0 (TID 133). 9154 bytes result sent to driver
[2025-07-19T22:09:58.132+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 179.0 in stage 5.0 (TID 142) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.138+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 169.0 in stage 5.0 (TID 133) in 215 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T22:09:58.139+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 179.0 in stage 5.0 (TID 142)
[2025-07-19T22:09:58.140+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@609bbde6
[2025-07-19T22:09:58.140+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.141+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175] for update
[2025-07-19T22:09:58.141+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.142+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:58.143+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.144+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.1.delta.ada2060f-1471-4781-8950-14018707a27d.TID140.tmp
[2025-07-19T22:09:58.145+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 173 (task 137, attempt 0, stage 5.0)
[2025-07-19T22:09:58.145+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 173.0 in stage 5.0 (TID 137). 9158 bytes result sent to driver
[2025-07-19T22:09:58.145+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 171 (task 135, attempt 0, stage 5.0)
[2025-07-19T22:09:58.145+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 180.0 in stage 5.0 (TID 143) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.145+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@640b6b83
[2025-07-19T22:09:58.145+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 171.0 in stage 5.0 (TID 135). 9162 bytes result sent to driver
[2025-07-19T22:09:58.145+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 180.0 in stage 5.0 (TID 143)
[2025-07-19T22:09:58.146+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 173.0 in stage 5.0 (TID 137) in 212 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T22:09:58.146+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 172 (task 136, attempt 0, stage 5.0)
[2025-07-19T22:09:58.146+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.146+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178] for update
[2025-07-19T22:09:58.147+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 172.0 in stage 5.0 (TID 136). 9153 bytes result sent to driver
[2025-07-19T22:09:58.147+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 181.0 in stage 5.0 (TID 144) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.148+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 182.0 in stage 5.0 (TID 145) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.148+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 182.0 in stage 5.0 (TID 145)
[2025-07-19T22:09:58.148+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 181.0 in stage 5.0 (TID 144)
[2025-07-19T22:09:58.149+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 171.0 in stage 5.0 (TID 135) in 229 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T22:09:58.152+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.154+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.157+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.158+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.159+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.161+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 172.0 in stage 5.0 (TID 136) in 223 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T22:09:58.164+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.164+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17237d7
[2025-07-19T22:09:58.164+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.1.delta.b6c2c4d5-cc7f-40bd-804b-989d19ea7315.TID138.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/1.delta
[2025-07-19T22:09:58.165+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/1.delta
[2025-07-19T22:09:58.165+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:58.165+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.167+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179] for update
[2025-07-19T22:09:58.168+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 138, attempt 0, stage 5.0)
[2025-07-19T22:09:58.169+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.170+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.1.delta.9b510b2e-53f7-4e3c-959b-543a6d14fc72.TID139.tmp
[2025-07-19T22:09:58.172+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.1.delta.2bf04499-9777-4388-815a-66b5a5a391d8.TID141.tmp
[2025-07-19T22:09:58.172+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6638b87b
[2025-07-19T22:09:58.172+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.173+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.1.delta.68c98412-24bf-444e-b067-0001ff8b336a.TID142.tmp
[2025-07-19T22:09:58.173+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180] for update
[2025-07-19T22:09:58.174+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.175+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11803f8a
[2025-07-19T22:09:58.177+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.178+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 174 (task 138, attempt 0, stage 5.0)
[2025-07-19T22:09:58.178+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181] for update
[2025-07-19T22:09:58.179+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 174.0 in stage 5.0 (TID 138). 9144 bytes result sent to driver
[2025-07-19T22:09:58.179+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.184+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 183.0 in stage 5.0 (TID 146) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.186+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 174.0 in stage 5.0 (TID 138) in 184 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T22:09:58.187+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.1.delta.e603a9e5-cc3a-475a-9fa5-133d12f47748.TID143.tmp
[2025-07-19T22:09:58.187+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 183.0 in stage 5.0 (TID 146)
[2025-07-19T22:09:58.193+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.193+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.194+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@390ade54
[2025-07-19T22:09:58.195+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.195+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.1.delta.ada2060f-1471-4781-8950-14018707a27d.TID140.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/1.delta
[2025-07-19T22:09:58.196+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/1.delta
[2025-07-19T22:09:58.197+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 140, attempt 0, stage 5.0)
[2025-07-19T22:09:58.199+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182] for update
[2025-07-19T22:09:58.200+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.1.delta.48919322-597a-4c01-ab3f-d9a8e6b25a4d.TID144.tmp
[2025-07-19T22:09:58.201+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.203+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1917ca9c
[2025-07-19T22:09:58.204+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.204+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183] for update
[2025-07-19T22:09:58.208+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.223+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.1.delta.2bf04499-9777-4388-815a-66b5a5a391d8.TID141.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/1.delta
[2025-07-19T22:09:58.224+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/1.delta
[2025-07-19T22:09:58.224+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 177 (task 140, attempt 0, stage 5.0)
[2025-07-19T22:09:58.226+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.1.delta.9b510b2e-53f7-4e3c-959b-543a6d14fc72.TID139.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/1.delta
[2025-07-19T22:09:58.226+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/1.delta
[2025-07-19T22:09:58.227+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 141, attempt 0, stage 5.0)
[2025-07-19T22:09:58.227+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 139, attempt 0, stage 5.0)
[2025-07-19T22:09:58.227+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 177.0 in stage 5.0 (TID 140). 9153 bytes result sent to driver
[2025-07-19T22:09:58.228+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 184.0 in stage 5.0 (TID 147) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.233+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.1.delta.68c98412-24bf-444e-b067-0001ff8b336a.TID142.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/1.delta
[2025-07-19T22:09:58.234+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/1.delta
[2025-07-19T22:09:58.236+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 142, attempt 0, stage 5.0)
[2025-07-19T22:09:58.236+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 184.0 in stage 5.0 (TID 147)
[2025-07-19T22:09:58.236+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 177.0 in stage 5.0 (TID 140) in 177 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T22:09:58.236+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.1.delta.95c57cc5-364e-4d41-941d-268a7ee6bf9f.TID145.tmp
[2025-07-19T22:09:58.236+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.1.delta.dbb292c8-2fb2-4596-b7b1-4bc118f6a5c2.TID146.tmp
[2025-07-19T22:09:58.236+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.237+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.243+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50b52265
[2025-07-19T22:09:58.250+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.251+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184] for update
[2025-07-19T22:09:58.252+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.259+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.1.delta.e603a9e5-cc3a-475a-9fa5-133d12f47748.TID143.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/1.delta
[2025-07-19T22:09:58.260+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/1.delta
[2025-07-19T22:09:58.264+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 143, attempt 0, stage 5.0)
[2025-07-19T22:09:58.267+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 179 (task 142, attempt 0, stage 5.0)
[2025-07-19T22:09:58.268+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 179.0 in stage 5.0 (TID 142). 9150 bytes result sent to driver
[2025-07-19T22:09:58.269+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 185.0 in stage 5.0 (TID 148) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.269+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 179.0 in stage 5.0 (TID 142) in 183 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T22:09:58.274+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 185.0 in stage 5.0 (TID 148)
[2025-07-19T22:09:58.277+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 175 (task 139, attempt 0, stage 5.0)
[2025-07-19T22:09:58.279+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 175.0 in stage 5.0 (TID 139). 9164 bytes result sent to driver
[2025-07-19T22:09:58.282+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.1.delta.e2c137a6-28c4-41fe-9901-2e3bbbc13ea7.TID147.tmp
[2025-07-19T22:09:58.284+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 187.0 in stage 5.0 (TID 149) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.286+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 175.0 in stage 5.0 (TID 139) in 232 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T22:09:58.288+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 187.0 in stage 5.0 (TID 149)
[2025-07-19T22:09:58.290+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.290+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T22:09:58.294+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.1.delta.48919322-597a-4c01-ab3f-d9a8e6b25a4d.TID144.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/1.delta
[2025-07-19T22:09:58.297+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/1.delta
[2025-07-19T22:09:58.303+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 178 (task 141, attempt 0, stage 5.0)
[2025-07-19T22:09:58.307+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 144, attempt 0, stage 5.0)
[2025-07-19T22:09:58.309+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 180 (task 143, attempt 0, stage 5.0)
[2025-07-19T22:09:58.314+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 178.0 in stage 5.0 (TID 141). 9156 bytes result sent to driver
[2025-07-19T22:09:58.315+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.316+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.321+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 188.0 in stage 5.0 (TID 150) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.324+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 188.0 in stage 5.0 (TID 150)
[2025-07-19T22:09:58.326+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 178.0 in stage 5.0 (TID 141) in 236 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T22:09:58.328+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 180.0 in stage 5.0 (TID 143). 9196 bytes result sent to driver
[2025-07-19T22:09:58.328+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 189.0 in stage 5.0 (TID 151) (8b44f3d35cfa, executor driver, partition 189, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.333+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2775a933
[2025-07-19T22:09:58.335+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 189.0 in stage 5.0 (TID 151)
[2025-07-19T22:09:58.337+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.340+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185] for update
[2025-07-19T22:09:58.343+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.1.delta.95c57cc5-364e-4d41-941d-268a7ee6bf9f.TID145.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/1.delta
[2025-07-19T22:09:58.345+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/1.delta
[2025-07-19T22:09:58.348+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.354+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 145, attempt 0, stage 5.0)
[2025-07-19T22:09:58.356+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.356+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 180.0 in stage 5.0 (TID 143) in 173 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T22:09:58.356+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.357+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.358+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.359+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c238ab0
[2025-07-19T22:09:58.360+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.361+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187] for update
[2025-07-19T22:09:58.363+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.1.delta.dbb292c8-2fb2-4596-b7b1-4bc118f6a5c2.TID146.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/1.delta
[2025-07-19T22:09:58.364+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/1.delta
[2025-07-19T22:09:58.365+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 146, attempt 0, stage 5.0)
[2025-07-19T22:09:58.366+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ca3df05
[2025-07-19T22:09:58.366+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.367+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188] for update
[2025-07-19T22:09:58.367+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.1.delta.4fe5f353-fc6c-456b-97f7-bd13ad0c5566.TID148.tmp
[2025-07-19T22:09:58.368+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.369+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.371+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cf8466f
[2025-07-19T22:09:58.374+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.1.delta.9ed69efe-6b46-4bfa-a88e-5b51f99cb83b.TID149.tmp
[2025-07-19T22:09:58.375+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 181 (task 144, attempt 0, stage 5.0)
[2025-07-19T22:09:58.375+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.375+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189] for update
[2025-07-19T22:09:58.375+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 181.0 in stage 5.0 (TID 144). 9199 bytes result sent to driver
[2025-07-19T22:09:58.376+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 192.0 in stage 5.0 (TID 152) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.377+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 181.0 in stage 5.0 (TID 144) in 229 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T22:09:58.379+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 192.0 in stage 5.0 (TID 152)
[2025-07-19T22:09:58.381+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.381+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.1.delta.e39c2a2e-a3eb-4f71-b861-4c01f3c0c1bc.TID150.tmp
[2025-07-19T22:09:58.384+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 182 (task 145, attempt 0, stage 5.0)
[2025-07-19T22:09:58.385+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.386+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 182.0 in stage 5.0 (TID 145). 9204 bytes result sent to driver
[2025-07-19T22:09:58.386+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:58.386+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 183 (task 146, attempt 0, stage 5.0)
[2025-07-19T22:09:58.386+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 183.0 in stage 5.0 (TID 146). 9184 bytes result sent to driver
[2025-07-19T22:09:58.387+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 194.0 in stage 5.0 (TID 153) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.387+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 196.0 in stage 5.0 (TID 154) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.387+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 194.0 in stage 5.0 (TID 153)
[2025-07-19T22:09:58.387+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 182.0 in stage 5.0 (TID 145) in 247 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T22:09:58.388+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 196.0 in stage 5.0 (TID 154)
[2025-07-19T22:09:58.389+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 183.0 in stage 5.0 (TID 146) in 199 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T22:09:58.390+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a742652
[2025-07-19T22:09:58.390+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.390+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192] for update
[2025-07-19T22:09:58.391+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.1.delta.e1682b16-7b8f-4278-b791-c6602f0222c7.TID151.tmp
[2025-07-19T22:09:58.393+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.393+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:09:58.395+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.1.delta.e2c137a6-28c4-41fe-9901-2e3bbbc13ea7.TID147.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/1.delta
[2025-07-19T22:09:58.395+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/1.delta
[2025-07-19T22:09:58.396+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 147, attempt 0, stage 5.0)
[2025-07-19T22:09:58.396+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.396+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.396+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.404+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b0187d5
[2025-07-19T22:09:58.407+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.407+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196] for update
[2025-07-19T22:09:58.414+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18785113
[2025-07-19T22:09:58.416+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.1.delta.f4555db9-d1e0-48cf-b65f-3da6ac0b825b.TID152.tmp
[2025-07-19T22:09:58.417+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.418+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194] for update
[2025-07-19T22:09:58.418+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.419+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.425+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.1.delta.4fe5f353-fc6c-456b-97f7-bd13ad0c5566.TID148.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/1.delta
[2025-07-19T22:09:58.427+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/1.delta
[2025-07-19T22:09:58.428+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 148, attempt 0, stage 5.0)
[2025-07-19T22:09:58.439+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.1.delta.9ed69efe-6b46-4bfa-a88e-5b51f99cb83b.TID149.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/1.delta
[2025-07-19T22:09:58.440+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.1.delta.e39c2a2e-a3eb-4f71-b861-4c01f3c0c1bc.TID150.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/1.delta
[2025-07-19T22:09:58.441+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/1.delta
[2025-07-19T22:09:58.442+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/1.delta
[2025-07-19T22:09:58.442+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 149, attempt 0, stage 5.0)
[2025-07-19T22:09:58.443+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.1.delta.56ceaa7f-90ef-4285-a1db-c9b704572344.TID154.tmp
[2025-07-19T22:09:58.444+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 150, attempt 0, stage 5.0)
[2025-07-19T22:09:58.444+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 184 (task 147, attempt 0, stage 5.0)
[2025-07-19T22:09:58.445+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 184.0 in stage 5.0 (TID 147). 9150 bytes result sent to driver
[2025-07-19T22:09:58.446+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 197.0 in stage 5.0 (TID 155) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.447+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.1.delta.af2410bc-8eb5-4bcb-880c-b7581bc2a824.TID153.tmp
[2025-07-19T22:09:58.448+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 197.0 in stage 5.0 (TID 155)
[2025-07-19T22:09:58.448+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 184.0 in stage 5.0 (TID 147) in 210 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T22:09:58.449+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.449+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:09:58.454+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.1.delta.e1682b16-7b8f-4278-b791-c6602f0222c7.TID151.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/1.delta
[2025-07-19T22:09:58.456+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/1.delta
[2025-07-19T22:09:58.458+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 151, attempt 0, stage 5.0)
[2025-07-19T22:09:58.460+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23f51893
[2025-07-19T22:09:58.461+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.462+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197] for update
[2025-07-19T22:09:58.464+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.465+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 185 (task 148, attempt 0, stage 5.0)
[2025-07-19T22:09:58.466+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 188 (task 150, attempt 0, stage 5.0)
[2025-07-19T22:09:58.467+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 188.0 in stage 5.0 (TID 150). 9163 bytes result sent to driver
[2025-07-19T22:09:58.469+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 185.0 in stage 5.0 (TID 148). 9156 bytes result sent to driver
[2025-07-19T22:09:58.474+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 198.0 in stage 5.0 (TID 156) (8b44f3d35cfa, executor driver, partition 198, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.478+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 187 (task 149, attempt 0, stage 5.0)
[2025-07-19T22:09:58.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 198.0 in stage 5.0 (TID 156)
[2025-07-19T22:09:58.482+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 199.0 in stage 5.0 (TID 157) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.488+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 185.0 in stage 5.0 (TID 148) in 210 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T22:09:58.492+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 199.0 in stage 5.0 (TID 157)
[2025-07-19T22:09:58.494+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 187.0 in stage 5.0 (TID 149). 9171 bytes result sent to driver
[2025-07-19T22:09:58.496+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 158) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.497+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.498+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:58.499+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.500+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:09:58.503+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 5.0 in stage 5.0 (TID 158)
[2025-07-19T22:09:58.503+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 188.0 in stage 5.0 (TID 150) in 184 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T22:09:58.503+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 189 (task 151, attempt 0, stage 5.0)
[2025-07-19T22:09:58.506+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.509+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 187.0 in stage 5.0 (TID 149) in 201 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T22:09:58.511+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:58.512+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 189.0 in stage 5.0 (TID 151). 9158 bytes result sent to driver
[2025-07-19T22:09:58.516+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.1.delta.98418b7a-cb70-48f4-8c66-b4d3f6931953.TID155.tmp
[2025-07-19T22:09:58.517+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.1.delta.f4555db9-d1e0-48cf-b65f-3da6ac0b825b.TID152.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/1.delta
[2025-07-19T22:09:58.517+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/1.delta
[2025-07-19T22:09:58.517+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 159) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.518+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 152, attempt 0, stage 5.0)
[2025-07-19T22:09:58.521+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 189.0 in stage 5.0 (TID 151) in 188 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T22:09:58.522+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40a7ab48
[2025-07-19T22:09:58.523+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.524+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199] for update
[2025-07-19T22:09:58.526+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 6.0 in stage 5.0 (TID 159)
[2025-07-19T22:09:58.526+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.527+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.529+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.530+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.1.delta.56ceaa7f-90ef-4285-a1db-c9b704572344.TID154.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/1.delta
[2025-07-19T22:09:58.532+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/1.delta
[2025-07-19T22:09:58.533+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b5a66cf
[2025-07-19T22:09:58.534+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.534+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 154, attempt 0, stage 5.0)
[2025-07-19T22:09:58.534+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5] for update
[2025-07-19T22:09:58.535+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.1.delta.af2410bc-8eb5-4bcb-880c-b7581bc2a824.TID153.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/1.delta
[2025-07-19T22:09:58.535+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/1.delta
[2025-07-19T22:09:58.535+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 153, attempt 0, stage 5.0)
[2025-07-19T22:09:58.535+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.535+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f95189c
[2025-07-19T22:09:58.536+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.536+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198] for update
[2025-07-19T22:09:58.537+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.537+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@722e4db5
[2025-07-19T22:09:58.537+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.1.delta.b4278a82-b10a-438d-99e0-0e5d6fb5455d.TID157.tmp
[2025-07-19T22:09:58.538+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.540+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6] for update
[2025-07-19T22:09:58.542+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 196 (task 154, attempt 0, stage 5.0)
[2025-07-19T22:09:58.542+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.548+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 196.0 in stage 5.0 (TID 154). 9162 bytes result sent to driver
[2025-07-19T22:09:58.554+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.1.delta.beaab84b-5ad0-4a26-bb23-e94788e918b6.TID156.tmp
[2025-07-19T22:09:58.555+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.1.delta.381693a5-ff2b-44e5-b7a6-a7fe0120fa1d.TID158.tmp
[2025-07-19T22:09:58.556+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 194 (task 153, attempt 0, stage 5.0)
[2025-07-19T22:09:58.557+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 192 (task 152, attempt 0, stage 5.0)
[2025-07-19T22:09:58.558+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 192.0 in stage 5.0 (TID 152). 9150 bytes result sent to driver
[2025-07-19T22:09:58.558+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 194.0 in stage 5.0 (TID 153). 9219 bytes result sent to driver
[2025-07-19T22:09:58.561+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 160) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.563+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 17.0 in stage 5.0 (TID 160)
[2025-07-19T22:09:58.567+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 161) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.567+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 19.0 in stage 5.0 (TID 161)
[2025-07-19T22:09:58.571+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.1.delta.607fb014-e0a9-458a-b24b-c179cb12ad00.TID159.tmp
[2025-07-19T22:09:58.572+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.572+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.573+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.574+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.575+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 162) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.575+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 21.0 in stage 5.0 (TID 162)
[2025-07-19T22:09:58.576+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 196.0 in stage 5.0 (TID 154) in 197 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T22:09:58.579+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 194.0 in stage 5.0 (TID 153) in 200 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T22:09:58.579+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 192.0 in stage 5.0 (TID 152) in 219 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T22:09:58.580+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.580+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.585+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.1.delta.98418b7a-cb70-48f4-8c66-b4d3f6931953.TID155.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/1.delta
[2025-07-19T22:09:58.586+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/1.delta
[2025-07-19T22:09:58.590+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 155, attempt 0, stage 5.0)
[2025-07-19T22:09:58.593+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bcf025
[2025-07-19T22:09:58.596+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.597+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17] for update
[2025-07-19T22:09:58.605+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.610+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.1.delta.beaab84b-5ad0-4a26-bb23-e94788e918b6.TID156.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/1.delta
[2025-07-19T22:09:58.611+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/1.delta
[2025-07-19T22:09:58.611+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 156, attempt 0, stage 5.0)
[2025-07-19T22:09:58.613+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35a5d535
[2025-07-19T22:09:58.614+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.615+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21] for update
[2025-07-19T22:09:58.638+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.1.delta.381693a5-ff2b-44e5-b7a6-a7fe0120fa1d.TID158.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/1.delta
[2025-07-19T22:09:58.644+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.1.delta.607fb014-e0a9-458a-b24b-c179cb12ad00.TID159.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/1.delta
[2025-07-19T22:09:58.645+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.1.delta.b4278a82-b10a-438d-99e0-0e5d6fb5455d.TID157.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/1.delta
[2025-07-19T22:09:58.647+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/1.delta
[2025-07-19T22:09:58.648+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/1.delta
[2025-07-19T22:09:58.649+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.1.delta.99c09056-c14a-4887-918a-c968ae7cff6d.TID160.tmp
[2025-07-19T22:09:58.650+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 157, attempt 0, stage 5.0)
[2025-07-19T22:09:58.657+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/1.delta
[2025-07-19T22:09:58.672+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 158, attempt 0, stage 5.0)
[2025-07-19T22:09:58.679+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.680+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 159, attempt 0, stage 5.0)
[2025-07-19T22:09:58.681+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2040e28a
[2025-07-19T22:09:58.683+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.684+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19] for update
[2025-07-19T22:09:58.687+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 198 (task 156, attempt 0, stage 5.0)
[2025-07-19T22:09:58.687+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.702+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 198.0 in stage 5.0 (TID 156). 9197 bytes result sent to driver
[2025-07-19T22:09:58.729+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 163) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.753+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 197 (task 155, attempt 0, stage 5.0)
[2025-07-19T22:09:58.758+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 198.0 in stage 5.0 (TID 156) in 266 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T22:09:58.759+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 197.0 in stage 5.0 (TID 155). 9199 bytes result sent to driver
[2025-07-19T22:09:58.759+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 24.0 in stage 5.0 (TID 163)
[2025-07-19T22:09:58.760+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 164) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.760+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 197.0 in stage 5.0 (TID 155) in 319 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T22:09:58.761+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 25.0 in stage 5.0 (TID 164)
[2025-07-19T22:09:58.774+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 6 (task 159, attempt 0, stage 5.0)
[2025-07-19T22:09:58.777+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 5 (task 158, attempt 0, stage 5.0)
[2025-07-19T22:09:58.778+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 5.0 in stage 5.0 (TID 158). 6243 bytes result sent to driver
[2025-07-19T22:09:58.779+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 6.0 in stage 5.0 (TID 159). 6243 bytes result sent to driver
[2025-07-19T22:09:58.800+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 165) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.802+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 29.0 in stage 5.0 (TID 165)
[2025-07-19T22:09:58.808+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 166) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.818+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.822+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.824+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T22:09:58.824+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 32.0 in stage 5.0 (TID 166)
[2025-07-19T22:09:58.825+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 158) in 346 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T22:09:58.826+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T22:09:58.828+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 159) in 338 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T22:09:58.830+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Committed partition 199 (task 157, attempt 0, stage 5.0)
[2025-07-19T22:09:58.833+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Finished task 199.0 in stage 5.0 (TID 157). 9197 bytes result sent to driver
[2025-07-19T22:09:58.835+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.835+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.836+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.1.delta.340ea7d0-fda1-408e-9a81-8fac6d7621bd.TID162.tmp
[2025-07-19T22:09:58.836+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.838+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.1.delta.e1041634-d419-4620-8d56-e27c2f6937ee.TID161.tmp
[2025-07-19T22:09:58.840+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.841+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 167) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:58.843+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO TaskSetManager: Finished task 199.0 in stage 5.0 (TID 157) in 365 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T22:09:58.846+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO Executor: Running task 34.0 in stage 5.0 (TID 167)
[2025-07-19T22:09:58.846+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a6c6372
[2025-07-19T22:09:58.847+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.850+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25] for update
[2025-07-19T22:09:58.862+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:58.862+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:58.864+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.877+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d00932a
[2025-07-19T22:09:58.879+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.884+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29] for update
[2025-07-19T22:09:58.889+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.927+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d51a109
[2025-07-19T22:09:58.928+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.928+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32] for update
[2025-07-19T22:09:58.950+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:58.954+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.1.delta.b3529e39-5786-4198-9f44-9a4badfcfb5c.TID164.tmp
[2025-07-19T22:09:58.962+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.1.delta.99c09056-c14a-4887-918a-c968ae7cff6d.TID160.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/1.delta
[2025-07-19T22:09:58.963+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/1.delta
[2025-07-19T22:09:58.978+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10271ab
[2025-07-19T22:09:58.983+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 160, attempt 0, stage 5.0)
[2025-07-19T22:09:58.986+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:58.991+0000] {subprocess.py:93} INFO - 25/07/19 22:09:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24] for update
[2025-07-19T22:09:59.057+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:59.058+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Committed partition 17 (task 160, attempt 0, stage 5.0)
[2025-07-19T22:09:59.061+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.1.delta.20518c37-0806-4221-8689-52039d3be6dc.TID165.tmp
[2025-07-19T22:09:59.063+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e72d609
[2025-07-19T22:09:59.065+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:59.066+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34] for update
[2025-07-19T22:09:59.067+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Finished task 17.0 in stage 5.0 (TID 160). 6243 bytes result sent to driver
[2025-07-19T22:09:59.090+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 168) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:59.091+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Running task 36.0 in stage 5.0 (TID 168)
[2025-07-19T22:09:59.094+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 160) in 516 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T22:09:59.095+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.1.delta.340ea7d0-fda1-408e-9a81-8fac6d7621bd.TID162.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/1.delta
[2025-07-19T22:09:59.096+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/1.delta
[2025-07-19T22:09:59.103+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 162, attempt 0, stage 5.0)
[2025-07-19T22:09:59.107+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:59.157+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.1.delta.f5b6a5a3-fa45-4273-aa8e-111a6fe016f3.TID166.tmp
[2025-07-19T22:09:59.158+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Committed partition 21 (task 162, attempt 0, stage 5.0)
[2025-07-19T22:09:59.206+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:59.208+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:59.209+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.1.delta.134b1ce6-f91b-4960-9684-4cb68df65be6.TID167.tmp
[2025-07-19T22:09:59.217+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Finished task 21.0 in stage 5.0 (TID 162). 6286 bytes result sent to driver
[2025-07-19T22:09:59.223+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 169) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:59.224+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 162) in 652 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T22:09:59.229+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Running task 49.0 in stage 5.0 (TID 169)
[2025-07-19T22:09:59.238+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d04e3fe
[2025-07-19T22:09:59.241+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.1.delta.e1041634-d419-4620-8d56-e27c2f6937ee.TID161.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/1.delta
[2025-07-19T22:09:59.242+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/1.delta
[2025-07-19T22:09:59.243+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:59.243+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 161, attempt 0, stage 5.0)
[2025-07-19T22:09:59.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36] for update
[2025-07-19T22:09:59.244+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:59.248+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:59.258+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:59.262+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Committed partition 19 (task 161, attempt 0, stage 5.0)
[2025-07-19T22:09:59.265+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Finished task 19.0 in stage 5.0 (TID 161). 6243 bytes result sent to driver
[2025-07-19T22:09:59.273+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.1.delta.f0421507-8242-4e9b-a6ab-d401bafe6d20.TID163.tmp
[2025-07-19T22:09:59.274+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Starting task 53.0 in stage 5.0 (TID 170) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:59.276+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f508bd0
[2025-07-19T22:09:59.277+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 161) in 712 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T22:09:59.308+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:59.326+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Running task 53.0 in stage 5.0 (TID 170)
[2025-07-19T22:09:59.368+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49] for update
[2025-07-19T22:09:59.403+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:59.418+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T22:09:59.421+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:59.426+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.1.delta.abbee8a4-2553-4248-abed-9f119072cfb6.TID168.tmp
[2025-07-19T22:09:59.447+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15861a63
[2025-07-19T22:09:59.456+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:59.462+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53] for update
[2025-07-19T22:09:59.463+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:59.472+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.1.delta.f5b6a5a3-fa45-4273-aa8e-111a6fe016f3.TID166.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/1.delta
[2025-07-19T22:09:59.475+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.1.delta.134b1ce6-f91b-4960-9684-4cb68df65be6.TID167.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/1.delta
[2025-07-19T22:09:59.476+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/1.delta
[2025-07-19T22:09:59.479+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/1.delta
[2025-07-19T22:09:59.480+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 166, attempt 0, stage 5.0)
[2025-07-19T22:09:59.482+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 167, attempt 0, stage 5.0)
[2025-07-19T22:09:59.484+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.1.delta.70e0ea6f-472b-4496-a902-f9e44a382340.TID169.tmp
[2025-07-19T22:09:59.488+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.1.delta.8024d01c-959f-48bb-99a3-c4a2fe691a89.TID170.tmp
[2025-07-19T22:09:59.509+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.1.delta.b3529e39-5786-4198-9f44-9a4badfcfb5c.TID164.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/1.delta
[2025-07-19T22:09:59.513+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/1.delta
[2025-07-19T22:09:59.516+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 164, attempt 0, stage 5.0)
[2025-07-19T22:09:59.519+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Committed partition 32 (task 166, attempt 0, stage 5.0)
[2025-07-19T22:09:59.520+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Finished task 32.0 in stage 5.0 (TID 166). 6243 bytes result sent to driver
[2025-07-19T22:09:59.524+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Committed partition 34 (task 167, attempt 0, stage 5.0)
[2025-07-19T22:09:59.526+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Finished task 34.0 in stage 5.0 (TID 167). 6243 bytes result sent to driver
[2025-07-19T22:09:59.527+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Committed partition 25 (task 164, attempt 0, stage 5.0)
[2025-07-19T22:09:59.529+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Starting task 61.0 in stage 5.0 (TID 171) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:59.546+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Running task 61.0 in stage 5.0 (TID 171)
[2025-07-19T22:09:59.547+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Starting task 64.0 in stage 5.0 (TID 172) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:59.552+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Finished task 25.0 in stage 5.0 (TID 164). 6286 bytes result sent to driver
[2025-07-19T22:09:59.559+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 166) in 742 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T22:09:59.560+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 167) in 718 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T22:09:59.560+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.1.delta.20518c37-0806-4221-8689-52039d3be6dc.TID165.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/1.delta
[2025-07-19T22:09:59.561+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/1.delta
[2025-07-19T22:09:59.562+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:59.564+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:59.566+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 165, attempt 0, stage 5.0)
[2025-07-19T22:09:59.568+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Running task 64.0 in stage 5.0 (TID 172)
[2025-07-19T22:09:59.570+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Starting task 69.0 in stage 5.0 (TID 173) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:59.573+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 164) in 808 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T22:09:59.574+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Running task 69.0 in stage 5.0 (TID 173)
[2025-07-19T22:09:59.574+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:59.575+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:09:59.576+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Committed partition 29 (task 165, attempt 0, stage 5.0)
[2025-07-19T22:09:59.581+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Finished task 29.0 in stage 5.0 (TID 165). 6243 bytes result sent to driver
[2025-07-19T22:09:59.582+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:59.582+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Starting task 70.0 in stage 5.0 (TID 174) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:09:59.588+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:09:59.591+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 165) in 781 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T22:09:59.592+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO Executor: Running task 70.0 in stage 5.0 (TID 174)
[2025-07-19T22:09:59.592+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c00fb9a
[2025-07-19T22:09:59.593+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:59.596+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61] for update
[2025-07-19T22:09:59.601+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:59.607+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:09:59.613+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:09:59.867+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49d75ebf
[2025-07-19T22:09:59.928+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:09:59.937+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64] for update
[2025-07-19T22:09:59.938+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.1.delta.abbee8a4-2553-4248-abed-9f119072cfb6.TID168.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/1.delta
[2025-07-19T22:09:59.939+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/1.delta
[2025-07-19T22:09:59.940+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 168, attempt 0, stage 5.0)
[2025-07-19T22:09:59.940+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:09:59.941+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.1.delta.f0421507-8242-4e9b-a6ab-d401bafe6d20.TID163.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/1.delta
[2025-07-19T22:09:59.941+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/1.delta
[2025-07-19T22:09:59.941+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 163, attempt 0, stage 5.0)
[2025-07-19T22:09:59.941+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.1.delta.70e0ea6f-472b-4496-a902-f9e44a382340.TID169.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/1.delta
[2025-07-19T22:09:59.942+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/1.delta
[2025-07-19T22:09:59.943+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.1.delta.47732d6b-edb6-4926-86ed-81afd273fcba.TID171.tmp
[2025-07-19T22:09:59.945+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.1.delta.07e26ef4-8382-453d-a9cb-541fd4ea2365.TID172.tmp
[2025-07-19T22:09:59.946+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 169, attempt 0, stage 5.0)
[2025-07-19T22:10:00.002+0000] {subprocess.py:93} INFO - 25/07/19 22:09:59 INFO DataWritingSparkTask: Committed partition 36 (task 168, attempt 0, stage 5.0)
[2025-07-19T22:10:00.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 49 (task 169, attempt 0, stage 5.0)
[2025-07-19T22:10:00.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 24 (task 163, attempt 0, stage 5.0)
[2025-07-19T22:10:00.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 36.0 in stage 5.0 (TID 168). 6286 bytes result sent to driver
[2025-07-19T22:10:00.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 49.0 in stage 5.0 (TID 169). 6286 bytes result sent to driver
[2025-07-19T22:10:00.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 24.0 in stage 5.0 (TID 163). 6243 bytes result sent to driver
[2025-07-19T22:10:00.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 73.0 in stage 5.0 (TID 175) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.077+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 73.0 in stage 5.0 (TID 175)
[2025-07-19T22:10:00.086+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 81.0 in stage 5.0 (TID 176) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 89.0 in stage 5.0 (TID 177) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.1.delta.8024d01c-959f-48bb-99a3-c4a2fe691a89.TID170.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/1.delta
[2025-07-19T22:10:00.102+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73042ef
[2025-07-19T22:10:00.103+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.104+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 89.0 in stage 5.0 (TID 177)
[2025-07-19T22:10:00.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69] for update
[2025-07-19T22:10:00.121+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/1.delta
[2025-07-19T22:10:00.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 81.0 in stage 5.0 (TID 176)
[2025-07-19T22:10:00.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 169) in 856 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T22:10:00.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 170, attempt 0, stage 5.0)
[2025-07-19T22:10:00.153+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 163) in 1361 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T22:10:00.154+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 168) in 1019 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T22:10:00.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:00.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:00.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 53 (task 170, attempt 0, stage 5.0)
[2025-07-19T22:10:00.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 53.0 in stage 5.0 (TID 170). 6243 bytes result sent to driver
[2025-07-19T22:10:00.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1038cbd9
[2025-07-19T22:10:00.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 91.0 in stage 5.0 (TID 178) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 91.0 in stage 5.0 (TID 178)
[2025-07-19T22:10:00.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70] for update
[2025-07-19T22:10:00.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 53.0 in stage 5.0 (TID 170) in 903 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T22:10:00.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@260fba98
[2025-07-19T22:10:00.295+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89] for update
[2025-07-19T22:10:00.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.313+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b42063b
[2025-07-19T22:10:00.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.1.delta.c5a8e24b-3dbd-4fa2-8c3b-86cf106fee44.TID173.tmp
[2025-07-19T22:10:00.317+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.1.delta.9c548392-2275-4379-aa97-4d582e0e4545.TID174.tmp
[2025-07-19T22:10:00.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81] for update
[2025-07-19T22:10:00.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.1.delta.47732d6b-edb6-4926-86ed-81afd273fcba.TID171.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/1.delta
[2025-07-19T22:10:00.355+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/1.delta
[2025-07-19T22:10:00.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 171, attempt 0, stage 5.0)
[2025-07-19T22:10:00.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21385dc6
[2025-07-19T22:10:00.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 61 (task 171, attempt 0, stage 5.0)
[2025-07-19T22:10:00.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73] for update
[2025-07-19T22:10:00.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 61.0 in stage 5.0 (TID 171). 6200 bytes result sent to driver
[2025-07-19T22:10:00.387+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 92.0 in stage 5.0 (TID 179) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 61.0 in stage 5.0 (TID 171) in 863 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T22:10:00.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.1.delta.48e0b557-3935-403b-97ca-710c31f9676b.TID177.tmp
[2025-07-19T22:10:00.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@443a8568
[2025-07-19T22:10:00.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 92.0 in stage 5.0 (TID 179)
[2025-07-19T22:10:00.409+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91] for update
[2025-07-19T22:10:00.415+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:00.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.1.delta.6e1e242c-e275-4fba-aea7-1615c4eb0aca.TID175.tmp
[2025-07-19T22:10:00.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.1.delta.124669f3-c9ee-43fe-8d03-3042833d1f46.TID176.tmp
[2025-07-19T22:10:00.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.489+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71cb61a4
[2025-07-19T22:10:00.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92] for update
[2025-07-19T22:10:00.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.511+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.1.delta.07e26ef4-8382-453d-a9cb-541fd4ea2365.TID172.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/1.delta
[2025-07-19T22:10:00.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/1.delta
[2025-07-19T22:10:00.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 172, attempt 0, stage 5.0)
[2025-07-19T22:10:00.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.1.delta.bd57d79c-3a03-4a58-bbfd-453f5107197d.TID178.tmp
[2025-07-19T22:10:00.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 64 (task 172, attempt 0, stage 5.0)
[2025-07-19T22:10:00.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.1.delta.281f5a75-a7a8-4c29-b5e5-200ef60d901d.TID179.tmp
[2025-07-19T22:10:00.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 64.0 in stage 5.0 (TID 172). 6243 bytes result sent to driver
[2025-07-19T22:10:00.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.1.delta.9c548392-2275-4379-aa97-4d582e0e4545.TID174.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/1.delta
[2025-07-19T22:10:00.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/1.delta
[2025-07-19T22:10:00.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 93.0 in stage 5.0 (TID 180) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 64.0 in stage 5.0 (TID 172) in 996 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T22:10:00.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 93.0 in stage 5.0 (TID 180)
[2025-07-19T22:10:00.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 174, attempt 0, stage 5.0)
[2025-07-19T22:10:00.553+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.1.delta.c5a8e24b-3dbd-4fa2-8c3b-86cf106fee44.TID173.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/1.delta
[2025-07-19T22:10:00.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/1.delta
[2025-07-19T22:10:00.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 173, attempt 0, stage 5.0)
[2025-07-19T22:10:00.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:00.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 70 (task 174, attempt 0, stage 5.0)
[2025-07-19T22:10:00.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 70.0 in stage 5.0 (TID 174). 6286 bytes result sent to driver
[2025-07-19T22:10:00.571+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 69 (task 173, attempt 0, stage 5.0)
[2025-07-19T22:10:00.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 69.0 in stage 5.0 (TID 173). 6243 bytes result sent to driver
[2025-07-19T22:10:00.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@610b3521
[2025-07-19T22:10:00.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93] for update
[2025-07-19T22:10:00.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 98.0 in stage 5.0 (TID 181) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 69.0 in stage 5.0 (TID 173) in 1022 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T22:10:00.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.594+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 70.0 in stage 5.0 (TID 174) in 1004 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T22:10:00.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 98.0 in stage 5.0 (TID 181)
[2025-07-19T22:10:00.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 102.0 in stage 5.0 (TID 182) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 102.0 in stage 5.0 (TID 182)
[2025-07-19T22:10:00.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:00.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T22:10:00.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.1.delta.6e1e242c-e275-4fba-aea7-1615c4eb0aca.TID175.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/1.delta
[2025-07-19T22:10:00.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/1.delta
[2025-07-19T22:10:00.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 175, attempt 0, stage 5.0)
[2025-07-19T22:10:00.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.1.delta.48e0b557-3935-403b-97ca-710c31f9676b.TID177.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/1.delta
[2025-07-19T22:10:00.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/1.delta
[2025-07-19T22:10:00.637+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c5dfeaf
[2025-07-19T22:10:00.640+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.1.delta.d76e4bd3-e3e9-4a64-8a01-7f5ca63d4980.TID180.tmp
[2025-07-19T22:10:00.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 177, attempt 0, stage 5.0)
[2025-07-19T22:10:00.645+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.1.delta.124669f3-c9ee-43fe-8d03-3042833d1f46.TID176.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/1.delta
[2025-07-19T22:10:00.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/1.delta
[2025-07-19T22:10:00.647+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.649+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102] for update
[2025-07-19T22:10:00.652+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 176, attempt 0, stage 5.0)
[2025-07-19T22:10:00.660+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 73 (task 175, attempt 0, stage 5.0)
[2025-07-19T22:10:00.661+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 89 (task 177, attempt 0, stage 5.0)
[2025-07-19T22:10:00.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 89.0 in stage 5.0 (TID 177). 6243 bytes result sent to driver
[2025-07-19T22:10:00.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 73.0 in stage 5.0 (TID 175). 6243 bytes result sent to driver
[2025-07-19T22:10:00.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 123.0 in stage 5.0 (TID 183) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 81 (task 176, attempt 0, stage 5.0)
[2025-07-19T22:10:00.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 123.0 in stage 5.0 (TID 183)
[2025-07-19T22:10:00.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 124.0 in stage 5.0 (TID 184) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 124.0 in stage 5.0 (TID 184)
[2025-07-19T22:10:00.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 81.0 in stage 5.0 (TID 176). 6243 bytes result sent to driver
[2025-07-19T22:10:00.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 127.0 in stage 5.0 (TID 185) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 127.0 in stage 5.0 (TID 185)
[2025-07-19T22:10:00.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 89.0 in stage 5.0 (TID 177) in 590 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T22:10:00.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 73.0 in stage 5.0 (TID 175) in 606 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T22:10:00.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 81.0 in stage 5.0 (TID 176) in 598 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T22:10:00.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.1.delta.281f5a75-a7a8-4c29-b5e5-200ef60d901d.TID179.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/1.delta
[2025-07-19T22:10:00.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/1.delta
[2025-07-19T22:10:00.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29bd8306
[2025-07-19T22:10:00.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 179, attempt 0, stage 5.0)
[2025-07-19T22:10:00.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98] for update
[2025-07-19T22:10:00.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.1.delta.bd57d79c-3a03-4a58-bbfd-453f5107197d.TID178.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/1.delta
[2025-07-19T22:10:00.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/1.delta
[2025-07-19T22:10:00.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 178, attempt 0, stage 5.0)
[2025-07-19T22:10:00.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 92 (task 179, attempt 0, stage 5.0)
[2025-07-19T22:10:00.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.1.delta.e5542ee9-2b23-40f9-8170-6d5e62df2d6f.TID182.tmp
[2025-07-19T22:10:00.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a169fb
[2025-07-19T22:10:00.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127] for update
[2025-07-19T22:10:00.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 92.0 in stage 5.0 (TID 179). 6286 bytes result sent to driver
[2025-07-19T22:10:00.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 92.0 in stage 5.0 (TID 179) in 308 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T22:10:00.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 132.0 in stage 5.0 (TID 186) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 91 (task 178, attempt 0, stage 5.0)
[2025-07-19T22:10:00.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 132.0 in stage 5.0 (TID 186)
[2025-07-19T22:10:00.698+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 91.0 in stage 5.0 (TID 178). 6243 bytes result sent to driver
[2025-07-19T22:10:00.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 91.0 in stage 5.0 (TID 178) in 535 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T22:10:00.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 136.0 in stage 5.0 (TID 187) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 136.0 in stage 5.0 (TID 187)
[2025-07-19T22:10:00.706+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.1.delta.38534d99-65da-48df-999b-c557d3d61d9a.TID181.tmp
[2025-07-19T22:10:00.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.710+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.710+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47ff7be1
[2025-07-19T22:10:00.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124] for update
[2025-07-19T22:10:00.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.1.delta.95b8d06d-e9cf-40d5-b0b5-7abeae417b8f.TID185.tmp
[2025-07-19T22:10:00.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61144e4c
[2025-07-19T22:10:00.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136] for update
[2025-07-19T22:10:00.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.1.delta.bfa8afbf-a94c-4d33-9873-bf2c5a825074.TID184.tmp
[2025-07-19T22:10:00.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6df46341
[2025-07-19T22:10:00.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.1.delta.d76e4bd3-e3e9-4a64-8a01-7f5ca63d4980.TID180.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/1.delta
[2025-07-19T22:10:00.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132] for update
[2025-07-19T22:10:00.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/1.delta
[2025-07-19T22:10:00.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.1.delta.96fcddfd-b592-42d8-bfa0-ed5d4fc0eedc.TID187.tmp
[2025-07-19T22:10:00.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 180, attempt 0, stage 5.0)
[2025-07-19T22:10:00.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49d6ad70
[2025-07-19T22:10:00.798+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.801+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123] for update
[2025-07-19T22:10:00.801+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 93 (task 180, attempt 0, stage 5.0)
[2025-07-19T22:10:00.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 93.0 in stage 5.0 (TID 180). 6243 bytes result sent to driver
[2025-07-19T22:10:00.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 138.0 in stage 5.0 (TID 188) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 138.0 in stage 5.0 (TID 188)
[2025-07-19T22:10:00.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 93.0 in stage 5.0 (TID 180) in 262 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T22:10:00.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:00.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.1.delta.ee980d45-6e0b-4a4d-bead-74e949769e6e.TID186.tmp
[2025-07-19T22:10:00.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f69e1e2
[2025-07-19T22:10:00.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138] for update
[2025-07-19T22:10:00.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.830+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.1.delta.8fc4a17b-509f-463b-856a-007321ef4dd2.TID183.tmp
[2025-07-19T22:10:00.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.1.delta.e5542ee9-2b23-40f9-8170-6d5e62df2d6f.TID182.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/1.delta
[2025-07-19T22:10:00.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/1.delta
[2025-07-19T22:10:00.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.1.delta.95b8d06d-e9cf-40d5-b0b5-7abeae417b8f.TID185.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/1.delta
[2025-07-19T22:10:00.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/1.delta
[2025-07-19T22:10:00.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 182, attempt 0, stage 5.0)
[2025-07-19T22:10:00.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 185, attempt 0, stage 5.0)
[2025-07-19T22:10:00.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.1.delta.38534d99-65da-48df-999b-c557d3d61d9a.TID181.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/1.delta
[2025-07-19T22:10:00.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/1.delta
[2025-07-19T22:10:00.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 181, attempt 0, stage 5.0)
[2025-07-19T22:10:00.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 98 (task 181, attempt 0, stage 5.0)
[2025-07-19T22:10:00.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 98.0 in stage 5.0 (TID 181). 6243 bytes result sent to driver
[2025-07-19T22:10:00.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 127 (task 185, attempt 0, stage 5.0)
[2025-07-19T22:10:00.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 127.0 in stage 5.0 (TID 185). 6243 bytes result sent to driver
[2025-07-19T22:10:00.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 102 (task 182, attempt 0, stage 5.0)
[2025-07-19T22:10:00.862+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 140.0 in stage 5.0 (TID 189) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.864+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 102.0 in stage 5.0 (TID 182). 6243 bytes result sent to driver
[2025-07-19T22:10:00.865+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 140.0 in stage 5.0 (TID 189)
[2025-07-19T22:10:00.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 98.0 in stage 5.0 (TID 181) in 279 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T22:10:00.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 152.0 in stage 5.0 (TID 190) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.872+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 127.0 in stage 5.0 (TID 185) in 196 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T22:10:00.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 152.0 in stage 5.0 (TID 190)
[2025-07-19T22:10:00.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.1.delta.bfa8afbf-a94c-4d33-9873-bf2c5a825074.TID184.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/1.delta
[2025-07-19T22:10:00.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/1.delta
[2025-07-19T22:10:00.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 184, attempt 0, stage 5.0)
[2025-07-19T22:10:00.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 155.0 in stage 5.0 (TID 191) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 155.0 in stage 5.0 (TID 191)
[2025-07-19T22:10:00.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 102.0 in stage 5.0 (TID 182) in 281 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T22:10:00.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.1.delta.fcd2e126-f45d-47b2-ad77-8b73aaeaeb9a.TID188.tmp
[2025-07-19T22:10:00.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 124 (task 184, attempt 0, stage 5.0)
[2025-07-19T22:10:00.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:00.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:00.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:00.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 124.0 in stage 5.0 (TID 184). 6243 bytes result sent to driver
[2025-07-19T22:10:00.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 160.0 in stage 5.0 (TID 192) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 124.0 in stage 5.0 (TID 184) in 218 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T22:10:00.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 160.0 in stage 5.0 (TID 192)
[2025-07-19T22:10:00.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a1b3cf1
[2025-07-19T22:10:00.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152] for update
[2025-07-19T22:10:00.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.915+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.1.delta.96fcddfd-b592-42d8-bfa0-ed5d4fc0eedc.TID187.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/1.delta
[2025-07-19T22:10:00.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/1.delta
[2025-07-19T22:10:00.918+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 187, attempt 0, stage 5.0)
[2025-07-19T22:10:00.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ab52167
[2025-07-19T22:10:00.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155] for update
[2025-07-19T22:10:00.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 136 (task 187, attempt 0, stage 5.0)
[2025-07-19T22:10:00.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.1.delta.ee980d45-6e0b-4a4d-bead-74e949769e6e.TID186.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/1.delta
[2025-07-19T22:10:00.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/1.delta
[2025-07-19T22:10:00.928+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 136.0 in stage 5.0 (TID 187). 6286 bytes result sent to driver
[2025-07-19T22:10:00.929+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17ac4e5d
[2025-07-19T22:10:00.929+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.930+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140] for update
[2025-07-19T22:10:00.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 161.0 in stage 5.0 (TID 193) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 186, attempt 0, stage 5.0)
[2025-07-19T22:10:00.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 136.0 in stage 5.0 (TID 187) in 218 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T22:10:00.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 161.0 in stage 5.0 (TID 193)
[2025-07-19T22:10:00.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.1.delta.70c2007a-b441-45e9-957c-d59cfd107b0b.TID190.tmp
[2025-07-19T22:10:00.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 132 (task 186, attempt 0, stage 5.0)
[2025-07-19T22:10:00.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 132.0 in stage 5.0 (TID 186). 6243 bytes result sent to driver
[2025-07-19T22:10:00.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24a6d3c8
[2025-07-19T22:10:00.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160] for update
[2025-07-19T22:10:00.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.1.delta.8fc4a17b-509f-463b-856a-007321ef4dd2.TID183.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/1.delta
[2025-07-19T22:10:00.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/1.delta
[2025-07-19T22:10:00.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 163.0 in stage 5.0 (TID 194) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 183, attempt 0, stage 5.0)
[2025-07-19T22:10:00.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 132.0 in stage 5.0 (TID 186) in 236 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T22:10:00.949+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 163.0 in stage 5.0 (TID 194)
[2025-07-19T22:10:00.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.1.delta.ff5825d7-fdae-4d3f-8c3d-04d14f246352.TID191.tmp
[2025-07-19T22:10:00.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:00.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.1.delta.17a31c94-c4b8-45ae-ac68-aaec2710bd82.TID189.tmp
[2025-07-19T22:10:00.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 123 (task 183, attempt 0, stage 5.0)
[2025-07-19T22:10:00.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@522f085c
[2025-07-19T22:10:00.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 123.0 in stage 5.0 (TID 183). 6243 bytes result sent to driver
[2025-07-19T22:10:00.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 164.0 in stage 5.0 (TID 195) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 123.0 in stage 5.0 (TID 183) in 294 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T22:10:00.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 164.0 in stage 5.0 (TID 195)
[2025-07-19T22:10:00.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161] for update
[2025-07-19T22:10:00.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.1.delta.fcd2e126-f45d-47b2-ad77-8b73aaeaeb9a.TID188.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/1.delta
[2025-07-19T22:10:00.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/1.delta
[2025-07-19T22:10:00.955+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 188, attempt 0, stage 5.0)
[2025-07-19T22:10:00.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.1.delta.6282c371-26cb-4e5d-8621-29c670ef9158.TID192.tmp
[2025-07-19T22:10:00.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@599d4ad3
[2025-07-19T22:10:00.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163] for update
[2025-07-19T22:10:00.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.964+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO DataWritingSparkTask: Committed partition 138 (task 188, attempt 0, stage 5.0)
[2025-07-19T22:10:00.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Finished task 138.0 in stage 5.0 (TID 188). 6243 bytes result sent to driver
[2025-07-19T22:10:00.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@208161f4
[2025-07-19T22:10:00.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Starting task 166.0 in stage 5.0 (TID 196) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:00.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO Executor: Running task 166.0 in stage 5.0 (TID 196)
[2025-07-19T22:10:00.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO TaskSetManager: Finished task 138.0 in stage 5.0 (TID 188) in 175 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T22:10:00.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164] for update
[2025-07-19T22:10:00.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.1.delta.84554666-3e53-452c-a521-fb198c530262.TID193.tmp
[2025-07-19T22:10:00.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:00.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:00.985+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:00.986+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.1.delta.7cefcd9e-d2d3-4057-8e0d-11bb54e7011c.TID194.tmp
[2025-07-19T22:10:00.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58c6403d
[2025-07-19T22:10:00.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:00.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166] for update
[2025-07-19T22:10:01.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.1.delta.10245229-ec08-4113-9aa2-797650d0d425.TID195.tmp
[2025-07-19T22:10:01.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.008+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.1.delta.70c2007a-b441-45e9-957c-d59cfd107b0b.TID190.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/1.delta
[2025-07-19T22:10:01.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/1.delta
[2025-07-19T22:10:01.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 190, attempt 0, stage 5.0)
[2025-07-19T22:10:01.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.1.delta.17a31c94-c4b8-45ae-ac68-aaec2710bd82.TID189.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/1.delta
[2025-07-19T22:10:01.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/1.delta
[2025-07-19T22:10:01.020+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 189, attempt 0, stage 5.0)
[2025-07-19T22:10:01.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 152 (task 190, attempt 0, stage 5.0)
[2025-07-19T22:10:01.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.1.delta.b951f6e6-d19e-4784-95f9-41e7b3e79855.TID196.tmp
[2025-07-19T22:10:01.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 152.0 in stage 5.0 (TID 190). 6243 bytes result sent to driver
[2025-07-19T22:10:01.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 176.0 in stage 5.0 (TID 197) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 152.0 in stage 5.0 (TID 190) in 169 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T22:10:01.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 176.0 in stage 5.0 (TID 197)
[2025-07-19T22:10:01.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.1.delta.ff5825d7-fdae-4d3f-8c3d-04d14f246352.TID191.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/1.delta
[2025-07-19T22:10:01.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/1.delta
[2025-07-19T22:10:01.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 191, attempt 0, stage 5.0)
[2025-07-19T22:10:01.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 140 (task 189, attempt 0, stage 5.0)
[2025-07-19T22:10:01.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 140.0 in stage 5.0 (TID 189). 6286 bytes result sent to driver
[2025-07-19T22:10:01.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 186.0 in stage 5.0 (TID 198) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 140.0 in stage 5.0 (TID 189) in 185 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T22:10:01.043+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 186.0 in stage 5.0 (TID 198)
[2025-07-19T22:10:01.043+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.1.delta.6282c371-26cb-4e5d-8621-29c670ef9158.TID192.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/1.delta
[2025-07-19T22:10:01.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/1.delta
[2025-07-19T22:10:01.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 192, attempt 0, stage 5.0)
[2025-07-19T22:10:01.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 155 (task 191, attempt 0, stage 5.0)
[2025-07-19T22:10:01.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.051+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@602226a6
[2025-07-19T22:10:01.054+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 155.0 in stage 5.0 (TID 191). 6243 bytes result sent to driver
[2025-07-19T22:10:01.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:01.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176] for update
[2025-07-19T22:10:01.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 155.0 in stage 5.0 (TID 191) in 193 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T22:10:01.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 190.0 in stage 5.0 (TID 199) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.1.delta.84554666-3e53-452c-a521-fb198c530262.TID193.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/1.delta
[2025-07-19T22:10:01.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/1.delta
[2025-07-19T22:10:01.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 193, attempt 0, stage 5.0)
[2025-07-19T22:10:01.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 160 (task 192, attempt 0, stage 5.0)
[2025-07-19T22:10:01.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 160.0 in stage 5.0 (TID 192). 6243 bytes result sent to driver
[2025-07-19T22:10:01.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 191.0 in stage 5.0 (TID 200) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 160.0 in stage 5.0 (TID 192) in 189 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T22:10:01.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 191.0 in stage 5.0 (TID 200)
[2025-07-19T22:10:01.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 190.0 in stage 5.0 (TID 199)
[2025-07-19T22:10:01.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 161 (task 193, attempt 0, stage 5.0)
[2025-07-19T22:10:01.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 161.0 in stage 5.0 (TID 193). 6243 bytes result sent to driver
[2025-07-19T22:10:01.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 193.0 in stage 5.0 (TID 201) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 161.0 in stage 5.0 (TID 193) in 147 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T22:10:01.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 193.0 in stage 5.0 (TID 201)
[2025-07-19T22:10:01.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70f53e1c
[2025-07-19T22:10:01.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:01.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186] for update
[2025-07-19T22:10:01.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.071+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.1.delta.10245229-ec08-4113-9aa2-797650d0d425.TID195.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/1.delta
[2025-07-19T22:10:01.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/1.delta
[2025-07-19T22:10:01.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.1.delta.7cefcd9e-d2d3-4057-8e0d-11bb54e7011c.TID194.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/1.delta
[2025-07-19T22:10:01.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/1.delta
[2025-07-19T22:10:01.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 195, attempt 0, stage 5.0)
[2025-07-19T22:10:01.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.1.delta.3bf40a7a-aa55-4154-96aa-a0d0604409c5.TID197.tmp
[2025-07-19T22:10:01.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 194, attempt 0, stage 5.0)
[2025-07-19T22:10:01.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:01.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 163 (task 194, attempt 0, stage 5.0)
[2025-07-19T22:10:01.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 164 (task 195, attempt 0, stage 5.0)
[2025-07-19T22:10:01.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 163.0 in stage 5.0 (TID 194). 6243 bytes result sent to driver
[2025-07-19T22:10:01.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 164.0 in stage 5.0 (TID 195). 6243 bytes result sent to driver
[2025-07-19T22:10:01.086+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c7d072a
[2025-07-19T22:10:01.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 195.0 in stage 5.0 (TID 202) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 195.0 in stage 5.0 (TID 202)
[2025-07-19T22:10:01.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 163.0 in stage 5.0 (TID 194) in 148 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T22:10:01.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 164.0 in stage 5.0 (TID 195) in 130 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T22:10:01.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:01.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191] for update
[2025-07-19T22:10:01.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 203) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 1.0 in stage 3.0 (TID 203)
[2025-07-19T22:10:01.090+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.090+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.090+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.090+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.091+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.091+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d0b8b77
[2025-07-19T22:10:01.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:01.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193] for update
[2025-07-19T22:10:01.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f6e8069
[2025-07-19T22:10:01.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.1.delta.302bf940-cb78-40c9-956f-2dbc6a1a7b22.TID198.tmp
[2025-07-19T22:10:01.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:01.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190] for update
[2025-07-19T22:10:01.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.103+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.1.delta.dfde557e-426f-4f99-bca4-04537dad368f.TID201.tmp
[2025-07-19T22:10:01.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.1.delta.b951f6e6-d19e-4784-95f9-41e7b3e79855.TID196.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/1.delta
[2025-07-19T22:10:01.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/1.delta
[2025-07-19T22:10:01.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.1.delta.80f3032d-3ca8-4b21-9130-b8f57c0faeb4.TID200.tmp
[2025-07-19T22:10:01.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 196, attempt 0, stage 5.0)
[2025-07-19T22:10:01.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.1.delta.df429a02-6720-4183-8467-691a187fad9c.TID199.tmp
[2025-07-19T22:10:01.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 166 (task 196, attempt 0, stage 5.0)
[2025-07-19T22:10:01.123+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 166.0 in stage 5.0 (TID 196). 6243 bytes result sent to driver
[2025-07-19T22:10:01.124+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 204) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.1.delta.3bf40a7a-aa55-4154-96aa-a0d0604409c5.TID197.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/1.delta
[2025-07-19T22:10:01.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/1.delta
[2025-07-19T22:10:01.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 166.0 in stage 5.0 (TID 196) in 156 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T22:10:01.130+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 2.0 in stage 3.0 (TID 204)
[2025-07-19T22:10:01.131+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c54468d
[2025-07-19T22:10:01.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 197, attempt 0, stage 5.0)
[2025-07-19T22:10:01.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/1] for update
[2025-07-19T22:10:01.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 176 (task 197, attempt 0, stage 5.0)
[2025-07-19T22:10:01.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 176.0 in stage 5.0 (TID 197). 6243 bytes result sent to driver
[2025-07-19T22:10:01.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 205) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 176.0 in stage 5.0 (TID 197) in 110 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T22:10:01.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 3.0 in stage 3.0 (TID 205)
[2025-07-19T22:10:01.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cd8fd98
[2025-07-19T22:10:01.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:01.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195] for update
[2025-07-19T22:10:01.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.154+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4724b02a
[2025-07-19T22:10:01.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.1.delta.302bf940-cb78-40c9-956f-2dbc6a1a7b22.TID198.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/1.delta
[2025-07-19T22:10:01.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/1.delta
[2025-07-19T22:10:01.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 198, attempt 0, stage 5.0)
[2025-07-19T22:10:01.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.1.delta.dfde557e-426f-4f99-bca4-04537dad368f.TID201.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/1.delta
[2025-07-19T22:10:01.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/1.delta
[2025-07-19T22:10:01.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.1.delta.acd86788-244a-4b5b-bd6c-d7d2eee1b6ad.TID202.tmp
[2025-07-19T22:10:01.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 201, attempt 0, stage 5.0)
[2025-07-19T22:10:01.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/3] for update
[2025-07-19T22:10:01.166+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.1.delta.80f3032d-3ca8-4b21-9130-b8f57c0faeb4.TID200.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/1.delta
[2025-07-19T22:10:01.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/1.delta
[2025-07-19T22:10:01.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 186 (task 198, attempt 0, stage 5.0)
[2025-07-19T22:10:01.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 186.0 in stage 5.0 (TID 198). 6243 bytes result sent to driver
[2025-07-19T22:10:01.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.1.delta.df429a02-6720-4183-8467-691a187fad9c.TID199.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/1.delta
[2025-07-19T22:10:01.190+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/1.delta
[2025-07-19T22:10:01.194+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 200, attempt 0, stage 5.0)
[2025-07-19T22:10:01.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 199, attempt 0, stage 5.0)
[2025-07-19T22:10:01.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 206) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 4.0 in stage 3.0 (TID 206)
[2025-07-19T22:10:01.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 186.0 in stage 5.0 (TID 198) in 150 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T22:10:01.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 193 (task 201, attempt 0, stage 5.0)
[2025-07-19T22:10:01.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 193.0 in stage 5.0 (TID 201). 6243 bytes result sent to driver
[2025-07-19T22:10:01.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 190 (task 199, attempt 0, stage 5.0)
[2025-07-19T22:10:01.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 190.0 in stage 5.0 (TID 199). 6243 bytes result sent to driver
[2025-07-19T22:10:01.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:01.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ad7c26
[2025-07-19T22:10:01.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 207) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 208) (8b44f3d35cfa, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 193.0 in stage 5.0 (TID 201) in 137 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T22:10:01.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 190.0 in stage 5.0 (TID 199) in 148 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T22:10:01.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 6.0 in stage 3.0 (TID 208)
[2025-07-19T22:10:01.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/2] for update
[2025-07-19T22:10:01.202+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 191 (task 200, attempt 0, stage 5.0)
[2025-07-19T22:10:01.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 191.0 in stage 5.0 (TID 200). 6243 bytes result sent to driver
[2025-07-19T22:10:01.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.205+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 5.0 in stage 3.0 (TID 207)
[2025-07-19T22:10:01.205+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 209) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.206+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 191.0 in stage 5.0 (TID 200) in 148 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T22:10:01.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 7.0 in stage 3.0 (TID 209)
[2025-07-19T22:10:01.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:01.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.209+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.209+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.211+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@657c5439
[2025-07-19T22:10:01.211+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.211+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/4] for update
[2025-07-19T22:10:01.213+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1edc3a49
[2025-07-19T22:10:01.219+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/7] for update
[2025-07-19T22:10:01.226+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.1.delta.883ad487-cb2c-4367-bb2e-b60a07e4e864.TID203.tmp
[2025-07-19T22:10:01.226+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.1.delta.ceb4b748-7bad-4d43-a76c-fe7f050c4966.TID206.tmp
[2025-07-19T22:10:01.229+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6afaaaef
[2025-07-19T22:10:01.229+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.1.delta.d46560fe-c627-48f8-b1d4-e59f605d21bb.TID204.tmp
[2025-07-19T22:10:01.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.1.delta.43e309e6-c28e-4faa-86d1-39cb7d36d891.TID205.tmp
[2025-07-19T22:10:01.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.1.delta.ef25707d-c90c-437b-bee8-80166c676839.TID209.tmp
[2025-07-19T22:10:01.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/5] for update
[2025-07-19T22:10:01.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.1.delta.acd86788-244a-4b5b-bd6c-d7d2eee1b6ad.TID202.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/1.delta
[2025-07-19T22:10:01.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/1.delta
[2025-07-19T22:10:01.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 202, attempt 0, stage 5.0)
[2025-07-19T22:10:01.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34b85d39
[2025-07-19T22:10:01.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/6] for update
[2025-07-19T22:10:01.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 195 (task 202, attempt 0, stage 5.0)
[2025-07-19T22:10:01.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 195.0 in stage 5.0 (TID 202). 6243 bytes result sent to driver
[2025-07-19T22:10:01.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 210) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.258+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 195.0 in stage 5.0 (TID 202) in 177 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T22:10:01.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DAGScheduler: ResultStage 5 (start at <unknown>:0) finished in 8.945 s
[2025-07-19T22:10:01.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-19T22:10:01.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 9.0 in stage 3.0 (TID 210)
[2025-07-19T22:10:01.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.1.delta.81371c69-34c6-4231-9436-4f2891880a21.TID207.tmp
[2025-07-19T22:10:01.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T22:10:01.266+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-19T22:10:01.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.1.delta.e8d98d44-ded8-4dae-a5ca-05a87b810fba.TID208.tmp
[2025-07-19T22:10:01.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 10.536796 s
[2025-07-19T22:10:01.272+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28319766
[2025-07-19T22:10:01.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/9] for update
[2025-07-19T22:10:01.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T22:10:01.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO SparkWrite: Committing epoch 0 for query 46c08399-34b2-49a9-aadd-060519c28563 in append mode
[2025-07-19T22:10:01.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.1.delta.c657b2c7-17af-4c8c-969a-697fed5323bd.TID210.tmp
[2025-07-19T22:10:01.295+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.1.delta.ef25707d-c90c-437b-bee8-80166c676839.TID209.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/7/1.delta
[2025-07-19T22:10:01.297+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/7] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/7/1.delta
[2025-07-19T22:10:01.297+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 209, attempt 0, stage 3.0)
[2025-07-19T22:10:01.302+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.1.delta.d46560fe-c627-48f8-b1d4-e59f605d21bb.TID204.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/2/1.delta
[2025-07-19T22:10:01.303+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/2] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/2/1.delta
[2025-07-19T22:10:01.304+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 204, attempt 0, stage 3.0)
[2025-07-19T22:10:01.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.1.delta.ceb4b748-7bad-4d43-a76c-fe7f050c4966.TID206.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/4/1.delta
[2025-07-19T22:10:01.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.1.delta.883ad487-cb2c-4367-bb2e-b60a07e4e864.TID203.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/1/1.delta
[2025-07-19T22:10:01.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/1] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/1/1.delta
[2025-07-19T22:10:01.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/4] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/4/1.delta
[2025-07-19T22:10:01.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 206, attempt 0, stage 3.0)
[2025-07-19T22:10:01.324+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 203, attempt 0, stage 3.0)
[2025-07-19T22:10:01.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.1.delta.43e309e6-c28e-4faa-86d1-39cb7d36d891.TID205.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/3/1.delta
[2025-07-19T22:10:01.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/3] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/3/1.delta
[2025-07-19T22:10:01.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 205, attempt 0, stage 3.0)
[2025-07-19T22:10:01.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.1.delta.81371c69-34c6-4231-9436-4f2891880a21.TID207.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/5/1.delta
[2025-07-19T22:10:01.341+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/5] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/5/1.delta
[2025-07-19T22:10:01.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 207, attempt 0, stage 3.0)
[2025-07-19T22:10:01.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO SparkWrite: Committing streaming append with 155 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:01.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.1.delta.e8d98d44-ded8-4dae-a5ca-05a87b810fba.TID208.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/6/1.delta
[2025-07-19T22:10:01.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/6] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/6/1.delta
[2025-07-19T22:10:01.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 208, attempt 0, stage 3.0)
[2025-07-19T22:10:01.371+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.1.delta.c657b2c7-17af-4c8c-969a-697fed5323bd.TID210.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/9/1.delta
[2025-07-19T22:10:01.371+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/9] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/9/1.delta
[2025-07-19T22:10:01.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 2 (task 204, attempt 0, stage 3.0)
[2025-07-19T22:10:01.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 4 (task 206, attempt 0, stage 3.0)
[2025-07-19T22:10:01.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 5 (task 207, attempt 0, stage 3.0)
[2025-07-19T22:10:01.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 1 (task 203, attempt 0, stage 3.0)
[2025-07-19T22:10:01.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 2.0 in stage 3.0 (TID 204). 9074 bytes result sent to driver
[2025-07-19T22:10:01.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 3 (task 205, attempt 0, stage 3.0)
[2025-07-19T22:10:01.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 7 (task 209, attempt 0, stage 3.0)
[2025-07-19T22:10:01.377+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 5.0 in stage 3.0 (TID 207). 9033 bytes result sent to driver
[2025-07-19T22:10:01.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 211) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.396+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 1.0 in stage 3.0 (TID 203). 9097 bytes result sent to driver
[2025-07-19T22:10:01.407+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 210, attempt 0, stage 3.0)
[2025-07-19T22:10:01.415+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 7.0 in stage 3.0 (TID 209). 9138 bytes result sent to driver
[2025-07-19T22:10:01.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 3.0 in stage 3.0 (TID 205). 9121 bytes result sent to driver
[2025-07-19T22:10:01.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 212) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 213) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 214) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 215) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.421+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 11.0 in stage 3.0 (TID 211)
[2025-07-19T22:10:01.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 12.0 in stage 3.0 (TID 212)
[2025-07-19T22:10:01.424+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 16.0 in stage 3.0 (TID 215)
[2025-07-19T22:10:01.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 4.0 in stage 3.0 (TID 206). 9105 bytes result sent to driver
[2025-07-19T22:10:01.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 204) in 262 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T22:10:01.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 13.0 in stage 3.0 (TID 213)
[2025-07-19T22:10:01.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 207) in 189 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T22:10:01.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 209) in 183 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T22:10:01.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 203) in 309 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T22:10:01.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 14.0 in stage 3.0 (TID 214)
[2025-07-19T22:10:01.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 205) in 257 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T22:10:01.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 216) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 18.0 in stage 3.0 (TID 216)
[2025-07-19T22:10:01.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 206) in 207 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T22:10:01.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T22:10:01.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.450+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T22:10:01.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fa8205d
[2025-07-19T22:10:01.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/14] for update
[2025-07-19T22:10:01.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
[2025-07-19T22:10:01.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ff87849
[2025-07-19T22:10:01.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/18] for update
[2025-07-19T22:10:01.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 6 (task 208, attempt 0, stage 3.0)
[2025-07-19T22:10:01.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 9 (task 210, attempt 0, stage 3.0)
[2025-07-19T22:10:01.457+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 9.0 in stage 3.0 (TID 210). 9086 bytes result sent to driver
[2025-07-19T22:10:01.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 6.0 in stage 3.0 (TID 208). 9078 bytes result sent to driver
[2025-07-19T22:10:01.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 217) (8b44f3d35cfa, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 218) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 19.0 in stage 3.0 (TID 217)
[2025-07-19T22:10:01.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 208) in 252 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T22:10:01.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 210) in 198 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T22:10:01.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7236c440
[2025-07-19T22:10:01.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 20.0 in stage 3.0 (TID 218)
[2025-07-19T22:10:01.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/16] for update
[2025-07-19T22:10:01.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.1.delta.bf028d29-5812-4767-9e5c-46eba7637410.TID216.tmp
[2025-07-19T22:10:01.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:01.471+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.1.delta.8e09cf28-00a3-4e1b-89f3-7c6520259caa.TID214.tmp
[2025-07-19T22:10:01.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@392ed81
[2025-07-19T22:10:01.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:01.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/12] for update
[2025-07-19T22:10:01.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.1.delta.3257c760-3fca-456a-b582-e9fb1a577758.TID215.tmp
[2025-07-19T22:10:01.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f2df271
[2025-07-19T22:10:01.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/13] for update
[2025-07-19T22:10:01.519+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.1.delta.66a086dc-56af-4a62-9b85-5b04e9804eb5.TID212.tmp
[2025-07-19T22:10:01.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c3b424d
[2025-07-19T22:10:01.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/19] for update
[2025-07-19T22:10:01.531+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.1.delta.90262eac-51e7-4037-b5a2-3e0c11940396.TID213.tmp
[2025-07-19T22:10:01.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73d98b0e
[2025-07-19T22:10:01.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.1.delta.bf028d29-5812-4767-9e5c-46eba7637410.TID216.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/18/1.delta
[2025-07-19T22:10:01.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/18] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/18/1.delta
[2025-07-19T22:10:01.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 216, attempt 0, stage 3.0)
[2025-07-19T22:10:01.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.571+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/20] for update
[2025-07-19T22:10:01.580+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.1.delta.43e01ac8-a5dd-42ba-b306-f50acf4496bf.TID217.tmp
[2025-07-19T22:10:01.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.1.delta.3257c760-3fca-456a-b582-e9fb1a577758.TID215.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/16/1.delta
[2025-07-19T22:10:01.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/16] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/16/1.delta
[2025-07-19T22:10:01.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 215, attempt 0, stage 3.0)
[2025-07-19T22:10:01.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@645895e2
[2025-07-19T22:10:01.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.1.delta.8e09cf28-00a3-4e1b-89f3-7c6520259caa.TID214.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/14/1.delta
[2025-07-19T22:10:01.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/14] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/14/1.delta
[2025-07-19T22:10:01.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/11] for update
[2025-07-19T22:10:01.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 214, attempt 0, stage 3.0)
[2025-07-19T22:10:01.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.1.delta.a2e6a23d-03ea-48cc-8950-ed15afd8ac7c.TID218.tmp
[2025-07-19T22:10:01.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 16 (task 215, attempt 0, stage 3.0)
[2025-07-19T22:10:01.656+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 16.0 in stage 3.0 (TID 215). 9123 bytes result sent to driver
[2025-07-19T22:10:01.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 219) (8b44f3d35cfa, executor driver, partition 21, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 215) in 253 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T22:10:01.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 21.0 in stage 3.0 (TID 219)
[2025-07-19T22:10:01.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.1.delta.ba7c81e0-7595-4047-b9e7-ff2e3ffddb43.TID211.tmp
[2025-07-19T22:10:01.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 18 (task 216, attempt 0, stage 3.0)
[2025-07-19T22:10:01.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 18.0 in stage 3.0 (TID 216). 9076 bytes result sent to driver
[2025-07-19T22:10:01.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 220) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 22.0 in stage 3.0 (TID 220)
[2025-07-19T22:10:01.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 216) in 274 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T22:10:01.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1062907d
[2025-07-19T22:10:01.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/21] for update
[2025-07-19T22:10:01.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 14 (task 214, attempt 0, stage 3.0)
[2025-07-19T22:10:01.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 14.0 in stage 3.0 (TID 214). 9098 bytes result sent to driver
[2025-07-19T22:10:01.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 221) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 23.0 in stage 3.0 (TID 221)
[2025-07-19T22:10:01.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 214) in 296 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T22:10:01.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.1.delta.66a086dc-56af-4a62-9b85-5b04e9804eb5.TID212.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/12/1.delta
[2025-07-19T22:10:01.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/12] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/12/1.delta
[2025-07-19T22:10:01.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.1.delta.90262eac-51e7-4037-b5a2-3e0c11940396.TID213.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/13/1.delta
[2025-07-19T22:10:01.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/13] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/13/1.delta
[2025-07-19T22:10:01.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 212, attempt 0, stage 3.0)
[2025-07-19T22:10:01.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 213, attempt 0, stage 3.0)
[2025-07-19T22:10:01.698+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:01.700+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ac472d7
[2025-07-19T22:10:01.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/22] for update
[2025-07-19T22:10:01.711+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.1.delta.43e01ac8-a5dd-42ba-b306-f50acf4496bf.TID217.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/19/1.delta
[2025-07-19T22:10:01.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/19] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/19/1.delta
[2025-07-19T22:10:01.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.1.delta.ff2f2055-1b7e-4115-b6e9-05b5a95c66b0.TID219.tmp
[2025-07-19T22:10:01.719+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 217, attempt 0, stage 3.0)
[2025-07-19T22:10:01.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bc1d30
[2025-07-19T22:10:01.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 13 (task 213, attempt 0, stage 3.0)
[2025-07-19T22:10:01.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/23] for update
[2025-07-19T22:10:01.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 13.0 in stage 3.0 (TID 213). 9078 bytes result sent to driver
[2025-07-19T22:10:01.728+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 222) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.730+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 213) in 339 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T22:10:01.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 24.0 in stage 3.0 (TID 222)
[2025-07-19T22:10:01.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 12 (task 212, attempt 0, stage 3.0)
[2025-07-19T22:10:01.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 12.0 in stage 3.0 (TID 212). 9097 bytes result sent to driver
[2025-07-19T22:10:01.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 223) (8b44f3d35cfa, executor driver, partition 25, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 212) in 348 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T22:10:01.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 25.0 in stage 3.0 (TID 223)
[2025-07-19T22:10:01.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.1.delta.5b55dbe6-8572-4176-9489-5933b6badfec.TID220.tmp
[2025-07-19T22:10:01.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.1.delta.a2e6a23d-03ea-48cc-8950-ed15afd8ac7c.TID218.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/20/1.delta
[2025-07-19T22:10:01.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/20] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/20/1.delta
[2025-07-19T22:10:01.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 218, attempt 0, stage 3.0)
[2025-07-19T22:10:01.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.1.delta.76502c18-7a17-4297-b645-35e5c71f8743.TID221.tmp
[2025-07-19T22:10:01.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17f349b4
[2025-07-19T22:10:01.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.772+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/24] for update
[2025-07-19T22:10:01.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b0811d0
[2025-07-19T22:10:01.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/25] for update
[2025-07-19T22:10:01.781+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 19 (task 217, attempt 0, stage 3.0)
[2025-07-19T22:10:01.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 19.0 in stage 3.0 (TID 217). 9097 bytes result sent to driver
[2025-07-19T22:10:01.785+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.1.delta.c1fa9562-adf9-4a81-85f6-50fcfab7ab4f.TID222.tmp
[2025-07-19T22:10:01.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 224) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 26.0 in stage 3.0 (TID 224)
[2025-07-19T22:10:01.790+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 217) in 337 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T22:10:01.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.800+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.801+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.801+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 20 (task 218, attempt 0, stage 3.0)
[2025-07-19T22:10:01.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 20.0 in stage 3.0 (TID 218). 9087 bytes result sent to driver
[2025-07-19T22:10:01.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 225) (8b44f3d35cfa, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 29.0 in stage 3.0 (TID 225)
[2025-07-19T22:10:01.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 218) in 360 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T22:10:01.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@377c8bfc
[2025-07-19T22:10:01.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/26] for update
[2025-07-19T22:10:01.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.1.delta.ff2f2055-1b7e-4115-b6e9-05b5a95c66b0.TID219.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/21/1.delta
[2025-07-19T22:10:01.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/21] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/21/1.delta
[2025-07-19T22:10:01.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.1.delta.248d3a55-47d4-4290-a207-ddabbbff92bc.TID223.tmp
[2025-07-19T22:10:01.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 219, attempt 0, stage 3.0)
[2025-07-19T22:10:01.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.831+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ccb7cd6
[2025-07-19T22:10:01.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.1.delta.ba7c81e0-7595-4047-b9e7-ff2e3ffddb43.TID211.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/11/1.delta
[2025-07-19T22:10:01.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/11] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/11/1.delta
[2025-07-19T22:10:01.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 211, attempt 0, stage 3.0)
[2025-07-19T22:10:01.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/29] for update
[2025-07-19T22:10:01.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.1.delta.5b55dbe6-8572-4176-9489-5933b6badfec.TID220.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/22/1.delta
[2025-07-19T22:10:01.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/22] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/22/1.delta
[2025-07-19T22:10:01.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 220, attempt 0, stage 3.0)
[2025-07-19T22:10:01.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.1.delta.76502c18-7a17-4297-b645-35e5c71f8743.TID221.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/23/1.delta
[2025-07-19T22:10:01.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/23] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/23/1.delta
[2025-07-19T22:10:01.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 221, attempt 0, stage 3.0)
[2025-07-19T22:10:01.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.1.delta.2933c69e-fcdb-4b01-8ba9-4143132b0963.TID224.tmp
[2025-07-19T22:10:01.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 21 (task 219, attempt 0, stage 3.0)
[2025-07-19T22:10:01.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 11 (task 211, attempt 0, stage 3.0)
[2025-07-19T22:10:01.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 11.0 in stage 3.0 (TID 211). 9080 bytes result sent to driver
[2025-07-19T22:10:01.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.1.delta.1262b274-5e34-4d01-9abf-20d2a8ae4d7b.TID225.tmp
[2025-07-19T22:10:01.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 21.0 in stage 3.0 (TID 219). 9040 bytes result sent to driver
[2025-07-19T22:10:01.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 226) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 30.0 in stage 3.0 (TID 226)
[2025-07-19T22:10:01.896+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 227) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 211) in 515 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T22:10:01.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 32.0 in stage 3.0 (TID 227)
[2025-07-19T22:10:01.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 219) in 268 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T22:10:01.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.907+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.1.delta.c1fa9562-adf9-4a81-85f6-50fcfab7ab4f.TID222.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/24/1.delta
[2025-07-19T22:10:01.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/24] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/24/1.delta
[2025-07-19T22:10:01.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.1.delta.248d3a55-47d4-4290-a207-ddabbbff92bc.TID223.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/25/1.delta
[2025-07-19T22:10:01.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/25] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/25/1.delta
[2025-07-19T22:10:01.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 223, attempt 0, stage 3.0)
[2025-07-19T22:10:01.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 222, attempt 0, stage 3.0)
[2025-07-19T22:10:01.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 22 (task 220, attempt 0, stage 3.0)
[2025-07-19T22:10:01.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 22.0 in stage 3.0 (TID 220). 9129 bytes result sent to driver
[2025-07-19T22:10:01.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T22:10:01.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 228) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3409c589
[2025-07-19T22:10:01.928+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 35.0 in stage 3.0 (TID 228)
[2025-07-19T22:10:01.929+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 220) in 265 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T22:10:01.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/32] for update
[2025-07-19T22:10:01.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 23 (task 221, attempt 0, stage 3.0)
[2025-07-19T22:10:01.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 23.0 in stage 3.0 (TID 221). 9082 bytes result sent to driver
[2025-07-19T22:10:01.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 229) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 37.0 in stage 3.0 (TID 229)
[2025-07-19T22:10:01.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 221) in 263 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T22:10:01.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:01.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.1.delta.466a55a5-f08d-45b8-82db-48f7cf68570e.TID227.tmp
[2025-07-19T22:10:01.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 25 (task 223, attempt 0, stage 3.0)
[2025-07-19T22:10:01.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@618289d2
[2025-07-19T22:10:01.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 25.0 in stage 3.0 (TID 223). 9096 bytes result sent to driver
[2025-07-19T22:10:01.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 230) (8b44f3d35cfa, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/35] for update
[2025-07-19T22:10:01.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 223) in 227 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T22:10:01.977+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 38.0 in stage 3.0 (TID 230)
[2025-07-19T22:10:01.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:01.980+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:01.981+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@533b0d1c
[2025-07-19T22:10:01.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:01.986+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/30] for update
[2025-07-19T22:10:01.987+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Committed partition 24 (task 222, attempt 0, stage 3.0)
[2025-07-19T22:10:01.988+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Finished task 24.0 in stage 3.0 (TID 222). 9093 bytes result sent to driver
[2025-07-19T22:10:01.989+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 231) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:01.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO Executor: Running task 39.0 in stage 3.0 (TID 231)
[2025-07-19T22:10:01.992+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 222) in 266 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T22:10:01.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:01.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.1.delta.2933c69e-fcdb-4b01-8ba9-4143132b0963.TID224.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/26/1.delta
[2025-07-19T22:10:01.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/26] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/26/1.delta
[2025-07-19T22:10:01.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 224, attempt 0, stage 3.0)
[2025-07-19T22:10:02.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78207250
[2025-07-19T22:10:02.008+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.1.delta.1262b274-5e34-4d01-9abf-20d2a8ae4d7b.TID225.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/29/1.delta
[2025-07-19T22:10:02.009+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/29] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/29/1.delta
[2025-07-19T22:10:02.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/38] for update
[2025-07-19T22:10:02.016+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 225, attempt 0, stage 3.0)
[2025-07-19T22:10:02.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.1.delta.4aa04a68-6980-4e32-93ff-fd008e2babba.TID226.tmp
[2025-07-19T22:10:02.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.1.delta.aea8377b-f926-42d1-8be6-ac56261adb82.TID228.tmp
[2025-07-19T22:10:02.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f804e3e
[2025-07-19T22:10:02.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/37] for update
[2025-07-19T22:10:02.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.035+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.1.delta.6de4fe35-bb12-4565-b0a4-050cbd652730.TID230.tmp
[2025-07-19T22:10:02.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 26 (task 224, attempt 0, stage 3.0)
[2025-07-19T22:10:02.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 26.0 in stage 3.0 (TID 224). 9073 bytes result sent to driver
[2025-07-19T22:10:02.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 232) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44899f89
[2025-07-19T22:10:02.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 224) in 258 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T22:10:02.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 41.0 in stage 3.0 (TID 232)
[2025-07-19T22:10:02.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.054+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/39] for update
[2025-07-19T22:10:02.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 29 (task 225, attempt 0, stage 3.0)
[2025-07-19T22:10:02.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 29.0 in stage 3.0 (TID 225). 9068 bytes result sent to driver
[2025-07-19T22:10:02.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 233) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 43.0 in stage 3.0 (TID 233)
[2025-07-19T22:10:02.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 225) in 250 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T22:10:02.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.1.delta.a5483ad5-2991-4491-8972-9f171d35ee69.TID229.tmp
[2025-07-19T22:10:02.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:02.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31fe5031
[2025-07-19T22:10:02.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/41] for update
[2025-07-19T22:10:02.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.1.delta.78e2c645-8405-4d8e-babe-3d704e5a83e1.TID231.tmp
[2025-07-19T22:10:02.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55d2a668
[2025-07-19T22:10:02.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/43] for update
[2025-07-19T22:10:02.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.1.delta.466a55a5-f08d-45b8-82db-48f7cf68570e.TID227.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/32/1.delta
[2025-07-19T22:10:02.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/32] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/32/1.delta
[2025-07-19T22:10:02.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 227, attempt 0, stage 3.0)
[2025-07-19T22:10:02.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.1.delta.8da4c0dc-b64f-4a27-b2ea-76227b1a330a.TID232.tmp
[2025-07-19T22:10:02.116+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.1.delta.6c8bd885-4ef3-41a9-b135-6d918c11079c.TID233.tmp
[2025-07-19T22:10:02.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.1.delta.aea8377b-f926-42d1-8be6-ac56261adb82.TID228.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/35/1.delta
[2025-07-19T22:10:02.121+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/35] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/35/1.delta
[2025-07-19T22:10:02.121+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 32 (task 227, attempt 0, stage 3.0)
[2025-07-19T22:10:02.121+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.1.delta.4aa04a68-6980-4e32-93ff-fd008e2babba.TID226.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/30/1.delta
[2025-07-19T22:10:02.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/30] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/30/1.delta
[2025-07-19T22:10:02.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 228, attempt 0, stage 3.0)
[2025-07-19T22:10:02.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 226, attempt 0, stage 3.0)
[2025-07-19T22:10:02.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 32.0 in stage 3.0 (TID 227). 9123 bytes result sent to driver
[2025-07-19T22:10:02.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 234) (8b44f3d35cfa, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.123+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 45.0 in stage 3.0 (TID 234)
[2025-07-19T22:10:02.123+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 227) in 230 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T22:10:02.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@261b3da7
[2025-07-19T22:10:02.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/45] for update
[2025-07-19T22:10:02.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.166+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.1.delta.6de4fe35-bb12-4565-b0a4-050cbd652730.TID230.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/38/1.delta
[2025-07-19T22:10:02.172+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/38] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/38/1.delta
[2025-07-19T22:10:02.174+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 230, attempt 0, stage 3.0)
[2025-07-19T22:10:02.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 35 (task 228, attempt 0, stage 3.0)
[2025-07-19T22:10:02.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 35.0 in stage 3.0 (TID 228). 9089 bytes result sent to driver
[2025-07-19T22:10:02.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 30 (task 226, attempt 0, stage 3.0)
[2025-07-19T22:10:02.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 235) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 30.0 in stage 3.0 (TID 226). 9103 bytes result sent to driver
[2025-07-19T22:10:02.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 228) in 251 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T22:10:02.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 236) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 226) in 294 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T22:10:02.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 47.0 in stage 3.0 (TID 236)
[2025-07-19T22:10:02.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 46.0 in stage 3.0 (TID 235)
[2025-07-19T22:10:02.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.1.delta.78e2c645-8405-4d8e-babe-3d704e5a83e1.TID231.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/39/1.delta
[2025-07-19T22:10:02.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:02.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/39] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/39/1.delta
[2025-07-19T22:10:02.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 38 (task 230, attempt 0, stage 3.0)
[2025-07-19T22:10:02.190+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.1.delta.77d55941-5791-46d8-8939-b5442ba1a76d.TID234.tmp
[2025-07-19T22:10:02.191+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 231, attempt 0, stage 3.0)
[2025-07-19T22:10:02.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 38.0 in stage 3.0 (TID 230). 9074 bytes result sent to driver
[2025-07-19T22:10:02.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.1.delta.a5483ad5-2991-4491-8972-9f171d35ee69.TID229.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/37/1.delta
[2025-07-19T22:10:02.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 237) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/37] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/37/1.delta
[2025-07-19T22:10:02.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 48.0 in stage 3.0 (TID 237)
[2025-07-19T22:10:02.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:02.204+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 230) in 241 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T22:10:02.206+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 229, attempt 0, stage 3.0)
[2025-07-19T22:10:02.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b8942b3
[2025-07-19T22:10:02.209+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/46] for update
[2025-07-19T22:10:02.214+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.1.delta.8da4c0dc-b64f-4a27-b2ea-76227b1a330a.TID232.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/41/1.delta
[2025-07-19T22:10:02.214+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/41] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/41/1.delta
[2025-07-19T22:10:02.215+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.215+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.215+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 232, attempt 0, stage 3.0)
[2025-07-19T22:10:02.216+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.217+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fbdfac8
[2025-07-19T22:10:02.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/47] for update
[2025-07-19T22:10:02.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.1.delta.6c8bd885-4ef3-41a9-b135-6d918c11079c.TID233.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/43/1.delta
[2025-07-19T22:10:02.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/43] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/43/1.delta
[2025-07-19T22:10:02.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 233, attempt 0, stage 3.0)
[2025-07-19T22:10:02.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.1.delta.b693f6a4-10e8-432a-8f4d-2a3b52926bae.TID235.tmp
[2025-07-19T22:10:02.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bc4ec2f
[2025-07-19T22:10:02.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/48] for update
[2025-07-19T22:10:02.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 41 (task 232, attempt 0, stage 3.0)
[2025-07-19T22:10:02.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 41.0 in stage 3.0 (TID 232). 9076 bytes result sent to driver
[2025-07-19T22:10:02.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 51.0 in stage 3.0 (TID 238) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 232) in 197 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T22:10:02.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 51.0 in stage 3.0 (TID 238)
[2025-07-19T22:10:02.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 39 (task 231, attempt 0, stage 3.0)
[2025-07-19T22:10:02.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 37 (task 229, attempt 0, stage 3.0)
[2025-07-19T22:10:02.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 39.0 in stage 3.0 (TID 231). 9068 bytes result sent to driver
[2025-07-19T22:10:02.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 37.0 in stage 3.0 (TID 229). 9089 bytes result sent to driver
[2025-07-19T22:10:02.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 52.0 in stage 3.0 (TID 239) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.1.delta.c161a769-ac06-4e81-baf8-4838d7c6d347.TID236.tmp
[2025-07-19T22:10:02.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 53.0 in stage 3.0 (TID 240) (8b44f3d35cfa, executor driver, partition 53, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 52.0 in stage 3.0 (TID 239)
[2025-07-19T22:10:02.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 231) in 264 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T22:10:02.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 53.0 in stage 3.0 (TID 240)
[2025-07-19T22:10:02.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 229) in 311 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T22:10:02.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:02.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:02.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25d089fd
[2025-07-19T22:10:02.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/51] for update
[2025-07-19T22:10:02.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 43 (task 233, attempt 0, stage 3.0)
[2025-07-19T22:10:02.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 43.0 in stage 3.0 (TID 233). 9076 bytes result sent to driver
[2025-07-19T22:10:02.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 56.0 in stage 3.0 (TID 241) (8b44f3d35cfa, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 233) in 215 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T22:10:02.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 56.0 in stage 3.0 (TID 241)
[2025-07-19T22:10:02.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.1.delta.d2a0d093-4ac0-4a52-a478-81a78fa586b9.TID237.tmp
[2025-07-19T22:10:02.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13f93c8b
[2025-07-19T22:10:02.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/53] for update
[2025-07-19T22:10:02.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.1.delta.77d55941-5791-46d8-8939-b5442ba1a76d.TID234.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/45/1.delta
[2025-07-19T22:10:02.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/45] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/45/1.delta
[2025-07-19T22:10:02.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 234, attempt 0, stage 3.0)
[2025-07-19T22:10:02.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3abe8b61
[2025-07-19T22:10:02.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/52] for update
[2025-07-19T22:10:02.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.1.delta.997e9bdb-c802-4284-a12f-f91cbfe738ee.TID238.tmp
[2025-07-19T22:10:02.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.1.delta.1c07e62b-87db-4add-ba2e-9e4177b3ea3f.TID240.tmp
[2025-07-19T22:10:02.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44a0489b
[2025-07-19T22:10:02.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 45 (task 234, attempt 0, stage 3.0)
[2025-07-19T22:10:02.300+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.302+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 45.0 in stage 3.0 (TID 234). 9086 bytes result sent to driver
[2025-07-19T22:10:02.302+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/56] for update
[2025-07-19T22:10:02.303+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 57.0 in stage 3.0 (TID 242) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 57.0 in stage 3.0 (TID 242)
[2025-07-19T22:10:02.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 234) in 190 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T22:10:02.306+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.1.delta.b693f6a4-10e8-432a-8f4d-2a3b52926bae.TID235.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/46/1.delta
[2025-07-19T22:10:02.306+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/46] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/46/1.delta
[2025-07-19T22:10:02.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 235, attempt 0, stage 3.0)
[2025-07-19T22:10:02.311+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.1.delta.0ffca9f2-4b40-423e-aeb0-378b9665509a.TID239.tmp
[2025-07-19T22:10:02.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.1.delta.c161a769-ac06-4e81-baf8-4838d7c6d347.TID236.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/47/1.delta
[2025-07-19T22:10:02.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/47] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/47/1.delta
[2025-07-19T22:10:02.328+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 236, attempt 0, stage 3.0)
[2025-07-19T22:10:02.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.1.delta.173b039f-6701-4a9c-a9bf-d390b0cb28d2.TID241.tmp
[2025-07-19T22:10:02.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 46 (task 235, attempt 0, stage 3.0)
[2025-07-19T22:10:02.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2db5b01d
[2025-07-19T22:10:02.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 46.0 in stage 3.0 (TID 235). 9140 bytes result sent to driver
[2025-07-19T22:10:02.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/57] for update
[2025-07-19T22:10:02.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 58.0 in stage 3.0 (TID 243) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.1.delta.d2a0d093-4ac0-4a52-a478-81a78fa586b9.TID237.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/48/1.delta
[2025-07-19T22:10:02.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/48] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/48/1.delta
[2025-07-19T22:10:02.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 237, attempt 0, stage 3.0)
[2025-07-19T22:10:02.355+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 235) in 180 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T22:10:02.355+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 58.0 in stage 3.0 (TID 243)
[2025-07-19T22:10:02.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.1.delta.997e9bdb-c802-4284-a12f-f91cbfe738ee.TID238.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/51/1.delta
[2025-07-19T22:10:02.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/51] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/51/1.delta
[2025-07-19T22:10:02.359+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 238, attempt 0, stage 3.0)
[2025-07-19T22:10:02.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 47 (task 236, attempt 0, stage 3.0)
[2025-07-19T22:10:02.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 47.0 in stage 3.0 (TID 236). 9085 bytes result sent to driver
[2025-07-19T22:10:02.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 59.0 in stage 3.0 (TID 244) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:02.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 59.0 in stage 3.0 (TID 244)
[2025-07-19T22:10:02.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 236) in 194 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T22:10:02.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.1.delta.1c07e62b-87db-4add-ba2e-9e4177b3ea3f.TID240.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/53/1.delta
[2025-07-19T22:10:02.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/53] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/53/1.delta
[2025-07-19T22:10:02.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 240, attempt 0, stage 3.0)
[2025-07-19T22:10:02.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.1.delta.8eac72d9-4684-49fa-8485-6a3b4344f720.TID242.tmp
[2025-07-19T22:10:02.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 48 (task 237, attempt 0, stage 3.0)
[2025-07-19T22:10:02.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:02.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bfe4162
[2025-07-19T22:10:02.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 48.0 in stage 3.0 (TID 237). 9087 bytes result sent to driver
[2025-07-19T22:10:02.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 60.0 in stage 3.0 (TID 245) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.388+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 60.0 in stage 3.0 (TID 245)
[2025-07-19T22:10:02.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.1.delta.0ffca9f2-4b40-423e-aeb0-378b9665509a.TID239.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/52/1.delta
[2025-07-19T22:10:02.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/52] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/52/1.delta
[2025-07-19T22:10:02.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 239, attempt 0, stage 3.0)
[2025-07-19T22:10:02.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 237) in 193 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T22:10:02.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.390+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/58] for update
[2025-07-19T22:10:02.393+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 51 (task 238, attempt 0, stage 3.0)
[2025-07-19T22:10:02.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@621eec91
[2025-07-19T22:10:02.402+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/59] for update
[2025-07-19T22:10:02.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 51.0 in stage 3.0 (TID 238). 9096 bytes result sent to driver
[2025-07-19T22:10:02.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.407+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 62.0 in stage 3.0 (TID 246) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.408+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 51.0 in stage 3.0 (TID 238) in 164 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T22:10:02.409+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 62.0 in stage 3.0 (TID 246)
[2025-07-19T22:10:02.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58ada66b
[2025-07-19T22:10:02.418+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.1.delta.173b039f-6701-4a9c-a9bf-d390b0cb28d2.TID241.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/56/1.delta
[2025-07-19T22:10:02.419+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/56] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/56/1.delta
[2025-07-19T22:10:02.420+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.421+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/60] for update
[2025-07-19T22:10:02.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.1.delta.2915e4d5-dcb1-465a-95dc-f48e9ebea159.TID243.tmp
[2025-07-19T22:10:02.424+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 241, attempt 0, stage 3.0)
[2025-07-19T22:10:02.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 52 (task 239, attempt 0, stage 3.0)
[2025-07-19T22:10:02.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 52.0 in stage 3.0 (TID 239). 9070 bytes result sent to driver
[2025-07-19T22:10:02.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.1.delta.385a9cfe-71cb-4a3a-9bd6-884ba38d7cb0.TID244.tmp
[2025-07-19T22:10:02.430+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 63.0 in stage 3.0 (TID 247) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 52.0 in stage 3.0 (TID 239) in 182 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T22:10:02.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 63.0 in stage 3.0 (TID 247)
[2025-07-19T22:10:02.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cb8b98b
[2025-07-19T22:10:02.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/62] for update
[2025-07-19T22:10:02.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 53 (task 240, attempt 0, stage 3.0)
[2025-07-19T22:10:02.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 53.0 in stage 3.0 (TID 240). 9094 bytes result sent to driver
[2025-07-19T22:10:02.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.1.delta.3b5e97ef-aad9-4fe9-97ec-d32f517158c0.TID245.tmp
[2025-07-19T22:10:02.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 64.0 in stage 3.0 (TID 248) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 53.0 in stage 3.0 (TID 240) in 196 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T22:10:02.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 64.0 in stage 3.0 (TID 248)
[2025-07-19T22:10:02.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.457+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 56 (task 241, attempt 0, stage 3.0)
[2025-07-19T22:10:02.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 56.0 in stage 3.0 (TID 241). 9093 bytes result sent to driver
[2025-07-19T22:10:02.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.1.delta.e1eee22e-f954-4da0-8105-a3cc5860ea4d.TID246.tmp
[2025-07-19T22:10:02.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 65.0 in stage 3.0 (TID 249) (8b44f3d35cfa, executor driver, partition 65, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 65.0 in stage 3.0 (TID 249)
[2025-07-19T22:10:02.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.471+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 56.0 in stage 3.0 (TID 241) in 206 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T22:10:02.473+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@670ab168
[2025-07-19T22:10:02.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/63] for update
[2025-07-19T22:10:02.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.1.delta.8eac72d9-4684-49fa-8485-6a3b4344f720.TID242.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/57/1.delta
[2025-07-19T22:10:02.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/57] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/57/1.delta
[2025-07-19T22:10:02.480+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 242, attempt 0, stage 3.0)
[2025-07-19T22:10:02.488+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@264c8b80
[2025-07-19T22:10:02.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/65] for update
[2025-07-19T22:10:02.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.1.delta.4e203c38-4da8-4b97-a16b-a3841c4b0836.TID247.tmp
[2025-07-19T22:10:02.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.1.delta.2915e4d5-dcb1-465a-95dc-f48e9ebea159.TID243.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/58/1.delta
[2025-07-19T22:10:02.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/58] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/58/1.delta
[2025-07-19T22:10:02.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 243, attempt 0, stage 3.0)
[2025-07-19T22:10:02.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@281984bb
[2025-07-19T22:10:02.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/64] for update
[2025-07-19T22:10:02.507+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 57 (task 242, attempt 0, stage 3.0)
[2025-07-19T22:10:02.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.1.delta.385a9cfe-71cb-4a3a-9bd6-884ba38d7cb0.TID244.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/59/1.delta
[2025-07-19T22:10:02.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/59] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/59/1.delta
[2025-07-19T22:10:02.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 244, attempt 0, stage 3.0)
[2025-07-19T22:10:02.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.1.delta.3b5e97ef-aad9-4fe9-97ec-d32f517158c0.TID245.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/60/1.delta
[2025-07-19T22:10:02.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/60] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/60/1.delta
[2025-07-19T22:10:02.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.1.delta.0e95ce43-da07-4591-bc80-e447e8f31a26.TID249.tmp
[2025-07-19T22:10:02.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 245, attempt 0, stage 3.0)
[2025-07-19T22:10:02.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 57.0 in stage 3.0 (TID 242). 9133 bytes result sent to driver
[2025-07-19T22:10:02.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 66.0 in stage 3.0 (TID 250) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.1.delta.de479f69-58eb-4a12-8fd5-0fb79578c9a3.TID248.tmp
[2025-07-19T22:10:02.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 57.0 in stage 3.0 (TID 242) in 241 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T22:10:02.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 66.0 in stage 3.0 (TID 250)
[2025-07-19T22:10:02.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 58 (task 243, attempt 0, stage 3.0)
[2025-07-19T22:10:02.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v156.metadata.json
[2025-07-19T22:10:02.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 58.0 in stage 3.0 (TID 243). 9090 bytes result sent to driver
[2025-07-19T22:10:02.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.1.delta.e1eee22e-f954-4da0-8105-a3cc5860ea4d.TID246.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/62/1.delta
[2025-07-19T22:10:02.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/62] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/62/1.delta
[2025-07-19T22:10:02.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 246, attempt 0, stage 3.0)
[2025-07-19T22:10:02.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 68.0 in stage 3.0 (TID 251) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 58.0 in stage 3.0 (TID 243) in 212 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T22:10:02.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.1.delta.4e203c38-4da8-4b97-a16b-a3841c4b0836.TID247.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/63/1.delta
[2025-07-19T22:10:02.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/63] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/63/1.delta
[2025-07-19T22:10:02.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T22:10:02.572+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 68.0 in stage 3.0 (TID 251)
[2025-07-19T22:10:02.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 247, attempt 0, stage 3.0)
[2025-07-19T22:10:02.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 59 (task 244, attempt 0, stage 3.0)
[2025-07-19T22:10:02.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 59.0 in stage 3.0 (TID 244). 9091 bytes result sent to driver
[2025-07-19T22:10:02.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 69.0 in stage 3.0 (TID 252) (8b44f3d35cfa, executor driver, partition 69, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 59.0 in stage 3.0 (TID 244) in 213 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T22:10:02.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d405baf
[2025-07-19T22:10:02.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 69.0 in stage 3.0 (TID 252)
[2025-07-19T22:10:02.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/66] for update
[2025-07-19T22:10:02.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 60 (task 245, attempt 0, stage 3.0)
[2025-07-19T22:10:02.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 60.0 in stage 3.0 (TID 245). 9080 bytes result sent to driver
[2025-07-19T22:10:02.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 71.0 in stage 3.0 (TID 253) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 60.0 in stage 3.0 (TID 245) in 214 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T22:10:02.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 71.0 in stage 3.0 (TID 253)
[2025-07-19T22:10:02.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dbaff8d
[2025-07-19T22:10:02.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/68] for update
[2025-07-19T22:10:02.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 63 (task 247, attempt 0, stage 3.0)
[2025-07-19T22:10:02.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 63.0 in stage 3.0 (TID 247). 9076 bytes result sent to driver
[2025-07-19T22:10:02.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.1.delta.ba76fea9-6341-4a8e-b0a9-266fe5f50253.TID250.tmp
[2025-07-19T22:10:02.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 72.0 in stage 3.0 (TID 254) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.620+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.1.delta.0e95ce43-da07-4591-bc80-e447e8f31a26.TID249.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/65/1.delta
[2025-07-19T22:10:02.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 72.0 in stage 3.0 (TID 254)
[2025-07-19T22:10:02.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/65] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/65/1.delta
[2025-07-19T22:10:02.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 249, attempt 0, stage 3.0)
[2025-07-19T22:10:02.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 63.0 in stage 3.0 (TID 247) in 187 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T22:10:02.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 62 (task 246, attempt 0, stage 3.0)
[2025-07-19T22:10:02.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65da65da
[2025-07-19T22:10:02.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 62.0 in stage 3.0 (TID 246). 9086 bytes result sent to driver
[2025-07-19T22:10:02.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 73.0 in stage 3.0 (TID 255) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/71] for update
[2025-07-19T22:10:02.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 62.0 in stage 3.0 (TID 246) in 221 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T22:10:02.638+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.1.delta.de479f69-58eb-4a12-8fd5-0fb79578c9a3.TID248.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/64/1.delta
[2025-07-19T22:10:02.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/64] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/64/1.delta
[2025-07-19T22:10:02.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 73.0 in stage 3.0 (TID 255)
[2025-07-19T22:10:02.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 248, attempt 0, stage 3.0)
[2025-07-19T22:10:02.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.1.delta.23a4ede0-6d04-48d8-b928-56c4b03898b0.TID251.tmp
[2025-07-19T22:10:02.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1092a51d
[2025-07-19T22:10:02.647+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.650+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:02.652+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/69] for update
[2025-07-19T22:10:02.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.1.delta.cdf25958-2c56-4f3a-88f4-c991db414b3b.TID253.tmp
[2025-07-19T22:10:02.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO SnapshotProducer: Committed snapshot 6766203055048202844 (FastAppend)
[2025-07-19T22:10:02.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 65 (task 249, attempt 0, stage 3.0)
[2025-07-19T22:10:02.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 65.0 in stage 3.0 (TID 249). 9086 bytes result sent to driver
[2025-07-19T22:10:02.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 75.0 in stage 3.0 (TID 256) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 65.0 in stage 3.0 (TID 249) in 207 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T22:10:02.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e180908
[2025-07-19T22:10:02.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 64 (task 248, attempt 0, stage 3.0)
[2025-07-19T22:10:02.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 64.0 in stage 3.0 (TID 248). 9093 bytes result sent to driver
[2025-07-19T22:10:02.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 75.0 in stage 3.0 (TID 256)
[2025-07-19T22:10:02.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.1.delta.062a5944-1577-428c-8c0d-39ea2a58449f.TID252.tmp
[2025-07-19T22:10:02.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/73] for update
[2025-07-19T22:10:02.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 77.0 in stage 3.0 (TID 257) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.685+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 77.0 in stage 3.0 (TID 257)
[2025-07-19T22:10:02.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 64.0 in stage 3.0 (TID 248) in 237 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T22:10:02.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.1.delta.ba76fea9-6341-4a8e-b0a9-266fe5f50253.TID250.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/66/1.delta
[2025-07-19T22:10:02.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/66] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/66/1.delta
[2025-07-19T22:10:02.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 250, attempt 0, stage 3.0)
[2025-07-19T22:10:02.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:02.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:02.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ae5501e
[2025-07-19T22:10:02.698+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/72] for update
[2025-07-19T22:10:02.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.1.delta.cd0f9ea9-334c-4328-bfef-579b84345abb.TID255.tmp
[2025-07-19T22:10:02.700+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.710+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@431a822f
[2025-07-19T22:10:02.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/77] for update
[2025-07-19T22:10:02.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.1.delta.41309772-9437-4b9e-9b17-d7526bfd37ab.TID254.tmp
[2025-07-19T22:10:02.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.1.delta.23a4ede0-6d04-48d8-b928-56c4b03898b0.TID251.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/68/1.delta
[2025-07-19T22:10:02.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/68] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/68/1.delta
[2025-07-19T22:10:02.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 251, attempt 0, stage 3.0)
[2025-07-19T22:10:02.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 66 (task 250, attempt 0, stage 3.0)
[2025-07-19T22:10:02.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 66.0 in stage 3.0 (TID 250). 9146 bytes result sent to driver
[2025-07-19T22:10:02.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c465efb
[2025-07-19T22:10:02.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.1.delta.08da45be-6af5-4c81-b573-93b7be9aa6c8.TID257.tmp
[2025-07-19T22:10:02.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.1.delta.cdf25958-2c56-4f3a-88f4-c991db414b3b.TID253.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/71/1.delta
[2025-07-19T22:10:02.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/71] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/71/1.delta
[2025-07-19T22:10:02.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 78.0 in stage 3.0 (TID 258) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 66.0 in stage 3.0 (TID 250) in 212 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T22:10:02.771+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/75] for update
[2025-07-19T22:10:02.771+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.772+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 78.0 in stage 3.0 (TID 258)
[2025-07-19T22:10:02.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 253, attempt 0, stage 3.0)
[2025-07-19T22:10:02.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 68 (task 251, attempt 0, stage 3.0)
[2025-07-19T22:10:02.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.1.delta.062a5944-1577-428c-8c0d-39ea2a58449f.TID252.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/69/1.delta
[2025-07-19T22:10:02.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/69] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/69/1.delta
[2025-07-19T22:10:02.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 252, attempt 0, stage 3.0)
[2025-07-19T22:10:02.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 68.0 in stage 3.0 (TID 251). 9072 bytes result sent to driver
[2025-07-19T22:10:02.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:02.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 79.0 in stage 3.0 (TID 259) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 68.0 in stage 3.0 (TID 251) in 212 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T22:10:02.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 79.0 in stage 3.0 (TID 259)
[2025-07-19T22:10:02.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:02.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c8050d1
[2025-07-19T22:10:02.781+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.793+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/78] for update
[2025-07-19T22:10:02.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 69 (task 252, attempt 0, stage 3.0)
[2025-07-19T22:10:02.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.1.delta.892cff45-f806-4240-9ea2-24c2c3c77564.TID256.tmp
[2025-07-19T22:10:02.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 69.0 in stage 3.0 (TID 252). 9066 bytes result sent to driver
[2025-07-19T22:10:02.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 71 (task 253, attempt 0, stage 3.0)
[2025-07-19T22:10:02.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.798+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 71.0 in stage 3.0 (TID 253). 9074 bytes result sent to driver
[2025-07-19T22:10:02.798+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 82.0 in stage 3.0 (TID 260) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 83.0 in stage 3.0 (TID 261) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.801+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 82.0 in stage 3.0 (TID 260)
[2025-07-19T22:10:02.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 71.0 in stage 3.0 (TID 253) in 203 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T22:10:02.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 83.0 in stage 3.0 (TID 261)
[2025-07-19T22:10:02.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 69.0 in stage 3.0 (TID 252) in 225 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T22:10:02.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.809+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.809+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:02.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:02.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@146b2550
[2025-07-19T22:10:02.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.1.delta.cd0f9ea9-334c-4328-bfef-579b84345abb.TID255.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/73/1.delta
[2025-07-19T22:10:02.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/73] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/73/1.delta
[2025-07-19T22:10:02.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/79] for update
[2025-07-19T22:10:02.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.1.delta.62aaa288-8047-4bcd-b9dd-1dc0f961c7bf.TID258.tmp
[2025-07-19T22:10:02.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 255, attempt 0, stage 3.0)
[2025-07-19T22:10:02.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@304600cc
[2025-07-19T22:10:02.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.1.delta.41309772-9437-4b9e-9b17-d7526bfd37ab.TID254.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/72/1.delta
[2025-07-19T22:10:02.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/72] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/72/1.delta
[2025-07-19T22:10:02.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/82] for update
[2025-07-19T22:10:02.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 254, attempt 0, stage 3.0)
[2025-07-19T22:10:02.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.1.delta.08da45be-6af5-4c81-b573-93b7be9aa6c8.TID257.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/77/1.delta
[2025-07-19T22:10:02.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/77] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/77/1.delta
[2025-07-19T22:10:02.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 257, attempt 0, stage 3.0)
[2025-07-19T22:10:02.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25c67f47
[2025-07-19T22:10:02.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/83] for update
[2025-07-19T22:10:02.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.1.delta.892cff45-f806-4240-9ea2-24c2c3c77564.TID256.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/75/1.delta
[2025-07-19T22:10:02.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=6766203055048202844, sequenceNumber=155, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT1.456936542S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=155}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=8521}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=276}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=12519}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=451758}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=24611748}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752962984887, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T22:10:02.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO SparkWrite: Committed in 1504 ms
[2025-07-19T22:10:02.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T22:10:02.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/75] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/75/1.delta
[2025-07-19T22:10:02.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 256, attempt 0, stage 3.0)
[2025-07-19T22:10:02.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 73 (task 255, attempt 0, stage 3.0)
[2025-07-19T22:10:02.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 72 (task 254, attempt 0, stage 3.0)
[2025-07-19T22:10:02.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 72.0 in stage 3.0 (TID 254). 9070 bytes result sent to driver
[2025-07-19T22:10:02.870+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 85.0 in stage 3.0 (TID 262) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.872+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 72.0 in stage 3.0 (TID 254) in 258 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T22:10:02.872+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 85.0 in stage 3.0 (TID 262)
[2025-07-19T22:10:02.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.1.delta.e2259683-c604-4836-a0a9-1f00091c20e9.TID260.tmp
[2025-07-19T22:10:02.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 77 (task 257, attempt 0, stage 3.0)
[2025-07-19T22:10:02.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 73.0 in stage 3.0 (TID 255). 9095 bytes result sent to driver
[2025-07-19T22:10:02.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 77.0 in stage 3.0 (TID 257). 9080 bytes result sent to driver
[2025-07-19T22:10:02.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 86.0 in stage 3.0 (TID 263) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:02.885+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.1.delta.47a43b5d-af78-46e5-a32d-f926ccb002b2.TID261.tmp
[2025-07-19T22:10:02.885+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 73.0 in stage 3.0 (TID 255) in 256 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T22:10:02.885+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 86.0 in stage 3.0 (TID 263)
[2025-07-19T22:10:02.885+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 77.0 in stage 3.0 (TID 257) in 200 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T22:10:02.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.1.delta.d0a32d75-534c-45fc-af07-42a209c1713a.TID259.tmp
[2025-07-19T22:10:02.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 87.0 in stage 3.0 (TID 264) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 87.0 in stage 3.0 (TID 264)
[2025-07-19T22:10:02.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:02.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 75 (task 256, attempt 0, stage 3.0)
[2025-07-19T22:10:02.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 75.0 in stage 3.0 (TID 256). 9076 bytes result sent to driver
[2025-07-19T22:10:02.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 89.0 in stage 3.0 (TID 265) (8b44f3d35cfa, executor driver, partition 89, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 75.0 in stage 3.0 (TID 256) in 222 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T22:10:02.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752790177000 ms
[2025-07-19T22:10:02.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 89.0 in stage 3.0 (TID 265)
[2025-07-19T22:10:02.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.1.delta.62aaa288-8047-4bcd-b9dd-1dc0f961c7bf.TID258.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/78/1.delta
[2025-07-19T22:10:02.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/78] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/78/1.delta
[2025-07-19T22:10:02.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b63598
[2025-07-19T22:10:02.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 258, attempt 0, stage 3.0)
[2025-07-19T22:10:02.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/85] for update
[2025-07-19T22:10:02.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/commits/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/commits/.0.a9ebded9-63fb-4b66-bcee-6285a19e19c4.tmp
[2025-07-19T22:10:02.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47706e0a
[2025-07-19T22:10:02.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/89] for update
[2025-07-19T22:10:02.915+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50f17966
[2025-07-19T22:10:02.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 78 (task 258, attempt 0, stage 3.0)
[2025-07-19T22:10:02.928+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.930+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/87] for update
[2025-07-19T22:10:02.930+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 78.0 in stage 3.0 (TID 258). 9132 bytes result sent to driver
[2025-07-19T22:10:02.930+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 92.0 in stage 3.0 (TID 266) (8b44f3d35cfa, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 92.0 in stage 3.0 (TID 266)
[2025-07-19T22:10:02.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 78.0 in stage 3.0 (TID 258) in 181 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T22:10:02.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.1.delta.2431fca3-4d81-4498-a2cf-d2266b3a661b.TID262.tmp
[2025-07-19T22:10:02.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:02.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.1.delta.47a43b5d-af78-46e5-a32d-f926ccb002b2.TID261.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/83/1.delta
[2025-07-19T22:10:02.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/83] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/83/1.delta
[2025-07-19T22:10:02.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.1.delta.96c6e550-9434-48fa-9012-0f4c1f3fe0ef.TID265.tmp
[2025-07-19T22:10:02.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2650554b
[2025-07-19T22:10:02.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 261, attempt 0, stage 3.0)
[2025-07-19T22:10:02.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/86] for update
[2025-07-19T22:10:02.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41b035f0
[2025-07-19T22:10:02.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:02.955+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/92] for update
[2025-07-19T22:10:02.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:02.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.1.delta.d0a32d75-534c-45fc-af07-42a209c1713a.TID259.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/79/1.delta
[2025-07-19T22:10:02.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/79] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/79/1.delta
[2025-07-19T22:10:02.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 259, attempt 0, stage 3.0)
[2025-07-19T22:10:02.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.1.delta.0f7a1212-3c99-40b0-96cd-0895a8012b11.TID264.tmp
[2025-07-19T22:10:02.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.1.delta.e2259683-c604-4836-a0a9-1f00091c20e9.TID260.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/82/1.delta
[2025-07-19T22:10:02.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/82] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/82/1.delta
[2025-07-19T22:10:02.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 260, attempt 0, stage 3.0)
[2025-07-19T22:10:02.966+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.1.delta.92acc218-4100-4610-9763-50cfcc896fa8.TID263.tmp
[2025-07-19T22:10:02.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.1.delta.4aa7d13b-9e1d-46eb-809a-35ec279e9d4f.TID266.tmp
[2025-07-19T22:10:02.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 83 (task 261, attempt 0, stage 3.0)
[2025-07-19T22:10:02.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 83.0 in stage 3.0 (TID 261). 9081 bytes result sent to driver
[2025-07-19T22:10:02.981+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 94.0 in stage 3.0 (TID 267) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 83.0 in stage 3.0 (TID 261) in 187 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T22:10:02.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 94.0 in stage 3.0 (TID 267)
[2025-07-19T22:10:02.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.985+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 79 (task 259, attempt 0, stage 3.0)
[2025-07-19T22:10:02.987+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 79.0 in stage 3.0 (TID 259). 9082 bytes result sent to driver
[2025-07-19T22:10:02.990+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/commits/.0.a9ebded9-63fb-4b66-bcee-6285a19e19c4.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/commits/0
[2025-07-19T22:10:02.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 95.0 in stage 3.0 (TID 268) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:02.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 79.0 in stage 3.0 (TID 259) in 222 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T22:10:02.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 95.0 in stage 3.0 (TID 268)
[2025-07-19T22:10:02.994+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:02.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:02.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO DataWritingSparkTask: Committed partition 82 (task 260, attempt 0, stage 3.0)
[2025-07-19T22:10:02.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fe2b90d
[2025-07-19T22:10:02.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.000+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/94] for update
[2025-07-19T22:10:03.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Finished task 82.0 in stage 3.0 (TID 260). 9082 bytes result sent to driver
[2025-07-19T22:10:03.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Starting task 96.0 in stage 3.0 (TID 269) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.004+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO Executor: Running task 96.0 in stage 3.0 (TID 269)
[2025-07-19T22:10:03.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO TaskSetManager: Finished task 82.0 in stage 3.0 (TID 260) in 205 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T22:10:03.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.1.delta.2431fca3-4d81-4498-a2cf-d2266b3a661b.TID262.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/85/1.delta
[2025-07-19T22:10:03.008+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/85] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/85/1.delta
[2025-07-19T22:10:03.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a6ac62f
[2025-07-19T22:10:03.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 262, attempt 0, stage 3.0)
[2025-07-19T22:10:03.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/95] for update
[2025-07-19T22:10:03.015+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.1.delta.96c6e550-9434-48fa-9012-0f4c1f3fe0ef.TID265.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/89/1.delta
[2025-07-19T22:10:03.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/89] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/89/1.delta
[2025-07-19T22:10:03.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 265, attempt 0, stage 3.0)
[2025-07-19T22:10:03.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f882cca
[2025-07-19T22:10:03.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/96] for update
[2025-07-19T22:10:03.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.1.delta.0f7a1212-3c99-40b0-96cd-0895a8012b11.TID264.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/87/1.delta
[2025-07-19T22:10:03.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/87] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/87/1.delta
[2025-07-19T22:10:03.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.1.delta.789651bb-5b67-4b58-93c9-74a269ba5aa8.TID267.tmp
[2025-07-19T22:10:03.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.1.delta.23322a39-561b-47f7-8437-b52640c5fbe2.TID268.tmp
[2025-07-19T22:10:03.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 264, attempt 0, stage 3.0)
[2025-07-19T22:10:03.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.1.delta.92acc218-4100-4610-9763-50cfcc896fa8.TID263.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/86/1.delta
[2025-07-19T22:10:03.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/86] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/86/1.delta
[2025-07-19T22:10:03.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 263, attempt 0, stage 3.0)
[2025-07-19T22:10:03.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 85 (task 262, attempt 0, stage 3.0)
[2025-07-19T22:10:03.043+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 85.0 in stage 3.0 (TID 262). 9092 bytes result sent to driver
[2025-07-19T22:10:03.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 97.0 in stage 3.0 (TID 270) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 97.0 in stage 3.0 (TID 270)
[2025-07-19T22:10:03.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 85.0 in stage 3.0 (TID 262) in 177 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T22:10:03.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.1.delta.65e3e8b1-56af-4bff-8de6-dd3ea93a5741.TID269.tmp
[2025-07-19T22:10:03.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 89 (task 265, attempt 0, stage 3.0)
[2025-07-19T22:10:03.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 89.0 in stage 3.0 (TID 265). 9078 bytes result sent to driver
[2025-07-19T22:10:03.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.1.delta.4aa7d13b-9e1d-46eb-809a-35ec279e9d4f.TID266.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/92/1.delta
[2025-07-19T22:10:03.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/92] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/92/1.delta
[2025-07-19T22:10:03.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 98.0 in stage 3.0 (TID 271) (8b44f3d35cfa, executor driver, partition 98, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 266, attempt 0, stage 3.0)
[2025-07-19T22:10:03.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 87 (task 264, attempt 0, stage 3.0)
[2025-07-19T22:10:03.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 89.0 in stage 3.0 (TID 265) in 176 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T22:10:03.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 98.0 in stage 3.0 (TID 271)
[2025-07-19T22:10:03.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 87.0 in stage 3.0 (TID 264). 9094 bytes result sent to driver
[2025-07-19T22:10:03.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 99.0 in stage 3.0 (TID 272) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 99.0 in stage 3.0 (TID 272)
[2025-07-19T22:10:03.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 87.0 in stage 3.0 (TID 264) in 196 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T22:10:03.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69593f52
[2025-07-19T22:10:03.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 86 (task 263, attempt 0, stage 3.0)
[2025-07-19T22:10:03.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 86.0 in stage 3.0 (TID 263). 9094 bytes result sent to driver
[2025-07-19T22:10:03.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:03.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 100.0 in stage 3.0 (TID 273) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/97] for update
[2025-07-19T22:10:03.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 100.0 in stage 3.0 (TID 273)
[2025-07-19T22:10:03.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 86.0 in stage 3.0 (TID 263) in 205 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T22:10:03.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T22:10:03.086+0000] {subprocess.py:93} INFO -   "id" : "46c08399-34b2-49a9-aadd-060519c28563",
[2025-07-19T22:10:03.086+0000] {subprocess.py:93} INFO -   "runId" : "9b56af61-c478-4de4-bf3d-6c85462edb9c",
[2025-07-19T22:10:03.087+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T22:10:03.088+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T22:09:48.857Z",
[2025-07-19T22:10:03.090+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T22:10:03.090+0000] {subprocess.py:93} INFO -   "numInputRows" : 276,
[2025-07-19T22:10:03.090+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:03.091+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 19.53014435324087,
[2025-07-19T22:10:03.091+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T22:10:03.092+0000] {subprocess.py:93} INFO -     "addBatch" : 12859,
[2025-07-19T22:10:03.092+0000] {subprocess.py:93} INFO -     "commitOffsets" : 98,
[2025-07-19T22:10:03.093+0000] {subprocess.py:93} INFO -     "getBatch" : 21,
[2025-07-19T22:10:03.094+0000] {subprocess.py:93} INFO -     "latestOffset" : 314,
[2025-07-19T22:10:03.095+0000] {subprocess.py:93} INFO -     "queryPlanning" : 645,
[2025-07-19T22:10:03.096+0000] {subprocess.py:93} INFO -     "triggerExecution" : 14132,
[2025-07-19T22:10:03.097+0000] {subprocess.py:93} INFO -     "walCommit" : 154
[2025-07-19T22:10:03.098+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:03.098+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T22:10:03.098+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T19:36:32.902Z",
[2025-07-19T22:10:03.098+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T22:09:37.000Z",
[2025-07-19T22:10:03.099+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T18:00:01.000Z",
[2025-07-19T22:10:03.099+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T22:10:03.100+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:03.100+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T22:10:03.101+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T22:10:03.101+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 276,
[2025-07-19T22:10:03.101+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 276,
[2025-07-19T22:10:03.102+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 7827,
[2025-07-19T22:10:03.102+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T22:10:03.102+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 813,
[2025-07-19T22:10:03.102+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 28025,
[2025-07-19T22:10:03.103+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 111184,
[2025-07-19T22:10:03.103+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T22:10:03.103+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T22:10:03.103+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T22:10:03.103+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T22:10:03.103+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T22:10:03.103+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T22:10:03.103+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 82384
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:03.104+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -     "numInputRows" : 276,
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 19.53014435324087,
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:03.105+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:03.106+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T22:10:03.106+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T22:10:03.106+0000] {subprocess.py:93} INFO -     "numOutputRows" : 276
[2025-07-19T22:10:03.106+0000] {subprocess.py:93} INFO -   }
[2025-07-19T22:10:03.107+0000] {subprocess.py:93} INFO - }
[2025-07-19T22:10:03.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.109+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.109+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.110+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3be8b1b2
[2025-07-19T22:10:03.110+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/98] for update
[2025-07-19T22:10:03.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.1.delta.953d39b8-fe9a-4c81-a35a-d1d04eb5abdf.TID270.tmp
[2025-07-19T22:10:03.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 92 (task 266, attempt 0, stage 3.0)
[2025-07-19T22:10:03.116+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1334adc1
[2025-07-19T22:10:03.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 92.0 in stage 3.0 (TID 266). 9078 bytes result sent to driver
[2025-07-19T22:10:03.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 102.0 in stage 3.0 (TID 274) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/99] for update
[2025-07-19T22:10:03.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 92.0 in stage 3.0 (TID 266) in 185 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T22:10:03.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 102.0 in stage 3.0 (TID 274)
[2025-07-19T22:10:03.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.1.delta.789651bb-5b67-4b58-93c9-74a269ba5aa8.TID267.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/94/1.delta
[2025-07-19T22:10:03.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/94] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/94/1.delta
[2025-07-19T22:10:03.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 267, attempt 0, stage 3.0)
[2025-07-19T22:10:03.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.1.delta.d742f2bb-421e-4b07-99ea-9cf8a148a294.TID271.tmp
[2025-07-19T22:10:03.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.124+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.1.delta.23322a39-561b-47f7-8437-b52640c5fbe2.TID268.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/95/1.delta
[2025-07-19T22:10:03.124+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/95] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/95/1.delta
[2025-07-19T22:10:03.125+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 268, attempt 0, stage 3.0)
[2025-07-19T22:10:03.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@543bd0b7
[2025-07-19T22:10:03.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.130+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/100] for update
[2025-07-19T22:10:03.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/offsets/.1.b96474a1-140c-457d-b1e6-a182b10c14f0.tmp
[2025-07-19T22:10:03.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30089d7d
[2025-07-19T22:10:03.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/102] for update
[2025-07-19T22:10:03.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.1.delta.3780ffac-81b0-47ae-a405-b025b5bbad79.TID273.tmp
[2025-07-19T22:10:03.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.1.delta.65e3e8b1-56af-4bff-8de6-dd3ea93a5741.TID269.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/96/1.delta
[2025-07-19T22:10:03.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/96] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/96/1.delta
[2025-07-19T22:10:03.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 269, attempt 0, stage 3.0)
[2025-07-19T22:10:03.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 94 (task 267, attempt 0, stage 3.0)
[2025-07-19T22:10:03.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 94.0 in stage 3.0 (TID 267). 9092 bytes result sent to driver
[2025-07-19T22:10:03.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.1.delta.3f226046-5e66-4bfd-9761-53fb10b45043.TID272.tmp
[2025-07-19T22:10:03.153+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 104.0 in stage 3.0 (TID 275) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.154+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 104.0 in stage 3.0 (TID 275)
[2025-07-19T22:10:03.154+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 94.0 in stage 3.0 (TID 267) in 172 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T22:10:03.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.1.delta.433fa90a-c39d-43e6-92a2-552d72a86a9c.TID274.tmp
[2025-07-19T22:10:03.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.1.delta.953d39b8-fe9a-4c81-a35a-d1d04eb5abdf.TID270.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/97/1.delta
[2025-07-19T22:10:03.168+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/97] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/97/1.delta
[2025-07-19T22:10:03.172+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 95 (task 268, attempt 0, stage 3.0)
[2025-07-19T22:10:03.173+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55eecb34
[2025-07-19T22:10:03.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/104] for update
[2025-07-19T22:10:03.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 95.0 in stage 3.0 (TID 268). 9080 bytes result sent to driver
[2025-07-19T22:10:03.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 270, attempt 0, stage 3.0)
[2025-07-19T22:10:03.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 105.0 in stage 3.0 (TID 276) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 95.0 in stage 3.0 (TID 268) in 182 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T22:10:03.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 105.0 in stage 3.0 (TID 276)
[2025-07-19T22:10:03.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 96 (task 269, attempt 0, stage 3.0)
[2025-07-19T22:10:03.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 96.0 in stage 3.0 (TID 269). 9075 bytes result sent to driver
[2025-07-19T22:10:03.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 106.0 in stage 3.0 (TID 277) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 96.0 in stage 3.0 (TID 269) in 179 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T22:10:03.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 106.0 in stage 3.0 (TID 277)
[2025-07-19T22:10:03.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.1.delta.d742f2bb-421e-4b07-99ea-9cf8a148a294.TID271.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/98/1.delta
[2025-07-19T22:10:03.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/98] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/98/1.delta
[2025-07-19T22:10:03.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 271, attempt 0, stage 3.0)
[2025-07-19T22:10:03.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.1.delta.c2630eed-3fda-4829-9ed6-478ccb754023.TID275.tmp
[2025-07-19T22:10:03.191+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c0496b1
[2025-07-19T22:10:03.194+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/105] for update
[2025-07-19T22:10:03.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 97 (task 270, attempt 0, stage 3.0)
[2025-07-19T22:10:03.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 97.0 in stage 3.0 (TID 270). 9080 bytes result sent to driver
[2025-07-19T22:10:03.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 107.0 in stage 3.0 (TID 278) (8b44f3d35cfa, executor driver, partition 107, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@530ce831
[2025-07-19T22:10:03.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 97.0 in stage 3.0 (TID 270) in 156 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T22:10:03.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/offsets/.1.b96474a1-140c-457d-b1e6-a182b10c14f0.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/offsets/1
[2025-07-19T22:10:03.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752790177000,1752963003109,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T22:10:03.202+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 107.0 in stage 3.0 (TID 278)
[2025-07-19T22:10:03.202+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/106] for update
[2025-07-19T22:10:03.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.213+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:03.213+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.1.delta.c5981055-96e0-4a0d-b4b2-1dc6dd00ed4c.TID276.tmp
[2025-07-19T22:10:03.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 98 (task 271, attempt 0, stage 3.0)
[2025-07-19T22:10:03.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 98.0 in stage 3.0 (TID 271). 9072 bytes result sent to driver
[2025-07-19T22:10:03.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 109.0 in stage 3.0 (TID 279) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 98.0 in stage 3.0 (TID 271) in 166 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T22:10:03.225+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 109.0 in stage 3.0 (TID 279)
[2025-07-19T22:10:03.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.1.delta.3f226046-5e66-4bfd-9761-53fb10b45043.TID272.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/99/1.delta
[2025-07-19T22:10:03.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/99] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/99/1.delta
[2025-07-19T22:10:03.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 272, attempt 0, stage 3.0)
[2025-07-19T22:10:03.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4baaa463
[2025-07-19T22:10:03.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/107] for update
[2025-07-19T22:10:03.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:03.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.1.delta.433fa90a-c39d-43e6-92a2-552d72a86a9c.TID274.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/102/1.delta
[2025-07-19T22:10:03.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/102] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/102/1.delta
[2025-07-19T22:10:03.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 274, attempt 0, stage 3.0)
[2025-07-19T22:10:03.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6374241b
[2025-07-19T22:10:03.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.1.delta.3780ffac-81b0-47ae-a405-b025b5bbad79.TID273.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/100/1.delta
[2025-07-19T22:10:03.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/100] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/100/1.delta
[2025-07-19T22:10:03.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.1.delta.4afb9532-42ea-4348-b57a-7416f9b47dd1.TID277.tmp
[2025-07-19T22:10:03.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 273, attempt 0, stage 3.0)
[2025-07-19T22:10:03.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/109] for update
[2025-07-19T22:10:03.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.1.delta.a1ba510b-2848-4956-b535-e056a2da5b91.TID278.tmp
[2025-07-19T22:10:03.266+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 99 (task 272, attempt 0, stage 3.0)
[2025-07-19T22:10:03.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 99.0 in stage 3.0 (TID 272). 9123 bytes result sent to driver
[2025-07-19T22:10:03.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:03.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:03.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:03.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 110.0 in stage 3.0 (TID 280) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 99.0 in stage 3.0 (TID 272) in 201 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T22:10:03.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 110.0 in stage 3.0 (TID 280)
[2025-07-19T22:10:03.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 102 (task 274, attempt 0, stage 3.0)
[2025-07-19T22:10:03.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 102.0 in stage 3.0 (TID 274). 9080 bytes result sent to driver
[2025-07-19T22:10:03.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.1.delta.c2630eed-3fda-4829-9ed6-478ccb754023.TID275.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/104/1.delta
[2025-07-19T22:10:03.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/104] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/104/1.delta
[2025-07-19T22:10:03.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 100 (task 273, attempt 0, stage 3.0)
[2025-07-19T22:10:03.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 100.0 in stage 3.0 (TID 273). 9088 bytes result sent to driver
[2025-07-19T22:10:03.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 275, attempt 0, stage 3.0)
[2025-07-19T22:10:03.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 111.0 in stage 3.0 (TID 281) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 113.0 in stage 3.0 (TID 282) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 113.0 in stage 3.0 (TID 282)
[2025-07-19T22:10:03.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 102.0 in stage 3.0 (TID 274) in 171 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T22:10:03.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 100.0 in stage 3.0 (TID 273) in 204 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T22:10:03.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 111.0 in stage 3.0 (TID 281)
[2025-07-19T22:10:03.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.290+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.290+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:03.291+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.1.delta.bc14351a-c0a8-4ab6-8874-f24a4dcb04f9.TID279.tmp
[2025-07-19T22:10:03.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.1.delta.c5981055-96e0-4a0d-b4b2-1dc6dd00ed4c.TID276.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/105/1.delta
[2025-07-19T22:10:03.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/105] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/105/1.delta
[2025-07-19T22:10:03.293+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 276, attempt 0, stage 3.0)
[2025-07-19T22:10:03.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43f8dbcc
[2025-07-19T22:10:03.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.303+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/110] for update
[2025-07-19T22:10:03.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 104 (task 275, attempt 0, stage 3.0)
[2025-07-19T22:10:03.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 104.0 in stage 3.0 (TID 275). 9085 bytes result sent to driver
[2025-07-19T22:10:03.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 117.0 in stage 3.0 (TID 283) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a1d0f20
[2025-07-19T22:10:03.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/113] for update
[2025-07-19T22:10:03.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:03.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:03.324+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:03.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c1f73bf
[2025-07-19T22:10:03.326+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 117.0 in stage 3.0 (TID 283)
[2025-07-19T22:10:03.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 105 (task 276, attempt 0, stage 3.0)
[2025-07-19T22:10:03.328+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.1.delta.a1ba510b-2848-4956-b535-e056a2da5b91.TID278.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/107/1.delta
[2025-07-19T22:10:03.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/107] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/107/1.delta
[2025-07-19T22:10:03.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 105.0 in stage 3.0 (TID 276). 9095 bytes result sent to driver
[2025-07-19T22:10:03.330+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.330+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/111] for update
[2025-07-19T22:10:03.330+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.1.delta.65bdbdb6-63b2-4026-aba1-3d516b0a81d0.TID280.tmp
[2025-07-19T22:10:03.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.1.delta.4afb9532-42ea-4348-b57a-7416f9b47dd1.TID277.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/106/1.delta
[2025-07-19T22:10:03.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/106] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/106/1.delta
[2025-07-19T22:10:03.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 104.0 in stage 3.0 (TID 275) in 180 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T22:10:03.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.1.delta.56d3c317-cfe6-43d9-bd63-5ef0423b08c1.TID282.tmp
[2025-07-19T22:10:03.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 277, attempt 0, stage 3.0)
[2025-07-19T22:10:03.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 278, attempt 0, stage 3.0)
[2025-07-19T22:10:03.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.1.delta.5f0e7374-659d-42ee-9257-5a8e27d20ad4.TID281.tmp
[2025-07-19T22:10:03.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@425c4d0b
[2025-07-19T22:10:03.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/117] for update
[2025-07-19T22:10:03.351+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.1.delta.bc14351a-c0a8-4ab6-8874-f24a4dcb04f9.TID279.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/109/1.delta
[2025-07-19T22:10:03.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/109] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/109/1.delta
[2025-07-19T22:10:03.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 279, attempt 0, stage 3.0)
[2025-07-19T22:10:03.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 118.0 in stage 3.0 (TID 284) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.354+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 105.0 in stage 3.0 (TID 276) in 182 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T22:10:03.359+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 118.0 in stage 3.0 (TID 284)
[2025-07-19T22:10:03.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 107 (task 278, attempt 0, stage 3.0)
[2025-07-19T22:10:03.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 107.0 in stage 3.0 (TID 278). 9084 bytes result sent to driver
[2025-07-19T22:10:03.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 119.0 in stage 3.0 (TID 285) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 119.0 in stage 3.0 (TID 285)
[2025-07-19T22:10:03.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:03.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.1.delta.371c8671-0a83-4655-aebe-bd12b5e280bc.TID283.tmp
[2025-07-19T22:10:03.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 106 (task 277, attempt 0, stage 3.0)
[2025-07-19T22:10:03.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 106.0 in stage 3.0 (TID 277). 9076 bytes result sent to driver
[2025-07-19T22:10:03.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 107.0 in stage 3.0 (TID 278) in 176 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T22:10:03.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 120.0 in stage 3.0 (TID 286) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 106.0 in stage 3.0 (TID 277) in 207 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T22:10:03.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 109 (task 279, attempt 0, stage 3.0)
[2025-07-19T22:10:03.387+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 120.0 in stage 3.0 (TID 286)
[2025-07-19T22:10:03.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 109.0 in stage 3.0 (TID 279). 9080 bytes result sent to driver
[2025-07-19T22:10:03.391+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 121.0 in stage 3.0 (TID 287) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.391+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 109.0 in stage 3.0 (TID 279) in 167 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T22:10:03.392+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d35c4c0
[2025-07-19T22:10:03.393+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.393+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:03.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 121.0 in stage 3.0 (TID 287)
[2025-07-19T22:10:03.396+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:03.397+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:03.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:03.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/119] for update
[2025-07-19T22:10:03.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.1.delta.65bdbdb6-63b2-4026-aba1-3d516b0a81d0.TID280.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/110/1.delta
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/110] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/110/1.delta
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 280, attempt 0, stage 3.0)
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@501b411d
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/118] for update
[2025-07-19T22:10:03.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.418+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e8b335f
[2025-07-19T22:10:03.420+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.1.delta.9384dbdb-890d-4880-bbbb-0b0fa29fe430.TID285.tmp
[2025-07-19T22:10:03.421+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.421+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.1.delta.56d3c317-cfe6-43d9-bd63-5ef0423b08c1.TID282.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/113/1.delta
[2025-07-19T22:10:03.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/113] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/113/1.delta
[2025-07-19T22:10:03.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/121] for update
[2025-07-19T22:10:03.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 282, attempt 0, stage 3.0)
[2025-07-19T22:10:03.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 110 (task 280, attempt 0, stage 3.0)
[2025-07-19T22:10:03.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 110.0 in stage 3.0 (TID 280). 9061 bytes result sent to driver
[2025-07-19T22:10:03.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.1.delta.5f0e7374-659d-42ee-9257-5a8e27d20ad4.TID281.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/111/1.delta
[2025-07-19T22:10:03.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/111] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/111/1.delta
[2025-07-19T22:10:03.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 110.0 in stage 3.0 (TID 280) in 168 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T22:10:03.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 281, attempt 0, stage 3.0)
[2025-07-19T22:10:03.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28b1bb0a
[2025-07-19T22:10:03.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 122.0 in stage 3.0 (TID 288) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/120] for update
[2025-07-19T22:10:03.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 122.0 in stage 3.0 (TID 288)
[2025-07-19T22:10:03.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.1.delta.6f05ce08-0218-4d63-aceb-0c75ff535ceb.TID284.tmp
[2025-07-19T22:10:03.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 113 (task 282, attempt 0, stage 3.0)
[2025-07-19T22:10:03.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 113.0 in stage 3.0 (TID 282). 9099 bytes result sent to driver
[2025-07-19T22:10:03.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 123.0 in stage 3.0 (TID 289) (8b44f3d35cfa, executor driver, partition 123, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 209.0 KiB, free 433.1 MiB)
[2025-07-19T22:10:03.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 123.0 in stage 3.0 (TID 289)
[2025-07-19T22:10:03.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 113.0 in stage 3.0 (TID 282) in 172 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T22:10:03.457+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.1.delta.c9211646-ef48-4350-893d-73173f4221ba.TID287.tmp
[2025-07-19T22:10:03.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b2c7ec4
[2025-07-19T22:10:03.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/122] for update
[2025-07-19T22:10:03.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 111 (task 281, attempt 0, stage 3.0)
[2025-07-19T22:10:03.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 111.0 in stage 3.0 (TID 281). 9103 bytes result sent to driver
[2025-07-19T22:10:03.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.1 MiB)
[2025-07-19T22:10:03.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 8b44f3d35cfa:37751 (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T22:10:03.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.1.delta.6b4bbed4-1c18-4338-b818-49a462eb2f4c.TID286.tmp
[2025-07-19T22:10:03.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 125.0 in stage 3.0 (TID 290) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 111.0 in stage 3.0 (TID 281) in 196 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T22:10:03.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkContext: Created broadcast 12 from start at <unknown>:0
[2025-07-19T22:10:03.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 125.0 in stage 3.0 (TID 290)
[2025-07-19T22:10:03.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@741c0bc0
[2025-07-19T22:10:03.480+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/123] for update
[2025-07-19T22:10:03.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.1.delta.371c8671-0a83-4655-aebe-bd12b5e280bc.TID283.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/117/1.delta
[2025-07-19T22:10:03.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/117] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/117/1.delta
[2025-07-19T22:10:03.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 283, attempt 0, stage 3.0)
[2025-07-19T22:10:03.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-07-19T22:10:03.489+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.1.delta.87be12d3-b296-4298-afdc-596a159fc128.TID288.tmp
[2025-07-19T22:10:03.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.0 MiB)
[2025-07-19T22:10:03.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 8b44f3d35cfa:37751 (size: 29.5 KiB, free: 434.1 MiB)
[2025-07-19T22:10:03.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23127a17
[2025-07-19T22:10:03.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkContext: Created broadcast 13 from start at <unknown>:0
[2025-07-19T22:10:03.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T22:10:03.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/125] for update
[2025-07-19T22:10:03.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T22:10:03.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DAGScheduler: Registering RDD 27 (start at <unknown>:0) as input to shuffle 3
[2025-07-19T22:10:03.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DAGScheduler: Got job 3 (start at <unknown>:0) with 200 output partitions
[2025-07-19T22:10:03.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DAGScheduler: Final stage: ResultStage 7 (start at <unknown>:0)
[2025-07-19T22:10:03.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2025-07-19T22:10:03.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DAGScheduler: Missing parents: List()
[2025-07-19T22:10:03.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.1.delta.5feec079-16eb-4baa-9548-9a5da6a847e3.TID289.tmp
[2025-07-19T22:10:03.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DAGScheduler: Submitting ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0), which has no missing parents
[2025-07-19T22:10:03.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.1.delta.9384dbdb-890d-4880-bbbb-0b0fa29fe430.TID285.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/119/1.delta
[2025-07-19T22:10:03.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/119] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/119/1.delta
[2025-07-19T22:10:03.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 285, attempt 0, stage 3.0)
[2025-07-19T22:10:03.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 117 (task 283, attempt 0, stage 3.0)
[2025-07-19T22:10:03.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 117.0 in stage 3.0 (TID 283). 9121 bytes result sent to driver
[2025-07-19T22:10:03.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 127.0 in stage 3.0 (TID 291) (8b44f3d35cfa, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.1.delta.0ddae625-b20d-45e7-8067-61cae264bb75.TID290.tmp
[2025-07-19T22:10:03.515+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 117.0 in stage 3.0 (TID 283) in 208 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T22:10:03.515+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 127.0 in stage 3.0 (TID 291)
[2025-07-19T22:10:03.519+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.1.delta.6f05ce08-0218-4d63-aceb-0c75ff535ceb.TID284.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/118/1.delta
[2025-07-19T22:10:03.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/118] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/118/1.delta
[2025-07-19T22:10:03.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 284, attempt 0, stage 3.0)
[2025-07-19T22:10:03.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.1.delta.c9211646-ef48-4350-893d-73173f4221ba.TID287.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/121/1.delta
[2025-07-19T22:10:03.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/121] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/121/1.delta
[2025-07-19T22:10:03.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 287, attempt 0, stage 3.0)
[2025-07-19T22:10:03.533+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.1.delta.6b4bbed4-1c18-4338-b818-49a462eb2f4c.TID286.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/120/1.delta
[2025-07-19T22:10:03.534+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/120] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/120/1.delta
[2025-07-19T22:10:03.535+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 286, attempt 0, stage 3.0)
[2025-07-19T22:10:03.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1597fa99
[2025-07-19T22:10:03.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.1.delta.87be12d3-b296-4298-afdc-596a159fc128.TID288.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/122/1.delta
[2025-07-19T22:10:03.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/122] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/122/1.delta
[2025-07-19T22:10:03.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 288, attempt 0, stage 3.0)
[2025-07-19T22:10:03.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/127] for update
[2025-07-19T22:10:03.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.1.delta.5feec079-16eb-4baa-9548-9a5da6a847e3.TID289.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/123/1.delta
[2025-07-19T22:10:03.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/123] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/123/1.delta
[2025-07-19T22:10:03.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 289, attempt 0, stage 3.0)
[2025-07-19T22:10:03.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 119 (task 285, attempt 0, stage 3.0)
[2025-07-19T22:10:03.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 119.0 in stage 3.0 (TID 285). 9080 bytes result sent to driver
[2025-07-19T22:10:03.553+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 128.0 in stage 3.0 (TID 292) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 128.0 in stage 3.0 (TID 292)
[2025-07-19T22:10:03.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 119.0 in stage 3.0 (TID 285) in 190 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T22:10:03.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 121 (task 287, attempt 0, stage 3.0)
[2025-07-19T22:10:03.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 118 (task 284, attempt 0, stage 3.0)
[2025-07-19T22:10:03.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 121.0 in stage 3.0 (TID 287). 9076 bytes result sent to driver
[2025-07-19T22:10:03.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:03.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 129.0 in stage 3.0 (TID 293) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 118.0 in stage 3.0 (TID 284). 9078 bytes result sent to driver
[2025-07-19T22:10:03.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 129.0 in stage 3.0 (TID 293)
[2025-07-19T22:10:03.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 121.0 in stage 3.0 (TID 287) in 174 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T22:10:03.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 130.0 in stage 3.0 (TID 294) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 118.0 in stage 3.0 (TID 284) in 217 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T22:10:03.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 130.0 in stage 3.0 (TID 294)
[2025-07-19T22:10:03.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.1.delta.b2e6de17-37bf-410d-bcbb-e0000c6befc9.TID291.tmp
[2025-07-19T22:10:03.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 122 (task 288, attempt 0, stage 3.0)
[2025-07-19T22:10:03.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.572+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 122.0 in stage 3.0 (TID 288). 9061 bytes result sent to driver
[2025-07-19T22:10:03.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 131.0 in stage 3.0 (TID 295) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 131.0 in stage 3.0 (TID 295)
[2025-07-19T22:10:03.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 122.0 in stage 3.0 (TID 288) in 131 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T22:10:03.580+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.1.delta.0ddae625-b20d-45e7-8067-61cae264bb75.TID290.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/125/1.delta
[2025-07-19T22:10:03.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/125] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/125/1.delta
[2025-07-19T22:10:03.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 290, attempt 0, stage 3.0)
[2025-07-19T22:10:03.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d3e8bd9
[2025-07-19T22:10:03.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/128] for update
[2025-07-19T22:10:03.594+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 123 (task 289, attempt 0, stage 3.0)
[2025-07-19T22:10:03.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.7 KiB, free 433.0 MiB)
[2025-07-19T22:10:03.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 123.0 in stage 3.0 (TID 289). 9072 bytes result sent to driver
[2025-07-19T22:10:03.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.0 MiB)
[2025-07-19T22:10:03.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 132.0 in stage 3.0 (TID 296) (8b44f3d35cfa, executor driver, partition 132, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 123.0 in stage 3.0 (TID 289) in 125 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T22:10:03.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 132.0 in stage 3.0 (TID 296)
[2025-07-19T22:10:03.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 8b44f3d35cfa:37751 (size: 15.8 KiB, free: 434.1 MiB)
[2025-07-19T22:10:03.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 120 (task 286, attempt 0, stage 3.0)
[2025-07-19T22:10:03.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 120.0 in stage 3.0 (TID 286). 9080 bytes result sent to driver
[2025-07-19T22:10:03.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.612+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1611
[2025-07-19T22:10:03.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 133.0 in stage 3.0 (TID 297) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T22:10:03.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSchedulerImpl: Adding task set 7.0 with 200 tasks resource profile 0
[2025-07-19T22:10:03.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 133.0 in stage 3.0 (TID 297)
[2025-07-19T22:10:03.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a5c85fb
[2025-07-19T22:10:03.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 120.0 in stage 3.0 (TID 286) in 205 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T22:10:03.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/129] for update
[2025-07-19T22:10:03.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.1.delta.8785f2d6-d940-4272-8441-bf307534419e.TID292.tmp
[2025-07-19T22:10:03.620+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50d1fdd1
[2025-07-19T22:10:03.621+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.621+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/131] for update
[2025-07-19T22:10:03.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 125 (task 290, attempt 0, stage 3.0)
[2025-07-19T22:10:03.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 125.0 in stage 3.0 (TID 290). 9074 bytes result sent to driver
[2025-07-19T22:10:03.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 135.0 in stage 3.0 (TID 298) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 135.0 in stage 3.0 (TID 298)
[2025-07-19T22:10:03.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 125.0 in stage 3.0 (TID 290) in 136 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T22:10:03.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75a20d95
[2025-07-19T22:10:03.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/130] for update
[2025-07-19T22:10:03.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.1.delta.80abb09c-c757-4cf7-bcc2-a7075c3751e4.TID293.tmp
[2025-07-19T22:10:03.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.1.delta.5165a044-9f87-41b7-87a1-091e0b27ea65.TID295.tmp
[2025-07-19T22:10:03.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.1.delta.b2e6de17-37bf-410d-bcbb-e0000c6befc9.TID291.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/127/1.delta
[2025-07-19T22:10:03.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/127] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/127/1.delta
[2025-07-19T22:10:03.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 291, attempt 0, stage 3.0)
[2025-07-19T22:10:03.637+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bb0d3bf
[2025-07-19T22:10:03.638+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/135] for update
[2025-07-19T22:10:03.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.1.delta.6683b228-f68e-4cde-b91b-d157ccf13f7c.TID294.tmp
[2025-07-19T22:10:03.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26bf2db2
[2025-07-19T22:10:03.645+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/133] for update
[2025-07-19T22:10:03.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.1.delta.8785f2d6-d940-4272-8441-bf307534419e.TID292.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/128/1.delta
[2025-07-19T22:10:03.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/128] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/128/1.delta
[2025-07-19T22:10:03.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fa257f1
[2025-07-19T22:10:03.661+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/132] for update
[2025-07-19T22:10:03.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 292, attempt 0, stage 3.0)
[2025-07-19T22:10:03.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.1.delta.d20c575c-bf1f-497e-a3a3-4aaae1adaaeb.TID298.tmp
[2025-07-19T22:10:03.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.1.delta.443b1348-e7ad-4be2-b5b7-d17cb64f40ce.TID297.tmp
[2025-07-19T22:10:03.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 127 (task 291, attempt 0, stage 3.0)
[2025-07-19T22:10:03.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 127.0 in stage 3.0 (TID 291). 9025 bytes result sent to driver
[2025-07-19T22:10:03.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.1.delta.e4f163fd-3455-4665-8abb-f8cefa011f1f.TID296.tmp
[2025-07-19T22:10:03.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.1.delta.80abb09c-c757-4cf7-bcc2-a7075c3751e4.TID293.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/129/1.delta
[2025-07-19T22:10:03.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/129] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/129/1.delta
[2025-07-19T22:10:03.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 136.0 in stage 3.0 (TID 299) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 128 (task 292, attempt 0, stage 3.0)
[2025-07-19T22:10:03.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 293, attempt 0, stage 3.0)
[2025-07-19T22:10:03.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 136.0 in stage 3.0 (TID 299)
[2025-07-19T22:10:03.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 128.0 in stage 3.0 (TID 292). 9025 bytes result sent to driver
[2025-07-19T22:10:03.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 127.0 in stage 3.0 (TID 291) in 169 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T22:10:03.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 137.0 in stage 3.0 (TID 300) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 137.0 in stage 3.0 (TID 300)
[2025-07-19T22:10:03.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 128.0 in stage 3.0 (TID 292) in 129 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T22:10:03.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.1.delta.5165a044-9f87-41b7-87a1-091e0b27ea65.TID295.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/131/1.delta
[2025-07-19T22:10:03.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/131] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/131/1.delta
[2025-07-19T22:10:03.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 295, attempt 0, stage 3.0)
[2025-07-19T22:10:03.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.1.delta.6683b228-f68e-4cde-b91b-d157ccf13f7c.TID294.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/130/1.delta
[2025-07-19T22:10:03.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/130] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/130/1.delta
[2025-07-19T22:10:03.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 294, attempt 0, stage 3.0)
[2025-07-19T22:10:03.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5806881
[2025-07-19T22:10:03.698+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/137] for update
[2025-07-19T22:10:03.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.706+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 131 (task 295, attempt 0, stage 3.0)
[2025-07-19T22:10:03.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3238cf
[2025-07-19T22:10:03.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/136] for update
[2025-07-19T22:10:03.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 129 (task 293, attempt 0, stage 3.0)
[2025-07-19T22:10:03.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.1.delta.7fd4b090-92d4-4684-94ca-63b4bb6b3a2d.TID300.tmp
[2025-07-19T22:10:03.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 131.0 in stage 3.0 (TID 295). 9132 bytes result sent to driver
[2025-07-19T22:10:03.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 129.0 in stage 3.0 (TID 293). 9087 bytes result sent to driver
[2025-07-19T22:10:03.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 130 (task 294, attempt 0, stage 3.0)
[2025-07-19T22:10:03.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 130.0 in stage 3.0 (TID 294). 9092 bytes result sent to driver
[2025-07-19T22:10:03.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 138.0 in stage 3.0 (TID 301) (8b44f3d35cfa, executor driver, partition 138, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 139.0 in stage 3.0 (TID 302) (8b44f3d35cfa, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 138.0 in stage 3.0 (TID 301)
[2025-07-19T22:10:03.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 140.0 in stage 3.0 (TID 303) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 131.0 in stage 3.0 (TID 295) in 154 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T22:10:03.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 140.0 in stage 3.0 (TID 303)
[2025-07-19T22:10:03.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 130.0 in stage 3.0 (TID 294) in 162 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T22:10:03.728+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 129.0 in stage 3.0 (TID 293) in 165 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T22:10:03.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 139.0 in stage 3.0 (TID 302)
[2025-07-19T22:10:03.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.730+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.1.delta.d20c575c-bf1f-497e-a3a3-4aaae1adaaeb.TID298.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/135/1.delta
[2025-07-19T22:10:03.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/135] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/135/1.delta
[2025-07-19T22:10:03.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 298, attempt 0, stage 3.0)
[2025-07-19T22:10:03.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:03.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@223a3a65
[2025-07-19T22:10:03.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/138] for update
[2025-07-19T22:10:03.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.1.delta.443b1348-e7ad-4be2-b5b7-d17cb64f40ce.TID297.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/133/1.delta
[2025-07-19T22:10:03.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.1.delta.e4f163fd-3455-4665-8abb-f8cefa011f1f.TID296.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/132/1.delta
[2025-07-19T22:10:03.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/132] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/132/1.delta
[2025-07-19T22:10:03.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/133] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/133/1.delta
[2025-07-19T22:10:03.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 296, attempt 0, stage 3.0)
[2025-07-19T22:10:03.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 297, attempt 0, stage 3.0)
[2025-07-19T22:10:03.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.1.delta.08f9c350-f78a-4f45-80df-8b58357e7d27.TID299.tmp
[2025-07-19T22:10:03.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21ef4f68
[2025-07-19T22:10:03.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/140] for update
[2025-07-19T22:10:03.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.1.delta.694d73af-0ebb-48b0-a0ab-cfeff09664a5.TID301.tmp
[2025-07-19T22:10:03.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5aa95aef
[2025-07-19T22:10:03.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/139] for update
[2025-07-19T22:10:03.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 135 (task 298, attempt 0, stage 3.0)
[2025-07-19T22:10:03.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 135.0 in stage 3.0 (TID 298). 9080 bytes result sent to driver
[2025-07-19T22:10:03.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 132 (task 296, attempt 0, stage 3.0)
[2025-07-19T22:10:03.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 132.0 in stage 3.0 (TID 296). 9076 bytes result sent to driver
[2025-07-19T22:10:03.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.1.delta.b4a67966-94b0-4aeb-b043-9f0a8c51e840.TID303.tmp
[2025-07-19T22:10:03.772+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 143.0 in stage 3.0 (TID 304) (8b44f3d35cfa, executor driver, partition 143, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 135.0 in stage 3.0 (TID 298) in 169 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T22:10:03.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 144.0 in stage 3.0 (TID 305) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 144.0 in stage 3.0 (TID 305)
[2025-07-19T22:10:03.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 132.0 in stage 3.0 (TID 296) in 197 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T22:10:03.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 143.0 in stage 3.0 (TID 304)
[2025-07-19T22:10:03.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.1.delta.7fd4b090-92d4-4684-94ca-63b4bb6b3a2d.TID300.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/137/1.delta
[2025-07-19T22:10:03.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/137] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/137/1.delta
[2025-07-19T22:10:03.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 300, attempt 0, stage 3.0)
[2025-07-19T22:10:03.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 133 (task 297, attempt 0, stage 3.0)
[2025-07-19T22:10:03.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.1.delta.08f9c350-f78a-4f45-80df-8b58357e7d27.TID299.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/136/1.delta
[2025-07-19T22:10:03.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/136] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/136/1.delta
[2025-07-19T22:10:03.794+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@601a4fd
[2025-07-19T22:10:03.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 299, attempt 0, stage 3.0)
[2025-07-19T22:10:03.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 133.0 in stage 3.0 (TID 297). 9088 bytes result sent to driver
[2025-07-19T22:10:03.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/144] for update
[2025-07-19T22:10:03.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 145.0 in stage 3.0 (TID 306) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 145.0 in stage 3.0 (TID 306)
[2025-07-19T22:10:03.800+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 133.0 in stage 3.0 (TID 297) in 206 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T22:10:03.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.1.delta.f08fe46a-2eec-4455-a6d3-713e9f11d880.TID302.tmp
[2025-07-19T22:10:03.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.811+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f7b19d8
[2025-07-19T22:10:03.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/143] for update
[2025-07-19T22:10:03.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.1.delta.694d73af-0ebb-48b0-a0ab-cfeff09664a5.TID301.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/138/1.delta
[2025-07-19T22:10:03.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/138] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/138/1.delta
[2025-07-19T22:10:03.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.1.delta.1523c2f8-a125-4511-a3da-2f319e5f4560.TID305.tmp
[2025-07-19T22:10:03.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 301, attempt 0, stage 3.0)
[2025-07-19T22:10:03.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 137 (task 300, attempt 0, stage 3.0)
[2025-07-19T22:10:03.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 137.0 in stage 3.0 (TID 300). 9138 bytes result sent to driver
[2025-07-19T22:10:03.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cd54d32
[2025-07-19T22:10:03.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 146.0 in stage 3.0 (TID 307) (8b44f3d35cfa, executor driver, partition 146, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/145] for update
[2025-07-19T22:10:03.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 137.0 in stage 3.0 (TID 300) in 143 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T22:10:03.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 146.0 in stage 3.0 (TID 307)
[2025-07-19T22:10:03.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.830+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.830+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.831+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.1.delta.b4a67966-94b0-4aeb-b043-9f0a8c51e840.TID303.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/140/1.delta
[2025-07-19T22:10:03.831+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/140] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/140/1.delta
[2025-07-19T22:10:03.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 303, attempt 0, stage 3.0)
[2025-07-19T22:10:03.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12cf9431
[2025-07-19T22:10:03.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.840+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/146] for update
[2025-07-19T22:10:03.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.1.delta.3f043435-90fd-4964-9002-2a00e1369402.TID304.tmp
[2025-07-19T22:10:03.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.1.delta.e1c047af-52ee-4de0-8990-07eebc6cc007.TID306.tmp
[2025-07-19T22:10:03.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 136 (task 299, attempt 0, stage 3.0)
[2025-07-19T22:10:03.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 136.0 in stage 3.0 (TID 299). 9121 bytes result sent to driver
[2025-07-19T22:10:03.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 149.0 in stage 3.0 (TID 308) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 138 (task 301, attempt 0, stage 3.0)
[2025-07-19T22:10:03.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 149.0 in stage 3.0 (TID 308)
[2025-07-19T22:10:03.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 138.0 in stage 3.0 (TID 301). 9044 bytes result sent to driver
[2025-07-19T22:10:03.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 150.0 in stage 3.0 (TID 309) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 136.0 in stage 3.0 (TID 299) in 178 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T22:10:03.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 150.0 in stage 3.0 (TID 309)
[2025-07-19T22:10:03.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 138.0 in stage 3.0 (TID 301) in 135 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T22:10:03.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:03.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.1.delta.3a551b6b-5001-4f3a-9b36-9f533f63cd84.TID307.tmp
[2025-07-19T22:10:03.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 140 (task 303, attempt 0, stage 3.0)
[2025-07-19T22:10:03.870+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T22:10:03.874+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.1.delta.f08fe46a-2eec-4455-a6d3-713e9f11d880.TID302.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/139/1.delta
[2025-07-19T22:10:03.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/139] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/139/1.delta
[2025-07-19T22:10:03.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 140.0 in stage 3.0 (TID 303). 9125 bytes result sent to driver
[2025-07-19T22:10:03.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 302, attempt 0, stage 3.0)
[2025-07-19T22:10:03.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 152.0 in stage 3.0 (TID 310) (8b44f3d35cfa, executor driver, partition 152, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 152.0 in stage 3.0 (TID 310)
[2025-07-19T22:10:03.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 140.0 in stage 3.0 (TID 303) in 152 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T22:10:03.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b201645
[2025-07-19T22:10:03.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/149] for update
[2025-07-19T22:10:03.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.1.delta.56e72474-8e27-481d-9082-ebf635d08732.TID308.tmp
[2025-07-19T22:10:03.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3353c21d
[2025-07-19T22:10:03.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 139 (task 302, attempt 0, stage 3.0)
[2025-07-19T22:10:03.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 139.0 in stage 3.0 (TID 302). 9089 bytes result sent to driver
[2025-07-19T22:10:03.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.1.delta.1523c2f8-a125-4511-a3da-2f319e5f4560.TID305.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/144/1.delta
[2025-07-19T22:10:03.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/144] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/144/1.delta
[2025-07-19T22:10:03.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 153.0 in stage 3.0 (TID 311) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 139.0 in stage 3.0 (TID 302) in 183 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T22:10:03.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/150] for update
[2025-07-19T22:10:03.907+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 305, attempt 0, stage 3.0)
[2025-07-19T22:10:03.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 153.0 in stage 3.0 (TID 311)
[2025-07-19T22:10:03.918+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c180eb0
[2025-07-19T22:10:03.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/152] for update
[2025-07-19T22:10:03.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38f46520
[2025-07-19T22:10:03.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/153] for update
[2025-07-19T22:10:03.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.1.delta.3f043435-90fd-4964-9002-2a00e1369402.TID304.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/143/1.delta
[2025-07-19T22:10:03.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/143] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/143/1.delta
[2025-07-19T22:10:03.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 304, attempt 0, stage 3.0)
[2025-07-19T22:10:03.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.1.delta.ed65b94b-060c-48d3-8162-f34258f78855.TID309.tmp
[2025-07-19T22:10:03.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.1.delta.a1ade7e3-d6be-4cc1-8569-5d79cda32c39.TID311.tmp
[2025-07-19T22:10:03.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 144 (task 305, attempt 0, stage 3.0)
[2025-07-19T22:10:03.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.1.delta.e1c047af-52ee-4de0-8990-07eebc6cc007.TID306.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/145/1.delta
[2025-07-19T22:10:03.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 144.0 in stage 3.0 (TID 305). 9074 bytes result sent to driver
[2025-07-19T22:10:03.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/145] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/145/1.delta
[2025-07-19T22:10:03.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.1.delta.bc739a79-ce25-4487-80fb-b70a68b45c9b.TID310.tmp
[2025-07-19T22:10:03.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 154.0 in stage 3.0 (TID 312) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 154.0 in stage 3.0 (TID 312)
[2025-07-19T22:10:03.949+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 306, attempt 0, stage 3.0)
[2025-07-19T22:10:03.950+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 144.0 in stage 3.0 (TID 305) in 175 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T22:10:03.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:03.955+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 143 (task 304, attempt 0, stage 3.0)
[2025-07-19T22:10:03.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 143.0 in stage 3.0 (TID 304). 9074 bytes result sent to driver
[2025-07-19T22:10:03.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 155.0 in stage 3.0 (TID 313) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 155.0 in stage 3.0 (TID 313)
[2025-07-19T22:10:03.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 143.0 in stage 3.0 (TID 304) in 187 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T22:10:03.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.959+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@675d6925
[2025-07-19T22:10:03.960+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:03.960+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/154] for update
[2025-07-19T22:10:03.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.1.delta.56e72474-8e27-481d-9082-ebf635d08732.TID308.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/149/1.delta
[2025-07-19T22:10:03.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/149] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/149/1.delta
[2025-07-19T22:10:03.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 308, attempt 0, stage 3.0)
[2025-07-19T22:10:03.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@325f2d10
[2025-07-19T22:10:03.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:03.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.1.delta.3a551b6b-5001-4f3a-9b36-9f533f63cd84.TID307.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/146/1.delta
[2025-07-19T22:10:03.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/146] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/146/1.delta
[2025-07-19T22:10:03.977+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/155] for update
[2025-07-19T22:10:03.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Committed partition 145 (task 306, attempt 0, stage 3.0)
[2025-07-19T22:10:03.981+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Finished task 145.0 in stage 3.0 (TID 306). 9100 bytes result sent to driver
[2025-07-19T22:10:03.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 307, attempt 0, stage 3.0)
[2025-07-19T22:10:03.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Starting task 157.0 in stage 3.0 (TID 314) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:03.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO TaskSetManager: Finished task 145.0 in stage 3.0 (TID 306) in 196 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T22:10:03.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO Executor: Running task 157.0 in stage 3.0 (TID 314)
[2025-07-19T22:10:03.985+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:03.986+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:03.987+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:03.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.1.delta.4b3bc4d0-24d6-4691-af96-9f5f932c3a4b.TID312.tmp
[2025-07-19T22:10:04.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.1.delta.7b8bfac2-c5f6-42ca-97d9-94e416a3ee99.TID313.tmp
[2025-07-19T22:10:04.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@480e4d52
[2025-07-19T22:10:04.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/157] for update
[2025-07-19T22:10:04.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 149 (task 308, attempt 0, stage 3.0)
[2025-07-19T22:10:04.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 149.0 in stage 3.0 (TID 308). 9099 bytes result sent to driver
[2025-07-19T22:10:04.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.1.delta.bc739a79-ce25-4487-80fb-b70a68b45c9b.TID310.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/152/1.delta
[2025-07-19T22:10:04.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 158.0 in stage 3.0 (TID 315) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/152] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/152/1.delta
[2025-07-19T22:10:04.015+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.1.delta.ed65b94b-060c-48d3-8162-f34258f78855.TID309.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/150/1.delta
[2025-07-19T22:10:04.015+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/150] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/150/1.delta
[2025-07-19T22:10:04.016+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 310, attempt 0, stage 3.0)
[2025-07-19T22:10:04.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 309, attempt 0, stage 3.0)
[2025-07-19T22:10:04.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 149.0 in stage 3.0 (TID 308) in 168 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T22:10:04.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 158.0 in stage 3.0 (TID 315)
[2025-07-19T22:10:04.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.1.delta.a1ade7e3-d6be-4cc1-8569-5d79cda32c39.TID311.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/153/1.delta
[2025-07-19T22:10:04.020+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/153] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/153/1.delta
[2025-07-19T22:10:04.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 146 (task 307, attempt 0, stage 3.0)
[2025-07-19T22:10:04.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 146.0 in stage 3.0 (TID 307). 9084 bytes result sent to driver
[2025-07-19T22:10:04.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 159.0 in stage 3.0 (TID 316) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.030+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 311, attempt 0, stage 3.0)
[2025-07-19T22:10:04.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 146.0 in stage 3.0 (TID 307) in 204 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T22:10:04.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 159.0 in stage 3.0 (TID 316)
[2025-07-19T22:10:04.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 152 (task 310, attempt 0, stage 3.0)
[2025-07-19T22:10:04.035+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 152.0 in stage 3.0 (TID 310). 9031 bytes result sent to driver
[2025-07-19T22:10:04.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 160.0 in stage 3.0 (TID 317) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a44902f
[2025-07-19T22:10:04.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/158] for update
[2025-07-19T22:10:04.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 160.0 in stage 3.0 (TID 317)
[2025-07-19T22:10:04.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 152.0 in stage 3.0 (TID 310) in 166 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T22:10:04.056+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.056+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.1.delta.fcdd4d50-6a54-4c10-87a5-2970157a6978.TID314.tmp
[2025-07-19T22:10:04.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 153 (task 311, attempt 0, stage 3.0)
[2025-07-19T22:10:04.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 153.0 in stage 3.0 (TID 311). 9039 bytes result sent to driver
[2025-07-19T22:10:04.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 161.0 in stage 3.0 (TID 318) (8b44f3d35cfa, executor driver, partition 161, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 161.0 in stage 3.0 (TID 318)
[2025-07-19T22:10:04.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 153.0 in stage 3.0 (TID 311) in 149 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T22:10:04.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 150 (task 309, attempt 0, stage 3.0)
[2025-07-19T22:10:04.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 150.0 in stage 3.0 (TID 309). 9126 bytes result sent to driver
[2025-07-19T22:10:04.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 162.0 in stage 3.0 (TID 319) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.1.delta.e2a55b7f-4d28-4763-94d6-8f3fd9e919e4.TID315.tmp
[2025-07-19T22:10:04.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 150.0 in stage 3.0 (TID 309) in 215 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T22:10:04.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 162.0 in stage 3.0 (TID 319)
[2025-07-19T22:10:04.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.1.delta.7b8bfac2-c5f6-42ca-97d9-94e416a3ee99.TID313.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/155/1.delta
[2025-07-19T22:10:04.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/155] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/155/1.delta
[2025-07-19T22:10:04.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 313, attempt 0, stage 3.0)
[2025-07-19T22:10:04.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.071+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a18a4a8
[2025-07-19T22:10:04.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:04.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/159] for update
[2025-07-19T22:10:04.074+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.1.delta.4b3bc4d0-24d6-4691-af96-9f5f932c3a4b.TID312.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/154/1.delta
[2025-07-19T22:10:04.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/154] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/154/1.delta
[2025-07-19T22:10:04.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:04.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 312, attempt 0, stage 3.0)
[2025-07-19T22:10:04.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a1ba3ba
[2025-07-19T22:10:04.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.080+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/161] for update
[2025-07-19T22:10:04.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.085+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a247295
[2025-07-19T22:10:04.086+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/160] for update
[2025-07-19T22:10:04.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.1.delta.8a62a135-e328-4cea-a796-b0d3a0144aaf.TID316.tmp
[2025-07-19T22:10:04.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.1.delta.03fe3cda-94dc-4a26-b5fe-a1113d2252ae.TID318.tmp
[2025-07-19T22:10:04.098+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 154 (task 312, attempt 0, stage 3.0)
[2025-07-19T22:10:04.099+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11ee077b
[2025-07-19T22:10:04.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 155 (task 313, attempt 0, stage 3.0)
[2025-07-19T22:10:04.105+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 154.0 in stage 3.0 (TID 312). 9099 bytes result sent to driver
[2025-07-19T22:10:04.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/162] for update
[2025-07-19T22:10:04.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 155.0 in stage 3.0 (TID 313). 9096 bytes result sent to driver
[2025-07-19T22:10:04.109+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.1.delta.f3b0b7f0-9214-4421-89bc-6f9744680170.TID317.tmp
[2025-07-19T22:10:04.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 163.0 in stage 3.0 (TID 320) (8b44f3d35cfa, executor driver, partition 163, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 165.0 in stage 3.0 (TID 321) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 165.0 in stage 3.0 (TID 321)
[2025-07-19T22:10:04.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 154.0 in stage 3.0 (TID 312) in 158 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T22:10:04.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 155.0 in stage 3.0 (TID 313) in 150 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T22:10:04.116+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 163.0 in stage 3.0 (TID 320)
[2025-07-19T22:10:04.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.1.delta.fcdd4d50-6a54-4c10-87a5-2970157a6978.TID314.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/157/1.delta
[2025-07-19T22:10:04.125+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/157] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/157/1.delta
[2025-07-19T22:10:04.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 314, attempt 0, stage 3.0)
[2025-07-19T22:10:04.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.129+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.130+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5de467ff
[2025-07-19T22:10:04.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/165] for update
[2025-07-19T22:10:04.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.1.delta.e2a55b7f-4d28-4763-94d6-8f3fd9e919e4.TID315.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/158/1.delta
[2025-07-19T22:10:04.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/158] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/158/1.delta
[2025-07-19T22:10:04.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 315, attempt 0, stage 3.0)
[2025-07-19T22:10:04.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.1.delta.4720bc48-e68c-4d8f-bebc-0f658001ed54.TID319.tmp
[2025-07-19T22:10:04.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a9b3490
[2025-07-19T22:10:04.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/163] for update
[2025-07-19T22:10:04.141+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.1.delta.58eeceb5-83c5-446f-bb77-d9fafa5b474b.TID321.tmp
[2025-07-19T22:10:04.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 157 (task 314, attempt 0, stage 3.0)
[2025-07-19T22:10:04.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 157.0 in stage 3.0 (TID 314). 9072 bytes result sent to driver
[2025-07-19T22:10:04.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 169.0 in stage 3.0 (TID 322) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 169.0 in stage 3.0 (TID 322)
[2025-07-19T22:10:04.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 157.0 in stage 3.0 (TID 314) in 168 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T22:10:04.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eaa37ee
[2025-07-19T22:10:04.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/169] for update
[2025-07-19T22:10:04.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.171+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 158 (task 315, attempt 0, stage 3.0)
[2025-07-19T22:10:04.173+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 158.0 in stage 3.0 (TID 315). 9085 bytes result sent to driver
[2025-07-19T22:10:04.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.1.delta.03fe3cda-94dc-4a26-b5fe-a1113d2252ae.TID318.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/161/1.delta
[2025-07-19T22:10:04.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/161] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/161/1.delta
[2025-07-19T22:10:04.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 170.0 in stage 3.0 (TID 323) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 318, attempt 0, stage 3.0)
[2025-07-19T22:10:04.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 170.0 in stage 3.0 (TID 323)
[2025-07-19T22:10:04.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 158.0 in stage 3.0 (TID 315) in 164 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T22:10:04.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.1.delta.8a62a135-e328-4cea-a796-b0d3a0144aaf.TID316.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/159/1.delta
[2025-07-19T22:10:04.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/159] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/159/1.delta
[2025-07-19T22:10:04.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 316, attempt 0, stage 3.0)
[2025-07-19T22:10:04.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d8f06be
[2025-07-19T22:10:04.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/170] for update
[2025-07-19T22:10:04.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.1.delta.099425b0-a067-4de6-a012-a0d4dd341938.TID320.tmp
[2025-07-19T22:10:04.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.1.delta.a76bf29f-f0a2-4d34-866e-936e721bd55f.TID322.tmp
[2025-07-19T22:10:04.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.1.delta.4720bc48-e68c-4d8f-bebc-0f658001ed54.TID319.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/162/1.delta
[2025-07-19T22:10:04.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/162] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/162/1.delta
[2025-07-19T22:10:04.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 319, attempt 0, stage 3.0)
[2025-07-19T22:10:04.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.1.delta.f3b0b7f0-9214-4421-89bc-6f9744680170.TID317.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/160/1.delta
[2025-07-19T22:10:04.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/160] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/160/1.delta
[2025-07-19T22:10:04.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 317, attempt 0, stage 3.0)
[2025-07-19T22:10:04.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 161 (task 318, attempt 0, stage 3.0)
[2025-07-19T22:10:04.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 161.0 in stage 3.0 (TID 318). 9121 bytes result sent to driver
[2025-07-19T22:10:04.204+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 172.0 in stage 3.0 (TID 324) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.204+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.1.delta.58eeceb5-83c5-446f-bb77-d9fafa5b474b.TID321.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/165/1.delta
[2025-07-19T22:10:04.205+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/165] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/165/1.delta
[2025-07-19T22:10:04.206+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 172.0 in stage 3.0 (TID 324)
[2025-07-19T22:10:04.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 321, attempt 0, stage 3.0)
[2025-07-19T22:10:04.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 159 (task 316, attempt 0, stage 3.0)
[2025-07-19T22:10:04.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 161.0 in stage 3.0 (TID 318) in 157 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T22:10:04.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 159.0 in stage 3.0 (TID 316). 9080 bytes result sent to driver
[2025-07-19T22:10:04.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 174.0 in stage 3.0 (TID 325) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 159.0 in stage 3.0 (TID 316) in 187 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T22:10:04.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.1.delta.8d7e8047-036c-48c0-8a22-4f565505cf18.TID323.tmp
[2025-07-19T22:10:04.213+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 174.0 in stage 3.0 (TID 325)
[2025-07-19T22:10:04.214+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 160 (task 317, attempt 0, stage 3.0)
[2025-07-19T22:10:04.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.226+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 160.0 in stage 3.0 (TID 317). 9126 bytes result sent to driver
[2025-07-19T22:10:04.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 162 (task 319, attempt 0, stage 3.0)
[2025-07-19T22:10:04.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 175.0 in stage 3.0 (TID 326) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.230+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 162.0 in stage 3.0 (TID 319). 9084 bytes result sent to driver
[2025-07-19T22:10:04.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73701068
[2025-07-19T22:10:04.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 175.0 in stage 3.0 (TID 326)
[2025-07-19T22:10:04.232+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 162.0 in stage 3.0 (TID 319) in 165 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T22:10:04.232+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 176.0 in stage 3.0 (TID 327) (8b44f3d35cfa, executor driver, partition 176, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 160.0 in stage 3.0 (TID 317) in 194 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T22:10:04.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/172] for update
[2025-07-19T22:10:04.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 176.0 in stage 3.0 (TID 327)
[2025-07-19T22:10:04.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:04.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a699b02
[2025-07-19T22:10:04.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/174] for update
[2025-07-19T22:10:04.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 165 (task 321, attempt 0, stage 3.0)
[2025-07-19T22:10:04.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 165.0 in stage 3.0 (TID 321). 9073 bytes result sent to driver
[2025-07-19T22:10:04.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 177.0 in stage 3.0 (TID 328) (8b44f3d35cfa, executor driver, partition 177, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.1.delta.a76bf29f-f0a2-4d34-866e-936e721bd55f.TID322.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/169/1.delta
[2025-07-19T22:10:04.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/169] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/169/1.delta
[2025-07-19T22:10:04.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 165.0 in stage 3.0 (TID 321) in 144 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T22:10:04.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 177.0 in stage 3.0 (TID 328)
[2025-07-19T22:10:04.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 322, attempt 0, stage 3.0)
[2025-07-19T22:10:04.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1803cf39
[2025-07-19T22:10:04.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/175] for update
[2025-07-19T22:10:04.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:04.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.1.delta.099425b0-a067-4de6-a012-a0d4dd341938.TID320.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/163/1.delta
[2025-07-19T22:10:04.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/163] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/163/1.delta
[2025-07-19T22:10:04.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ee18c78
[2025-07-19T22:10:04.258+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 320, attempt 0, stage 3.0)
[2025-07-19T22:10:04.258+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/176] for update
[2025-07-19T22:10:04.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.1.delta.80166566-4dfc-4b07-a967-2bbbf785c45b.TID324.tmp
[2025-07-19T22:10:04.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51c192c6
[2025-07-19T22:10:04.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.266+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/177] for update
[2025-07-19T22:10:04.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.1.delta.0051f0ae-e6dd-4a69-8aaf-d06face08165.TID325.tmp
[2025-07-19T22:10:04.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 169 (task 322, attempt 0, stage 3.0)
[2025-07-19T22:10:04.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 169.0 in stage 3.0 (TID 322). 9080 bytes result sent to driver
[2025-07-19T22:10:04.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 178.0 in stage 3.0 (TID 329) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.271+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 178.0 in stage 3.0 (TID 329)
[2025-07-19T22:10:04.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.1.delta.9fb65f42-4ccf-4bd8-9ecb-582a181dee4e.TID326.tmp
[2025-07-19T22:10:04.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 169.0 in stage 3.0 (TID 322) in 130 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T22:10:04.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.1.delta.ab752fad-a2a1-4371-8464-92917c165282.TID327.tmp
[2025-07-19T22:10:04.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.1.delta.8d7e8047-036c-48c0-8a22-4f565505cf18.TID323.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/170/1.delta
[2025-07-19T22:10:04.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/170] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/170/1.delta
[2025-07-19T22:10:04.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 323, attempt 0, stage 3.0)
[2025-07-19T22:10:04.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59a03d6d
[2025-07-19T22:10:04.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/178] for update
[2025-07-19T22:10:04.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 163 (task 320, attempt 0, stage 3.0)
[2025-07-19T22:10:04.293+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.1.delta.8c4d62e7-6e95-4366-bcf4-956814e7636d.TID328.tmp
[2025-07-19T22:10:04.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 163.0 in stage 3.0 (TID 320). 9093 bytes result sent to driver
[2025-07-19T22:10:04.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 163.0 in stage 3.0 (TID 320) in 187 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T22:10:04.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 179.0 in stage 3.0 (TID 330) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.300+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 179.0 in stage 3.0 (TID 330)
[2025-07-19T22:10:04.301+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.301+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.302+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.1.delta.3759e8c6-741b-4192-b839-86cf810e7b0c.TID329.tmp
[2025-07-19T22:10:04.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72ca1353
[2025-07-19T22:10:04.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/179] for update
[2025-07-19T22:10:04.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 170 (task 323, attempt 0, stage 3.0)
[2025-07-19T22:10:04.317+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 170.0 in stage 3.0 (TID 323). 9125 bytes result sent to driver
[2025-07-19T22:10:04.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 180.0 in stage 3.0 (TID 331) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 180.0 in stage 3.0 (TID 331)
[2025-07-19T22:10:04.330+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 170.0 in stage 3.0 (TID 323) in 156 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T22:10:04.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.1.delta.80166566-4dfc-4b07-a967-2bbbf785c45b.TID324.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/172/1.delta
[2025-07-19T22:10:04.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/172] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/172/1.delta
[2025-07-19T22:10:04.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 324, attempt 0, stage 3.0)
[2025-07-19T22:10:04.340+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.1.delta.0051f0ae-e6dd-4a69-8aaf-d06face08165.TID325.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/174/1.delta
[2025-07-19T22:10:04.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/174] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/174/1.delta
[2025-07-19T22:10:04.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 325, attempt 0, stage 3.0)
[2025-07-19T22:10:04.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.1.delta.ceda0999-ed53-456c-8ca8-c6b669174445.TID330.tmp
[2025-07-19T22:10:04.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ce89140
[2025-07-19T22:10:04.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/180] for update
[2025-07-19T22:10:04.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.1.delta.9fb65f42-4ccf-4bd8-9ecb-582a181dee4e.TID326.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/175/1.delta
[2025-07-19T22:10:04.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/175] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/175/1.delta
[2025-07-19T22:10:04.350+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 326, attempt 0, stage 3.0)
[2025-07-19T22:10:04.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.1.delta.942ff76f-595c-46f4-8be6-d7fed75c3a38.TID331.tmp
[2025-07-19T22:10:04.359+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.1.delta.ab752fad-a2a1-4371-8464-92917c165282.TID327.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/176/1.delta
[2025-07-19T22:10:04.360+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/176] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/176/1.delta
[2025-07-19T22:10:04.361+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 327, attempt 0, stage 3.0)
[2025-07-19T22:10:04.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 172 (task 324, attempt 0, stage 3.0)
[2025-07-19T22:10:04.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 172.0 in stage 3.0 (TID 324). 9086 bytes result sent to driver
[2025-07-19T22:10:04.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 181.0 in stage 3.0 (TID 332) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 181.0 in stage 3.0 (TID 332)
[2025-07-19T22:10:04.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 172.0 in stage 3.0 (TID 324) in 167 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T22:10:04.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.377+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.378+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.1.delta.8c4d62e7-6e95-4366-bcf4-956814e7636d.TID328.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/177/1.delta
[2025-07-19T22:10:04.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/177] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/177/1.delta
[2025-07-19T22:10:04.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 328, attempt 0, stage 3.0)
[2025-07-19T22:10:04.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 174 (task 325, attempt 0, stage 3.0)
[2025-07-19T22:10:04.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.1.delta.3759e8c6-741b-4192-b839-86cf810e7b0c.TID329.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/178/1.delta
[2025-07-19T22:10:04.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/178] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/178/1.delta
[2025-07-19T22:10:04.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 329, attempt 0, stage 3.0)
[2025-07-19T22:10:04.393+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 174.0 in stage 3.0 (TID 325). 9115 bytes result sent to driver
[2025-07-19T22:10:04.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@566fb6b
[2025-07-19T22:10:04.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 182.0 in stage 3.0 (TID 333) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 175 (task 326, attempt 0, stage 3.0)
[2025-07-19T22:10:04.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/181] for update
[2025-07-19T22:10:04.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 174.0 in stage 3.0 (TID 325) in 188 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T22:10:04.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 175.0 in stage 3.0 (TID 326). 9077 bytes result sent to driver
[2025-07-19T22:10:04.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 182.0 in stage 3.0 (TID 333)
[2025-07-19T22:10:04.406+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 183.0 in stage 3.0 (TID 334) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.407+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 183.0 in stage 3.0 (TID 334)
[2025-07-19T22:10:04.408+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.409+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 175.0 in stage 3.0 (TID 326) in 178 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T22:10:04.410+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 176 (task 327, attempt 0, stage 3.0)
[2025-07-19T22:10:04.415+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 176.0 in stage 3.0 (TID 327). 9086 bytes result sent to driver
[2025-07-19T22:10:04.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:04.420+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 185.0 in stage 3.0 (TID 335) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.424+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 185.0 in stage 3.0 (TID 335)
[2025-07-19T22:10:04.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 176.0 in stage 3.0 (TID 327) in 181 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T22:10:04.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.430+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 177 (task 328, attempt 0, stage 3.0)
[2025-07-19T22:10:04.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 177.0 in stage 3.0 (TID 328). 9095 bytes result sent to driver
[2025-07-19T22:10:04.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 178 (task 329, attempt 0, stage 3.0)
[2025-07-19T22:10:04.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.1.delta.f3669032-1d0e-4fd2-959b-82f82b68886d.TID332.tmp
[2025-07-19T22:10:04.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 178.0 in stage 3.0 (TID 329). 9072 bytes result sent to driver
[2025-07-19T22:10:04.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.1.delta.ceda0999-ed53-456c-8ca8-c6b669174445.TID330.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/179/1.delta
[2025-07-19T22:10:04.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/179] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/179/1.delta
[2025-07-19T22:10:04.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 330, attempt 0, stage 3.0)
[2025-07-19T22:10:04.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bc33e72
[2025-07-19T22:10:04.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 186.0 in stage 3.0 (TID 336) (8b44f3d35cfa, executor driver, partition 186, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 186.0 in stage 3.0 (TID 336)
[2025-07-19T22:10:04.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 187.0 in stage 3.0 (TID 337) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/182] for update
[2025-07-19T22:10:04.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 187.0 in stage 3.0 (TID 337)
[2025-07-19T22:10:04.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 177.0 in stage 3.0 (TID 328) in 186 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T22:10:04.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 178.0 in stage 3.0 (TID 329) in 159 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T22:10:04.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c6ecf1f
[2025-07-19T22:10:04.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/185] for update
[2025-07-19T22:10:04.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.1.delta.942ff76f-595c-46f4-8be6-d7fed75c3a38.TID331.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/180/1.delta
[2025-07-19T22:10:04.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/180] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/180/1.delta
[2025-07-19T22:10:04.457+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 331, attempt 0, stage 3.0)
[2025-07-19T22:10:04.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.1.delta.3a55094e-03ae-422c-b1d1-cf5f5f98d999.TID333.tmp
[2025-07-19T22:10:04.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c46f7c
[2025-07-19T22:10:04.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/183] for update
[2025-07-19T22:10:04.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 179 (task 330, attempt 0, stage 3.0)
[2025-07-19T22:10:04.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 179.0 in stage 3.0 (TID 330). 9096 bytes result sent to driver
[2025-07-19T22:10:04.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.1.delta.61ef979b-30e4-4167-9cfb-8e3a84c3ac8e.TID335.tmp
[2025-07-19T22:10:04.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 188.0 in stage 3.0 (TID 338) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 188.0 in stage 3.0 (TID 338)
[2025-07-19T22:10:04.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e01c0c8
[2025-07-19T22:10:04.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 179.0 in stage 3.0 (TID 330) in 166 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T22:10:04.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/187] for update
[2025-07-19T22:10:04.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 180 (task 331, attempt 0, stage 3.0)
[2025-07-19T22:10:04.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 180.0 in stage 3.0 (TID 331). 9100 bytes result sent to driver
[2025-07-19T22:10:04.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 190.0 in stage 3.0 (TID 339) (8b44f3d35cfa, executor driver, partition 190, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c64e5b6
[2025-07-19T22:10:04.473+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 180.0 in stage 3.0 (TID 331) in 147 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T22:10:04.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/186] for update
[2025-07-19T22:10:04.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 190.0 in stage 3.0 (TID 339)
[2025-07-19T22:10:04.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.1.delta.e4a694b8-3a48-4a21-9634-f23a584926ac.TID334.tmp
[2025-07-19T22:10:04.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@732ec8c8
[2025-07-19T22:10:04.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/188] for update
[2025-07-19T22:10:04.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:04.480+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.1.delta.647f4700-0db0-41f3-9fab-6736c8f2ed58.TID337.tmp
[2025-07-19T22:10:04.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7427d64a
[2025-07-19T22:10:04.488+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.490+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/190] for update
[2025-07-19T22:10:04.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.1.delta.7e7561ff-e362-4aa2-afc0-f0a2e8bad4b0.TID336.tmp
[2025-07-19T22:10:04.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.1.delta.f3669032-1d0e-4fd2-959b-82f82b68886d.TID332.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/181/1.delta
[2025-07-19T22:10:04.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/181] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/181/1.delta
[2025-07-19T22:10:04.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 332, attempt 0, stage 3.0)
[2025-07-19T22:10:04.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.1.delta.4fe2bb17-a302-4ac7-a7d0-93946613c75b.TID338.tmp
[2025-07-19T22:10:04.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.1.delta.3a55094e-03ae-422c-b1d1-cf5f5f98d999.TID333.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/182/1.delta
[2025-07-19T22:10:04.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/182] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/182/1.delta
[2025-07-19T22:10:04.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 333, attempt 0, stage 3.0)
[2025-07-19T22:10:04.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.1.delta.6f05fa04-ffb6-45cd-af38-236e077f14da.TID339.tmp
[2025-07-19T22:10:04.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 181 (task 332, attempt 0, stage 3.0)
[2025-07-19T22:10:04.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 181.0 in stage 3.0 (TID 332). 9131 bytes result sent to driver
[2025-07-19T22:10:04.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 192.0 in stage 3.0 (TID 340) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.519+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 192.0 in stage 3.0 (TID 340)
[2025-07-19T22:10:04.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 181.0 in stage 3.0 (TID 332) in 153 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T22:10:04.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 182 (task 333, attempt 0, stage 3.0)
[2025-07-19T22:10:04.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 182.0 in stage 3.0 (TID 333). 9074 bytes result sent to driver
[2025-07-19T22:10:04.528+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.1.delta.e4a694b8-3a48-4a21-9634-f23a584926ac.TID334.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/183/1.delta
[2025-07-19T22:10:04.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/183] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/183/1.delta
[2025-07-19T22:10:04.530+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 195.0 in stage 3.0 (TID 341) (8b44f3d35cfa, executor driver, partition 195, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.530+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.1.delta.61ef979b-30e4-4167-9cfb-8e3a84c3ac8e.TID335.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/185/1.delta
[2025-07-19T22:10:04.531+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/185] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/185/1.delta
[2025-07-19T22:10:04.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 182.0 in stage 3.0 (TID 333) in 132 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T22:10:04.534+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 335, attempt 0, stage 3.0)
[2025-07-19T22:10:04.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 334, attempt 0, stage 3.0)
[2025-07-19T22:10:04.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:04.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 195.0 in stage 3.0 (TID 341)
[2025-07-19T22:10:04.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.1.delta.647f4700-0db0-41f3-9fab-6736c8f2ed58.TID337.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/187/1.delta
[2025-07-19T22:10:04.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/187] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/187/1.delta
[2025-07-19T22:10:04.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 337, attempt 0, stage 3.0)
[2025-07-19T22:10:04.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.1.delta.4fe2bb17-a302-4ac7-a7d0-93946613c75b.TID338.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/188/1.delta
[2025-07-19T22:10:04.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/188] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/188/1.delta
[2025-07-19T22:10:04.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 338, attempt 0, stage 3.0)
[2025-07-19T22:10:04.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.1.delta.6f05fa04-ffb6-45cd-af38-236e077f14da.TID339.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/190/1.delta
[2025-07-19T22:10:04.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/190] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/190/1.delta
[2025-07-19T22:10:04.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51271452
[2025-07-19T22:10:04.553+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 339, attempt 0, stage 3.0)
[2025-07-19T22:10:04.556+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.556+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/192] for update
[2025-07-19T22:10:04.556+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.1.delta.7e7561ff-e362-4aa2-afc0-f0a2e8bad4b0.TID336.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/186/1.delta
[2025-07-19T22:10:04.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/186] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/186/1.delta
[2025-07-19T22:10:04.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 336, attempt 0, stage 3.0)
[2025-07-19T22:10:04.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7422a618
[2025-07-19T22:10:04.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 185 (task 335, attempt 0, stage 3.0)
[2025-07-19T22:10:04.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/195] for update
[2025-07-19T22:10:04.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 185.0 in stage 3.0 (TID 335). 9068 bytes result sent to driver
[2025-07-19T22:10:04.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 196.0 in stage 3.0 (TID 342) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 183 (task 334, attempt 0, stage 3.0)
[2025-07-19T22:10:04.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 196.0 in stage 3.0 (TID 342)
[2025-07-19T22:10:04.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 183.0 in stage 3.0 (TID 334). 9089 bytes result sent to driver
[2025-07-19T22:10:04.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 199.0 in stage 3.0 (TID 343) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 199.0 in stage 3.0 (TID 343)
[2025-07-19T22:10:04.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 185.0 in stage 3.0 (TID 335) in 153 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T22:10:04.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 183.0 in stage 3.0 (TID 334) in 164 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T22:10:04.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 187 (task 337, attempt 0, stage 3.0)
[2025-07-19T22:10:04.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 187.0 in stage 3.0 (TID 337). 9098 bytes result sent to driver
[2025-07-19T22:10:04.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 344) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.572+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 0.0 in stage 3.0 (TID 344)
[2025-07-19T22:10:04.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 187.0 in stage 3.0 (TID 337) in 146 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T22:10:04.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.1.delta.6b719941-7759-4e22-af85-69040a0fe74f.TID341.tmp
[2025-07-19T22:10:04.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.1.delta.67575d24-444b-4be2-b6df-df990729686a.TID340.tmp
[2025-07-19T22:10:04.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63dc09aa
[2025-07-19T22:10:04.579+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 190 (task 339, attempt 0, stage 3.0)
[2025-07-19T22:10:04.580+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 190.0 in stage 3.0 (TID 339). 9091 bytes result sent to driver
[2025-07-19T22:10:04.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 345) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/199] for update
[2025-07-19T22:10:04.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 8.0 in stage 3.0 (TID 345)
[2025-07-19T22:10:04.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 188 (task 338, attempt 0, stage 3.0)
[2025-07-19T22:10:04.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 186 (task 336, attempt 0, stage 3.0)
[2025-07-19T22:10:04.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 188.0 in stage 3.0 (TID 338). 9093 bytes result sent to driver
[2025-07-19T22:10:04.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 186.0 in stage 3.0 (TID 336). 9067 bytes result sent to driver
[2025-07-19T22:10:04.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 346) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 347) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 15.0 in stage 3.0 (TID 347)
[2025-07-19T22:10:04.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 190.0 in stage 3.0 (TID 339) in 115 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T22:10:04.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 186.0 in stage 3.0 (TID 336) in 160 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T22:10:04.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 188.0 in stage 3.0 (TID 338) in 126 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T22:10:04.594+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 10.0 in stage 3.0 (TID 346)
[2025-07-19T22:10:04.594+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.594+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24720190
[2025-07-19T22:10:04.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/196] for update
[2025-07-19T22:10:04.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:04.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.1.delta.829c6e3c-521a-4c05-9c61-a585ec3639fa.TID343.tmp
[2025-07-19T22:10:04.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.1.delta.de22bcce-abfd-44ee-9c29-0f021dd32ef6.TID342.tmp
[2025-07-19T22:10:04.611+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/.schema.0a6e72e2-f62d-450b-97e4-4f7e5c32dc76.TID344.tmp
[2025-07-19T22:10:04.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.1.delta.67575d24-444b-4be2-b6df-df990729686a.TID340.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/192/1.delta
[2025-07-19T22:10:04.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/192] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/192/1.delta
[2025-07-19T22:10:04.621+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.1.delta.6b719941-7759-4e22-af85-69040a0fe74f.TID341.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/195/1.delta
[2025-07-19T22:10:04.621+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 340, attempt 0, stage 3.0)
[2025-07-19T22:10:04.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/195] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/195/1.delta
[2025-07-19T22:10:04.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 341, attempt 0, stage 3.0)
[2025-07-19T22:10:04.638+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.1.delta.829c6e3c-521a-4c05-9c61-a585ec3639fa.TID343.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/199/1.delta
[2025-07-19T22:10:04.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/199] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/199/1.delta
[2025-07-19T22:10:04.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 343, attempt 0, stage 3.0)
[2025-07-19T22:10:04.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 195 (task 341, attempt 0, stage 3.0)
[2025-07-19T22:10:04.648+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 192 (task 340, attempt 0, stage 3.0)
[2025-07-19T22:10:04.649+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 192.0 in stage 3.0 (TID 340). 9043 bytes result sent to driver
[2025-07-19T22:10:04.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 195.0 in stage 3.0 (TID 341). 9037 bytes result sent to driver
[2025-07-19T22:10:04.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 348) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 17.0 in stage 3.0 (TID 348)
[2025-07-19T22:10:04.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 349) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 192.0 in stage 3.0 (TID 340) in 135 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T22:10:04.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 27.0 in stage 3.0 (TID 349)
[2025-07-19T22:10:04.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 195.0 in stage 3.0 (TID 341) in 128 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T22:10:04.660+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.660+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.660+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.1.delta.de22bcce-abfd-44ee-9c29-0f021dd32ef6.TID342.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/196/1.delta
[2025-07-19T22:10:04.660+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/196] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/196/1.delta
[2025-07-19T22:10:04.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 342, attempt 0, stage 3.0)
[2025-07-19T22:10:04.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/.schema.0a6e72e2-f62d-450b-97e4-4f7e5c32dc76.TID344.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/schema
[2025-07-19T22:10:04.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e905feb
[2025-07-19T22:10:04.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0] for update
[2025-07-19T22:10:04.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 199 (task 343, attempt 0, stage 3.0)
[2025-07-19T22:10:04.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 199.0 in stage 3.0 (TID 343). 9046 bytes result sent to driver
[2025-07-19T22:10:04.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 350) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 28.0 in stage 3.0 (TID 350)
[2025-07-19T22:10:04.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 199.0 in stage 3.0 (TID 343) in 124 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T22:10:04.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14d919a1
[2025-07-19T22:10:04.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/27] for update
[2025-07-19T22:10:04.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a14dcfa
[2025-07-19T22:10:04.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 196 (task 342, attempt 0, stage 3.0)
[2025-07-19T22:10:04.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 196.0 in stage 3.0 (TID 342). 9074 bytes result sent to driver
[2025-07-19T22:10:04.700+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 351) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.706+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 196.0 in stage 3.0 (TID 342) in 138 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T22:10:04.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/17] for update
[2025-07-19T22:10:04.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 31.0 in stage 3.0 (TID 351)
[2025-07-19T22:10:04.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.709+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.1.delta.7c18249d-6f06-4e83-bd28-674daac2a5cc.TID344.tmp
[2025-07-19T22:10:04.711+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3151cc0f
[2025-07-19T22:10:04.711+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/10] for update
[2025-07-19T22:10:04.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.1.delta.bdbac818-9007-4caa-8f06-e65b900fa7d2.TID349.tmp
[2025-07-19T22:10:04.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.1.delta.542f0e60-d5b9-41db-bd94-ee162dec7750.TID348.tmp
[2025-07-19T22:10:04.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@633b5dcd
[2025-07-19T22:10:04.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/31] for update
[2025-07-19T22:10:04.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c4a114b
[2025-07-19T22:10:04.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/15] for update
[2025-07-19T22:10:04.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.728+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.1.delta.bdabba9f-6fc8-418c-af6c-218956b9e9ec.TID346.tmp
[2025-07-19T22:10:04.733+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fe66029
[2025-07-19T22:10:04.733+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/8] for update
[2025-07-19T22:10:04.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.1.delta.453e3965-73bb-4ed1-8edd-59b786d7d1f4.TID351.tmp
[2025-07-19T22:10:04.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.1.delta.f0048dc8-b7dc-4f3a-8ebe-cdc6dc03e1cc.TID347.tmp
[2025-07-19T22:10:04.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@180165fe
[2025-07-19T22:10:04.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/28] for update
[2025-07-19T22:10:04.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.1.delta.899ca317-8383-4279-96fb-f08b6888c1ec.TID345.tmp
[2025-07-19T22:10:04.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.1.delta.542f0e60-d5b9-41db-bd94-ee162dec7750.TID348.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/17/1.delta
[2025-07-19T22:10:04.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/17] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/17/1.delta
[2025-07-19T22:10:04.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 348, attempt 0, stage 3.0)
[2025-07-19T22:10:04.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.1.delta.7c18249d-6f06-4e83-bd28-674daac2a5cc.TID344.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0/1.delta
[2025-07-19T22:10:04.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/0/1.delta
[2025-07-19T22:10:04.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 344, attempt 0, stage 3.0)
[2025-07-19T22:10:04.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 17 (task 348, attempt 0, stage 3.0)
[2025-07-19T22:10:04.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 17.0 in stage 3.0 (TID 348). 6243 bytes result sent to driver
[2025-07-19T22:10:04.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.1.delta.bdbac818-9007-4caa-8f06-e65b900fa7d2.TID349.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/27/1.delta
[2025-07-19T22:10:04.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/27] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/27/1.delta
[2025-07-19T22:10:04.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 352) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 349, attempt 0, stage 3.0)
[2025-07-19T22:10:04.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 0 (task 344, attempt 0, stage 3.0)
[2025-07-19T22:10:04.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 0.0 in stage 3.0 (TID 344). 6243 bytes result sent to driver
[2025-07-19T22:10:04.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.1.delta.2bd63e5f-ddf2-48d8-abeb-9ecca510f156.TID350.tmp
[2025-07-19T22:10:04.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 348) in 114 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T22:10:04.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 344) in 196 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T22:10:04.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 353) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 34.0 in stage 3.0 (TID 353)
[2025-07-19T22:10:04.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 33.0 in stage 3.0 (TID 352)
[2025-07-19T22:10:04.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 27 (task 349, attempt 0, stage 3.0)
[2025-07-19T22:10:04.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 27.0 in stage 3.0 (TID 349). 6243 bytes result sent to driver
[2025-07-19T22:10:04.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 354) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 36.0 in stage 3.0 (TID 354)
[2025-07-19T22:10:04.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ca7b132
[2025-07-19T22:10:04.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 349) in 125 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T22:10:04.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/33] for update
[2025-07-19T22:10:04.781+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.1.delta.453e3965-73bb-4ed1-8edd-59b786d7d1f4.TID351.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/31/1.delta
[2025-07-19T22:10:04.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/31] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/31/1.delta
[2025-07-19T22:10:04.784+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.784+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 351, attempt 0, stage 3.0)
[2025-07-19T22:10:04.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.1.delta.bdabba9f-6fc8-418c-af6c-218956b9e9ec.TID346.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/10/1.delta
[2025-07-19T22:10:04.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/10] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/10/1.delta
[2025-07-19T22:10:04.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 346, attempt 0, stage 3.0)
[2025-07-19T22:10:04.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50a54cf9
[2025-07-19T22:10:04.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 31 (task 351, attempt 0, stage 3.0)
[2025-07-19T22:10:04.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.1.delta.899ca317-8383-4279-96fb-f08b6888c1ec.TID345.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/8/1.delta
[2025-07-19T22:10:04.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/8] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/8/1.delta
[2025-07-19T22:10:04.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 345, attempt 0, stage 3.0)
[2025-07-19T22:10:04.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/34] for update
[2025-07-19T22:10:04.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 31.0 in stage 3.0 (TID 351). 6286 bytes result sent to driver
[2025-07-19T22:10:04.798+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 355) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 351) in 105 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T22:10:04.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22120ec2
[2025-07-19T22:10:04.801+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 40.0 in stage 3.0 (TID 355)
[2025-07-19T22:10:04.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/36] for update
[2025-07-19T22:10:04.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 10 (task 346, attempt 0, stage 3.0)
[2025-07-19T22:10:04.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.1.delta.41c42458-c2ea-4121-8a1a-1185266f4dd6.TID352.tmp
[2025-07-19T22:10:04.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 10.0 in stage 3.0 (TID 346). 6243 bytes result sent to driver
[2025-07-19T22:10:04.809+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.1.delta.f0048dc8-b7dc-4f3a-8ebe-cdc6dc03e1cc.TID347.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/15/1.delta
[2025-07-19T22:10:04.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/15] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/15/1.delta
[2025-07-19T22:10:04.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 8 (task 345, attempt 0, stage 3.0)
[2025-07-19T22:10:04.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 356) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 8.0 in stage 3.0 (TID 345). 6243 bytes result sent to driver
[2025-07-19T22:10:04.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 347, attempt 0, stage 3.0)
[2025-07-19T22:10:04.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 346) in 228 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T22:10:04.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 357) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 44.0 in stage 3.0 (TID 357)
[2025-07-19T22:10:04.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 42.0 in stage 3.0 (TID 356)
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 345) in 231 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ded66e3
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/40] for update
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 15 (task 347, attempt 0, stage 3.0)
[2025-07-19T22:10:04.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 15.0 in stage 3.0 (TID 347). 6243 bytes result sent to driver
[2025-07-19T22:10:04.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.1.delta.860735f8-66f3-45a4-9c30-d3aa1bbc24f5.TID353.tmp
[2025-07-19T22:10:04.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 347) in 236 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T22:10:04.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 358) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 49.0 in stage 3.0 (TID 358)
[2025-07-19T22:10:04.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1554dce6
[2025-07-19T22:10:04.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/42] for update
[2025-07-19T22:10:04.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.1.delta.2bd63e5f-ddf2-48d8-abeb-9ecca510f156.TID350.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/28/1.delta
[2025-07-19T22:10:04.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/28] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/28/1.delta
[2025-07-19T22:10:04.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 350, attempt 0, stage 3.0)
[2025-07-19T22:10:04.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.1.delta.f35c93de-c0c9-4d28-adb7-f1d697223ccd.TID354.tmp
[2025-07-19T22:10:04.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 28 (task 350, attempt 0, stage 3.0)
[2025-07-19T22:10:04.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.1.delta.71118006-4536-4c0e-901b-17e0c910690b.TID355.tmp
[2025-07-19T22:10:04.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 28.0 in stage 3.0 (TID 350). 6243 bytes result sent to driver
[2025-07-19T22:10:04.830+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 50.0 in stage 3.0 (TID 359) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@116cdae2
[2025-07-19T22:10:04.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 350) in 160 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T22:10:04.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 50.0 in stage 3.0 (TID 359)
[2025-07-19T22:10:04.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/44] for update
[2025-07-19T22:10:04.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18c286cf
[2025-07-19T22:10:04.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/49] for update
[2025-07-19T22:10:04.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.1.delta.31b836b2-133e-4177-b745-c4b63131e489.TID356.tmp
[2025-07-19T22:10:04.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@580a41f
[2025-07-19T22:10:04.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/50] for update
[2025-07-19T22:10:04.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.1.delta.4bd780fa-29a9-41e9-a465-1580b4ec106e.TID357.tmp
[2025-07-19T22:10:04.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.1.delta.860735f8-66f3-45a4-9c30-d3aa1bbc24f5.TID353.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/34/1.delta
[2025-07-19T22:10:04.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/34] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/34/1.delta
[2025-07-19T22:10:04.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.1.delta.41c42458-c2ea-4121-8a1a-1185266f4dd6.TID352.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/33/1.delta
[2025-07-19T22:10:04.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/33] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/33/1.delta
[2025-07-19T22:10:04.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 353, attempt 0, stage 3.0)
[2025-07-19T22:10:04.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 352, attempt 0, stage 3.0)
[2025-07-19T22:10:04.865+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.1.delta.9f4667d8-7507-4fab-ab0c-da82163f6b27.TID358.tmp
[2025-07-19T22:10:04.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 34 (task 353, attempt 0, stage 3.0)
[2025-07-19T22:10:04.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 33 (task 352, attempt 0, stage 3.0)
[2025-07-19T22:10:04.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.1.delta.506c9466-6a4a-4712-b933-6490f8dbdc89.TID359.tmp
[2025-07-19T22:10:04.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 33.0 in stage 3.0 (TID 352). 6243 bytes result sent to driver
[2025-07-19T22:10:04.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 34.0 in stage 3.0 (TID 353). 6243 bytes result sent to driver
[2025-07-19T22:10:04.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 54.0 in stage 3.0 (TID 360) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 55.0 in stage 3.0 (TID 361) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 353) in 104 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T22:10:04.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 352) in 110 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T22:10:04.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 54.0 in stage 3.0 (TID 360)
[2025-07-19T22:10:04.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 55.0 in stage 3.0 (TID 361)
[2025-07-19T22:10:04.870+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40872878
[2025-07-19T22:10:04.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.1.delta.f35c93de-c0c9-4d28-adb7-f1d697223ccd.TID354.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/36/1.delta
[2025-07-19T22:10:04.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/36] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/36/1.delta
[2025-07-19T22:10:04.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/54] for update
[2025-07-19T22:10:04.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 354, attempt 0, stage 3.0)
[2025-07-19T22:10:04.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.1.delta.71118006-4536-4c0e-901b-17e0c910690b.TID355.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/40/1.delta
[2025-07-19T22:10:04.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/40] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/40/1.delta
[2025-07-19T22:10:04.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 355, attempt 0, stage 3.0)
[2025-07-19T22:10:04.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 36 (task 354, attempt 0, stage 3.0)
[2025-07-19T22:10:04.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 36.0 in stage 3.0 (TID 354). 6286 bytes result sent to driver
[2025-07-19T22:10:04.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 61.0 in stage 3.0 (TID 362) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 61.0 in stage 3.0 (TID 362)
[2025-07-19T22:10:04.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 354) in 115 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T22:10:04.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1201779f
[2025-07-19T22:10:04.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 40 (task 355, attempt 0, stage 3.0)
[2025-07-19T22:10:04.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/55] for update
[2025-07-19T22:10:04.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 40.0 in stage 3.0 (TID 355). 6243 bytes result sent to driver
[2025-07-19T22:10:04.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 67.0 in stage 3.0 (TID 363) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 67.0 in stage 3.0 (TID 363)
[2025-07-19T22:10:04.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.1.delta.31b836b2-133e-4177-b745-c4b63131e489.TID356.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/42/1.delta
[2025-07-19T22:10:04.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/42] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/42/1.delta
[2025-07-19T22:10:04.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 355) in 103 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T22:10:04.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 356, attempt 0, stage 3.0)
[2025-07-19T22:10:04.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.1.delta.4bd780fa-29a9-41e9-a465-1580b4ec106e.TID357.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/44/1.delta
[2025-07-19T22:10:04.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/44] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/44/1.delta
[2025-07-19T22:10:04.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b2582a
[2025-07-19T22:10:04.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 357, attempt 0, stage 3.0)
[2025-07-19T22:10:04.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.1.delta.0a5d1186-d3cd-4446-8a42-6e38915456a0.TID360.tmp
[2025-07-19T22:10:04.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/61] for update
[2025-07-19T22:10:04.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 42 (task 356, attempt 0, stage 3.0)
[2025-07-19T22:10:04.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4732c395
[2025-07-19T22:10:04.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 42.0 in stage 3.0 (TID 356). 6243 bytes result sent to driver
[2025-07-19T22:10:04.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/67] for update
[2025-07-19T22:10:04.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 70.0 in stage 3.0 (TID 364) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.915+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 44 (task 357, attempt 0, stage 3.0)
[2025-07-19T22:10:04.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 70.0 in stage 3.0 (TID 364)
[2025-07-19T22:10:04.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 44.0 in stage 3.0 (TID 357). 6243 bytes result sent to driver
[2025-07-19T22:10:04.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 356) in 108 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T22:10:04.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 74.0 in stage 3.0 (TID 365) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 74.0 in stage 3.0 (TID 365)
[2025-07-19T22:10:04.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 357) in 109 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T22:10:04.918+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.918+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.1.delta.506c9466-6a4a-4712-b933-6490f8dbdc89.TID359.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/50/1.delta
[2025-07-19T22:10:04.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/50] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/50/1.delta
[2025-07-19T22:10:04.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.1.delta.d6085b40-9d33-4120-aced-f056f5f5438d.TID361.tmp
[2025-07-19T22:10:04.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 359, attempt 0, stage 3.0)
[2025-07-19T22:10:04.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 50 (task 359, attempt 0, stage 3.0)
[2025-07-19T22:10:04.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 50.0 in stage 3.0 (TID 359). 6243 bytes result sent to driver
[2025-07-19T22:10:04.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.1.delta.4d4cdd49-84c6-4568-bb58-b1e86dc65225.TID363.tmp
[2025-07-19T22:10:04.929+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 76.0 in stage 3.0 (TID 366) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 50.0 in stage 3.0 (TID 359) in 95 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T22:10:04.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.1.delta.9f4667d8-7507-4fab-ab0c-da82163f6b27.TID358.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/49/1.delta
[2025-07-19T22:10:04.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/49] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/49/1.delta
[2025-07-19T22:10:04.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 358, attempt 0, stage 3.0)
[2025-07-19T22:10:04.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 76.0 in stage 3.0 (TID 366)
[2025-07-19T22:10:04.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c91c4f8
[2025-07-19T22:10:04.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/74] for update
[2025-07-19T22:10:04.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:04.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 49 (task 358, attempt 0, stage 3.0)
[2025-07-19T22:10:04.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Finished task 49.0 in stage 3.0 (TID 358). 6243 bytes result sent to driver
[2025-07-19T22:10:04.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Starting task 80.0 in stage 3.0 (TID 367) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:04.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO Executor: Running task 80.0 in stage 3.0 (TID 367)
[2025-07-19T22:10:04.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 358) in 123 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T22:10:04.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.949+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:04.950+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:04.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@282a9264
[2025-07-19T22:10:04.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/70] for update
[2025-07-19T22:10:04.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.1.delta.37351289-156b-49bf-a9f9-e9e8a54e81da.TID362.tmp
[2025-07-19T22:10:04.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3aaf9f28
[2025-07-19T22:10:04.955+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/80] for update
[2025-07-19T22:10:04.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.964+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f92f2ad
[2025-07-19T22:10:04.964+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:04.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/76] for update
[2025-07-19T22:10:04.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.1.delta.df6701f4-832a-46a5-9e80-63bbe1222fa3.TID365.tmp
[2025-07-19T22:10:04.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:04.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.1.delta.4d4cdd49-84c6-4568-bb58-b1e86dc65225.TID363.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/67/1.delta
[2025-07-19T22:10:04.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/67] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/67/1.delta
[2025-07-19T22:10:04.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 363, attempt 0, stage 3.0)
[2025-07-19T22:10:04.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.1.delta.18a824cc-46cf-4cab-89b7-c70e242c3310.TID366.tmp
[2025-07-19T22:10:04.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.1.delta.d6085b40-9d33-4120-aced-f056f5f5438d.TID361.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/55/1.delta
[2025-07-19T22:10:04.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/55] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/55/1.delta
[2025-07-19T22:10:04.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 361, attempt 0, stage 3.0)
[2025-07-19T22:10:04.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.1.delta.0bfb68c5-e5a3-4bb4-afe5-4bfa96c31dd7.TID367.tmp
[2025-07-19T22:10:04.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.1.delta.59ca2337-72a1-41a1-8b20-5003c279fbcc.TID364.tmp
[2025-07-19T22:10:05.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:04 INFO DataWritingSparkTask: Committed partition 67 (task 363, attempt 0, stage 3.0)
[2025-07-19T22:10:05.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 67.0 in stage 3.0 (TID 363). 6200 bytes result sent to driver
[2025-07-19T22:10:05.004+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 81.0 in stage 3.0 (TID 368) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 67.0 in stage 3.0 (TID 363) in 110 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T22:10:05.008+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 81.0 in stage 3.0 (TID 368)
[2025-07-19T22:10:05.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 55 (task 361, attempt 0, stage 3.0)
[2025-07-19T22:10:05.015+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 55.0 in stage 3.0 (TID 361). 6243 bytes result sent to driver
[2025-07-19T22:10:05.016+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 84.0 in stage 3.0 (TID 369) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.1.delta.0a5d1186-d3cd-4446-8a42-6e38915456a0.TID360.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/54/1.delta
[2025-07-19T22:10:05.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 55.0 in stage 3.0 (TID 361) in 149 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T22:10:05.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/54] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/54/1.delta
[2025-07-19T22:10:05.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 360, attempt 0, stage 3.0)
[2025-07-19T22:10:05.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 84.0 in stage 3.0 (TID 369)
[2025-07-19T22:10:05.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@598053cb
[2025-07-19T22:10:05.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/81] for update
[2025-07-19T22:10:05.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.1.delta.37351289-156b-49bf-a9f9-e9e8a54e81da.TID362.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/61/1.delta
[2025-07-19T22:10:05.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/61] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/61/1.delta
[2025-07-19T22:10:05.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 362, attempt 0, stage 3.0)
[2025-07-19T22:10:05.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 54 (task 360, attempt 0, stage 3.0)
[2025-07-19T22:10:05.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 54.0 in stage 3.0 (TID 360). 6286 bytes result sent to driver
[2025-07-19T22:10:05.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.1.delta.55d828ab-764d-4d86-8104-303caae9a425.TID368.tmp
[2025-07-19T22:10:05.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 61 (task 362, attempt 0, stage 3.0)
[2025-07-19T22:10:05.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 61.0 in stage 3.0 (TID 362). 6243 bytes result sent to driver
[2025-07-19T22:10:05.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2194e903
[2025-07-19T22:10:05.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/84] for update
[2025-07-19T22:10:05.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 88.0 in stage 3.0 (TID 370) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 54.0 in stage 3.0 (TID 360) in 181 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T22:10:05.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 88.0 in stage 3.0 (TID 370)
[2025-07-19T22:10:05.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.1.delta.df6701f4-832a-46a5-9e80-63bbe1222fa3.TID365.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/74/1.delta
[2025-07-19T22:10:05.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/74] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/74/1.delta
[2025-07-19T22:10:05.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 365, attempt 0, stage 3.0)
[2025-07-19T22:10:05.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 90.0 in stage 3.0 (TID 371) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 61.0 in stage 3.0 (TID 362) in 162 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T22:10:05.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 90.0 in stage 3.0 (TID 371)
[2025-07-19T22:10:05.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:05.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 74 (task 365, attempt 0, stage 3.0)
[2025-07-19T22:10:05.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 74.0 in stage 3.0 (TID 365). 6243 bytes result sent to driver
[2025-07-19T22:10:05.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.1.delta.18a824cc-46cf-4cab-89b7-c70e242c3310.TID366.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/76/1.delta
[2025-07-19T22:10:05.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/76] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/76/1.delta
[2025-07-19T22:10:05.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 91.0 in stage 3.0 (TID 372) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 366, attempt 0, stage 3.0)
[2025-07-19T22:10:05.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 91.0 in stage 3.0 (TID 372)
[2025-07-19T22:10:05.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 74.0 in stage 3.0 (TID 365) in 147 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T22:10:05.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:05.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.1.delta.0bfb68c5-e5a3-4bb4-afe5-4bfa96c31dd7.TID367.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/80/1.delta
[2025-07-19T22:10:05.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.1.delta.59ca2337-72a1-41a1-8b20-5003c279fbcc.TID364.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/70/1.delta
[2025-07-19T22:10:05.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/70] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/70/1.delta
[2025-07-19T22:10:05.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 76 (task 366, attempt 0, stage 3.0)
[2025-07-19T22:10:05.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cf72929
[2025-07-19T22:10:05.074+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/80] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/80/1.delta
[2025-07-19T22:10:05.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 364, attempt 0, stage 3.0)
[2025-07-19T22:10:05.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 367, attempt 0, stage 3.0)
[2025-07-19T22:10:05.077+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/88] for update
[2025-07-19T22:10:05.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 76.0 in stage 3.0 (TID 366). 6243 bytes result sent to driver
[2025-07-19T22:10:05.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 93.0 in stage 3.0 (TID 373) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.080+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 93.0 in stage 3.0 (TID 373)
[2025-07-19T22:10:05.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 70 (task 364, attempt 0, stage 3.0)
[2025-07-19T22:10:05.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 76.0 in stage 3.0 (TID 366) in 150 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T22:10:05.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bcf37a2
[2025-07-19T22:10:05.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/91] for update
[2025-07-19T22:10:05.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 80 (task 367, attempt 0, stage 3.0)
[2025-07-19T22:10:05.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 80.0 in stage 3.0 (TID 367). 6243 bytes result sent to driver
[2025-07-19T22:10:05.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 101.0 in stage 3.0 (TID 374) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.1.delta.c7982e2f-1187-41ec-9a2a-4368754f1b9a.TID369.tmp
[2025-07-19T22:10:05.085+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 80.0 in stage 3.0 (TID 367) in 145 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T22:10:05.085+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.085+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.086+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 101.0 in stage 3.0 (TID 374)
[2025-07-19T22:10:05.086+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 70.0 in stage 3.0 (TID 364). 6243 bytes result sent to driver
[2025-07-19T22:10:05.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 103.0 in stage 3.0 (TID 375) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 103.0 in stage 3.0 (TID 375)
[2025-07-19T22:10:05.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.1.delta.55d828ab-764d-4d86-8104-303caae9a425.TID368.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/81/1.delta
[2025-07-19T22:10:05.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/81] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/81/1.delta
[2025-07-19T22:10:05.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 70.0 in stage 3.0 (TID 364) in 181 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T22:10:05.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 368, attempt 0, stage 3.0)
[2025-07-19T22:10:05.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T22:10:05.097+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.1.delta.1b44bd6d-d82d-43e7-a959-00d27c29fee9.TID372.tmp
[2025-07-19T22:10:05.097+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29a427f0
[2025-07-19T22:10:05.101+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 81 (task 368, attempt 0, stage 3.0)
[2025-07-19T22:10:05.101+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.101+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/90] for update
[2025-07-19T22:10:05.105+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 81.0 in stage 3.0 (TID 368). 6243 bytes result sent to driver
[2025-07-19T22:10:05.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 108.0 in stage 3.0 (TID 376) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 81.0 in stage 3.0 (TID 368) in 101 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T22:10:05.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 108.0 in stage 3.0 (TID 376)
[2025-07-19T22:10:05.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.109+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.1.delta.67137b8d-6380-49dc-af45-d6f544f6af3d.TID370.tmp
[2025-07-19T22:10:05.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b64ccab
[2025-07-19T22:10:05.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/103] for update
[2025-07-19T22:10:05.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.1.delta.2d2b07c1-e414-4682-8b07-d3463af69a3d.TID371.tmp
[2025-07-19T22:10:05.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.1.delta.c7982e2f-1187-41ec-9a2a-4368754f1b9a.TID369.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/84/1.delta
[2025-07-19T22:10:05.121+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/84] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/84/1.delta
[2025-07-19T22:10:05.121+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 369, attempt 0, stage 3.0)
[2025-07-19T22:10:05.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@447d7c21
[2025-07-19T22:10:05.123+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.125+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/101] for update
[2025-07-19T22:10:05.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 84 (task 369, attempt 0, stage 3.0)
[2025-07-19T22:10:05.130+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 84.0 in stage 3.0 (TID 369). 6243 bytes result sent to driver
[2025-07-19T22:10:05.131+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59de580e
[2025-07-19T22:10:05.131+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 112.0 in stage 3.0 (TID 377) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.131+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/93] for update
[2025-07-19T22:10:05.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 84.0 in stage 3.0 (TID 369) in 116 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T22:10:05.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 112.0 in stage 3.0 (TID 377)
[2025-07-19T22:10:05.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.1.delta.0b71f4b4-4dae-4891-b732-0f58b66dc208.TID375.tmp
[2025-07-19T22:10:05.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.142+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.1.delta.1b44bd6d-d82d-43e7-a959-00d27c29fee9.TID372.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/91/1.delta
[2025-07-19T22:10:05.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.1.delta.a3791200-960f-4029-855d-c371dbd32105.TID374.tmp
[2025-07-19T22:10:05.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/91] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/91/1.delta
[2025-07-19T22:10:05.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@523b7463
[2025-07-19T22:10:05.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/108] for update
[2025-07-19T22:10:05.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 372, attempt 0, stage 3.0)
[2025-07-19T22:10:05.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 91 (task 372, attempt 0, stage 3.0)
[2025-07-19T22:10:05.153+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 91.0 in stage 3.0 (TID 372). 6200 bytes result sent to driver
[2025-07-19T22:10:05.154+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.1.delta.324b9188-6aba-48a1-b970-3aef3f863d9c.TID373.tmp
[2025-07-19T22:10:05.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 114.0 in stage 3.0 (TID 378) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 114.0 in stage 3.0 (TID 378)
[2025-07-19T22:10:05.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 91.0 in stage 3.0 (TID 372) in 93 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T22:10:05.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3473043
[2025-07-19T22:10:05.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/112] for update
[2025-07-19T22:10:05.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@673dae0e
[2025-07-19T22:10:05.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/114] for update
[2025-07-19T22:10:05.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.1.delta.89139a64-98cc-4db4-a8f4-a4a2ec866112.TID377.tmp
[2025-07-19T22:10:05.192+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.1.delta.04392f28-12f3-48db-acf2-f0132458e515.TID378.tmp
[2025-07-19T22:10:05.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.1.delta.2d2b07c1-e414-4682-8b07-d3463af69a3d.TID371.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/90/1.delta
[2025-07-19T22:10:05.194+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/90] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/90/1.delta
[2025-07-19T22:10:05.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.1.delta.d306d214-2c1c-4a2b-8d5c-7532f5fe55fd.TID376.tmp
[2025-07-19T22:10:05.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 371, attempt 0, stage 3.0)
[2025-07-19T22:10:05.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 90 (task 371, attempt 0, stage 3.0)
[2025-07-19T22:10:05.202+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.1.delta.67137b8d-6380-49dc-af45-d6f544f6af3d.TID370.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/88/1.delta
[2025-07-19T22:10:05.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/88] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/88/1.delta
[2025-07-19T22:10:05.205+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 370, attempt 0, stage 3.0)
[2025-07-19T22:10:05.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 90.0 in stage 3.0 (TID 371). 6243 bytes result sent to driver
[2025-07-19T22:10:05.211+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 115.0 in stage 3.0 (TID 379) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.213+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 115.0 in stage 3.0 (TID 379)
[2025-07-19T22:10:05.215+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.1.delta.0b71f4b4-4dae-4891-b732-0f58b66dc208.TID375.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/103/1.delta
[2025-07-19T22:10:05.217+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/103] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/103/1.delta
[2025-07-19T22:10:05.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 90.0 in stage 3.0 (TID 371) in 158 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T22:10:05.219+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 375, attempt 0, stage 3.0)
[2025-07-19T22:10:05.220+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 88 (task 370, attempt 0, stage 3.0)
[2025-07-19T22:10:05.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 88.0 in stage 3.0 (TID 370). 6243 bytes result sent to driver
[2025-07-19T22:10:05.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 116.0 in stage 3.0 (TID 380) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.225+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 116.0 in stage 3.0 (TID 380)
[2025-07-19T22:10:05.226+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 103 (task 375, attempt 0, stage 3.0)
[2025-07-19T22:10:05.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 103.0 in stage 3.0 (TID 375). 6243 bytes result sent to driver
[2025-07-19T22:10:05.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 88.0 in stage 3.0 (TID 370) in 171 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T22:10:05.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 103.0 in stage 3.0 (TID 375) in 132 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T22:10:05.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.1.delta.a3791200-960f-4029-855d-c371dbd32105.TID374.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/101/1.delta
[2025-07-19T22:10:05.229+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/101] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/101/1.delta
[2025-07-19T22:10:05.229+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.230+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:05.230+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 124.0 in stage 3.0 (TID 381) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 374, attempt 0, stage 3.0)
[2025-07-19T22:10:05.232+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ce3eed9
[2025-07-19T22:10:05.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/115] for update
[2025-07-19T22:10:05.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.1.delta.324b9188-6aba-48a1-b970-3aef3f863d9c.TID373.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/93/1.delta
[2025-07-19T22:10:05.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/93] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/93/1.delta
[2025-07-19T22:10:05.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 373, attempt 0, stage 3.0)
[2025-07-19T22:10:05.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 124.0 in stage 3.0 (TID 381)
[2025-07-19T22:10:05.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 93 (task 373, attempt 0, stage 3.0)
[2025-07-19T22:10:05.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 93.0 in stage 3.0 (TID 373). 6243 bytes result sent to driver
[2025-07-19T22:10:05.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 101 (task 374, attempt 0, stage 3.0)
[2025-07-19T22:10:05.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 126.0 in stage 3.0 (TID 382) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 101.0 in stage 3.0 (TID 374). 6243 bytes result sent to driver
[2025-07-19T22:10:05.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 126.0 in stage 3.0 (TID 382)
[2025-07-19T22:10:05.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 134.0 in stage 3.0 (TID 383) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 93.0 in stage 3.0 (TID 373) in 166 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T22:10:05.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50632d5c
[2025-07-19T22:10:05.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 134.0 in stage 3.0 (TID 383)
[2025-07-19T22:10:05.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 101.0 in stage 3.0 (TID 374) in 161 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T22:10:05.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/116] for update
[2025-07-19T22:10:05.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.1.delta.357cf0f3-1aaa-4bd0-b147-d1dea3dad65e.TID379.tmp
[2025-07-19T22:10:05.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.1.delta.04392f28-12f3-48db-acf2-f0132458e515.TID378.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/114/1.delta
[2025-07-19T22:10:05.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/114] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/114/1.delta
[2025-07-19T22:10:05.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.1.delta.89139a64-98cc-4db4-a8f4-a4a2ec866112.TID377.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/112/1.delta
[2025-07-19T22:10:05.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/112] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/112/1.delta
[2025-07-19T22:10:05.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 378, attempt 0, stage 3.0)
[2025-07-19T22:10:05.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 377, attempt 0, stage 3.0)
[2025-07-19T22:10:05.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.1.delta.d306d214-2c1c-4a2b-8d5c-7532f5fe55fd.TID376.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/108/1.delta
[2025-07-19T22:10:05.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 114 (task 378, attempt 0, stage 3.0)
[2025-07-19T22:10:05.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3806f8d8
[2025-07-19T22:10:05.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/108] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/108/1.delta
[2025-07-19T22:10:05.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/124] for update
[2025-07-19T22:10:05.266+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 112 (task 377, attempt 0, stage 3.0)
[2025-07-19T22:10:05.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 112.0 in stage 3.0 (TID 377). 6243 bytes result sent to driver
[2025-07-19T22:10:05.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 141.0 in stage 3.0 (TID 384) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.271+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 376, attempt 0, stage 3.0)
[2025-07-19T22:10:05.272+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 112.0 in stage 3.0 (TID 377) in 124 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T22:10:05.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 114.0 in stage 3.0 (TID 378). 6286 bytes result sent to driver
[2025-07-19T22:10:05.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 141.0 in stage 3.0 (TID 384)
[2025-07-19T22:10:05.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 142.0 in stage 3.0 (TID 385) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 142.0 in stage 3.0 (TID 385)
[2025-07-19T22:10:05.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 114.0 in stage 3.0 (TID 378) in 105 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T22:10:05.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:05.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.1.delta.c314904b-6402-4b51-863f-08abdf3bfefa.TID380.tmp
[2025-07-19T22:10:05.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.1.delta.f5e946eb-d5cd-4b30-8488-2f17dbd0ccb2.TID381.tmp
[2025-07-19T22:10:05.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 108 (task 376, attempt 0, stage 3.0)
[2025-07-19T22:10:05.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 108.0 in stage 3.0 (TID 376). 6243 bytes result sent to driver
[2025-07-19T22:10:05.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 147.0 in stage 3.0 (TID 386) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 108.0 in stage 3.0 (TID 376) in 163 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T22:10:05.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c1b2b8
[2025-07-19T22:10:05.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 147.0 in stage 3.0 (TID 386)
[2025-07-19T22:10:05.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/126] for update
[2025-07-19T22:10:05.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63a47f2
[2025-07-19T22:10:05.290+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.291+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/134] for update
[2025-07-19T22:10:05.291+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.1.delta.a945fc10-4cb1-41e3-b3e0-60f992fd308a.TID382.tmp
[2025-07-19T22:10:05.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.1.delta.357cf0f3-1aaa-4bd0-b147-d1dea3dad65e.TID379.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/115/1.delta
[2025-07-19T22:10:05.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/115] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/115/1.delta
[2025-07-19T22:10:05.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 379, attempt 0, stage 3.0)
[2025-07-19T22:10:05.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73634ff6
[2025-07-19T22:10:05.293+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/147] for update
[2025-07-19T22:10:05.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.295+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 115 (task 379, attempt 0, stage 3.0)
[2025-07-19T22:10:05.295+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 115.0 in stage 3.0 (TID 379). 6200 bytes result sent to driver
[2025-07-19T22:10:05.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 115.0 in stage 3.0 (TID 379) in 95 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T22:10:05.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 148.0 in stage 3.0 (TID 387) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56f8dca9
[2025-07-19T22:10:05.300+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 148.0 in stage 3.0 (TID 387)
[2025-07-19T22:10:05.301+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.302+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/142] for update
[2025-07-19T22:10:05.303+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.1.delta.ad7bb13d-ecc1-45a4-997b-09adb7af2447.TID383.tmp
[2025-07-19T22:10:05.304+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.304+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.1.delta.f5e946eb-d5cd-4b30-8488-2f17dbd0ccb2.TID381.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/124/1.delta
[2025-07-19T22:10:05.304+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/124] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/124/1.delta
[2025-07-19T22:10:05.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 381, attempt 0, stage 3.0)
[2025-07-19T22:10:05.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.306+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.1.delta.3afa2647-4ef2-4eb3-bc9d-e815e3f8a3ce.TID386.tmp
[2025-07-19T22:10:05.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 124 (task 381, attempt 0, stage 3.0)
[2025-07-19T22:10:05.313+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 124.0 in stage 3.0 (TID 381). 6286 bytes result sent to driver
[2025-07-19T22:10:05.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 151.0 in stage 3.0 (TID 388) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b9b6397
[2025-07-19T22:10:05.317+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 151.0 in stage 3.0 (TID 388)
[2025-07-19T22:10:05.317+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.1.delta.c314904b-6402-4b51-863f-08abdf3bfefa.TID380.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/116/1.delta
[2025-07-19T22:10:05.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 124.0 in stage 3.0 (TID 381) in 90 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T22:10:05.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/116] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/116/1.delta
[2025-07-19T22:10:05.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 380, attempt 0, stage 3.0)
[2025-07-19T22:10:05.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.1.delta.39a70975-8406-4d02-882c-2dcf2152d4b3.TID385.tmp
[2025-07-19T22:10:05.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/141] for update
[2025-07-19T22:10:05.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 116 (task 380, attempt 0, stage 3.0)
[2025-07-19T22:10:05.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.324+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 116.0 in stage 3.0 (TID 380). 6243 bytes result sent to driver
[2025-07-19T22:10:05.324+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 156.0 in stage 3.0 (TID 389) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 156.0 in stage 3.0 (TID 389)
[2025-07-19T22:10:05.326+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 116.0 in stage 3.0 (TID 380) in 108 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T22:10:05.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.1.delta.e32fb206-0f74-46d4-bd65-d7be7701ad06.TID384.tmp
[2025-07-19T22:10:05.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.1.delta.a945fc10-4cb1-41e3-b3e0-60f992fd308a.TID382.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/126/1.delta
[2025-07-19T22:10:05.331+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/126] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/126/1.delta
[2025-07-19T22:10:05.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 382, attempt 0, stage 3.0)
[2025-07-19T22:10:05.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c9e7f30
[2025-07-19T22:10:05.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/148] for update
[2025-07-19T22:10:05.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 126 (task 382, attempt 0, stage 3.0)
[2025-07-19T22:10:05.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 126.0 in stage 3.0 (TID 382). 6243 bytes result sent to driver
[2025-07-19T22:10:05.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 164.0 in stage 3.0 (TID 390) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.341+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 164.0 in stage 3.0 (TID 390)
[2025-07-19T22:10:05.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 126.0 in stage 3.0 (TID 382) in 106 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T22:10:05.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5009c73c
[2025-07-19T22:10:05.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/156] for update
[2025-07-19T22:10:05.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.1.delta.ad7bb13d-ecc1-45a4-997b-09adb7af2447.TID383.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/134/1.delta
[2025-07-19T22:10:05.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/134] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/134/1.delta
[2025-07-19T22:10:05.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 383, attempt 0, stage 3.0)
[2025-07-19T22:10:05.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.350+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.1.delta.e431f805-9e23-4070-9627-d74cdfb85df4.TID387.tmp
[2025-07-19T22:10:05.350+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@529beb55
[2025-07-19T22:10:05.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/151] for update
[2025-07-19T22:10:05.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.1.delta.3afa2647-4ef2-4eb3-bc9d-e815e3f8a3ce.TID386.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/147/1.delta
[2025-07-19T22:10:05.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/147] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/147/1.delta
[2025-07-19T22:10:05.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 386, attempt 0, stage 3.0)
[2025-07-19T22:10:05.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 134 (task 383, attempt 0, stage 3.0)
[2025-07-19T22:10:05.359+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.1.delta.39a70975-8406-4d02-882c-2dcf2152d4b3.TID385.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/142/1.delta
[2025-07-19T22:10:05.361+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/142] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/142/1.delta
[2025-07-19T22:10:05.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 385, attempt 0, stage 3.0)
[2025-07-19T22:10:05.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 147 (task 386, attempt 0, stage 3.0)
[2025-07-19T22:10:05.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 147.0 in stage 3.0 (TID 386). 6243 bytes result sent to driver
[2025-07-19T22:10:05.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 134.0 in stage 3.0 (TID 383). 6243 bytes result sent to driver
[2025-07-19T22:10:05.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 166.0 in stage 3.0 (TID 391) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7edf1fb
[2025-07-19T22:10:05.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 166.0 in stage 3.0 (TID 391)
[2025-07-19T22:10:05.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 167.0 in stage 3.0 (TID 392) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 147.0 in stage 3.0 (TID 386) in 96 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T22:10:05.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 134.0 in stage 3.0 (TID 383) in 127 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T22:10:05.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 167.0 in stage 3.0 (TID 392)
[2025-07-19T22:10:05.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/164] for update
[2025-07-19T22:10:05.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.1.delta.cadff976-aa5e-4bb8-973c-2d0a600195f8.TID389.tmp
[2025-07-19T22:10:05.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 142 (task 385, attempt 0, stage 3.0)
[2025-07-19T22:10:05.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 142.0 in stage 3.0 (TID 385). 6243 bytes result sent to driver
[2025-07-19T22:10:05.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 168.0 in stage 3.0 (TID 393) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 142.0 in stage 3.0 (TID 385) in 113 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T22:10:05.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.371+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 168.0 in stage 3.0 (TID 393)
[2025-07-19T22:10:05.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.1.delta.3bb485fb-7254-4e88-804b-f1b681d9dd9f.TID388.tmp
[2025-07-19T22:10:05.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78ee2adf
[2025-07-19T22:10:05.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/167] for update
[2025-07-19T22:10:05.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.1.delta.796cca3d-a60a-4e0f-b3f2-fd30629d7df7.TID390.tmp
[2025-07-19T22:10:05.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@645d51a
[2025-07-19T22:10:05.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/168] for update
[2025-07-19T22:10:05.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.386+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.1.delta.e32fb206-0f74-46d4-bd65-d7be7701ad06.TID384.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/141/1.delta
[2025-07-19T22:10:05.386+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/141] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/141/1.delta
[2025-07-19T22:10:05.387+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 384, attempt 0, stage 3.0)
[2025-07-19T22:10:05.388+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.1.delta.888338ad-6745-4f68-a034-9221c49aca0c.TID392.tmp
[2025-07-19T22:10:05.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1283b39e
[2025-07-19T22:10:05.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/166] for update
[2025-07-19T22:10:05.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.397+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 141 (task 384, attempt 0, stage 3.0)
[2025-07-19T22:10:05.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.1.delta.a52dc19d-6b4d-4932-b12c-c5fd6fa92a79.TID393.tmp
[2025-07-19T22:10:05.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 141.0 in stage 3.0 (TID 384). 6243 bytes result sent to driver
[2025-07-19T22:10:05.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 171.0 in stage 3.0 (TID 394) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.400+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 141.0 in stage 3.0 (TID 384) in 145 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T22:10:05.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 171.0 in stage 3.0 (TID 394)
[2025-07-19T22:10:05.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.407+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.1.delta.730730eb-7027-4eb9-a574-be2705dc1068.TID391.tmp
[2025-07-19T22:10:05.407+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.1.delta.e431f805-9e23-4070-9627-d74cdfb85df4.TID387.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/148/1.delta
[2025-07-19T22:10:05.408+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/148] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/148/1.delta
[2025-07-19T22:10:05.410+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55647541
[2025-07-19T22:10:05.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/171] for update
[2025-07-19T22:10:05.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 387, attempt 0, stage 3.0)
[2025-07-19T22:10:05.414+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.1.delta.3bb485fb-7254-4e88-804b-f1b681d9dd9f.TID388.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/151/1.delta
[2025-07-19T22:10:05.414+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/151] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/151/1.delta
[2025-07-19T22:10:05.414+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 388, attempt 0, stage 3.0)
[2025-07-19T22:10:05.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.1.delta.cadff976-aa5e-4bb8-973c-2d0a600195f8.TID389.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/156/1.delta
[2025-07-19T22:10:05.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/156] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/156/1.delta
[2025-07-19T22:10:05.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 389, attempt 0, stage 3.0)
[2025-07-19T22:10:05.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.420+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 148 (task 387, attempt 0, stage 3.0)
[2025-07-19T22:10:05.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 148.0 in stage 3.0 (TID 387). 6286 bytes result sent to driver
[2025-07-19T22:10:05.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.1.delta.796cca3d-a60a-4e0f-b3f2-fd30629d7df7.TID390.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/164/1.delta
[2025-07-19T22:10:05.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/164] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/164/1.delta
[2025-07-19T22:10:05.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 173.0 in stage 3.0 (TID 395) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 156 (task 389, attempt 0, stage 3.0)
[2025-07-19T22:10:05.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 148.0 in stage 3.0 (TID 387) in 132 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T22:10:05.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 173.0 in stage 3.0 (TID 395)
[2025-07-19T22:10:05.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 156.0 in stage 3.0 (TID 389). 6243 bytes result sent to driver
[2025-07-19T22:10:05.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 390, attempt 0, stage 3.0)
[2025-07-19T22:10:05.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 151 (task 388, attempt 0, stage 3.0)
[2025-07-19T22:10:05.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 151.0 in stage 3.0 (TID 388). 6243 bytes result sent to driver
[2025-07-19T22:10:05.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 184.0 in stage 3.0 (TID 396) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 184.0 in stage 3.0 (TID 396)
[2025-07-19T22:10:05.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 189.0 in stage 3.0 (TID 397) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 156.0 in stage 3.0 (TID 389) in 110 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T22:10:05.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:05.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 189.0 in stage 3.0 (TID 397)
[2025-07-19T22:10:05.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 151.0 in stage 3.0 (TID 388) in 118 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T22:10:05.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 164 (task 390, attempt 0, stage 3.0)
[2025-07-19T22:10:05.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.1.delta.1e37b1dc-ac5c-4a5d-a0c7-a94545ba2c8b.TID394.tmp
[2025-07-19T22:10:05.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 164.0 in stage 3.0 (TID 390). 6243 bytes result sent to driver
[2025-07-19T22:10:05.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 191.0 in stage 3.0 (TID 398) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 191.0 in stage 3.0 (TID 398)
[2025-07-19T22:10:05.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 164.0 in stage 3.0 (TID 390) in 98 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T22:10:05.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a68443e
[2025-07-19T22:10:05.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/173] for update
[2025-07-19T22:10:05.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.1.delta.888338ad-6745-4f68-a034-9221c49aca0c.TID392.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/167/1.delta
[2025-07-19T22:10:05.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/167] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/167/1.delta
[2025-07-19T22:10:05.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 392, attempt 0, stage 3.0)
[2025-07-19T22:10:05.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 167 (task 392, attempt 0, stage 3.0)
[2025-07-19T22:10:05.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 167.0 in stage 3.0 (TID 392). 6243 bytes result sent to driver
[2025-07-19T22:10:05.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 193.0 in stage 3.0 (TID 399) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 167.0 in stage 3.0 (TID 392) in 84 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T22:10:05.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 193.0 in stage 3.0 (TID 399)
[2025-07-19T22:10:05.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@419829aa
[2025-07-19T22:10:05.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/191] for update
[2025-07-19T22:10:05.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.1.delta.a52dc19d-6b4d-4932-b12c-c5fd6fa92a79.TID393.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/168/1.delta
[2025-07-19T22:10:05.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/168] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/168/1.delta
[2025-07-19T22:10:05.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 393, attempt 0, stage 3.0)
[2025-07-19T22:10:05.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.1.delta.8c1973d6-d57a-4e36-9482-d43e5569b6d0.TID395.tmp
[2025-07-19T22:10:05.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.1.delta.730730eb-7027-4eb9-a574-be2705dc1068.TID391.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/166/1.delta
[2025-07-19T22:10:05.457+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/166] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/166/1.delta
[2025-07-19T22:10:05.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 168 (task 393, attempt 0, stage 3.0)
[2025-07-19T22:10:05.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 391, attempt 0, stage 3.0)
[2025-07-19T22:10:05.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 168.0 in stage 3.0 (TID 393). 6286 bytes result sent to driver
[2025-07-19T22:10:05.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3930738a
[2025-07-19T22:10:05.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/184] for update
[2025-07-19T22:10:05.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 194.0 in stage 3.0 (TID 400) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 168.0 in stage 3.0 (TID 393) in 93 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T22:10:05.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 166 (task 391, attempt 0, stage 3.0)
[2025-07-19T22:10:05.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 166.0 in stage 3.0 (TID 391). 6243 bytes result sent to driver
[2025-07-19T22:10:05.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 197.0 in stage 3.0 (TID 401) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 194.0 in stage 3.0 (TID 400)
[2025-07-19T22:10:05.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 197.0 in stage 3.0 (TID 401)
[2025-07-19T22:10:05.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 166.0 in stage 3.0 (TID 391) in 105 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T22:10:05.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:05.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.1.delta.1e37b1dc-ac5c-4a5d-a0c7-a94545ba2c8b.TID394.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/171/1.delta
[2025-07-19T22:10:05.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/171] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/171/1.delta
[2025-07-19T22:10:05.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 394, attempt 0, stage 3.0)
[2025-07-19T22:10:05.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d9883e5
[2025-07-19T22:10:05.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.480+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/193] for update
[2025-07-19T22:10:05.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.1.delta.b66673c2-b70d-4a37-8538-74da45f0c93d.TID396.tmp
[2025-07-19T22:10:05.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 171 (task 394, attempt 0, stage 3.0)
[2025-07-19T22:10:05.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 171.0 in stage 3.0 (TID 394). 6243 bytes result sent to driver
[2025-07-19T22:10:05.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.1.delta.c6b4c120-19c8-4da3-8c68-964319bd588e.TID398.tmp
[2025-07-19T22:10:05.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 198.0 in stage 3.0 (TID 402) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 171.0 in stage 3.0 (TID 394) in 81 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T22:10:05.484+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 198.0 in stage 3.0 (TID 402)
[2025-07-19T22:10:05.484+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.1.delta.c3326f6b-2d2c-4acc-a2da-c5387cb3f269.TID399.tmp
[2025-07-19T22:10:05.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32b33428
[2025-07-19T22:10:05.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/189] for update
[2025-07-19T22:10:05.490+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.1.delta.8c1973d6-d57a-4e36-9482-d43e5569b6d0.TID395.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/173/1.delta
[2025-07-19T22:10:05.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/173] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/173/1.delta
[2025-07-19T22:10:05.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 395, attempt 0, stage 3.0)
[2025-07-19T22:10:05.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.1.delta.34f174ae-3ce6-480b-a2a2-f5f9bae2b5bf.TID397.tmp
[2025-07-19T22:10:05.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66840e8e
[2025-07-19T22:10:05.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 173 (task 395, attempt 0, stage 3.0)
[2025-07-19T22:10:05.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 173.0 in stage 3.0 (TID 395). 6200 bytes result sent to driver
[2025-07-19T22:10:05.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/198] for update
[2025-07-19T22:10:05.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 403) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 403)
[2025-07-19T22:10:05.505+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 173.0 in stage 3.0 (TID 395) in 78 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T22:10:05.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.507+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50a7f783
[2025-07-19T22:10:05.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.510+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/194] for update
[2025-07-19T22:10:05.511+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.1.delta.b66673c2-b70d-4a37-8538-74da45f0c93d.TID396.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/184/1.delta
[2025-07-19T22:10:05.515+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/184] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/184/1.delta
[2025-07-19T22:10:05.515+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@618a3fc5
[2025-07-19T22:10:05.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 396, attempt 0, stage 3.0)
[2025-07-19T22:10:05.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],c4540072-4f24-4872-808b-e7ac78480bd8) is active
[2025-07-19T22:10:05.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/197] for update
[2025-07-19T22:10:05.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.1.delta.bb03bd95-e7cb-408e-9a25-1aad7e13ddbf.TID402.tmp
[2025-07-19T22:10:05.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.1.delta.c6b4c120-19c8-4da3-8c68-964319bd588e.TID398.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/191/1.delta
[2025-07-19T22:10:05.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/191] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/191/1.delta
[2025-07-19T22:10:05.528+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 184 (task 396, attempt 0, stage 3.0)
[2025-07-19T22:10:05.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 398, attempt 0, stage 3.0)
[2025-07-19T22:10:05.531+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 184.0 in stage 3.0 (TID 396). 6243 bytes result sent to driver
[2025-07-19T22:10:05.531+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.1.delta.c3326f6b-2d2c-4acc-a2da-c5387cb3f269.TID399.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/193/1.delta
[2025-07-19T22:10:05.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/193] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/193/1.delta
[2025-07-19T22:10:05.533+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 399, attempt 0, stage 3.0)
[2025-07-19T22:10:05.534+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 404) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.535+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 184.0 in stage 3.0 (TID 396) in 102 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T22:10:05.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.1.delta.6b146338-26ef-408f-b67d-698a7611063b.TID400.tmp
[2025-07-19T22:10:05.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 191 (task 398, attempt 0, stage 3.0)
[2025-07-19T22:10:05.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 2.0 in stage 1.0 (TID 404)
[2025-07-19T22:10:05.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 191.0 in stage 3.0 (TID 398). 6243 bytes result sent to driver
[2025-07-19T22:10:05.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 405) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 191.0 in stage 3.0 (TID 398) in 100 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T22:10:05.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 3.0 in stage 1.0 (TID 405)
[2025-07-19T22:10:05.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 193 (task 399, attempt 0, stage 3.0)
[2025-07-19T22:10:05.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 193.0 in stage 3.0 (TID 399). 6243 bytes result sent to driver
[2025-07-19T22:10:05.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 406) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 193.0 in stage 3.0 (TID 399) in 96 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T22:10:05.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.1.delta.4d72b7db-6ae5-4073-96f0-47f4f3fabbcd.TID401.tmp
[2025-07-19T22:10:05.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 5.0 in stage 1.0 (TID 406)
[2025-07-19T22:10:05.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1806e1a6
[2025-07-19T22:10:05.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1] for update
[2025-07-19T22:10:05.550+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15e46cc
[2025-07-19T22:10:05.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5] for update
[2025-07-19T22:10:05.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.1.delta.34f174ae-3ce6-480b-a2a2-f5f9bae2b5bf.TID397.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/189/1.delta
[2025-07-19T22:10:05.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/189] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/189/1.delta
[2025-07-19T22:10:05.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 397, attempt 0, stage 3.0)
[2025-07-19T22:10:05.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33a12b93
[2025-07-19T22:10:05.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3] for update
[2025-07-19T22:10:05.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 189 (task 397, attempt 0, stage 3.0)
[2025-07-19T22:10:05.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.1.delta.bb03bd95-e7cb-408e-9a25-1aad7e13ddbf.TID402.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/198/1.delta
[2025-07-19T22:10:05.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/198] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/198/1.delta
[2025-07-19T22:10:05.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 402, attempt 0, stage 3.0)
[2025-07-19T22:10:05.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 189.0 in stage 3.0 (TID 397). 6243 bytes result sent to driver
[2025-07-19T22:10:05.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 407) (8b44f3d35cfa, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 189.0 in stage 3.0 (TID 397) in 136 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T22:10:05.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 6.0 in stage 1.0 (TID 407)
[2025-07-19T22:10:05.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.571+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6752f757
[2025-07-19T22:10:05.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2] for update
[2025-07-19T22:10:05.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 198 (task 402, attempt 0, stage 3.0)
[2025-07-19T22:10:05.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 198.0 in stage 3.0 (TID 402). 6243 bytes result sent to driver
[2025-07-19T22:10:05.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 408) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 7.0 in stage 1.0 (TID 408)
[2025-07-19T22:10:05.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.1.delta.6b146338-26ef-408f-b67d-698a7611063b.TID400.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/194/1.delta
[2025-07-19T22:10:05.579+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/194] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/194/1.delta
[2025-07-19T22:10:05.580+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 198.0 in stage 3.0 (TID 402) in 95 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T22:10:05.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodeGenerator: Code generated in 21.536083 ms
[2025-07-19T22:10:05.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 400, attempt 0, stage 3.0)
[2025-07-19T22:10:05.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bd0e327
[2025-07-19T22:10:05.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodeGenerator: Code generated in 3.088292 ms
[2025-07-19T22:10:05.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6] for update
[2025-07-19T22:10:05.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@376ee4e3
[2025-07-19T22:10:05.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7] for update
[2025-07-19T22:10:05.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 194 (task 400, attempt 0, stage 3.0)
[2025-07-19T22:10:05.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.1.delta.4d72b7db-6ae5-4073-96f0-47f4f3fabbcd.TID401.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/197/1.delta
[2025-07-19T22:10:05.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/197] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/state/0/197/1.delta
[2025-07-19T22:10:05.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 194.0 in stage 3.0 (TID 400). 6243 bytes result sent to driver
[2025-07-19T22:10:05.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 409) (8b44f3d35cfa, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 401, attempt 0, stage 3.0)
[2025-07-19T22:10:05.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 194.0 in stage 3.0 (TID 400) in 132 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T22:10:05.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 8.0 in stage 1.0 (TID 409)
[2025-07-19T22:10:05.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 197 (task 401, attempt 0, stage 3.0)
[2025-07-19T22:10:05.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 197.0 in stage 3.0 (TID 401). 6243 bytes result sent to driver
[2025-07-19T22:10:05.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 410) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 9.0 in stage 1.0 (TID 410)
[2025-07-19T22:10:05.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.1.delta.72c9038c-1436-458b-b9fc-7ddc5b6656ae.TID403.tmp
[2025-07-19T22:10:05.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 197.0 in stage 3.0 (TID 401) in 138 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T22:10:05.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-07-19T22:10:05.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DAGScheduler: ResultStage 3 (start at <unknown>:0) finished in 13.198 s
[2025-07-19T22:10:05.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T22:10:05.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-07-19T22:10:05.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DAGScheduler: Job 1 finished: start at <unknown>:0, took 14.871589 s
[2025-07-19T22:10:05.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.1.delta.d0cc6ad7-9f38-4ea9-b49b-a624084fd266.TID405.tmp
[2025-07-19T22:10:05.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.1.delta.8f72cdfb-7fda-4e0f-90ca-903658128ce1.TID407.tmp
[2025-07-19T22:10:05.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.1.delta.fe995a78-1852-45e4-b3c5-006c995433c5.TID404.tmp
[2025-07-19T22:10:05.611+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] is committing.
[2025-07-19T22:10:05.612+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO SparkWrite: Committing epoch 0 for query 7b068dbd-ce57-48ee-985f-2e8eff7153ac in append mode
[2025-07-19T22:10:05.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.1.delta.d38ee538-aeaf-401e-965b-11a6d9d992aa.TID408.tmp
[2025-07-19T22:10:05.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.1.delta.d1ae617b-2522-42a5-9a7b-de3606c96fba.TID406.tmp
[2025-07-19T22:10:05.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@688e4800
[2025-07-19T22:10:05.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8] for update
[2025-07-19T22:10:05.619+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58def411
[2025-07-19T22:10:05.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9] for update
[2025-07-19T22:10:05.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO SparkWrite: Committing streaming append with 141 new data files to table my_catalog.bronze.Reservations_raw
[2025-07-19T22:10:05.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.1.delta.8c0bad93-84b4-47ef-82ef-503e38e3982b.TID409.tmp
[2025-07-19T22:10:05.647+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.1.delta.1eab8d69-a2ec-488d-ba78-42facbc0a1fd.TID410.tmp
[2025-07-19T22:10:05.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.1.delta.72c9038c-1436-458b-b9fc-7ddc5b6656ae.TID403.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/1.delta
[2025-07-19T22:10:05.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/1.delta
[2025-07-19T22:10:05.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 403, attempt 0, stage 1.0)
[2025-07-19T22:10:05.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.1.delta.fe995a78-1852-45e4-b3c5-006c995433c5.TID404.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/1.delta
[2025-07-19T22:10:05.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/1.delta
[2025-07-19T22:10:05.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 404, attempt 0, stage 1.0)
[2025-07-19T22:10:05.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.1.delta.d1ae617b-2522-42a5-9a7b-de3606c96fba.TID406.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/1.delta
[2025-07-19T22:10:05.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/1.delta
[2025-07-19T22:10:05.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 406, attempt 0, stage 1.0)
[2025-07-19T22:10:05.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.1.delta.8f72cdfb-7fda-4e0f-90ca-903658128ce1.TID407.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/1.delta
[2025-07-19T22:10:05.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/1.delta
[2025-07-19T22:10:05.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 407, attempt 0, stage 1.0)
[2025-07-19T22:10:05.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.1.delta.d38ee538-aeaf-401e-965b-11a6d9d992aa.TID408.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/1.delta
[2025-07-19T22:10:05.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/1.delta
[2025-07-19T22:10:05.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 408, attempt 0, stage 1.0)
[2025-07-19T22:10:05.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.1.delta.d0cc6ad7-9f38-4ea9-b49b-a624084fd266.TID405.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/1.delta
[2025-07-19T22:10:05.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/1.delta
[2025-07-19T22:10:05.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 405, attempt 0, stage 1.0)
[2025-07-19T22:10:05.704+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 1 (task 403, attempt 0, stage 1.0)
[2025-07-19T22:10:05.720+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 403). 9330 bytes result sent to driver
[2025-07-19T22:10:05.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 411) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.728+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 2 (task 404, attempt 0, stage 1.0)
[2025-07-19T22:10:05.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.1.delta.8c0bad93-84b4-47ef-82ef-503e38e3982b.TID409.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/1.delta
[2025-07-19T22:10:05.730+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/1.delta
[2025-07-19T22:10:05.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.1.delta.1eab8d69-a2ec-488d-ba78-42facbc0a1fd.TID410.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/1.delta
[2025-07-19T22:10:05.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/1.delta
[2025-07-19T22:10:05.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 2.0 in stage 1.0 (TID 404). 9303 bytes result sent to driver
[2025-07-19T22:10:05.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 5 (task 406, attempt 0, stage 1.0)
[2025-07-19T22:10:05.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 403) in 220 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T22:10:05.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 10.0 in stage 1.0 (TID 411)
[2025-07-19T22:10:05.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 5.0 in stage 1.0 (TID 406). 9278 bytes result sent to driver
[2025-07-19T22:10:05.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 409, attempt 0, stage 1.0)
[2025-07-19T22:10:05.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 412) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 413) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 6 (task 407, attempt 0, stage 1.0)
[2025-07-19T22:10:05.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 404) in 199 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T22:10:05.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 11.0 in stage 1.0 (TID 412)
[2025-07-19T22:10:05.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 406) in 189 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T22:10:05.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 410, attempt 0, stage 1.0)
[2025-07-19T22:10:05.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.743+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 6.0 in stage 1.0 (TID 407). 9289 bytes result sent to driver
[2025-07-19T22:10:05.743+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 12.0 in stage 1.0 (TID 413)
[2025-07-19T22:10:05.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 407) in 169 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T22:10:05.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 414) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 13.0 in stage 1.0 (TID 414)
[2025-07-19T22:10:05.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 7 (task 408, attempt 0, stage 1.0)
[2025-07-19T22:10:05.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 3 (task 405, attempt 0, stage 1.0)
[2025-07-19T22:10:05.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 3.0 in stage 1.0 (TID 405). 9293 bytes result sent to driver
[2025-07-19T22:10:05.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 7.0 in stage 1.0 (TID 408). 9296 bytes result sent to driver
[2025-07-19T22:10:05.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 415) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 416) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5905d8e6
[2025-07-19T22:10:05.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 15.0 in stage 1.0 (TID 416)
[2025-07-19T22:10:05.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10] for update
[2025-07-19T22:10:05.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:05.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a944167
[2025-07-19T22:10:05.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13] for update
[2025-07-19T22:10:05.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 405) in 212 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T22:10:05.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 408) in 174 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T22:10:05.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 14.0 in stage 1.0 (TID 415)
[2025-07-19T22:10:05.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@537abdd
[2025-07-19T22:10:05.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15] for update
[2025-07-19T22:10:05.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.1.delta.3adc8202-ec2e-4c09-8d0f-a99c839736cb.TID411.tmp
[2025-07-19T22:10:05.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76bc187
[2025-07-19T22:10:05.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 8 (task 409, attempt 0, stage 1.0)
[2025-07-19T22:10:05.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:05.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 8.0 in stage 1.0 (TID 409). 9293 bytes result sent to driver
[2025-07-19T22:10:05.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.1.delta.799ee411-48c7-4798-afda-ab3f45e40fea.TID414.tmp
[2025-07-19T22:10:05.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11] for update
[2025-07-19T22:10:05.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 417) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 409) in 178 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T22:10:05.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 9 (task 410, attempt 0, stage 1.0)
[2025-07-19T22:10:05.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 9.0 in stage 1.0 (TID 410). 9295 bytes result sent to driver
[2025-07-19T22:10:05.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 16.0 in stage 1.0 (TID 417)
[2025-07-19T22:10:05.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 410) in 171 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T22:10:05.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.771+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 418) (8b44f3d35cfa, executor driver, partition 17, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.771+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.1.delta.d0b0288f-f201-4103-ac8c-f7c74adc1622.TID416.tmp
[2025-07-19T22:10:05.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 17.0 in stage 1.0 (TID 418)
[2025-07-19T22:10:05.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fea81f0
[2025-07-19T22:10:05.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.781+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14] for update
[2025-07-19T22:10:05.781+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.1.delta.d7a816f3-1e07-4d94-9989-01053e04454d.TID412.tmp
[2025-07-19T22:10:05.781+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.781+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.789+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ac27b84
[2025-07-19T22:10:05.794+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17] for update
[2025-07-19T22:10:05.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.1.delta.5fd6cd55-8d1c-4ce8-bada-5b4ad0074bbc.TID415.tmp
[2025-07-19T22:10:05.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a619be6
[2025-07-19T22:10:05.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12] for update
[2025-07-19T22:10:05.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.1.delta.bc55fee5-cb64-4d03-8748-38c4bfd45342.TID418.tmp
[2025-07-19T22:10:05.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3feaf119
[2025-07-19T22:10:05.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16] for update
[2025-07-19T22:10:05.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.1.delta.1720c305-a496-4531-870f-48202d169657.TID413.tmp
[2025-07-19T22:10:05.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.1.delta.799ee411-48c7-4798-afda-ab3f45e40fea.TID414.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/1.delta
[2025-07-19T22:10:05.830+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/1.delta
[2025-07-19T22:10:05.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 414, attempt 0, stage 1.0)
[2025-07-19T22:10:05.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.1.delta.3adc8202-ec2e-4c09-8d0f-a99c839736cb.TID411.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/1.delta
[2025-07-19T22:10:05.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/1.delta
[2025-07-19T22:10:05.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 411, attempt 0, stage 1.0)
[2025-07-19T22:10:05.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.1.delta.d0b0288f-f201-4103-ac8c-f7c74adc1622.TID416.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/1.delta
[2025-07-19T22:10:05.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/1.delta
[2025-07-19T22:10:05.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.1.delta.aab666fe-4062-47b9-82e5-10e0f0948398.TID417.tmp
[2025-07-19T22:10:05.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 416, attempt 0, stage 1.0)
[2025-07-19T22:10:05.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.1.delta.d7a816f3-1e07-4d94-9989-01053e04454d.TID412.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/1.delta
[2025-07-19T22:10:05.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/1.delta
[2025-07-19T22:10:05.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 412, attempt 0, stage 1.0)
[2025-07-19T22:10:05.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 13 (task 414, attempt 0, stage 1.0)
[2025-07-19T22:10:05.862+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 13.0 in stage 1.0 (TID 414). 9291 bytes result sent to driver
[2025-07-19T22:10:05.863+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 419) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.864+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 18.0 in stage 1.0 (TID 419)
[2025-07-19T22:10:05.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 414) in 124 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T22:10:05.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 10 (task 411, attempt 0, stage 1.0)
[2025-07-19T22:10:05.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 10.0 in stage 1.0 (TID 411). 9289 bytes result sent to driver
[2025-07-19T22:10:05.872+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 420) (8b44f3d35cfa, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:05.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 411) in 145 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T22:10:05.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 19.0 in stage 1.0 (TID 420)
[2025-07-19T22:10:05.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 15 (task 416, attempt 0, stage 1.0)
[2025-07-19T22:10:05.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 15.0 in stage 1.0 (TID 416). 9319 bytes result sent to driver
[2025-07-19T22:10:05.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 421) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 20.0 in stage 1.0 (TID 421)
[2025-07-19T22:10:05.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 416) in 134 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T22:10:05.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c144ee9
[2025-07-19T22:10:05.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18] for update
[2025-07-19T22:10:05.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.1.delta.bc55fee5-cb64-4d03-8748-38c4bfd45342.TID418.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/1.delta
[2025-07-19T22:10:05.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/1.delta
[2025-07-19T22:10:05.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 418, attempt 0, stage 1.0)
[2025-07-19T22:10:05.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 11 (task 412, attempt 0, stage 1.0)
[2025-07-19T22:10:05.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 11.0 in stage 1.0 (TID 412). 9293 bytes result sent to driver
[2025-07-19T22:10:05.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 422) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 22.0 in stage 1.0 (TID 422)
[2025-07-19T22:10:05.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 412) in 161 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T22:10:05.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.1.delta.5fd6cd55-8d1c-4ce8-bada-5b4ad0074bbc.TID415.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/1.delta
[2025-07-19T22:10:05.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/1.delta
[2025-07-19T22:10:05.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 415, attempt 0, stage 1.0)
[2025-07-19T22:10:05.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@665a7cde
[2025-07-19T22:10:05.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20] for update
[2025-07-19T22:10:05.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.1.delta.3a94880a-e712-482c-960a-1550d7bd71c0.TID419.tmp
[2025-07-19T22:10:05.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.1.delta.1720c305-a496-4531-870f-48202d169657.TID413.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/1.delta
[2025-07-19T22:10:05.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/1.delta
[2025-07-19T22:10:05.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 413, attempt 0, stage 1.0)
[2025-07-19T22:10:05.907+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37a741a1
[2025-07-19T22:10:05.907+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.907+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19] for update
[2025-07-19T22:10:05.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.1.delta.aab666fe-4062-47b9-82e5-10e0f0948398.TID417.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/1.delta
[2025-07-19T22:10:05.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/1.delta
[2025-07-19T22:10:05.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 417, attempt 0, stage 1.0)
[2025-07-19T22:10:05.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.1.delta.08d52f72-3bb3-4c74-b154-a7cf7ef743f4.TID421.tmp
[2025-07-19T22:10:05.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 17 (task 418, attempt 0, stage 1.0)
[2025-07-19T22:10:05.915+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52c8400
[2025-07-19T22:10:05.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22] for update
[2025-07-19T22:10:05.917+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 14 (task 415, attempt 0, stage 1.0)
[2025-07-19T22:10:05.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 17.0 in stage 1.0 (TID 418). 9338 bytes result sent to driver
[2025-07-19T22:10:05.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 14.0 in stage 1.0 (TID 415). 9289 bytes result sent to driver
[2025-07-19T22:10:05.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 423) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 12 (task 413, attempt 0, stage 1.0)
[2025-07-19T22:10:05.930+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Reservations_raw/metadata/v79.metadata.json
[2025-07-19T22:10:05.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.1.delta.7f737da6-8288-42f0-9846-ffabe078d54a.TID420.tmp
[2025-07-19T22:10:05.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 424) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 23.0 in stage 1.0 (TID 423)
[2025-07-19T22:10:05.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 12.0 in stage 1.0 (TID 413). 9301 bytes result sent to driver
[2025-07-19T22:10:05.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 418) in 158 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T22:10:05.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 415) in 190 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T22:10:05.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 24.0 in stage 1.0 (TID 424)
[2025-07-19T22:10:05.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 425) (8b44f3d35cfa, executor driver, partition 25, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 25.0 in stage 1.0 (TID 425)
[2025-07-19T22:10:05.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 413) in 200 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T22:10:05.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:05.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.1.delta.aac8d111-0713-4e7c-b396-91189bc0f448.TID422.tmp
[2025-07-19T22:10:05.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f73bb05
[2025-07-19T22:10:05.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24] for update
[2025-07-19T22:10:05.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 16 (task 417, attempt 0, stage 1.0)
[2025-07-19T22:10:05.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 16.0 in stage 1.0 (TID 417). 9304 bytes result sent to driver
[2025-07-19T22:10:05.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 426) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:05.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Running task 26.0 in stage 1.0 (TID 426)
[2025-07-19T22:10:05.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 417) in 184 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T22:10:05.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:05.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:05.959+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d083d00
[2025-07-19T22:10:05.960+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25] for update
[2025-07-19T22:10:05.966+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.1.delta.dcc4af25-9e97-4a98-b7cf-512a5dce334d.TID424.tmp
[2025-07-19T22:10:05.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e3c9c34
[2025-07-19T22:10:05.977+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.1.delta.08d52f72-3bb3-4c74-b154-a7cf7ef743f4.TID421.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/1.delta
[2025-07-19T22:10:05.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/1.delta
[2025-07-19T22:10:05.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.1.delta.3a94880a-e712-482c-960a-1550d7bd71c0.TID419.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/1.delta
[2025-07-19T22:10:05.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/1.delta
[2025-07-19T22:10:05.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 419, attempt 0, stage 1.0)
[2025-07-19T22:10:05.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 421, attempt 0, stage 1.0)
[2025-07-19T22:10:05.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23] for update
[2025-07-19T22:10:05.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.1.delta.7f737da6-8288-42f0-9846-ffabe078d54a.TID420.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/1.delta
[2025-07-19T22:10:05.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/1.delta
[2025-07-19T22:10:05.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.985+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 420, attempt 0, stage 1.0)
[2025-07-19T22:10:05.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@490dd61a
[2025-07-19T22:10:05.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.1.delta.5664b9f1-4f46-4cc6-989a-94988bf27fbe.TID425.tmp
[2025-07-19T22:10:05.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:05.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26] for update
[2025-07-19T22:10:05.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:05.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.1.delta.aac8d111-0713-4e7c-b396-91189bc0f448.TID422.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/1.delta
[2025-07-19T22:10:05.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/1.delta
[2025-07-19T22:10:05.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 422, attempt 0, stage 1.0)
[2025-07-19T22:10:06.000+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.1.delta.943a4eae-f15e-452b-8122-024dceb9e9b6.TID423.tmp
[2025-07-19T22:10:06.000+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO DataWritingSparkTask: Committed partition 18 (task 419, attempt 0, stage 1.0)
[2025-07-19T22:10:06.000+0000] {subprocess.py:93} INFO - 25/07/19 22:10:05 INFO Executor: Finished task 18.0 in stage 1.0 (TID 419). 9288 bytes result sent to driver
[2025-07-19T22:10:06.004+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO SnapshotProducer: Committed snapshot 7578249238753225380 (FastAppend)
[2025-07-19T22:10:06.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 427) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 20 (task 421, attempt 0, stage 1.0)
[2025-07-19T22:10:06.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 419) in 148 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T22:10:06.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 20.0 in stage 1.0 (TID 421). 9272 bytes result sent to driver
[2025-07-19T22:10:06.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 19 (task 420, attempt 0, stage 1.0)
[2025-07-19T22:10:06.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 27.0 in stage 1.0 (TID 427)
[2025-07-19T22:10:06.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 19.0 in stage 1.0 (TID 420). 9308 bytes result sent to driver
[2025-07-19T22:10:06.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 22 (task 422, attempt 0, stage 1.0)
[2025-07-19T22:10:06.015+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 22.0 in stage 1.0 (TID 422). 9295 bytes result sent to driver
[2025-07-19T22:10:06.016+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.1.delta.28c97632-0a30-4100-9d2a-9507474fd818.TID426.tmp
[2025-07-19T22:10:06.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:06.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 428) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 429) (8b44f3d35cfa, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 430) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 28.0 in stage 1.0 (TID 428)
[2025-07-19T22:10:06.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 421) in 150 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T22:10:06.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 420) in 158 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T22:10:06.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 422) in 134 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T22:10:06.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 29.0 in stage 1.0 (TID 429)
[2025-07-19T22:10:06.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 30.0 in stage 1.0 (TID 430)
[2025-07-19T22:10:06.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:06.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45bc26e6
[2025-07-19T22:10:06.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.1.delta.dcc4af25-9e97-4a98-b7cf-512a5dce334d.TID424.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/1.delta
[2025-07-19T22:10:06.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/1.delta
[2025-07-19T22:10:06.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 424, attempt 0, stage 1.0)
[2025-07-19T22:10:06.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27] for update
[2025-07-19T22:10:06.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.1.delta.5664b9f1-4f46-4cc6-989a-94988bf27fbe.TID425.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/1.delta
[2025-07-19T22:10:06.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/1.delta
[2025-07-19T22:10:06.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4822c9d4
[2025-07-19T22:10:06.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29] for update
[2025-07-19T22:10:06.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 425, attempt 0, stage 1.0)
[2025-07-19T22:10:06.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.1.delta.943a4eae-f15e-452b-8122-024dceb9e9b6.TID423.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/1.delta
[2025-07-19T22:10:06.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/1.delta
[2025-07-19T22:10:06.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 423, attempt 0, stage 1.0)
[2025-07-19T22:10:06.051+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.1.delta.b94878ef-5048-45ba-b939-a05ba50ca258.TID427.tmp
[2025-07-19T22:10:06.054+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ccb6b2c
[2025-07-19T22:10:06.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30] for update
[2025-07-19T22:10:06.056+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.1.delta.8915b7bc-9577-4f79-a0fc-df8ff5b95563.TID429.tmp
[2025-07-19T22:10:06.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31166579
[2025-07-19T22:10:06.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28] for update
[2025-07-19T22:10:06.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 24 (task 424, attempt 0, stage 1.0)
[2025-07-19T22:10:06.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.071+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 24.0 in stage 1.0 (TID 424). 9336 bytes result sent to driver
[2025-07-19T22:10:06.074+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Reservations_raw, snapshotId=7578249238753225380, sequenceNumber=78, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.437719416S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=141}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=8080}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=267}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=12194}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=423686}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=24126379}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752962984887, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T22:10:06.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO SparkWrite: Committed in 438 ms
[2025-07-19T22:10:06.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] committed.
[2025-07-19T22:10:06.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 431) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 31.0 in stage 1.0 (TID 431)
[2025-07-19T22:10:06.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 424) in 147 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T22:10:06.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.1.delta.f65f3c57-059c-4235-b502-acd7835a7ce6.TID430.tmp
[2025-07-19T22:10:06.077+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 23 (task 423, attempt 0, stage 1.0)
[2025-07-19T22:10:06.077+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 25 (task 425, attempt 0, stage 1.0)
[2025-07-19T22:10:06.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 25.0 in stage 1.0 (TID 425). 9321 bytes result sent to driver
[2025-07-19T22:10:06.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 432) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.090+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 32.0 in stage 1.0 (TID 432)
[2025-07-19T22:10:06.091+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e5c81e6
[2025-07-19T22:10:06.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 425) in 162 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T22:10:06.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 23.0 in stage 1.0 (TID 423). 9334 bytes result sent to driver
[2025-07-19T22:10:06.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31] for update
[2025-07-19T22:10:06.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 423) in 172 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T22:10:06.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 433) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 33.0 in stage 1.0 (TID 433)
[2025-07-19T22:10:06.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.1.delta.28c97632-0a30-4100-9d2a-9507474fd818.TID426.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/1.delta
[2025-07-19T22:10:06.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/1.delta
[2025-07-19T22:10:06.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 426, attempt 0, stage 1.0)
[2025-07-19T22:10:06.097+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.097+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:06.101+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/commits/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/commits/.0.c0653d24-bce0-4d11-b691-2137fe6ec1d0.tmp
[2025-07-19T22:10:06.102+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.1.delta.7ae2428a-00b1-4626-a205-40af0d8c18a4.TID428.tmp
[2025-07-19T22:10:06.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6126590f
[2025-07-19T22:10:06.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32] for update
[2025-07-19T22:10:06.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.1.delta.94ab1bb3-bd99-4926-9937-9b4e1ba5c590.TID431.tmp
[2025-07-19T22:10:06.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2046249b
[2025-07-19T22:10:06.116+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33] for update
[2025-07-19T22:10:06.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.123+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 26 (task 426, attempt 0, stage 1.0)
[2025-07-19T22:10:06.124+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 26.0 in stage 1.0 (TID 426). 9294 bytes result sent to driver
[2025-07-19T22:10:06.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 426) in 179 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T22:10:06.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 434) (8b44f3d35cfa, executor driver, partition 34, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 34.0 in stage 1.0 (TID 434)
[2025-07-19T22:10:06.129+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.130+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.1.delta.86f9f5da-64b0-42a4-a801-6073a68b14a1.TID432.tmp
[2025-07-19T22:10:06.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.1.delta.8915b7bc-9577-4f79-a0fc-df8ff5b95563.TID429.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/1.delta
[2025-07-19T22:10:06.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/1.delta
[2025-07-19T22:10:06.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 429, attempt 0, stage 1.0)
[2025-07-19T22:10:06.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35841907
[2025-07-19T22:10:06.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34] for update
[2025-07-19T22:10:06.141+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.142+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.1.delta.4a8b44a7-66df-4cb2-a35a-be44ae8009e7.TID433.tmp
[2025-07-19T22:10:06.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.1.delta.b94878ef-5048-45ba-b939-a05ba50ca258.TID427.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/1.delta
[2025-07-19T22:10:06.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/1.delta
[2025-07-19T22:10:06.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 427, attempt 0, stage 1.0)
[2025-07-19T22:10:06.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.1.delta.f65f3c57-059c-4235-b502-acd7835a7ce6.TID430.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/1.delta
[2025-07-19T22:10:06.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/1.delta
[2025-07-19T22:10:06.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 430, attempt 0, stage 1.0)
[2025-07-19T22:10:06.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/commits/.0.c0653d24-bce0-4d11-b691-2137fe6ec1d0.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T22:06:00+00:00/commits/0
[2025-07-19T22:10:06.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 29 (task 429, attempt 0, stage 1.0)
[2025-07-19T22:10:06.165+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 29.0 in stage 1.0 (TID 429). 9289 bytes result sent to driver
[2025-07-19T22:10:06.166+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T22:10:06.170+0000] {subprocess.py:93} INFO -   "id" : "7b068dbd-ce57-48ee-985f-2e8eff7153ac",
[2025-07-19T22:10:06.173+0000] {subprocess.py:93} INFO -   "runId" : "c4540072-4f24-4872-808b-e7ac78480bd8",
[2025-07-19T22:10:06.175+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T22:10:06.175+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T22:09:48.331Z",
[2025-07-19T22:10:06.175+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T22:10:06.176+0000] {subprocess.py:93} INFO -   "numInputRows" : 276,
[2025-07-19T22:10:06.178+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:06.179+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 15.483002356109054,
[2025-07-19T22:10:06.180+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T22:10:06.181+0000] {subprocess.py:93} INFO -     "addBatch" : 16065,
[2025-07-19T22:10:06.181+0000] {subprocess.py:93} INFO -     "commitOffsets" : 87,
[2025-07-19T22:10:06.182+0000] {subprocess.py:93} INFO -     "getBatch" : 22,
[2025-07-19T22:10:06.182+0000] {subprocess.py:93} INFO -     "latestOffset" : 826,
[2025-07-19T22:10:06.182+0000] {subprocess.py:93} INFO -     "queryPlanning" : 645,
[2025-07-19T22:10:06.183+0000] {subprocess.py:93} INFO -     "triggerExecution" : 17825,
[2025-07-19T22:10:06.184+0000] {subprocess.py:93} INFO -     "walCommit" : 154
[2025-07-19T22:10:06.184+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:06.184+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T22:10:06.185+0000] {subprocess.py:93} INFO -     "avg" : "1970-01-01T00:00:00.000Z",
[2025-07-19T22:10:06.185+0000] {subprocess.py:93} INFO -     "max" : "1970-01-01T00:00:00.000Z",
[2025-07-19T22:10:06.185+0000] {subprocess.py:93} INFO -     "min" : "1970-01-01T00:00:00.000Z",
[2025-07-19T22:10:06.186+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T22:10:06.187+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:06.187+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T22:10:06.187+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T22:10:06.188+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 267,
[2025-07-19T22:10:06.189+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 267,
[2025-07-19T22:10:06.192+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 3693,
[2025-07-19T22:10:06.193+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T22:10:06.194+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 212,
[2025-07-19T22:10:06.195+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 15378,
[2025-07-19T22:10:06.203+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 108408,
[2025-07-19T22:10:06.203+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T22:10:06.203+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T22:10:06.203+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T22:10:06.203+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T22:10:06.203+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T22:10:06.203+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 9,
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 79608
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[reservations]]",
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T22:10:06.204+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:06.205+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:06.205+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:06.205+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T22:10:06.205+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T22:10:06.205+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:06.206+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:06.207+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:06.208+0000] {subprocess.py:93} INFO -     "numInputRows" : 276,
[2025-07-19T22:10:06.209+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:06.209+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 15.483002356109054,
[2025-07-19T22:10:06.209+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T22:10:06.210+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T22:10:06.211+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T22:10:06.215+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T22:10:06.216+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:06.216+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:06.217+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T22:10:06.217+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Reservations_raw",
[2025-07-19T22:10:06.217+0000] {subprocess.py:93} INFO -     "numOutputRows" : 267
[2025-07-19T22:10:06.217+0000] {subprocess.py:93} INFO -   }
[2025-07-19T22:10:06.217+0000] {subprocess.py:93} INFO - }
[2025-07-19T22:10:06.217+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 27 (task 427, attempt 0, stage 1.0)
[2025-07-19T22:10:06.217+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.1.delta.2bbca0ed-c458-4d93-b032-506a33375217.TID434.tmp
[2025-07-19T22:10:06.217+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.1.delta.7ae2428a-00b1-4626-a205-40af0d8c18a4.TID428.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/1.delta
[2025-07-19T22:10:06.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/1.delta
[2025-07-19T22:10:06.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 27.0 in stage 1.0 (TID 427). 9306 bytes result sent to driver
[2025-07-19T22:10:06.219+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 435) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.219+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 29.0 in stage 1.0 (TID 429) in 147 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T22:10:06.220+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 35.0 in stage 1.0 (TID 435)
[2025-07-19T22:10:06.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 428, attempt 0, stage 1.0)
[2025-07-19T22:10:06.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 436) (8b44f3d35cfa, executor driver, partition 36, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 36.0 in stage 1.0 (TID 436)
[2025-07-19T22:10:06.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 427) in 175 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T22:10:06.225+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.1.delta.94ab1bb3-bd99-4926-9937-9b4e1ba5c590.TID431.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/1.delta
[2025-07-19T22:10:06.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/1.delta
[2025-07-19T22:10:06.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.232+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T22:10:06.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 431, attempt 0, stage 1.0)
[2025-07-19T22:10:06.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 28 (task 428, attempt 0, stage 1.0)
[2025-07-19T22:10:06.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 28.0 in stage 1.0 (TID 428). 9313 bytes result sent to driver
[2025-07-19T22:10:06.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 30 (task 430, attempt 0, stage 1.0)
[2025-07-19T22:10:06.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 437) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7682090a
[2025-07-19T22:10:06.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35] for update
[2025-07-19T22:10:06.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 30.0 in stage 1.0 (TID 430). 9330 bytes result sent to driver
[2025-07-19T22:10:06.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 438) (8b44f3d35cfa, executor driver, partition 40, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 39.0 in stage 1.0 (TID 437)
[2025-07-19T22:10:06.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 430) in 176 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T22:10:06.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 428) in 178 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T22:10:06.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 40.0 in stage 1.0 (TID 438)
[2025-07-19T22:10:06.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:06.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28dac8a3
[2025-07-19T22:10:06.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 31 (task 431, attempt 0, stage 1.0)
[2025-07-19T22:10:06.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36] for update
[2025-07-19T22:10:06.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 31.0 in stage 1.0 (TID 431). 9279 bytes result sent to driver
[2025-07-19T22:10:06.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 439) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.1.delta.86f9f5da-64b0-42a4-a801-6073a68b14a1.TID432.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/1.delta
[2025-07-19T22:10:06.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/1.delta
[2025-07-19T22:10:06.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 431) in 144 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T22:10:06.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 41.0 in stage 1.0 (TID 439)
[2025-07-19T22:10:06.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 432, attempt 0, stage 1.0)
[2025-07-19T22:10:06.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.1.delta.969a72ae-f741-417d-8203-25948224e664.TID435.tmp
[2025-07-19T22:10:06.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fef5844
[2025-07-19T22:10:06.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39] for update
[2025-07-19T22:10:06.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.1.delta.4a8b44a7-66df-4cb2-a35a-be44ae8009e7.TID433.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/1.delta
[2025-07-19T22:10:06.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/1.delta
[2025-07-19T22:10:06.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 433, attempt 0, stage 1.0)
[2025-07-19T22:10:06.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@696930f9
[2025-07-19T22:10:06.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40] for update
[2025-07-19T22:10:06.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.1.delta.c70eabd1-fbb2-45d9-af92-ae300515e9e8.TID436.tmp
[2025-07-19T22:10:06.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.1.delta.2bbca0ed-c458-4d93-b032-506a33375217.TID434.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/1.delta
[2025-07-19T22:10:06.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/1.delta
[2025-07-19T22:10:06.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 32 (task 432, attempt 0, stage 1.0)
[2025-07-19T22:10:06.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 434, attempt 0, stage 1.0)
[2025-07-19T22:10:06.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 32.0 in stage 1.0 (TID 432). 9293 bytes result sent to driver
[2025-07-19T22:10:06.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 440) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 432) in 153 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T22:10:06.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 42.0 in stage 1.0 (TID 440)
[2025-07-19T22:10:06.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 33 (task 433, attempt 0, stage 1.0)
[2025-07-19T22:10:06.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cb64904
[2025-07-19T22:10:06.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 33.0 in stage 1.0 (TID 433). 9310 bytes result sent to driver
[2025-07-19T22:10:06.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 441) (8b44f3d35cfa, executor driver, partition 44, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 44.0 in stage 1.0 (TID 441)
[2025-07-19T22:10:06.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41] for update
[2025-07-19T22:10:06.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 433) in 163 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T22:10:06.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.271+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 34 (task 434, attempt 0, stage 1.0)
[2025-07-19T22:10:06.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40d04c0d
[2025-07-19T22:10:06.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 34.0 in stage 1.0 (TID 434). 9293 bytes result sent to driver
[2025-07-19T22:10:06.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 442) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 46.0 in stage 1.0 (TID 442)
[2025-07-19T22:10:06.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 434) in 136 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T22:10:06.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42] for update
[2025-07-19T22:10:06.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.1.delta.21d781ab-46b7-4dab-9cfb-67adbd84e3d8.TID438.tmp
[2025-07-19T22:10:06.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.1.delta.aa440d93-30cf-4063-bcbd-c2b52d3e6f3f.TID437.tmp
[2025-07-19T22:10:06.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2079683c
[2025-07-19T22:10:06.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.1.delta.b7b11769-e2bf-44e4-81ee-991e751057b3.TID439.tmp
[2025-07-19T22:10:06.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44] for update
[2025-07-19T22:10:06.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.1.delta.b398effb-1e67-4d31-9ac8-62e7d5644090.TID440.tmp
[2025-07-19T22:10:06.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.1.delta.969a72ae-f741-417d-8203-25948224e664.TID435.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/1.delta
[2025-07-19T22:10:06.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/1.delta
[2025-07-19T22:10:06.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 435, attempt 0, stage 1.0)
[2025-07-19T22:10:06.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69c7bc16
[2025-07-19T22:10:06.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46] for update
[2025-07-19T22:10:06.290+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.291+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.1.delta.34d76117-f6eb-4575-83ff-d7a2b83db595.TID441.tmp
[2025-07-19T22:10:06.297+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 35 (task 435, attempt 0, stage 1.0)
[2025-07-19T22:10:06.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.1.delta.c70eabd1-fbb2-45d9-af92-ae300515e9e8.TID436.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/1.delta
[2025-07-19T22:10:06.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/1.delta
[2025-07-19T22:10:06.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 436, attempt 0, stage 1.0)
[2025-07-19T22:10:06.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.1.delta.fcba56d1-6928-4308-8971-150bb265d9e6.TID442.tmp
[2025-07-19T22:10:06.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 35.0 in stage 1.0 (TID 435). 9354 bytes result sent to driver
[2025-07-19T22:10:06.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 443) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 47.0 in stage 1.0 (TID 443)
[2025-07-19T22:10:06.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 435) in 142 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T22:10:06.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.311+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.1.delta.21d781ab-46b7-4dab-9cfb-67adbd84e3d8.TID438.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/1.delta
[2025-07-19T22:10:06.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/1.delta
[2025-07-19T22:10:06.317+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45f9eb97
[2025-07-19T22:10:06.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 438, attempt 0, stage 1.0)
[2025-07-19T22:10:06.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47] for update
[2025-07-19T22:10:06.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 36 (task 436, attempt 0, stage 1.0)
[2025-07-19T22:10:06.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 36.0 in stage 1.0 (TID 436). 9273 bytes result sent to driver
[2025-07-19T22:10:06.328+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 444) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 48.0 in stage 1.0 (TID 444)
[2025-07-19T22:10:06.330+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.1.delta.b7b11769-e2bf-44e4-81ee-991e751057b3.TID439.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/1.delta
[2025-07-19T22:10:06.331+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 436) in 154 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T22:10:06.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/1.delta
[2025-07-19T22:10:06.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.1.delta.aa440d93-30cf-4063-bcbd-c2b52d3e6f3f.TID437.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/1.delta
[2025-07-19T22:10:06.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/1.delta
[2025-07-19T22:10:06.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 439, attempt 0, stage 1.0)
[2025-07-19T22:10:06.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 437, attempt 0, stage 1.0)
[2025-07-19T22:10:06.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c43b668
[2025-07-19T22:10:06.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48] for update
[2025-07-19T22:10:06.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.1.delta.b398effb-1e67-4d31-9ac8-62e7d5644090.TID440.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/1.delta
[2025-07-19T22:10:06.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/1.delta
[2025-07-19T22:10:06.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 440, attempt 0, stage 1.0)
[2025-07-19T22:10:06.341+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.1.delta.56e0f1ef-2980-4117-99ae-2301ca14ab86.TID443.tmp
[2025-07-19T22:10:06.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 40 (task 438, attempt 0, stage 1.0)
[2025-07-19T22:10:06.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 40.0 in stage 1.0 (TID 438). 9304 bytes result sent to driver
[2025-07-19T22:10:06.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 445) (8b44f3d35cfa, executor driver, partition 49, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.1.delta.34d76117-f6eb-4575-83ff-d7a2b83db595.TID441.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/1.delta
[2025-07-19T22:10:06.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/1.delta
[2025-07-19T22:10:06.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 438) in 154 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T22:10:06.351+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 49.0 in stage 1.0 (TID 445)
[2025-07-19T22:10:06.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 441, attempt 0, stage 1.0)
[2025-07-19T22:10:06.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.354+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.355+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 39 (task 437, attempt 0, stage 1.0)
[2025-07-19T22:10:06.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 41 (task 439, attempt 0, stage 1.0)
[2025-07-19T22:10:06.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 39.0 in stage 1.0 (TID 437). 9282 bytes result sent to driver
[2025-07-19T22:10:06.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.1.delta.fcba56d1-6928-4308-8971-150bb265d9e6.TID442.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/1.delta
[2025-07-19T22:10:06.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/1.delta
[2025-07-19T22:10:06.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 446) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.1.delta.08d175fb-39c4-4453-b8c9-453a221186da.TID444.tmp
[2025-07-19T22:10:06.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 39.0 in stage 1.0 (TID 437) in 163 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T22:10:06.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 442, attempt 0, stage 1.0)
[2025-07-19T22:10:06.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 41.0 in stage 1.0 (TID 439). 9289 bytes result sent to driver
[2025-07-19T22:10:06.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 51.0 in stage 1.0 (TID 446)
[2025-07-19T22:10:06.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 54.0 in stage 1.0 (TID 447) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 54.0 in stage 1.0 (TID 447)
[2025-07-19T22:10:06.371+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 439) in 146 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T22:10:06.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 42 (task 440, attempt 0, stage 1.0)
[2025-07-19T22:10:06.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 42.0 in stage 1.0 (TID 440). 9295 bytes result sent to driver
[2025-07-19T22:10:06.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 55.0 in stage 1.0 (TID 448) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 440) in 121 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T22:10:06.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 55.0 in stage 1.0 (TID 448)
[2025-07-19T22:10:06.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f92ea66
[2025-07-19T22:10:06.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.377+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49] for update
[2025-07-19T22:10:06.377+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 44 (task 441, attempt 0, stage 1.0)
[2025-07-19T22:10:06.378+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 44.0 in stage 1.0 (TID 441). 9307 bytes result sent to driver
[2025-07-19T22:10:06.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 57.0 in stage 1.0 (TID 449) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 57.0 in stage 1.0 (TID 449)
[2025-07-19T22:10:06.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 441) in 119 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T22:10:06.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@253dbacb
[2025-07-19T22:10:06.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55] for update
[2025-07-19T22:10:06.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 46 (task 442, attempt 0, stage 1.0)
[2025-07-19T22:10:06.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 46.0 in stage 1.0 (TID 442). 9287 bytes result sent to driver
[2025-07-19T22:10:06.385+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 58.0 in stage 1.0 (TID 450) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.385+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 58.0 in stage 1.0 (TID 450)
[2025-07-19T22:10:06.387+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 442) in 121 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T22:10:06.388+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.1.delta.c4e29b6d-ea02-49b2-ae13-2ff0808dd6d0.TID445.tmp
[2025-07-19T22:10:06.388+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37c75a5a
[2025-07-19T22:10:06.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51] for update
[2025-07-19T22:10:06.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.396+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.1.delta.56e0f1ef-2980-4117-99ae-2301ca14ab86.TID443.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/1.delta
[2025-07-19T22:10:06.397+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/1.delta
[2025-07-19T22:10:06.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 443, attempt 0, stage 1.0)
[2025-07-19T22:10:06.400+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e6244e8
[2025-07-19T22:10:06.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.402+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58] for update
[2025-07-19T22:10:06.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.408+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.1.delta.fc0d8e56-b0ee-42d5-88c1-c547ec78a272.TID446.tmp
[2025-07-19T22:10:06.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.1.delta.8f2f42e6-e689-45e4-874e-442c74283f3a.TID448.tmp
[2025-07-19T22:10:06.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5da80bbc
[2025-07-19T22:10:06.414+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.415+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54] for update
[2025-07-19T22:10:06.419+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.420+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.1.delta.08d175fb-39c4-4453-b8c9-453a221186da.TID444.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/1.delta
[2025-07-19T22:10:06.420+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/1.delta
[2025-07-19T22:10:06.421+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.1.delta.60b62883-ded0-400b-947f-374c2832a30f.TID450.tmp
[2025-07-19T22:10:06.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 47 (task 443, attempt 0, stage 1.0)
[2025-07-19T22:10:06.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 47.0 in stage 1.0 (TID 443). 9318 bytes result sent to driver
[2025-07-19T22:10:06.423+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 60.0 in stage 1.0 (TID 451) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.424+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 60.0 in stage 1.0 (TID 451)
[2025-07-19T22:10:06.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.1.delta.488a4580-7ed3-4175-98b4-252228c6e14b.TID447.tmp
[2025-07-19T22:10:06.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 444, attempt 0, stage 1.0)
[2025-07-19T22:10:06.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 443) in 131 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T22:10:06.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d25d9d8
[2025-07-19T22:10:06.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57] for update
[2025-07-19T22:10:06.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.1.delta.c4e29b6d-ea02-49b2-ae13-2ff0808dd6d0.TID445.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/1.delta
[2025-07-19T22:10:06.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/1.delta
[2025-07-19T22:10:06.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 445, attempt 0, stage 1.0)
[2025-07-19T22:10:06.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7127fc41
[2025-07-19T22:10:06.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60] for update
[2025-07-19T22:10:06.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.1.delta.fc0d8e56-b0ee-42d5-88c1-c547ec78a272.TID446.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/1.delta
[2025-07-19T22:10:06.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/1.delta
[2025-07-19T22:10:06.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.1.delta.b1fc0f57-3c17-4a62-8362-6c9f56e3b9e8.TID449.tmp
[2025-07-19T22:10:06.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 48 (task 444, attempt 0, stage 1.0)
[2025-07-19T22:10:06.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 446, attempt 0, stage 1.0)
[2025-07-19T22:10:06.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 48.0 in stage 1.0 (TID 444). 9309 bytes result sent to driver
[2025-07-19T22:10:06.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 62.0 in stage 1.0 (TID 452) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 62.0 in stage 1.0 (TID 452)
[2025-07-19T22:10:06.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 444) in 137 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T22:10:06.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.1.delta.8f2f42e6-e689-45e4-874e-442c74283f3a.TID448.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/1.delta
[2025-07-19T22:10:06.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/1.delta
[2025-07-19T22:10:06.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 448, attempt 0, stage 1.0)
[2025-07-19T22:10:06.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 49 (task 445, attempt 0, stage 1.0)
[2025-07-19T22:10:06.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:06.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 49.0 in stage 1.0 (TID 445). 9312 bytes result sent to driver
[2025-07-19T22:10:06.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 63.0 in stage 1.0 (TID 453) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.473+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.1.delta.8a0a221d-c4ee-42c0-b9b7-35822af6135d.TID451.tmp
[2025-07-19T22:10:06.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 63.0 in stage 1.0 (TID 453)
[2025-07-19T22:10:06.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 445) in 126 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T22:10:06.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.1.delta.60b62883-ded0-400b-947f-374c2832a30f.TID450.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/1.delta
[2025-07-19T22:10:06.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/1.delta
[2025-07-19T22:10:06.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f31c178
[2025-07-19T22:10:06.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62] for update
[2025-07-19T22:10:06.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 450, attempt 0, stage 1.0)
[2025-07-19T22:10:06.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 51 (task 446, attempt 0, stage 1.0)
[2025-07-19T22:10:06.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.1.delta.488a4580-7ed3-4175-98b4-252228c6e14b.TID447.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/1.delta
[2025-07-19T22:10:06.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/1.delta
[2025-07-19T22:10:06.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 447, attempt 0, stage 1.0)
[2025-07-19T22:10:06.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 51.0 in stage 1.0 (TID 446). 9355 bytes result sent to driver
[2025-07-19T22:10:06.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 64.0 in stage 1.0 (TID 454) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 446) in 141 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T22:10:06.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 64.0 in stage 1.0 (TID 454)
[2025-07-19T22:10:06.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56592f95
[2025-07-19T22:10:06.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 55 (task 448, attempt 0, stage 1.0)
[2025-07-19T22:10:06.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 55.0 in stage 1.0 (TID 448). 9284 bytes result sent to driver
[2025-07-19T22:10:06.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63] for update
[2025-07-19T22:10:06.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.1.delta.40b0df6d-74fc-46df-a0c9-1351ec9deaa0.TID452.tmp
[2025-07-19T22:10:06.505+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 66.0 in stage 1.0 (TID 455) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 66.0 in stage 1.0 (TID 455)
[2025-07-19T22:10:06.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 55.0 in stage 1.0 (TID 448) in 140 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T22:10:06.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.507+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 58 (task 450, attempt 0, stage 1.0)
[2025-07-19T22:10:06.510+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 58.0 in stage 1.0 (TID 450). 9289 bytes result sent to driver
[2025-07-19T22:10:06.511+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 67.0 in stage 1.0 (TID 456) (8b44f3d35cfa, executor driver, partition 67, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 67.0 in stage 1.0 (TID 456)
[2025-07-19T22:10:06.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 58.0 in stage 1.0 (TID 450) in 129 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T22:10:06.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 54 (task 447, attempt 0, stage 1.0)
[2025-07-19T22:10:06.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66712018
[2025-07-19T22:10:06.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 54.0 in stage 1.0 (TID 447). 9302 bytes result sent to driver
[2025-07-19T22:10:06.515+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64] for update
[2025-07-19T22:10:06.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 68.0 in stage 1.0 (TID 457) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 54.0 in stage 1.0 (TID 447) in 159 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T22:10:06.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.1.delta.5563cbca-2324-4312-876a-aa0b82e9816b.TID453.tmp
[2025-07-19T22:10:06.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 68.0 in stage 1.0 (TID 457)
[2025-07-19T22:10:06.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8ee1e59
[2025-07-19T22:10:06.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.523+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66] for update
[2025-07-19T22:10:06.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.1.delta.b1fc0f57-3c17-4a62-8362-6c9f56e3b9e8.TID449.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/1.delta
[2025-07-19T22:10:06.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/1.delta
[2025-07-19T22:10:06.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.1.delta.47af9c2b-fda2-4468-9bfa-0c4fece5afb3.TID454.tmp
[2025-07-19T22:10:06.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 449, attempt 0, stage 1.0)
[2025-07-19T22:10:06.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d2399a1
[2025-07-19T22:10:06.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.535+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68] for update
[2025-07-19T22:10:06.535+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.1.delta.8a0a221d-c4ee-42c0-b9b7-35822af6135d.TID451.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/1.delta
[2025-07-19T22:10:06.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/1.delta
[2025-07-19T22:10:06.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 451, attempt 0, stage 1.0)
[2025-07-19T22:10:06.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34aada73
[2025-07-19T22:10:06.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67] for update
[2025-07-19T22:10:06.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.1.delta.40b0df6d-74fc-46df-a0c9-1351ec9deaa0.TID452.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/1.delta
[2025-07-19T22:10:06.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/1.delta
[2025-07-19T22:10:06.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.1.delta.1a8ebec0-a6e8-4c1c-9fb1-b5fe0d3c8f96.TID455.tmp
[2025-07-19T22:10:06.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 57 (task 449, attempt 0, stage 1.0)
[2025-07-19T22:10:06.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 57.0 in stage 1.0 (TID 449). 9287 bytes result sent to driver
[2025-07-19T22:10:06.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 71.0 in stage 1.0 (TID 458) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.553+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 452, attempt 0, stage 1.0)
[2025-07-19T22:10:06.553+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 71.0 in stage 1.0 (TID 458)
[2025-07-19T22:10:06.553+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.1.delta.46ec8510-7229-49b1-a964-ec464ad33f3b.TID456.tmp
[2025-07-19T22:10:06.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 57.0 in stage 1.0 (TID 449) in 184 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T22:10:06.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.1.delta.c166f24c-a517-4a2f-b735-7e8722934c9d.TID457.tmp
[2025-07-19T22:10:06.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fcfcd51
[2025-07-19T22:10:06.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71] for update
[2025-07-19T22:10:06.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 60 (task 451, attempt 0, stage 1.0)
[2025-07-19T22:10:06.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 60.0 in stage 1.0 (TID 451). 9338 bytes result sent to driver
[2025-07-19T22:10:06.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 73.0 in stage 1.0 (TID 459) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 60.0 in stage 1.0 (TID 451) in 160 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T22:10:06.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 73.0 in stage 1.0 (TID 459)
[2025-07-19T22:10:06.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 62 (task 452, attempt 0, stage 1.0)
[2025-07-19T22:10:06.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.1.delta.47af9c2b-fda2-4468-9bfa-0c4fece5afb3.TID454.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/1.delta
[2025-07-19T22:10:06.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/1.delta
[2025-07-19T22:10:06.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 454, attempt 0, stage 1.0)
[2025-07-19T22:10:06.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 62.0 in stage 1.0 (TID 452). 9338 bytes result sent to driver
[2025-07-19T22:10:06.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 74.0 in stage 1.0 (TID 460) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.1.delta.5563cbca-2324-4312-876a-aa0b82e9816b.TID453.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/1.delta
[2025-07-19T22:10:06.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/1.delta
[2025-07-19T22:10:06.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:06.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 453, attempt 0, stage 1.0)
[2025-07-19T22:10:06.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 74.0 in stage 1.0 (TID 460)
[2025-07-19T22:10:06.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 62.0 in stage 1.0 (TID 452) in 133 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T22:10:06.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:06.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.1.delta.49309eeb-ff30-47fe-9121-0fd44b1fd662.TID458.tmp
[2025-07-19T22:10:06.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@238ab916
[2025-07-19T22:10:06.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73] for update
[2025-07-19T22:10:06.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.1.delta.c166f24c-a517-4a2f-b735-7e8722934c9d.TID457.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/1.delta
[2025-07-19T22:10:06.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/1.delta
[2025-07-19T22:10:06.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 457, attempt 0, stage 1.0)
[2025-07-19T22:10:06.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cd39f79
[2025-07-19T22:10:06.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 64 (task 454, attempt 0, stage 1.0)
[2025-07-19T22:10:06.621+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74] for update
[2025-07-19T22:10:06.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.1.delta.1a8ebec0-a6e8-4c1c-9fb1-b5fe0d3c8f96.TID455.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/1.delta
[2025-07-19T22:10:06.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/1.delta
[2025-07-19T22:10:06.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 64.0 in stage 1.0 (TID 454). 9313 bytes result sent to driver
[2025-07-19T22:10:06.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 455, attempt 0, stage 1.0)
[2025-07-19T22:10:06.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.1.delta.46ec8510-7229-49b1-a964-ec464ad33f3b.TID456.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/1.delta
[2025-07-19T22:10:06.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/1.delta
[2025-07-19T22:10:06.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 75.0 in stage 1.0 (TID 461) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 456, attempt 0, stage 1.0)
[2025-07-19T22:10:06.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 75.0 in stage 1.0 (TID 461)
[2025-07-19T22:10:06.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 63 (task 453, attempt 0, stage 1.0)
[2025-07-19T22:10:06.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 64.0 in stage 1.0 (TID 454) in 127 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T22:10:06.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 63.0 in stage 1.0 (TID 453). 9291 bytes result sent to driver
[2025-07-19T22:10:06.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 76.0 in stage 1.0 (TID 462) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c67ad80
[2025-07-19T22:10:06.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 76.0 in stage 1.0 (TID 462)
[2025-07-19T22:10:06.637+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.1.delta.fafd33b1-b513-403a-b085-dfd349918a83.TID460.tmp
[2025-07-19T22:10:06.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75] for update
[2025-07-19T22:10:06.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:06.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 63.0 in stage 1.0 (TID 453) in 170 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T22:10:06.648+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.1.delta.007c7874-cc3a-4dab-888b-b0bafc3d8a97.TID459.tmp
[2025-07-19T22:10:06.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43256554
[2025-07-19T22:10:06.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 68 (task 457, attempt 0, stage 1.0)
[2025-07-19T22:10:06.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 68.0 in stage 1.0 (TID 457). 9309 bytes result sent to driver
[2025-07-19T22:10:06.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 77.0 in stage 1.0 (TID 463) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.655+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 66 (task 455, attempt 0, stage 1.0)
[2025-07-19T22:10:06.655+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 66.0 in stage 1.0 (TID 455). 9313 bytes result sent to driver
[2025-07-19T22:10:06.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.1.delta.0e46deb7-1f9e-4d62-8610-40d437710f8a.TID461.tmp
[2025-07-19T22:10:06.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 67 (task 456, attempt 0, stage 1.0)
[2025-07-19T22:10:06.660+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 67.0 in stage 1.0 (TID 456). 9347 bytes result sent to driver
[2025-07-19T22:10:06.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 77.0 in stage 1.0 (TID 463)
[2025-07-19T22:10:06.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 68.0 in stage 1.0 (TID 457) in 141 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T22:10:06.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76] for update
[2025-07-19T22:10:06.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 79.0 in stage 1.0 (TID 464) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 80.0 in stage 1.0 (TID 465) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 79.0 in stage 1.0 (TID 464)
[2025-07-19T22:10:06.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 80.0 in stage 1.0 (TID 465)
[2025-07-19T22:10:06.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 66.0 in stage 1.0 (TID 455) in 163 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T22:10:06.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 67.0 in stage 1.0 (TID 456) in 153 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T22:10:06.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:06.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.1.delta.49309eeb-ff30-47fe-9121-0fd44b1fd662.TID458.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/1.delta
[2025-07-19T22:10:06.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/1.delta
[2025-07-19T22:10:06.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 458, attempt 0, stage 1.0)
[2025-07-19T22:10:06.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60dbd689
[2025-07-19T22:10:06.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.685+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77] for update
[2025-07-19T22:10:06.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.1.delta.3033d455-a95f-4659-96be-16a9e27651da.TID462.tmp
[2025-07-19T22:10:06.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.1.delta.fafd33b1-b513-403a-b085-dfd349918a83.TID460.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/1.delta
[2025-07-19T22:10:06.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/1.delta
[2025-07-19T22:10:06.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 460, attempt 0, stage 1.0)
[2025-07-19T22:10:06.698+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17d0c942
[2025-07-19T22:10:06.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79] for update
[2025-07-19T22:10:06.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 71 (task 458, attempt 0, stage 1.0)
[2025-07-19T22:10:06.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 71.0 in stage 1.0 (TID 458). 9301 bytes result sent to driver
[2025-07-19T22:10:06.704+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 81.0 in stage 1.0 (TID 466) (8b44f3d35cfa, executor driver, partition 81, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 71.0 in stage 1.0 (TID 458) in 151 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T22:10:06.706+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.706+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.1.delta.24fb8a7e-9641-4a56-abfb-843eaac60606.TID463.tmp
[2025-07-19T22:10:06.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 81.0 in stage 1.0 (TID 466)
[2025-07-19T22:10:06.710+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.711+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a2f444b
[2025-07-19T22:10:06.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80] for update
[2025-07-19T22:10:06.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.1.delta.007c7874-cc3a-4dab-888b-b0bafc3d8a97.TID459.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/1.delta
[2025-07-19T22:10:06.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/1.delta
[2025-07-19T22:10:06.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.1.delta.aebb0a82-4a7e-481c-be91-6f3be215677b.TID464.tmp
[2025-07-19T22:10:06.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 459, attempt 0, stage 1.0)
[2025-07-19T22:10:06.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.1.delta.0e46deb7-1f9e-4d62-8610-40d437710f8a.TID461.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/1.delta
[2025-07-19T22:10:06.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/1.delta
[2025-07-19T22:10:06.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 461, attempt 0, stage 1.0)
[2025-07-19T22:10:06.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d8ebaa1
[2025-07-19T22:10:06.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81] for update
[2025-07-19T22:10:06.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 74 (task 460, attempt 0, stage 1.0)
[2025-07-19T22:10:06.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 74.0 in stage 1.0 (TID 460). 9305 bytes result sent to driver
[2025-07-19T22:10:06.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 82.0 in stage 1.0 (TID 467) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 82.0 in stage 1.0 (TID 467)
[2025-07-19T22:10:06.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 74.0 in stage 1.0 (TID 460) in 142 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T22:10:06.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.1.delta.3033d455-a95f-4659-96be-16a9e27651da.TID462.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/1.delta
[2025-07-19T22:10:06.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/1.delta
[2025-07-19T22:10:06.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 462, attempt 0, stage 1.0)
[2025-07-19T22:10:06.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.1.delta.5b8449cb-c87a-46b3-9742-441265a308d8.TID465.tmp
[2025-07-19T22:10:06.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.744+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.1.delta.1920de30-ca64-4d30-8801-f64efb832d6a.TID466.tmp
[2025-07-19T22:10:06.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e247c6e
[2025-07-19T22:10:06.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82] for update
[2025-07-19T22:10:06.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 75 (task 461, attempt 0, stage 1.0)
[2025-07-19T22:10:06.772+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 75.0 in stage 1.0 (TID 461). 9295 bytes result sent to driver
[2025-07-19T22:10:06.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 83.0 in stage 1.0 (TID 468) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 75.0 in stage 1.0 (TID 461) in 143 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T22:10:06.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 83.0 in stage 1.0 (TID 468)
[2025-07-19T22:10:06.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 73 (task 459, attempt 0, stage 1.0)
[2025-07-19T22:10:06.781+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 73.0 in stage 1.0 (TID 459). 9313 bytes result sent to driver
[2025-07-19T22:10:06.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:06.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 86.0 in stage 1.0 (TID 469) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 73.0 in stage 1.0 (TID 459) in 192 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T22:10:06.784+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 86.0 in stage 1.0 (TID 469)
[2025-07-19T22:10:06.784+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 76 (task 462, attempt 0, stage 1.0)
[2025-07-19T22:10:06.789+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 76.0 in stage 1.0 (TID 462). 9310 bytes result sent to driver
[2025-07-19T22:10:06.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 87.0 in stage 1.0 (TID 470) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.792+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 87.0 in stage 1.0 (TID 470)
[2025-07-19T22:10:06.793+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 76.0 in stage 1.0 (TID 462) in 149 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T22:10:06.794+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.1.delta.6d689332-01a8-4b7a-ba76-9142a733cd42.TID467.tmp
[2025-07-19T22:10:06.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63b23c66
[2025-07-19T22:10:06.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.798+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.798+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83] for update
[2025-07-19T22:10:06.800+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.1.delta.24fb8a7e-9641-4a56-abfb-843eaac60606.TID463.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/1.delta
[2025-07-19T22:10:06.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/1.delta
[2025-07-19T22:10:06.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 463, attempt 0, stage 1.0)
[2025-07-19T22:10:06.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.1.delta.aebb0a82-4a7e-481c-be91-6f3be215677b.TID464.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/1.delta
[2025-07-19T22:10:06.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/1.delta
[2025-07-19T22:10:06.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 464, attempt 0, stage 1.0)
[2025-07-19T22:10:06.812+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3baeb673
[2025-07-19T22:10:06.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87] for update
[2025-07-19T22:10:06.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26a94c93
[2025-07-19T22:10:06.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86] for update
[2025-07-19T22:10:06.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.821+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.1.delta.5b8449cb-c87a-46b3-9742-441265a308d8.TID465.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/1.delta
[2025-07-19T22:10:06.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/1.delta
[2025-07-19T22:10:06.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.1.delta.0c66b395-5e8c-4945-b68a-4e9133a25d68.TID468.tmp
[2025-07-19T22:10:06.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 465, attempt 0, stage 1.0)
[2025-07-19T22:10:06.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.1.delta.1920de30-ca64-4d30-8801-f64efb832d6a.TID466.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/1.delta
[2025-07-19T22:10:06.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/1.delta
[2025-07-19T22:10:06.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 466, attempt 0, stage 1.0)
[2025-07-19T22:10:06.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 77 (task 463, attempt 0, stage 1.0)
[2025-07-19T22:10:06.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 77.0 in stage 1.0 (TID 463). 9293 bytes result sent to driver
[2025-07-19T22:10:06.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 88.0 in stage 1.0 (TID 471) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 88.0 in stage 1.0 (TID 471)
[2025-07-19T22:10:06.830+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 77.0 in stage 1.0 (TID 463) in 176 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T22:10:06.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 79 (task 464, attempt 0, stage 1.0)
[2025-07-19T22:10:06.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.1.delta.2c95d037-3a60-4f2b-ae74-b9aa01e5f807.TID470.tmp
[2025-07-19T22:10:06.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 79.0 in stage 1.0 (TID 464). 9296 bytes result sent to driver
[2025-07-19T22:10:06.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 89.0 in stage 1.0 (TID 472) (8b44f3d35cfa, executor driver, partition 89, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 89.0 in stage 1.0 (TID 472)
[2025-07-19T22:10:06.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 79.0 in stage 1.0 (TID 464) in 174 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T22:10:06.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.1.delta.c3175bff-7312-4bb8-bcb7-f09c2055a80d.TID469.tmp
[2025-07-19T22:10:06.840+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@823fb89
[2025-07-19T22:10:06.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88] for update
[2025-07-19T22:10:06.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 80 (task 465, attempt 0, stage 1.0)
[2025-07-19T22:10:06.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 80.0 in stage 1.0 (TID 465). 9320 bytes result sent to driver
[2025-07-19T22:10:06.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 90.0 in stage 1.0 (TID 473) (8b44f3d35cfa, executor driver, partition 90, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 90.0 in stage 1.0 (TID 473)
[2025-07-19T22:10:06.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 80.0 in stage 1.0 (TID 465) in 187 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T22:10:06.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3388fd4e
[2025-07-19T22:10:06.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89] for update
[2025-07-19T22:10:06.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.1.delta.6d689332-01a8-4b7a-ba76-9142a733cd42.TID467.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/1.delta
[2025-07-19T22:10:06.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/1.delta
[2025-07-19T22:10:06.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 467, attempt 0, stage 1.0)
[2025-07-19T22:10:06.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 81 (task 466, attempt 0, stage 1.0)
[2025-07-19T22:10:06.864+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 81.0 in stage 1.0 (TID 466). 9332 bytes result sent to driver
[2025-07-19T22:10:06.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.1.delta.0be6ac73-9ad9-4515-9707-70d65e5c47ab.TID471.tmp
[2025-07-19T22:10:06.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 91.0 in stage 1.0 (TID 474) (8b44f3d35cfa, executor driver, partition 91, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71c4dc2
[2025-07-19T22:10:06.870+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.872+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90] for update
[2025-07-19T22:10:06.873+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 91.0 in stage 1.0 (TID 474)
[2025-07-19T22:10:06.874+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 81.0 in stage 1.0 (TID 466) in 169 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T22:10:06.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.1.delta.e0e8287f-9760-4142-95c8-e7d7bf32a727.TID472.tmp
[2025-07-19T22:10:06.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 82 (task 467, attempt 0, stage 1.0)
[2025-07-19T22:10:06.885+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 82.0 in stage 1.0 (TID 467). 9309 bytes result sent to driver
[2025-07-19T22:10:06.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63be4762
[2025-07-19T22:10:06.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 92.0 in stage 1.0 (TID 475) (8b44f3d35cfa, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.890+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.890+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91] for update
[2025-07-19T22:10:06.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 92.0 in stage 1.0 (TID 475)
[2025-07-19T22:10:06.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 82.0 in stage 1.0 (TID 467) in 154 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T22:10:06.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.1.delta.b0f5c88c-9e48-4830-a105-54adb32a9f55.TID473.tmp
[2025-07-19T22:10:06.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.1.delta.c3175bff-7312-4bb8-bcb7-f09c2055a80d.TID469.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/1.delta
[2025-07-19T22:10:06.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/1.delta
[2025-07-19T22:10:06.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.1.delta.2c95d037-3a60-4f2b-ae74-b9aa01e5f807.TID470.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/1.delta
[2025-07-19T22:10:06.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/1.delta
[2025-07-19T22:10:06.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 469, attempt 0, stage 1.0)
[2025-07-19T22:10:06.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 470, attempt 0, stage 1.0)
[2025-07-19T22:10:06.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.1.delta.0c66b395-5e8c-4945-b68a-4e9133a25d68.TID468.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/1.delta
[2025-07-19T22:10:06.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/1.delta
[2025-07-19T22:10:06.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.1.delta.22435897-a361-4efc-aac6-74cae41f66f1.TID474.tmp
[2025-07-19T22:10:06.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56f4fa77
[2025-07-19T22:10:06.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 468, attempt 0, stage 1.0)
[2025-07-19T22:10:06.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92] for update
[2025-07-19T22:10:06.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.1.delta.0be6ac73-9ad9-4515-9707-70d65e5c47ab.TID471.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/1.delta
[2025-07-19T22:10:06.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/1.delta
[2025-07-19T22:10:06.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 471, attempt 0, stage 1.0)
[2025-07-19T22:10:06.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.1.delta.85fcb522-b94b-4e67-85b5-3fba3e91ddcb.TID475.tmp
[2025-07-19T22:10:06.930+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 86 (task 469, attempt 0, stage 1.0)
[2025-07-19T22:10:06.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 87 (task 470, attempt 0, stage 1.0)
[2025-07-19T22:10:06.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 87.0 in stage 1.0 (TID 470). 9311 bytes result sent to driver
[2025-07-19T22:10:06.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.1.delta.e0e8287f-9760-4142-95c8-e7d7bf32a727.TID472.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/1.delta
[2025-07-19T22:10:06.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/1.delta
[2025-07-19T22:10:06.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 86.0 in stage 1.0 (TID 469). 9316 bytes result sent to driver
[2025-07-19T22:10:06.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 93.0 in stage 1.0 (TID 476) (8b44f3d35cfa, executor driver, partition 93, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 96.0 in stage 1.0 (TID 477) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 96.0 in stage 1.0 (TID 477)
[2025-07-19T22:10:06.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 93.0 in stage 1.0 (TID 476)
[2025-07-19T22:10:06.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 472, attempt 0, stage 1.0)
[2025-07-19T22:10:06.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 87.0 in stage 1.0 (TID 470) in 158 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T22:10:06.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 86.0 in stage 1.0 (TID 469) in 163 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T22:10:06.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.949+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f5781b8
[2025-07-19T22:10:06.950+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.950+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96] for update
[2025-07-19T22:10:06.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.955+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.1.delta.b0f5c88c-9e48-4830-a105-54adb32a9f55.TID473.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/1.delta
[2025-07-19T22:10:06.955+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/1.delta
[2025-07-19T22:10:06.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 473, attempt 0, stage 1.0)
[2025-07-19T22:10:06.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 88 (task 471, attempt 0, stage 1.0)
[2025-07-19T22:10:06.959+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 88.0 in stage 1.0 (TID 471). 9305 bytes result sent to driver
[2025-07-19T22:10:06.959+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 97.0 in stage 1.0 (TID 478) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.960+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 97.0 in stage 1.0 (TID 478)
[2025-07-19T22:10:06.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.1.delta.22435897-a361-4efc-aac6-74cae41f66f1.TID474.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/1.delta
[2025-07-19T22:10:06.966+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/1.delta
[2025-07-19T22:10:06.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 88.0 in stage 1.0 (TID 471) in 134 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T22:10:06.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 89 (task 472, attempt 0, stage 1.0)
[2025-07-19T22:10:06.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 89.0 in stage 1.0 (TID 472). 9295 bytes result sent to driver
[2025-07-19T22:10:06.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 474, attempt 0, stage 1.0)
[2025-07-19T22:10:06.971+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b4cacc0
[2025-07-19T22:10:06.971+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 99.0 in stage 1.0 (TID 479) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 99.0 in stage 1.0 (TID 479)
[2025-07-19T22:10:06.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93] for update
[2025-07-19T22:10:06.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:06.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.1.delta.ab149664-86a5-4ec3-b1d5-a56b0f429efb.TID477.tmp
[2025-07-19T22:10:06.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 89.0 in stage 1.0 (TID 472) in 138 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T22:10:06.977+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 90 (task 473, attempt 0, stage 1.0)
[2025-07-19T22:10:06.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 90.0 in stage 1.0 (TID 473). 9302 bytes result sent to driver
[2025-07-19T22:10:06.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 100.0 in stage 1.0 (TID 480) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:06.980+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 100.0 in stage 1.0 (TID 480)
[2025-07-19T22:10:06.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56df7deb
[2025-07-19T22:10:06.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:06.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97] for update
[2025-07-19T22:10:06.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:06.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:06.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.1.delta.b78db1b6-078c-41a3-927a-86c38eb55272.TID476.tmp
[2025-07-19T22:10:06.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 91 (task 474, attempt 0, stage 1.0)
[2025-07-19T22:10:06.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 91.0 in stage 1.0 (TID 474). 9250 bytes result sent to driver
[2025-07-19T22:10:06.988+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Committed partition 83 (task 468, attempt 0, stage 1.0)
[2025-07-19T22:10:06.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5032666e
[2025-07-19T22:10:06.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 90.0 in stage 1.0 (TID 473) in 133 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T22:10:07.004+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Finished task 83.0 in stage 1.0 (TID 468). 9352 bytes result sent to driver
[2025-07-19T22:10:07.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 102.0 in stage 1.0 (TID 481) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Starting task 103.0 in stage 1.0 (TID 482) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 103.0 in stage 1.0 (TID 482)
[2025-07-19T22:10:07.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 83.0 in stage 1.0 (TID 468) in 244 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T22:10:07.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.1.delta.85fcb522-b94b-4e67-85b5-3fba3e91ddcb.TID475.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/1.delta
[2025-07-19T22:10:07.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/1.delta
[2025-07-19T22:10:07.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99] for update
[2025-07-19T22:10:07.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 475, attempt 0, stage 1.0)
[2025-07-19T22:10:07.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO TaskSetManager: Finished task 91.0 in stage 1.0 (TID 474) in 135 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T22:10:07.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:06 INFO Executor: Running task 102.0 in stage 1.0 (TID 481)
[2025-07-19T22:10:07.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:07.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 92 (task 475, attempt 0, stage 1.0)
[2025-07-19T22:10:07.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.1.delta.98c899c0-1959-4360-ba0b-edcf95ac62b5.TID479.tmp
[2025-07-19T22:10:07.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 92.0 in stage 1.0 (TID 475). 9282 bytes result sent to driver
[2025-07-19T22:10:07.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@404875b1
[2025-07-19T22:10:07.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100] for update
[2025-07-19T22:10:07.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 104.0 in stage 1.0 (TID 483) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 104.0 in stage 1.0 (TID 483)
[2025-07-19T22:10:07.030+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.030+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 92.0 in stage 1.0 (TID 475) in 145 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T22:10:07.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.035+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a70acdb
[2025-07-19T22:10:07.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.037+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103] for update
[2025-07-19T22:10:07.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.1.delta.4af04255-42d6-4561-a76a-0fcf092ff8dd.TID478.tmp
[2025-07-19T22:10:07.043+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.1.delta.b78db1b6-078c-41a3-927a-86c38eb55272.TID476.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/1.delta
[2025-07-19T22:10:07.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/1.delta
[2025-07-19T22:10:07.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 476, attempt 0, stage 1.0)
[2025-07-19T22:10:07.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.1.delta.8b0a417e-7b83-4c10-944f-f08c4202620d.TID480.tmp
[2025-07-19T22:10:07.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ab312fe
[2025-07-19T22:10:07.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102] for update
[2025-07-19T22:10:07.054+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.1.delta.dab67e42-a8e0-452b-940c-e87d0c06b2c9.TID482.tmp
[2025-07-19T22:10:07.054+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e37c372
[2025-07-19T22:10:07.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104] for update
[2025-07-19T22:10:07.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 93 (task 476, attempt 0, stage 1.0)
[2025-07-19T22:10:07.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 93.0 in stage 1.0 (TID 476). 9270 bytes result sent to driver
[2025-07-19T22:10:07.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 105.0 in stage 1.0 (TID 484) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.1.delta.3f55fbf3-e259-4a49-be89-2039a011cbef.TID481.tmp
[2025-07-19T22:10:07.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 93.0 in stage 1.0 (TID 476) in 137 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T22:10:07.074+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 105.0 in stage 1.0 (TID 484)
[2025-07-19T22:10:07.077+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.1.delta.b1598693-ca59-471b-8b85-9e83b6aa064a.TID483.tmp
[2025-07-19T22:10:07.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.1.delta.ab149664-86a5-4ec3-b1d5-a56b0f429efb.TID477.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/1.delta
[2025-07-19T22:10:07.085+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/1.delta
[2025-07-19T22:10:07.086+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 477, attempt 0, stage 1.0)
[2025-07-19T22:10:07.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6287e178
[2025-07-19T22:10:07.090+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105] for update
[2025-07-19T22:10:07.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.098+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.1.delta.98c899c0-1959-4360-ba0b-edcf95ac62b5.TID479.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/1.delta
[2025-07-19T22:10:07.099+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/1.delta
[2025-07-19T22:10:07.102+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 479, attempt 0, stage 1.0)
[2025-07-19T22:10:07.105+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.1.delta.4af04255-42d6-4561-a76a-0fcf092ff8dd.TID478.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/1.delta
[2025-07-19T22:10:07.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/1.delta
[2025-07-19T22:10:07.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 478, attempt 0, stage 1.0)
[2025-07-19T22:10:07.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 96 (task 477, attempt 0, stage 1.0)
[2025-07-19T22:10:07.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 96.0 in stage 1.0 (TID 477). 9324 bytes result sent to driver
[2025-07-19T22:10:07.116+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 106.0 in stage 1.0 (TID 485) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 96.0 in stage 1.0 (TID 477) in 176 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T22:10:07.123+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 106.0 in stage 1.0 (TID 485)
[2025-07-19T22:10:07.123+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.1.delta.8b0a417e-7b83-4c10-944f-f08c4202620d.TID480.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/1.delta
[2025-07-19T22:10:07.124+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/1.delta
[2025-07-19T22:10:07.125+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 480, attempt 0, stage 1.0)
[2025-07-19T22:10:07.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.1.delta.dab67e42-a8e0-452b-940c-e87d0c06b2c9.TID482.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/1.delta
[2025-07-19T22:10:07.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/1.delta
[2025-07-19T22:10:07.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:07.129+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.1.delta.58bdebc3-c834-44b9-ae75-a52d8f069cb9.TID484.tmp
[2025-07-19T22:10:07.131+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 482, attempt 0, stage 1.0)
[2025-07-19T22:10:07.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.1.delta.b1598693-ca59-471b-8b85-9e83b6aa064a.TID483.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/1.delta
[2025-07-19T22:10:07.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/1.delta
[2025-07-19T22:10:07.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 99 (task 479, attempt 0, stage 1.0)
[2025-07-19T22:10:07.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 99.0 in stage 1.0 (TID 479). 9321 bytes result sent to driver
[2025-07-19T22:10:07.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 107.0 in stage 1.0 (TID 486) (8b44f3d35cfa, executor driver, partition 107, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.141+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 483, attempt 0, stage 1.0)
[2025-07-19T22:10:07.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 99.0 in stage 1.0 (TID 479) in 174 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T22:10:07.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 97 (task 478, attempt 0, stage 1.0)
[2025-07-19T22:10:07.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 107.0 in stage 1.0 (TID 486)
[2025-07-19T22:10:07.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.1.delta.3f55fbf3-e259-4a49-be89-2039a011cbef.TID481.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/1.delta
[2025-07-19T22:10:07.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/1.delta
[2025-07-19T22:10:07.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@331085b5
[2025-07-19T22:10:07.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106] for update
[2025-07-19T22:10:07.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 481, attempt 0, stage 1.0)
[2025-07-19T22:10:07.152+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.153+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 97.0 in stage 1.0 (TID 478). 9316 bytes result sent to driver
[2025-07-19T22:10:07.153+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 109.0 in stage 1.0 (TID 487) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 97.0 in stage 1.0 (TID 478) in 188 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T22:10:07.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 109.0 in stage 1.0 (TID 487)
[2025-07-19T22:10:07.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:07.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28cb0265
[2025-07-19T22:10:07.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.160+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107] for update
[2025-07-19T22:10:07.160+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.174+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 100 (task 480, attempt 0, stage 1.0)
[2025-07-19T22:10:07.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 100.0 in stage 1.0 (TID 480). 9294 bytes result sent to driver
[2025-07-19T22:10:07.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.1.delta.2d67a6a4-c733-4425-856b-9438588734bd.TID485.tmp
[2025-07-19T22:10:07.185+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 110.0 in stage 1.0 (TID 488) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.185+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 103 (task 482, attempt 0, stage 1.0)
[2025-07-19T22:10:07.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 110.0 in stage 1.0 (TID 488)
[2025-07-19T22:10:07.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 100.0 in stage 1.0 (TID 480) in 203 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T22:10:07.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 104 (task 483, attempt 0, stage 1.0)
[2025-07-19T22:10:07.190+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 104.0 in stage 1.0 (TID 483). 9285 bytes result sent to driver
[2025-07-19T22:10:07.192+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 103.0 in stage 1.0 (TID 482). 9304 bytes result sent to driver
[2025-07-19T22:10:07.192+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 111.0 in stage 1.0 (TID 489) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 112.0 in stage 1.0 (TID 490) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.194+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 111.0 in stage 1.0 (TID 489)
[2025-07-19T22:10:07.194+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 102 (task 481, attempt 0, stage 1.0)
[2025-07-19T22:10:07.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 103.0 in stage 1.0 (TID 482) in 192 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T22:10:07.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 112.0 in stage 1.0 (TID 490)
[2025-07-19T22:10:07.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 104.0 in stage 1.0 (TID 483) in 160 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T22:10:07.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 102.0 in stage 1.0 (TID 481). 9287 bytes result sent to driver
[2025-07-19T22:10:07.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 113.0 in stage 1.0 (TID 491) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.1.delta.0df23ca0-bdaf-40c9-935b-402211991daa.TID486.tmp
[2025-07-19T22:10:07.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 102.0 in stage 1.0 (TID 481) in 195 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T22:10:07.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65dcc25e
[2025-07-19T22:10:07.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 113.0 in stage 1.0 (TID 491)
[2025-07-19T22:10:07.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109] for update
[2025-07-19T22:10:07.206+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c209fb
[2025-07-19T22:10:07.209+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.209+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.1.delta.58bdebc3-c834-44b9-ae75-a52d8f069cb9.TID484.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/1.delta
[2025-07-19T22:10:07.209+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/1.delta
[2025-07-19T22:10:07.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 484, attempt 0, stage 1.0)
[2025-07-19T22:10:07.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111] for update
[2025-07-19T22:10:07.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.215+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.1.delta.48f2ba5a-e409-4ea5-8c47-5586439a51ba.TID487.tmp
[2025-07-19T22:10:07.219+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19f55ed9
[2025-07-19T22:10:07.220+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112] for update
[2025-07-19T22:10:07.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.225+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.1.delta.5bb812ee-979f-4bed-b5e7-5b56088ea0a2.TID489.tmp
[2025-07-19T22:10:07.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 105 (task 484, attempt 0, stage 1.0)
[2025-07-19T22:10:07.232+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 105.0 in stage 1.0 (TID 484). 9295 bytes result sent to driver
[2025-07-19T22:10:07.232+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 114.0 in stage 1.0 (TID 492) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 105.0 in stage 1.0 (TID 484) in 160 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T22:10:07.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 114.0 in stage 1.0 (TID 492)
[2025-07-19T22:10:07.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7425167a
[2025-07-19T22:10:07.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110] for update
[2025-07-19T22:10:07.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.1.delta.a2511081-3d34-41be-b13f-75c615a2cf39.TID490.tmp
[2025-07-19T22:10:07.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.1.delta.2d67a6a4-c733-4425-856b-9438588734bd.TID485.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/1.delta
[2025-07-19T22:10:07.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/1.delta
[2025-07-19T22:10:07.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 485, attempt 0, stage 1.0)
[2025-07-19T22:10:07.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bd5caad
[2025-07-19T22:10:07.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114] for update
[2025-07-19T22:10:07.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.1.delta.0df23ca0-bdaf-40c9-935b-402211991daa.TID486.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/1.delta
[2025-07-19T22:10:07.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/1.delta
[2025-07-19T22:10:07.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 486, attempt 0, stage 1.0)
[2025-07-19T22:10:07.258+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.1.delta.e3588eb7-f8ea-437d-bccd-53284b5c33f8.TID488.tmp
[2025-07-19T22:10:07.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 106 (task 485, attempt 0, stage 1.0)
[2025-07-19T22:10:07.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@775fc40b
[2025-07-19T22:10:07.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.272+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113] for update
[2025-07-19T22:10:07.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 106.0 in stage 1.0 (TID 485). 9305 bytes result sent to driver
[2025-07-19T22:10:07.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 116.0 in stage 1.0 (TID 493) (8b44f3d35cfa, executor driver, partition 116, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 106.0 in stage 1.0 (TID 485) in 158 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T22:10:07.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 116.0 in stage 1.0 (TID 493)
[2025-07-19T22:10:07.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.1.delta.71d73918-b8f7-4d7b-be50-d185404bc46f.TID492.tmp
[2025-07-19T22:10:07.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 107 (task 486, attempt 0, stage 1.0)
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 107.0 in stage 1.0 (TID 486). 9286 bytes result sent to driver
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 117.0 in stage 1.0 (TID 494) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43e2889d
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 117.0 in stage 1.0 (TID 494)
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 107.0 in stage 1.0 (TID 486) in 143 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116] for update
[2025-07-19T22:10:07.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.297+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.1.delta.1080b51d-6797-4acb-a4a7-9b96ff4b2b25.TID491.tmp
[2025-07-19T22:10:07.297+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.1.delta.15177e10-2ada-471e-90d6-35e6376ac30c.TID493.tmp
[2025-07-19T22:10:07.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@449b4730
[2025-07-19T22:10:07.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.313+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117] for update
[2025-07-19T22:10:07.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.1.delta.48f2ba5a-e409-4ea5-8c47-5586439a51ba.TID487.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/1.delta
[2025-07-19T22:10:07.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/1.delta
[2025-07-19T22:10:07.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 487, attempt 0, stage 1.0)
[2025-07-19T22:10:07.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.1.delta.5bb812ee-979f-4bed-b5e7-5b56088ea0a2.TID489.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/1.delta
[2025-07-19T22:10:07.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/1.delta
[2025-07-19T22:10:07.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 489, attempt 0, stage 1.0)
[2025-07-19T22:10:07.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.1.delta.a2511081-3d34-41be-b13f-75c615a2cf39.TID490.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/1.delta
[2025-07-19T22:10:07.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/1.delta
[2025-07-19T22:10:07.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 490, attempt 0, stage 1.0)
[2025-07-19T22:10:07.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.1.delta.c2611e18-6d5c-448f-82a6-2c760dd8c1e3.TID494.tmp
[2025-07-19T22:10:07.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 109 (task 487, attempt 0, stage 1.0)
[2025-07-19T22:10:07.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 109.0 in stage 1.0 (TID 487). 9307 bytes result sent to driver
[2025-07-19T22:10:07.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.1.delta.e3588eb7-f8ea-437d-bccd-53284b5c33f8.TID488.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/1.delta
[2025-07-19T22:10:07.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/1.delta
[2025-07-19T22:10:07.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 118.0 in stage 1.0 (TID 495) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 488, attempt 0, stage 1.0)
[2025-07-19T22:10:07.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 109.0 in stage 1.0 (TID 487) in 189 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T22:10:07.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 118.0 in stage 1.0 (TID 495)
[2025-07-19T22:10:07.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 111 (task 489, attempt 0, stage 1.0)
[2025-07-19T22:10:07.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.1.delta.71d73918-b8f7-4d7b-be50-d185404bc46f.TID492.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/1.delta
[2025-07-19T22:10:07.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/1.delta
[2025-07-19T22:10:07.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 111.0 in stage 1.0 (TID 489). 9311 bytes result sent to driver
[2025-07-19T22:10:07.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9478865
[2025-07-19T22:10:07.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 492, attempt 0, stage 1.0)
[2025-07-19T22:10:07.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.350+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 112 (task 490, attempt 0, stage 1.0)
[2025-07-19T22:10:07.350+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118] for update
[2025-07-19T22:10:07.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 119.0 in stage 1.0 (TID 496) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 112.0 in stage 1.0 (TID 490). 9300 bytes result sent to driver
[2025-07-19T22:10:07.354+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 120.0 in stage 1.0 (TID 497) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 112.0 in stage 1.0 (TID 490) in 166 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T22:10:07.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 111.0 in stage 1.0 (TID 489) in 167 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T22:10:07.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 119.0 in stage 1.0 (TID 496)
[2025-07-19T22:10:07.359+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.1.delta.1080b51d-6797-4acb-a4a7-9b96ff4b2b25.TID491.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/1.delta
[2025-07-19T22:10:07.360+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/1.delta
[2025-07-19T22:10:07.361+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 120.0 in stage 1.0 (TID 497)
[2025-07-19T22:10:07.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 491, attempt 0, stage 1.0)
[2025-07-19T22:10:07.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.1.delta.15177e10-2ada-471e-90d6-35e6376ac30c.TID493.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/1.delta
[2025-07-19T22:10:07.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/1.delta
[2025-07-19T22:10:07.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 493, attempt 0, stage 1.0)
[2025-07-19T22:10:07.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32276c00
[2025-07-19T22:10:07.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 110 (task 488, attempt 0, stage 1.0)
[2025-07-19T22:10:07.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120] for update
[2025-07-19T22:10:07.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 110.0 in stage 1.0 (TID 488). 9306 bytes result sent to driver
[2025-07-19T22:10:07.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.371+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 123.0 in stage 1.0 (TID 498) (8b44f3d35cfa, executor driver, partition 123, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 110.0 in stage 1.0 (TID 488) in 190 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T22:10:07.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:07.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 123.0 in stage 1.0 (TID 498)
[2025-07-19T22:10:07.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:07.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61da1da0
[2025-07-19T22:10:07.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.1.delta.23263ff9-4c3e-42b5-80d1-1ab9cd9e358d.TID495.tmp
[2025-07-19T22:10:07.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.1.delta.c2611e18-6d5c-448f-82a6-2c760dd8c1e3.TID494.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/1.delta
[2025-07-19T22:10:07.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/1.delta
[2025-07-19T22:10:07.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.385+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119] for update
[2025-07-19T22:10:07.386+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 113 (task 491, attempt 0, stage 1.0)
[2025-07-19T22:10:07.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 494, attempt 0, stage 1.0)
[2025-07-19T22:10:07.392+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 113.0 in stage 1.0 (TID 491). 9285 bytes result sent to driver
[2025-07-19T22:10:07.393+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 116 (task 493, attempt 0, stage 1.0)
[2025-07-19T22:10:07.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.1.delta.f047a55c-98a0-47e2-8fcf-038f7c6c4b2b.TID497.tmp
[2025-07-19T22:10:07.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 116.0 in stage 1.0 (TID 493). 9322 bytes result sent to driver
[2025-07-19T22:10:07.396+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 124.0 in stage 1.0 (TID 499) (8b44f3d35cfa, executor driver, partition 124, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.396+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.397+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 125.0 in stage 1.0 (TID 500) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 113.0 in stage 1.0 (TID 491) in 197 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T22:10:07.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 125.0 in stage 1.0 (TID 500)
[2025-07-19T22:10:07.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 124.0 in stage 1.0 (TID 499)
[2025-07-19T22:10:07.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a42ef78
[2025-07-19T22:10:07.400+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 116.0 in stage 1.0 (TID 493) in 126 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T22:10:07.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.402+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123] for update
[2025-07-19T22:10:07.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T22:10:07.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 117 (task 494, attempt 0, stage 1.0)
[2025-07-19T22:10:07.406+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.1.delta.26238566-710a-45ee-8e65-eb1f4c90e064.TID496.tmp
[2025-07-19T22:10:07.407+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 117.0 in stage 1.0 (TID 494). 9366 bytes result sent to driver
[2025-07-19T22:10:07.408+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 126.0 in stage 1.0 (TID 501) (8b44f3d35cfa, executor driver, partition 126, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.409+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c1762fa
[2025-07-19T22:10:07.410+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.410+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 117.0 in stage 1.0 (TID 494) in 132 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T22:10:07.411+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125] for update
[2025-07-19T22:10:07.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 126.0 in stage 1.0 (TID 501)
[2025-07-19T22:10:07.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 114 (task 492, attempt 0, stage 1.0)
[2025-07-19T22:10:07.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.1.delta.71d970d7-2a66-4dbb-89bb-960d2b9b1f7c.TID498.tmp
[2025-07-19T22:10:07.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 114.0 in stage 1.0 (TID 492). 9366 bytes result sent to driver
[2025-07-19T22:10:07.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 127.0 in stage 1.0 (TID 502) (8b44f3d35cfa, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 114.0 in stage 1.0 (TID 492) in 194 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T22:10:07.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 127.0 in stage 1.0 (TID 502)
[2025-07-19T22:10:07.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37bad06e
[2025-07-19T22:10:07.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:07.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:07.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124] for update
[2025-07-19T22:10:07.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.1.delta.4edb1b19-a3d6-4ee0-9f6f-baa9aeabd03f.TID500.tmp
[2025-07-19T22:10:07.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@137f198f
[2025-07-19T22:10:07.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127] for update
[2025-07-19T22:10:07.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54499bfc
[2025-07-19T22:10:07.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.1.delta.f047a55c-98a0-47e2-8fcf-038f7c6c4b2b.TID497.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/1.delta
[2025-07-19T22:10:07.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/1.delta
[2025-07-19T22:10:07.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.1.delta.23263ff9-4c3e-42b5-80d1-1ab9cd9e358d.TID495.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/1.delta
[2025-07-19T22:10:07.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/1.delta
[2025-07-19T22:10:07.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 497, attempt 0, stage 1.0)
[2025-07-19T22:10:07.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 495, attempt 0, stage 1.0)
[2025-07-19T22:10:07.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126] for update
[2025-07-19T22:10:07.450+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.1.delta.a3066c2f-5677-43a2-86c1-344abcf6ef1b.TID499.tmp
[2025-07-19T22:10:07.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.1.delta.6ac348b4-f250-4e79-ad41-90f0dda17299.TID502.tmp
[2025-07-19T22:10:07.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.1.delta.26238566-710a-45ee-8e65-eb1f4c90e064.TID496.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/1.delta
[2025-07-19T22:10:07.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/1.delta
[2025-07-19T22:10:07.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 496, attempt 0, stage 1.0)
[2025-07-19T22:10:07.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.1.delta.74b8e0e9-ce3f-422e-b4a7-85d1e855d5a6.TID501.tmp
[2025-07-19T22:10:07.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 120 (task 497, attempt 0, stage 1.0)
[2025-07-19T22:10:07.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 120.0 in stage 1.0 (TID 497). 9295 bytes result sent to driver
[2025-07-19T22:10:07.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 120.0 in stage 1.0 (TID 497) in 124 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T22:10:07.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 128.0 in stage 1.0 (TID 503) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 128.0 in stage 1.0 (TID 503)
[2025-07-19T22:10:07.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 118 (task 495, attempt 0, stage 1.0)
[2025-07-19T22:10:07.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 118.0 in stage 1.0 (TID 495). 9289 bytes result sent to driver
[2025-07-19T22:10:07.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.1.delta.71d970d7-2a66-4dbb-89bb-960d2b9b1f7c.TID498.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/1.delta
[2025-07-19T22:10:07.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/1.delta
[2025-07-19T22:10:07.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 130.0 in stage 1.0 (TID 504) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 498, attempt 0, stage 1.0)
[2025-07-19T22:10:07.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 118.0 in stage 1.0 (TID 495) in 152 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T22:10:07.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 130.0 in stage 1.0 (TID 504)
[2025-07-19T22:10:07.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 119 (task 496, attempt 0, stage 1.0)
[2025-07-19T22:10:07.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 119.0 in stage 1.0 (TID 496). 9287 bytes result sent to driver
[2025-07-19T22:10:07.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 131.0 in stage 1.0 (TID 505) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 119.0 in stage 1.0 (TID 496) in 139 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T22:10:07.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 131.0 in stage 1.0 (TID 505)
[2025-07-19T22:10:07.507+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:07.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7de9a8fb
[2025-07-19T22:10:07.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128] for update
[2025-07-19T22:10:07.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.1.delta.4edb1b19-a3d6-4ee0-9f6f-baa9aeabd03f.TID500.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/1.delta
[2025-07-19T22:10:07.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/1.delta
[2025-07-19T22:10:07.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 500, attempt 0, stage 1.0)
[2025-07-19T22:10:07.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f2c648a
[2025-07-19T22:10:07.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 123 (task 498, attempt 0, stage 1.0)
[2025-07-19T22:10:07.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 123.0 in stage 1.0 (TID 498). 9295 bytes result sent to driver
[2025-07-19T22:10:07.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131] for update
[2025-07-19T22:10:07.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.1.delta.44c026b0-ef3f-42c0-8e1c-ad8224fc721b.TID503.tmp
[2025-07-19T22:10:07.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 134.0 in stage 1.0 (TID 506) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 123.0 in stage 1.0 (TID 498) in 147 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T22:10:07.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 134.0 in stage 1.0 (TID 506)
[2025-07-19T22:10:07.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@530c16fc
[2025-07-19T22:10:07.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.523+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130] for update
[2025-07-19T22:10:07.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 125 (task 500, attempt 0, stage 1.0)
[2025-07-19T22:10:07.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.1.delta.a3066c2f-5677-43a2-86c1-344abcf6ef1b.TID499.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/1.delta
[2025-07-19T22:10:07.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/1.delta
[2025-07-19T22:10:07.530+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 499, attempt 0, stage 1.0)
[2025-07-19T22:10:07.534+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 125.0 in stage 1.0 (TID 500). 9336 bytes result sent to driver
[2025-07-19T22:10:07.535+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.1.delta.74b8e0e9-ce3f-422e-b4a7-85d1e855d5a6.TID501.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/1.delta
[2025-07-19T22:10:07.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/1.delta
[2025-07-19T22:10:07.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 135.0 in stage 1.0 (TID 507) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 501, attempt 0, stage 1.0)
[2025-07-19T22:10:07.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 135.0 in stage 1.0 (TID 507)
[2025-07-19T22:10:07.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 125.0 in stage 1.0 (TID 500) in 146 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T22:10:07.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:07.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.1.delta.ad17e1cc-da40-42d5-bdb0-1b9b7257fdfe.TID505.tmp
[2025-07-19T22:10:07.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49b48087
[2025-07-19T22:10:07.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134] for update
[2025-07-19T22:10:07.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.1.delta.6ac348b4-f250-4e79-ad41-90f0dda17299.TID502.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/1.delta
[2025-07-19T22:10:07.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/1.delta
[2025-07-19T22:10:07.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 502, attempt 0, stage 1.0)
[2025-07-19T22:10:07.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 124 (task 499, attempt 0, stage 1.0)
[2025-07-19T22:10:07.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d2c99e6
[2025-07-19T22:10:07.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 124.0 in stage 1.0 (TID 499). 9315 bytes result sent to driver
[2025-07-19T22:10:07.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 136.0 in stage 1.0 (TID 508) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135] for update
[2025-07-19T22:10:07.556+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 124.0 in stage 1.0 (TID 499) in 168 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T22:10:07.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 126 (task 501, attempt 0, stage 1.0)
[2025-07-19T22:10:07.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 126.0 in stage 1.0 (TID 501). 9300 bytes result sent to driver
[2025-07-19T22:10:07.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 137.0 in stage 1.0 (TID 509) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 126.0 in stage 1.0 (TID 501) in 149 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T22:10:07.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 137.0 in stage 1.0 (TID 509)
[2025-07-19T22:10:07.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 136.0 in stage 1.0 (TID 508)
[2025-07-19T22:10:07.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.1.delta.92833ed9-8dc2-4f16-a8a5-d9d3608725f8.TID504.tmp
[2025-07-19T22:10:07.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 127 (task 502, attempt 0, stage 1.0)
[2025-07-19T22:10:07.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 127.0 in stage 1.0 (TID 502). 9286 bytes result sent to driver
[2025-07-19T22:10:07.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.1.delta.a804b4f3-b0e3-4c14-90cf-3a37906f4304.TID506.tmp
[2025-07-19T22:10:07.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 138.0 in stage 1.0 (TID 510) (8b44f3d35cfa, executor driver, partition 138, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 127.0 in stage 1.0 (TID 502) in 146 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T22:10:07.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 138.0 in stage 1.0 (TID 510)
[2025-07-19T22:10:07.571+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@417b12e8
[2025-07-19T22:10:07.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136] for update
[2025-07-19T22:10:07.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.1.delta.33c5a35a-f043-4dd8-b310-53ad29a814ed.TID507.tmp
[2025-07-19T22:10:07.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1448850d
[2025-07-19T22:10:07.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137] for update
[2025-07-19T22:10:07.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.1.delta.96d3f269-acac-43ce-b734-4f9f2878dc30.TID508.tmp
[2025-07-19T22:10:07.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.1.delta.44c026b0-ef3f-42c0-8e1c-ad8224fc721b.TID503.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/1.delta
[2025-07-19T22:10:07.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/1.delta
[2025-07-19T22:10:07.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 503, attempt 0, stage 1.0)
[2025-07-19T22:10:07.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.1.delta.ad17e1cc-da40-42d5-bdb0-1b9b7257fdfe.TID505.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/1.delta
[2025-07-19T22:10:07.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/1.delta
[2025-07-19T22:10:07.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 505, attempt 0, stage 1.0)
[2025-07-19T22:10:07.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b32d955
[2025-07-19T22:10:07.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138] for update
[2025-07-19T22:10:07.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.1.delta.cec6a5c3-51af-4956-85c3-731d43838c19.TID509.tmp
[2025-07-19T22:10:07.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 128 (task 503, attempt 0, stage 1.0)
[2025-07-19T22:10:07.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 128.0 in stage 1.0 (TID 503). 9289 bytes result sent to driver
[2025-07-19T22:10:07.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 140.0 in stage 1.0 (TID 511) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 140.0 in stage 1.0 (TID 511)
[2025-07-19T22:10:07.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 128.0 in stage 1.0 (TID 503) in 142 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T22:10:07.619+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 131 (task 505, attempt 0, stage 1.0)
[2025-07-19T22:10:07.620+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 131.0 in stage 1.0 (TID 505). 9295 bytes result sent to driver
[2025-07-19T22:10:07.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:07.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 141.0 in stage 1.0 (TID 512) (8b44f3d35cfa, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.1.delta.b9f4040e-4832-4eac-843e-8005728f1e91.TID510.tmp
[2025-07-19T22:10:07.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.1.delta.92833ed9-8dc2-4f16-a8a5-d9d3608725f8.TID504.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/1.delta
[2025-07-19T22:10:07.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/1.delta
[2025-07-19T22:10:07.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 504, attempt 0, stage 1.0)
[2025-07-19T22:10:07.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 131.0 in stage 1.0 (TID 505) in 138 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T22:10:07.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 141.0 in stage 1.0 (TID 512)
[2025-07-19T22:10:07.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.1.delta.33c5a35a-f043-4dd8-b310-53ad29a814ed.TID507.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/1.delta
[2025-07-19T22:10:07.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/1.delta
[2025-07-19T22:10:07.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.1.delta.a804b4f3-b0e3-4c14-90cf-3a37906f4304.TID506.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/1.delta
[2025-07-19T22:10:07.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/1.delta
[2025-07-19T22:10:07.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a8595d8
[2025-07-19T22:10:07.638+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 507, attempt 0, stage 1.0)
[2025-07-19T22:10:07.638+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 506, attempt 0, stage 1.0)
[2025-07-19T22:10:07.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140] for update
[2025-07-19T22:10:07.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.640+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.645+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 130 (task 504, attempt 0, stage 1.0)
[2025-07-19T22:10:07.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.1.delta.b45a3740-ff71-4ed6-afab-a5abb293b67c.TID511.tmp
[2025-07-19T22:10:07.648+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@303a6ec8
[2025-07-19T22:10:07.650+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.1.delta.96d3f269-acac-43ce-b734-4f9f2878dc30.TID508.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/1.delta
[2025-07-19T22:10:07.650+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/1.delta
[2025-07-19T22:10:07.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 508, attempt 0, stage 1.0)
[2025-07-19T22:10:07.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141] for update
[2025-07-19T22:10:07.661+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 130.0 in stage 1.0 (TID 504). 9359 bytes result sent to driver
[2025-07-19T22:10:07.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 142.0 in stage 1.0 (TID 513) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 130.0 in stage 1.0 (TID 504) in 180 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T22:10:07.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 142.0 in stage 1.0 (TID 513)
[2025-07-19T22:10:07.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 134 (task 506, attempt 0, stage 1.0)
[2025-07-19T22:10:07.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 134.0 in stage 1.0 (TID 506). 9291 bytes result sent to driver
[2025-07-19T22:10:07.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 135 (task 507, attempt 0, stage 1.0)
[2025-07-19T22:10:07.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 135.0 in stage 1.0 (TID 507). 9304 bytes result sent to driver
[2025-07-19T22:10:07.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 143.0 in stage 1.0 (TID 514) (8b44f3d35cfa, executor driver, partition 143, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 144.0 in stage 1.0 (TID 515) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 134.0 in stage 1.0 (TID 506) in 158 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T22:10:07.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 144.0 in stage 1.0 (TID 515)
[2025-07-19T22:10:07.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 143.0 in stage 1.0 (TID 514)
[2025-07-19T22:10:07.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 135.0 in stage 1.0 (TID 507) in 142 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T22:10:07.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14281579
[2025-07-19T22:10:07.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142] for update
[2025-07-19T22:10:07.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.1.delta.cec6a5c3-51af-4956-85c3-731d43838c19.TID509.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/1.delta
[2025-07-19T22:10:07.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/1.delta
[2025-07-19T22:10:07.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 509, attempt 0, stage 1.0)
[2025-07-19T22:10:07.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 136 (task 508, attempt 0, stage 1.0)
[2025-07-19T22:10:07.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 136.0 in stage 1.0 (TID 508). 9306 bytes result sent to driver
[2025-07-19T22:10:07.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.1.delta.b9f4040e-4832-4eac-843e-8005728f1e91.TID510.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/1.delta
[2025-07-19T22:10:07.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/1.delta
[2025-07-19T22:10:07.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 510, attempt 0, stage 1.0)
[2025-07-19T22:10:07.685+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fc83d4
[2025-07-19T22:10:07.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.1.delta.af5ccacd-fb56-44ef-bb04-dd14dc8d8fe3.TID512.tmp
[2025-07-19T22:10:07.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 145.0 in stage 1.0 (TID 516) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144] for update
[2025-07-19T22:10:07.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 145.0 in stage 1.0 (TID 516)
[2025-07-19T22:10:07.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 136.0 in stage 1.0 (TID 508) in 134 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T22:10:07.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.1.delta.51f1d02c-c736-4398-a167-df782877de24.TID513.tmp
[2025-07-19T22:10:07.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70b1cc6f
[2025-07-19T22:10:07.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:07.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143] for update
[2025-07-19T22:10:07.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.1.delta.e4321626-5142-4b23-9787-2965cd4a1ef3.TID515.tmp
[2025-07-19T22:10:07.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 137 (task 509, attempt 0, stage 1.0)
[2025-07-19T22:10:07.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 137.0 in stage 1.0 (TID 509). 9302 bytes result sent to driver
[2025-07-19T22:10:07.704+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 147.0 in stage 1.0 (TID 517) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.704+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 137.0 in stage 1.0 (TID 509) in 148 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T22:10:07.704+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.1.delta.b45a3740-ff71-4ed6-afab-a5abb293b67c.TID511.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/1.delta
[2025-07-19T22:10:07.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/1.delta
[2025-07-19T22:10:07.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 147.0 in stage 1.0 (TID 517)
[2025-07-19T22:10:07.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 511, attempt 0, stage 1.0)
[2025-07-19T22:10:07.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@430fa6c3
[2025-07-19T22:10:07.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145] for update
[2025-07-19T22:10:07.709+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.710+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.1.delta.f9732257-280e-427e-b47a-20f9531cf2c3.TID514.tmp
[2025-07-19T22:10:07.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 138 (task 510, attempt 0, stage 1.0)
[2025-07-19T22:10:07.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 138.0 in stage 1.0 (TID 510). 9300 bytes result sent to driver
[2025-07-19T22:10:07.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 148.0 in stage 1.0 (TID 518) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 138.0 in stage 1.0 (TID 510) in 153 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T22:10:07.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7099dcb9
[2025-07-19T22:10:07.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 148.0 in stage 1.0 (TID 518)
[2025-07-19T22:10:07.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147] for update
[2025-07-19T22:10:07.728+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 140 (task 511, attempt 0, stage 1.0)
[2025-07-19T22:10:07.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:07.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 140.0 in stage 1.0 (TID 511). 9270 bytes result sent to driver
[2025-07-19T22:10:07.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.1.delta.8dc56f5b-902a-42a0-ad06-9bd038cf3af7.TID516.tmp
[2025-07-19T22:10:07.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 149.0 in stage 1.0 (TID 519) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 149.0 in stage 1.0 (TID 519)
[2025-07-19T22:10:07.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 140.0 in stage 1.0 (TID 511) in 118 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T22:10:07.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51f6aade
[2025-07-19T22:10:07.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.744+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148] for update
[2025-07-19T22:10:07.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.1.delta.51f1d02c-c736-4398-a167-df782877de24.TID513.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/1.delta
[2025-07-19T22:10:07.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/1.delta
[2025-07-19T22:10:07.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 513, attempt 0, stage 1.0)
[2025-07-19T22:10:07.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.1.delta.af5ccacd-fb56-44ef-bb04-dd14dc8d8fe3.TID512.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/1.delta
[2025-07-19T22:10:07.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/1.delta
[2025-07-19T22:10:07.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 512, attempt 0, stage 1.0)
[2025-07-19T22:10:07.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d892fb2
[2025-07-19T22:10:07.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149] for update
[2025-07-19T22:10:07.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.1.delta.1755d472-a8ae-4ade-b72f-81c789b3e8a3.TID517.tmp
[2025-07-19T22:10:07.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.1.delta.e4321626-5142-4b23-9787-2965cd4a1ef3.TID515.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/1.delta
[2025-07-19T22:10:07.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/1.delta
[2025-07-19T22:10:07.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 515, attempt 0, stage 1.0)
[2025-07-19T22:10:07.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.1.delta.5c4b6442-26e0-422b-b583-f3532e4e17aa.TID518.tmp
[2025-07-19T22:10:07.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.1.delta.f9732257-280e-427e-b47a-20f9531cf2c3.TID514.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/1.delta
[2025-07-19T22:10:07.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/1.delta
[2025-07-19T22:10:07.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 141 (task 512, attempt 0, stage 1.0)
[2025-07-19T22:10:07.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 514, attempt 0, stage 1.0)
[2025-07-19T22:10:07.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 141.0 in stage 1.0 (TID 512). 9266 bytes result sent to driver
[2025-07-19T22:10:07.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 151.0 in stage 1.0 (TID 520) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 142 (task 513, attempt 0, stage 1.0)
[2025-07-19T22:10:07.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.1.delta.795f0706-19a9-4692-8506-beba481a6d6c.TID519.tmp
[2025-07-19T22:10:07.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 151.0 in stage 1.0 (TID 520)
[2025-07-19T22:10:07.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 141.0 in stage 1.0 (TID 512) in 149 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T22:10:07.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 142.0 in stage 1.0 (TID 513). 9290 bytes result sent to driver
[2025-07-19T22:10:07.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 152.0 in stage 1.0 (TID 521) (8b44f3d35cfa, executor driver, partition 152, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.781+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 142.0 in stage 1.0 (TID 513) in 112 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T22:10:07.785+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 152.0 in stage 1.0 (TID 521)
[2025-07-19T22:10:07.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:07.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 144 (task 515, attempt 0, stage 1.0)
[2025-07-19T22:10:07.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 144.0 in stage 1.0 (TID 515). 9313 bytes result sent to driver
[2025-07-19T22:10:07.790+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56317c93
[2025-07-19T22:10:07.790+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 153.0 in stage 1.0 (TID 522) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151] for update
[2025-07-19T22:10:07.792+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 153.0 in stage 1.0 (TID 522)
[2025-07-19T22:10:07.792+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 144.0 in stage 1.0 (TID 515) in 114 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T22:10:07.792+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 143 (task 514, attempt 0, stage 1.0)
[2025-07-19T22:10:07.792+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 143.0 in stage 1.0 (TID 514). 9293 bytes result sent to driver
[2025-07-19T22:10:07.793+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.793+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.793+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.794+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 155.0 in stage 1.0 (TID 523) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.794+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 143.0 in stage 1.0 (TID 514) in 120 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T22:10:07.794+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5002778a
[2025-07-19T22:10:07.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 155.0 in stage 1.0 (TID 523)
[2025-07-19T22:10:07.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.1.delta.8dc56f5b-902a-42a0-ad06-9bd038cf3af7.TID516.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/1.delta
[2025-07-19T22:10:07.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/1.delta
[2025-07-19T22:10:07.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.798+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152] for update
[2025-07-19T22:10:07.800+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.1.delta.5f7ce3a9-3acd-4ec4-88f3-90918fb1ce95.TID520.tmp
[2025-07-19T22:10:07.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.1.delta.1755d472-a8ae-4ade-b72f-81c789b3e8a3.TID517.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/1.delta
[2025-07-19T22:10:07.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/1.delta
[2025-07-19T22:10:07.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 516, attempt 0, stage 1.0)
[2025-07-19T22:10:07.821+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20bc704f
[2025-07-19T22:10:07.821+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153] for update
[2025-07-19T22:10:07.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 517, attempt 0, stage 1.0)
[2025-07-19T22:10:07.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.1.delta.f74f4b12-07d4-4a00-bbb7-9aa6507da7f5.TID521.tmp
[2025-07-19T22:10:07.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f69b5e6
[2025-07-19T22:10:07.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155] for update
[2025-07-19T22:10:07.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.1.delta.5c4b6442-26e0-422b-b583-f3532e4e17aa.TID518.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/1.delta
[2025-07-19T22:10:07.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/1.delta
[2025-07-19T22:10:07.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 518, attempt 0, stage 1.0)
[2025-07-19T22:10:07.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.1.delta.5f7ce3a9-3acd-4ec4-88f3-90918fb1ce95.TID520.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/1.delta
[2025-07-19T22:10:07.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/1.delta
[2025-07-19T22:10:07.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.1.delta.795f0706-19a9-4692-8506-beba481a6d6c.TID519.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/1.delta
[2025-07-19T22:10:07.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/1.delta
[2025-07-19T22:10:07.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 520, attempt 0, stage 1.0)
[2025-07-19T22:10:07.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 519, attempt 0, stage 1.0)
[2025-07-19T22:10:07.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 147 (task 517, attempt 0, stage 1.0)
[2025-07-19T22:10:07.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 145 (task 516, attempt 0, stage 1.0)
[2025-07-19T22:10:07.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 147.0 in stage 1.0 (TID 517). 9293 bytes result sent to driver
[2025-07-19T22:10:07.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 145.0 in stage 1.0 (TID 516). 9295 bytes result sent to driver
[2025-07-19T22:10:07.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.1.delta.5fe9407b-4ed0-494e-b07f-42d0718d2715.TID522.tmp
[2025-07-19T22:10:07.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 156.0 in stage 1.0 (TID 524) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 157.0 in stage 1.0 (TID 525) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 156.0 in stage 1.0 (TID 524)
[2025-07-19T22:10:07.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 157.0 in stage 1.0 (TID 525)
[2025-07-19T22:10:07.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 147.0 in stage 1.0 (TID 517) in 142 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T22:10:07.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 145.0 in stage 1.0 (TID 516) in 162 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T22:10:07.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:07.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b8ec4bf
[2025-07-19T22:10:07.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.1.delta.f74f4b12-07d4-4a00-bbb7-9aa6507da7f5.TID521.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/1.delta
[2025-07-19T22:10:07.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/1.delta
[2025-07-19T22:10:07.863+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.865+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 521, attempt 0, stage 1.0)
[2025-07-19T22:10:07.865+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156] for update
[2025-07-19T22:10:07.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 151 (task 520, attempt 0, stage 1.0)
[2025-07-19T22:10:07.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 148 (task 518, attempt 0, stage 1.0)
[2025-07-19T22:10:07.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 148.0 in stage 1.0 (TID 518). 9306 bytes result sent to driver
[2025-07-19T22:10:07.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 149 (task 519, attempt 0, stage 1.0)
[2025-07-19T22:10:07.873+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.1.delta.feb48c25-e297-4f07-8561-747fe14f3d97.TID523.tmp
[2025-07-19T22:10:07.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 151.0 in stage 1.0 (TID 520). 9264 bytes result sent to driver
[2025-07-19T22:10:07.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 159.0 in stage 1.0 (TID 526) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 159.0 in stage 1.0 (TID 526)
[2025-07-19T22:10:07.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fc7cc52
[2025-07-19T22:10:07.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 160.0 in stage 1.0 (TID 527) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 151.0 in stage 1.0 (TID 520) in 109 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T22:10:07.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 160.0 in stage 1.0 (TID 527)
[2025-07-19T22:10:07.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 149.0 in stage 1.0 (TID 519). 9350 bytes result sent to driver
[2025-07-19T22:10:07.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 148.0 in stage 1.0 (TID 518) in 158 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T22:10:07.885+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157] for update
[2025-07-19T22:10:07.885+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 161.0 in stage 1.0 (TID 528) (8b44f3d35cfa, executor driver, partition 161, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 149.0 in stage 1.0 (TID 519) in 149 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T22:10:07.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 161.0 in stage 1.0 (TID 528)
[2025-07-19T22:10:07.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.1.delta.beee1750-19e0-45a5-bbf1-d3dc2b0ecc11.TID524.tmp
[2025-07-19T22:10:07.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 152 (task 521, attempt 0, stage 1.0)
[2025-07-19T22:10:07.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 152.0 in stage 1.0 (TID 521). 9302 bytes result sent to driver
[2025-07-19T22:10:07.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 162.0 in stage 1.0 (TID 529) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:07.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 162.0 in stage 1.0 (TID 529)
[2025-07-19T22:10:07.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 152.0 in stage 1.0 (TID 521) in 112 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T22:10:07.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a2898b3
[2025-07-19T22:10:07.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161] for update
[2025-07-19T22:10:07.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.1.delta.fe3775c8-1f55-4024-bbd4-8284fe5f2c94.TID525.tmp
[2025-07-19T22:10:07.896+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a6882db
[2025-07-19T22:10:07.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.1.delta.ff71c9e5-ce30-47e3-b1d0-802395ca78c4.TID528.tmp
[2025-07-19T22:10:07.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162] for update
[2025-07-19T22:10:07.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ce1971d
[2025-07-19T22:10:07.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159] for update
[2025-07-19T22:10:07.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.1.delta.5fe9407b-4ed0-494e-b07f-42d0718d2715.TID522.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/1.delta
[2025-07-19T22:10:07.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/1.delta
[2025-07-19T22:10:07.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 522, attempt 0, stage 1.0)
[2025-07-19T22:10:07.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2eec918b
[2025-07-19T22:10:07.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160] for update
[2025-07-19T22:10:07.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.1.delta.1315f2c3-1959-4f45-a16f-d849fbea4d20.TID529.tmp
[2025-07-19T22:10:07.915+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.1.delta.b17992bb-1fbe-41ea-a976-07a7c11aedbe.TID526.tmp
[2025-07-19T22:10:07.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 153 (task 522, attempt 0, stage 1.0)
[2025-07-19T22:10:07.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 153.0 in stage 1.0 (TID 522). 9308 bytes result sent to driver
[2025-07-19T22:10:07.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 164.0 in stage 1.0 (TID 530) (8b44f3d35cfa, executor driver, partition 164, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 164.0 in stage 1.0 (TID 530)
[2025-07-19T22:10:07.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 153.0 in stage 1.0 (TID 522) in 143 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T22:10:07.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.1.delta.1d976a0e-76e1-4c09-b2f8-b5a8e8dd7eb0.TID527.tmp
[2025-07-19T22:10:07.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.1.delta.beee1750-19e0-45a5-bbf1-d3dc2b0ecc11.TID524.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/1.delta
[2025-07-19T22:10:07.929+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/1.delta
[2025-07-19T22:10:07.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 524, attempt 0, stage 1.0)
[2025-07-19T22:10:07.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.1.delta.feb48c25-e297-4f07-8561-747fe14f3d97.TID523.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/1.delta
[2025-07-19T22:10:07.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/1.delta
[2025-07-19T22:10:07.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62dd009e
[2025-07-19T22:10:07.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 523, attempt 0, stage 1.0)
[2025-07-19T22:10:07.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164] for update
[2025-07-19T22:10:07.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.1.delta.ff71c9e5-ce30-47e3-b1d0-802395ca78c4.TID528.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/1.delta
[2025-07-19T22:10:07.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/1.delta
[2025-07-19T22:10:07.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 528, attempt 0, stage 1.0)
[2025-07-19T22:10:07.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.1.delta.d72617fb-0ac9-42ce-a7d2-084779c1cbf7.TID530.tmp
[2025-07-19T22:10:07.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.1.delta.fe3775c8-1f55-4024-bbd4-8284fe5f2c94.TID525.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/1.delta
[2025-07-19T22:10:07.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/1.delta
[2025-07-19T22:10:07.950+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 525, attempt 0, stage 1.0)
[2025-07-19T22:10:07.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 156 (task 524, attempt 0, stage 1.0)
[2025-07-19T22:10:07.955+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 156.0 in stage 1.0 (TID 524). 9305 bytes result sent to driver
[2025-07-19T22:10:07.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 165.0 in stage 1.0 (TID 531) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 165.0 in stage 1.0 (TID 531)
[2025-07-19T22:10:07.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 156.0 in stage 1.0 (TID 524) in 107 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T22:10:07.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 155 (task 523, attempt 0, stage 1.0)
[2025-07-19T22:10:07.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:07.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 155.0 in stage 1.0 (TID 523). 9276 bytes result sent to driver
[2025-07-19T22:10:07.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 166.0 in stage 1.0 (TID 532) (8b44f3d35cfa, executor driver, partition 166, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 166.0 in stage 1.0 (TID 532)
[2025-07-19T22:10:07.959+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 155.0 in stage 1.0 (TID 523) in 168 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T22:10:07.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 161 (task 528, attempt 0, stage 1.0)
[2025-07-19T22:10:07.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 161.0 in stage 1.0 (TID 528). 9258 bytes result sent to driver
[2025-07-19T22:10:07.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 168.0 in stage 1.0 (TID 533) (8b44f3d35cfa, executor driver, partition 168, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.964+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 168.0 in stage 1.0 (TID 533)
[2025-07-19T22:10:07.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 161.0 in stage 1.0 (TID 528) in 84 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T22:10:07.966+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.966+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29988954
[2025-07-19T22:10:07.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165] for update
[2025-07-19T22:10:07.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 157 (task 525, attempt 0, stage 1.0)
[2025-07-19T22:10:07.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 157.0 in stage 1.0 (TID 525). 9288 bytes result sent to driver
[2025-07-19T22:10:07.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.1.delta.1315f2c3-1959-4f45-a16f-d849fbea4d20.TID529.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/1.delta
[2025-07-19T22:10:07.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/1.delta
[2025-07-19T22:10:07.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 169.0 in stage 1.0 (TID 534) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 529, attempt 0, stage 1.0)
[2025-07-19T22:10:07.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.970+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 157.0 in stage 1.0 (TID 525) in 124 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T22:10:07.970+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 169.0 in stage 1.0 (TID 534)
[2025-07-19T22:10:07.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.1.delta.b17992bb-1fbe-41ea-a976-07a7c11aedbe.TID526.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/1.delta
[2025-07-19T22:10:07.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/1.delta
[2025-07-19T22:10:07.977+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:07.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:07.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c11c361
[2025-07-19T22:10:07.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168] for update
[2025-07-19T22:10:07.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 526, attempt 0, stage 1.0)
[2025-07-19T22:10:07.981+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.1.delta.1d976a0e-76e1-4c09-b2f8-b5a8e8dd7eb0.TID527.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/1.delta
[2025-07-19T22:10:07.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/1.delta
[2025-07-19T22:10:07.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 527, attempt 0, stage 1.0)
[2025-07-19T22:10:07.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f1f0d02
[2025-07-19T22:10:07.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:07.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166] for update
[2025-07-19T22:10:07.986+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:07.987+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.1.delta.90152e64-1e24-4b2d-9a36-a158383f5277.TID531.tmp
[2025-07-19T22:10:07.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 162 (task 529, attempt 0, stage 1.0)
[2025-07-19T22:10:07.992+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 162.0 in stage 1.0 (TID 529). 9310 bytes result sent to driver
[2025-07-19T22:10:07.994+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 173.0 in stage 1.0 (TID 535) (8b44f3d35cfa, executor driver, partition 173, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:07.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 162.0 in stage 1.0 (TID 529) in 109 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T22:10:07.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.1.delta.6281f522-c349-488b-8c4a-bffa82bdf7d9.TID533.tmp
[2025-07-19T22:10:07.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@748ab712
[2025-07-19T22:10:07.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 173.0 in stage 1.0 (TID 535)
[2025-07-19T22:10:07.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.000+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169] for update
[2025-07-19T22:10:08.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO DataWritingSparkTask: Committed partition 159 (task 526, attempt 0, stage 1.0)
[2025-07-19T22:10:08.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Finished task 159.0 in stage 1.0 (TID 526). 9300 bytes result sent to driver
[2025-07-19T22:10:08.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Starting task 174.0 in stage 1.0 (TID 536) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO TaskSetManager: Finished task 159.0 in stage 1.0 (TID 526) in 122 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T22:10:08.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO Executor: Running task 174.0 in stage 1.0 (TID 536)
[2025-07-19T22:10:08.008+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.1.delta.093ae941-e338-41fc-aeb3-4f5d621f66b8.TID532.tmp
[2025-07-19T22:10:08.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.1.delta.3cd9e4f2-0918-40e7-9b32-5cf818a58caa.TID534.tmp
[2025-07-19T22:10:08.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 160 (task 527, attempt 0, stage 1.0)
[2025-07-19T22:10:08.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 160.0 in stage 1.0 (TID 527). 9317 bytes result sent to driver
[2025-07-19T22:10:08.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 175.0 in stage 1.0 (TID 537) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 160.0 in stage 1.0 (TID 527) in 132 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T22:10:08.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 175.0 in stage 1.0 (TID 537)
[2025-07-19T22:10:08.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.1.delta.d72617fb-0ac9-42ce-a7d2-084779c1cbf7.TID530.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/1.delta
[2025-07-19T22:10:08.020+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/1.delta
[2025-07-19T22:10:08.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54eb71bf
[2025-07-19T22:10:08.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173] for update
[2025-07-19T22:10:08.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 530, attempt 0, stage 1.0)
[2025-07-19T22:10:08.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dabc103
[2025-07-19T22:10:08.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174] for update
[2025-07-19T22:10:08.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@210b7c8b
[2025-07-19T22:10:08.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175] for update
[2025-07-19T22:10:08.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.1.delta.e70e9317-aa1b-40ce-85fa-fb3f1b085082.TID535.tmp
[2025-07-19T22:10:08.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 164 (task 530, attempt 0, stage 1.0)
[2025-07-19T22:10:08.035+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 164.0 in stage 1.0 (TID 530). 9300 bytes result sent to driver
[2025-07-19T22:10:08.035+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.1.delta.8a5e6f7a-7ec2-40eb-875e-3428b559c2ae.TID536.tmp
[2025-07-19T22:10:08.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 176.0 in stage 1.0 (TID 538) (8b44f3d35cfa, executor driver, partition 176, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 164.0 in stage 1.0 (TID 530) in 111 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T22:10:08.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 176.0 in stage 1.0 (TID 538)
[2025-07-19T22:10:08.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.1.delta.fc78d173-2cb0-47d7-8358-4e4ec010e645.TID537.tmp
[2025-07-19T22:10:08.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4af02244
[2025-07-19T22:10:08.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176] for update
[2025-07-19T22:10:08.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.1.delta.6281f522-c349-488b-8c4a-bffa82bdf7d9.TID533.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/1.delta
[2025-07-19T22:10:08.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/1.delta
[2025-07-19T22:10:08.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 533, attempt 0, stage 1.0)
[2025-07-19T22:10:08.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.1.delta.90152e64-1e24-4b2d-9a36-a158383f5277.TID531.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/1.delta
[2025-07-19T22:10:08.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/1.delta
[2025-07-19T22:10:08.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.1.delta.3cd9e4f2-0918-40e7-9b32-5cf818a58caa.TID534.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/1.delta
[2025-07-19T22:10:08.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/1.delta
[2025-07-19T22:10:08.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 534, attempt 0, stage 1.0)
[2025-07-19T22:10:08.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 531, attempt 0, stage 1.0)
[2025-07-19T22:10:08.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.1.delta.485060dc-1b27-4d20-9f7c-792a7ce6b461.TID538.tmp
[2025-07-19T22:10:08.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.1.delta.093ae941-e338-41fc-aeb3-4f5d621f66b8.TID532.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/1.delta
[2025-07-19T22:10:08.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/1.delta
[2025-07-19T22:10:08.098+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 532, attempt 0, stage 1.0)
[2025-07-19T22:10:08.102+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 168 (task 533, attempt 0, stage 1.0)
[2025-07-19T22:10:08.125+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 165 (task 531, attempt 0, stage 1.0)
[2025-07-19T22:10:08.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 168.0 in stage 1.0 (TID 533). 9337 bytes result sent to driver
[2025-07-19T22:10:08.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 165.0 in stage 1.0 (TID 531). 9343 bytes result sent to driver
[2025-07-19T22:10:08.129+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.1.delta.8a5e6f7a-7ec2-40eb-875e-3428b559c2ae.TID536.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/1.delta
[2025-07-19T22:10:08.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/1.delta
[2025-07-19T22:10:08.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 536, attempt 0, stage 1.0)
[2025-07-19T22:10:08.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 177.0 in stage 1.0 (TID 539) (8b44f3d35cfa, executor driver, partition 177, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 178.0 in stage 1.0 (TID 540) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 178.0 in stage 1.0 (TID 540)
[2025-07-19T22:10:08.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 168.0 in stage 1.0 (TID 533) in 170 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T22:10:08.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 165.0 in stage 1.0 (TID 531) in 182 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T22:10:08.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 177.0 in stage 1.0 (TID 539)
[2025-07-19T22:10:08.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.141+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:08.142+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:08.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63ed2adb
[2025-07-19T22:10:08.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.1.delta.e70e9317-aa1b-40ce-85fa-fb3f1b085082.TID535.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/1.delta
[2025-07-19T22:10:08.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/1.delta
[2025-07-19T22:10:08.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 166 (task 532, attempt 0, stage 1.0)
[2025-07-19T22:10:08.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178] for update
[2025-07-19T22:10:08.153+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 535, attempt 0, stage 1.0)
[2025-07-19T22:10:08.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 169 (task 534, attempt 0, stage 1.0)
[2025-07-19T22:10:08.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 166.0 in stage 1.0 (TID 532). 9294 bytes result sent to driver
[2025-07-19T22:10:08.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 169.0 in stage 1.0 (TID 534). 9300 bytes result sent to driver
[2025-07-19T22:10:08.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 179.0 in stage 1.0 (TID 541) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 182.0 in stage 1.0 (TID 542) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 179.0 in stage 1.0 (TID 541)
[2025-07-19T22:10:08.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 166.0 in stage 1.0 (TID 532) in 199 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T22:10:08.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 182.0 in stage 1.0 (TID 542)
[2025-07-19T22:10:08.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 169.0 in stage 1.0 (TID 534) in 188 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T22:10:08.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.1.delta.fc78d173-2cb0-47d7-8358-4e4ec010e645.TID537.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/1.delta
[2025-07-19T22:10:08.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/1.delta
[2025-07-19T22:10:08.158+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 537, attempt 0, stage 1.0)
[2025-07-19T22:10:08.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b0486af
[2025-07-19T22:10:08.165+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.168+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:08.168+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.173+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177] for update
[2025-07-19T22:10:08.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 174 (task 536, attempt 0, stage 1.0)
[2025-07-19T22:10:08.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 174.0 in stage 1.0 (TID 536). 9305 bytes result sent to driver
[2025-07-19T22:10:08.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 183.0 in stage 1.0 (TID 543) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 183.0 in stage 1.0 (TID 543)
[2025-07-19T22:10:08.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 174.0 in stage 1.0 (TID 536) in 170 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T22:10:08.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.1.delta.ea77cf8a-b507-4969-898f-78660227f014.TID540.tmp
[2025-07-19T22:10:08.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:08.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54fddaa9
[2025-07-19T22:10:08.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 173 (task 535, attempt 0, stage 1.0)
[2025-07-19T22:10:08.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 173.0 in stage 1.0 (TID 535). 9310 bytes result sent to driver
[2025-07-19T22:10:08.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 184.0 in stage 1.0 (TID 544) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179] for update
[2025-07-19T22:10:08.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 184.0 in stage 1.0 (TID 544)
[2025-07-19T22:10:08.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 173.0 in stage 1.0 (TID 535) in 184 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T22:10:08.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cd5209a
[2025-07-19T22:10:08.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183] for update
[2025-07-19T22:10:08.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.1.delta.c4586154-9905-4fb7-b268-ac8d9812f176.TID539.tmp
[2025-07-19T22:10:08.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 175 (task 537, attempt 0, stage 1.0)
[2025-07-19T22:10:08.190+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 175.0 in stage 1.0 (TID 537). 9287 bytes result sent to driver
[2025-07-19T22:10:08.191+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.1.delta.9c8e281a-a02c-4d7f-8d9c-8db6b477a5e7.TID541.tmp
[2025-07-19T22:10:08.192+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 185.0 in stage 1.0 (TID 545) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 185.0 in stage 1.0 (TID 545)
[2025-07-19T22:10:08.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 175.0 in stage 1.0 (TID 537) in 186 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T22:10:08.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4125e1a8
[2025-07-19T22:10:08.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182] for update
[2025-07-19T22:10:08.205+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.206+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.1.delta.c57ffbb4-18b0-4b04-b8a3-70365a046b1d.TID543.tmp
[2025-07-19T22:10:08.206+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36161623
[2025-07-19T22:10:08.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.209+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185] for update
[2025-07-19T22:10:08.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.1.delta.485060dc-1b27-4d20-9f7c-792a7ce6b461.TID538.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/1.delta
[2025-07-19T22:10:08.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/1.delta
[2025-07-19T22:10:08.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 538, attempt 0, stage 1.0)
[2025-07-19T22:10:08.214+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.1.delta.1c72c534-b08e-4a0d-8861-e49c1460070d.TID542.tmp
[2025-07-19T22:10:08.216+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66e275af
[2025-07-19T22:10:08.217+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184] for update
[2025-07-19T22:10:08.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.1.delta.91134f87-7268-4aab-b222-7e81902f5e6e.TID545.tmp
[2025-07-19T22:10:08.229+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.1.delta.ea77cf8a-b507-4969-898f-78660227f014.TID540.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/1.delta
[2025-07-19T22:10:08.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/1.delta
[2025-07-19T22:10:08.232+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 540, attempt 0, stage 1.0)
[2025-07-19T22:10:08.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.1.delta.33c7a208-ba9d-4ba4-82ed-a06e657e3d78.TID544.tmp
[2025-07-19T22:10:08.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 176 (task 538, attempt 0, stage 1.0)
[2025-07-19T22:10:08.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 176.0 in stage 1.0 (TID 538). 9303 bytes result sent to driver
[2025-07-19T22:10:08.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.1.delta.c4586154-9905-4fb7-b268-ac8d9812f176.TID539.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/1.delta
[2025-07-19T22:10:08.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/1.delta
[2025-07-19T22:10:08.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 187.0 in stage 1.0 (TID 546) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 539, attempt 0, stage 1.0)
[2025-07-19T22:10:08.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 176.0 in stage 1.0 (TID 538) in 212 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T22:10:08.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 187.0 in stage 1.0 (TID 546)
[2025-07-19T22:10:08.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 178 (task 540, attempt 0, stage 1.0)
[2025-07-19T22:10:08.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 178.0 in stage 1.0 (TID 540). 9350 bytes result sent to driver
[2025-07-19T22:10:08.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.258+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 188.0 in stage 1.0 (TID 547) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 188.0 in stage 1.0 (TID 547)
[2025-07-19T22:10:08.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 178.0 in stage 1.0 (TID 540) in 129 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T22:10:08.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.1.delta.9c8e281a-a02c-4d7f-8d9c-8db6b477a5e7.TID541.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/1.delta
[2025-07-19T22:10:08.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/1.delta
[2025-07-19T22:10:08.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 541, attempt 0, stage 1.0)
[2025-07-19T22:10:08.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.1.delta.c57ffbb4-18b0-4b04-b8a3-70365a046b1d.TID543.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/1.delta
[2025-07-19T22:10:08.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/1.delta
[2025-07-19T22:10:08.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79ba4bd2
[2025-07-19T22:10:08.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 543, attempt 0, stage 1.0)
[2025-07-19T22:10:08.272+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.1.delta.1c72c534-b08e-4a0d-8861-e49c1460070d.TID542.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/1.delta
[2025-07-19T22:10:08.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/1.delta
[2025-07-19T22:10:08.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 542, attempt 0, stage 1.0)
[2025-07-19T22:10:08.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187] for update
[2025-07-19T22:10:08.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 177 (task 539, attempt 0, stage 1.0)
[2025-07-19T22:10:08.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 177.0 in stage 1.0 (TID 539). 9289 bytes result sent to driver
[2025-07-19T22:10:08.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 177.0 in stage 1.0 (TID 539) in 149 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T22:10:08.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.1.delta.33c7a208-ba9d-4ba4-82ed-a06e657e3d78.TID544.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/1.delta
[2025-07-19T22:10:08.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/1.delta
[2025-07-19T22:10:08.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 190.0 in stage 1.0 (TID 548) (8b44f3d35cfa, executor driver, partition 190, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.1.delta.91134f87-7268-4aab-b222-7e81902f5e6e.TID545.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/1.delta
[2025-07-19T22:10:08.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f7b89b4
[2025-07-19T22:10:08.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/1.delta
[2025-07-19T22:10:08.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 544, attempt 0, stage 1.0)
[2025-07-19T22:10:08.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 190.0 in stage 1.0 (TID 548)
[2025-07-19T22:10:08.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 545, attempt 0, stage 1.0)
[2025-07-19T22:10:08.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188] for update
[2025-07-19T22:10:08.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.293+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 179 (task 541, attempt 0, stage 1.0)
[2025-07-19T22:10:08.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 179.0 in stage 1.0 (TID 541). 9301 bytes result sent to driver
[2025-07-19T22:10:08.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.1.delta.2777af7c-a64f-4dc1-be26-e0313a03a465.TID546.tmp
[2025-07-19T22:10:08.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.295+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 191.0 in stage 1.0 (TID 549) (8b44f3d35cfa, executor driver, partition 191, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 191.0 in stage 1.0 (TID 549)
[2025-07-19T22:10:08.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 179.0 in stage 1.0 (TID 541) in 142 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T22:10:08.297+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 182 (task 542, attempt 0, stage 1.0)
[2025-07-19T22:10:08.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 182.0 in stage 1.0 (TID 542). 9306 bytes result sent to driver
[2025-07-19T22:10:08.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 194.0 in stage 1.0 (TID 550) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 194.0 in stage 1.0 (TID 550)
[2025-07-19T22:10:08.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 182.0 in stage 1.0 (TID 542) in 147 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T22:10:08.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:08.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e7ee62b
[2025-07-19T22:10:08.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 183 (task 543, attempt 0, stage 1.0)
[2025-07-19T22:10:08.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190] for update
[2025-07-19T22:10:08.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 183.0 in stage 1.0 (TID 543). 9291 bytes result sent to driver
[2025-07-19T22:10:08.300+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.300+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.300+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.302+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 196.0 in stage 1.0 (TID 551) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 184 (task 544, attempt 0, stage 1.0)
[2025-07-19T22:10:08.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 196.0 in stage 1.0 (TID 551)
[2025-07-19T22:10:08.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 184.0 in stage 1.0 (TID 544). 9315 bytes result sent to driver
[2025-07-19T22:10:08.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 197.0 in stage 1.0 (TID 552) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 183.0 in stage 1.0 (TID 543) in 141 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T22:10:08.306+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 197.0 in stage 1.0 (TID 552)
[2025-07-19T22:10:08.306+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 184.0 in stage 1.0 (TID 544) in 133 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T22:10:08.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.1.delta.51b5d2bf-f44e-4094-a32f-b8e021e602a2.TID547.tmp
[2025-07-19T22:10:08.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4748965
[2025-07-19T22:10:08.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191] for update
[2025-07-19T22:10:08.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 185 (task 545, attempt 0, stage 1.0)
[2025-07-19T22:10:08.313+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.1.delta.4938ccc8-f874-48e2-a13e-f67f4abbc900.TID548.tmp
[2025-07-19T22:10:08.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 185.0 in stage 1.0 (TID 545). 9300 bytes result sent to driver
[2025-07-19T22:10:08.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 198.0 in stage 1.0 (TID 553) (8b44f3d35cfa, executor driver, partition 198, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 198.0 in stage 1.0 (TID 553)
[2025-07-19T22:10:08.317+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 185.0 in stage 1.0 (TID 545) in 125 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T22:10:08.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1422c3f8
[2025-07-19T22:10:08.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197] for update
[2025-07-19T22:10:08.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@509c9ad5
[2025-07-19T22:10:08.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196] for update
[2025-07-19T22:10:08.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.1.delta.418ee458-d62f-484a-84f7-0e8646c16801.TID549.tmp
[2025-07-19T22:10:08.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.1.delta.b5f32623-84b9-40a7-b0ad-fff9f4001215.TID552.tmp
[2025-07-19T22:10:08.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f7e94ce
[2025-07-19T22:10:08.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194] for update
[2025-07-19T22:10:08.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.1.delta.44532284-a8c0-49e3-8b94-eac53e890fd0.TID551.tmp
[2025-07-19T22:10:08.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.1.delta.2777af7c-a64f-4dc1-be26-e0313a03a465.TID546.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/1.delta
[2025-07-19T22:10:08.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/1.delta
[2025-07-19T22:10:08.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2af8075f
[2025-07-19T22:10:08.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198] for update
[2025-07-19T22:10:08.350+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 546, attempt 0, stage 1.0)
[2025-07-19T22:10:08.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.1.delta.62dfbb17-512e-4a0e-a942-79ae556fb240.TID550.tmp
[2025-07-19T22:10:08.360+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.1.delta.51b5d2bf-f44e-4094-a32f-b8e021e602a2.TID547.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/1.delta
[2025-07-19T22:10:08.361+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/1.delta
[2025-07-19T22:10:08.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 547, attempt 0, stage 1.0)
[2025-07-19T22:10:08.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 187 (task 546, attempt 0, stage 1.0)
[2025-07-19T22:10:08.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 187.0 in stage 1.0 (TID 546). 9300 bytes result sent to driver
[2025-07-19T22:10:08.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 199.0 in stage 1.0 (TID 554) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.1.delta.e6a37c6f-e856-4ec0-b93c-9878a46fa9a6.TID553.tmp
[2025-07-19T22:10:08.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 199.0 in stage 1.0 (TID 554)
[2025-07-19T22:10:08.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.1.delta.4938ccc8-f874-48e2-a13e-f67f4abbc900.TID548.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/1.delta
[2025-07-19T22:10:08.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/1.delta
[2025-07-19T22:10:08.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 187.0 in stage 1.0 (TID 546) in 130 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T22:10:08.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 548, attempt 0, stage 1.0)
[2025-07-19T22:10:08.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.377+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e3dadd4
[2025-07-19T22:10:08.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199] for update
[2025-07-19T22:10:08.385+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.396+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.1.delta.418ee458-d62f-484a-84f7-0e8646c16801.TID549.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/1.delta
[2025-07-19T22:10:08.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/1.delta
[2025-07-19T22:10:08.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 549, attempt 0, stage 1.0)
[2025-07-19T22:10:08.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 188 (task 547, attempt 0, stage 1.0)
[2025-07-19T22:10:08.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 188.0 in stage 1.0 (TID 547). 9300 bytes result sent to driver
[2025-07-19T22:10:08.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 555) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 555)
[2025-07-19T22:10:08.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 188.0 in stage 1.0 (TID 547) in 142 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T22:10:08.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 190 (task 548, attempt 0, stage 1.0)
[2025-07-19T22:10:08.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 190.0 in stage 1.0 (TID 548). 9301 bytes result sent to driver
[2025-07-19T22:10:08.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 556) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 4.0 in stage 1.0 (TID 556)
[2025-07-19T22:10:08.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 190.0 in stage 1.0 (TID 548) in 121 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T22:10:08.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.409+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.1.delta.944c1677-c465-4104-9d8c-cb954a4a26f3.TID554.tmp
[2025-07-19T22:10:08.411+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.1.delta.b5f32623-84b9-40a7-b0ad-fff9f4001215.TID552.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/1.delta
[2025-07-19T22:10:08.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/1.delta
[2025-07-19T22:10:08.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 552, attempt 0, stage 1.0)
[2025-07-19T22:10:08.414+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 191 (task 549, attempt 0, stage 1.0)
[2025-07-19T22:10:08.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 191.0 in stage 1.0 (TID 549). 9306 bytes result sent to driver
[2025-07-19T22:10:08.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.1.delta.44532284-a8c0-49e3-8b94-eac53e890fd0.TID551.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/1.delta
[2025-07-19T22:10:08.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/1.delta
[2025-07-19T22:10:08.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 551, attempt 0, stage 1.0)
[2025-07-19T22:10:08.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 557) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 191.0 in stage 1.0 (TID 549) in 125 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T22:10:08.418+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 21.0 in stage 1.0 (TID 557)
[2025-07-19T22:10:08.419+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.419+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 197 (task 552, attempt 0, stage 1.0)
[2025-07-19T22:10:08.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 197.0 in stage 1.0 (TID 552). 9296 bytes result sent to driver
[2025-07-19T22:10:08.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 558) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 37.0 in stage 1.0 (TID 558)
[2025-07-19T22:10:08.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/.schema.4afa9384-e434-4719-9682-7b734c98c139.TID555.tmp
[2025-07-19T22:10:08.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 197.0 in stage 1.0 (TID 552) in 126 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T22:10:08.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.1.delta.e6a37c6f-e856-4ec0-b93c-9878a46fa9a6.TID553.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/1.delta
[2025-07-19T22:10:08.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/1.delta
[2025-07-19T22:10:08.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.1.delta.62dfbb17-512e-4a0e-a942-79ae556fb240.TID550.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/1.delta
[2025-07-19T22:10:08.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/1.delta
[2025-07-19T22:10:08.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 553, attempt 0, stage 1.0)
[2025-07-19T22:10:08.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 550, attempt 0, stage 1.0)
[2025-07-19T22:10:08.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 196 (task 551, attempt 0, stage 1.0)
[2025-07-19T22:10:08.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 196.0 in stage 1.0 (TID 551). 9310 bytes result sent to driver
[2025-07-19T22:10:08.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 559) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 38.0 in stage 1.0 (TID 559)
[2025-07-19T22:10:08.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 196.0 in stage 1.0 (TID 551) in 134 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T22:10:08.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 198 (task 553, attempt 0, stage 1.0)
[2025-07-19T22:10:08.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 198.0 in stage 1.0 (TID 553). 9300 bytes result sent to driver
[2025-07-19T22:10:08.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.1.delta.944c1677-c465-4104-9d8c-cb954a4a26f3.TID554.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/1.delta
[2025-07-19T22:10:08.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/1.delta
[2025-07-19T22:10:08.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 560) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 194 (task 550, attempt 0, stage 1.0)
[2025-07-19T22:10:08.450+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 554, attempt 0, stage 1.0)
[2025-07-19T22:10:08.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 43.0 in stage 1.0 (TID 560)
[2025-07-19T22:10:08.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 198.0 in stage 1.0 (TID 553) in 131 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T22:10:08.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 194.0 in stage 1.0 (TID 550). 9294 bytes result sent to driver
[2025-07-19T22:10:08.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 561) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 194.0 in stage 1.0 (TID 550) in 154 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T22:10:08.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 45.0 in stage 1.0 (TID 561)
[2025-07-19T22:10:08.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/.schema.4afa9384-e434-4719-9682-7b734c98c139.TID555.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/_metadata/schema
[2025-07-19T22:10:08.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ebec68d
[2025-07-19T22:10:08.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0] for update
[2025-07-19T22:10:08.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 199 (task 554, attempt 0, stage 1.0)
[2025-07-19T22:10:08.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 199.0 in stage 1.0 (TID 554). 9320 bytes result sent to driver
[2025-07-19T22:10:08.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 562) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 50.0 in stage 1.0 (TID 562)
[2025-07-19T22:10:08.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 199.0 in stage 1.0 (TID 554) in 97 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T22:10:08.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d95ac4
[2025-07-19T22:10:08.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43] for update
[2025-07-19T22:10:08.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.1.delta.8e7f2c8d-ae95-493b-a2f3-9bcb186cc154.TID555.tmp
[2025-07-19T22:10:08.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.473+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53e35600
[2025-07-19T22:10:08.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45] for update
[2025-07-19T22:10:08.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.1.delta.e1fad6c7-6ed6-4eb2-8abb-abb178a648b6.TID560.tmp
[2025-07-19T22:10:08.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@380ba2d6
[2025-07-19T22:10:08.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38] for update
[2025-07-19T22:10:08.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.1.delta.10afb200-736e-4496-b55f-f692ec48dcdf.TID561.tmp
[2025-07-19T22:10:08.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54f5218
[2025-07-19T22:10:08.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37] for update
[2025-07-19T22:10:08.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.1.delta.4ba0904f-cb0d-4fa1-8be6-0c1981a1f466.TID559.tmp
[2025-07-19T22:10:08.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ee2779a
[2025-07-19T22:10:08.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21] for update
[2025-07-19T22:10:08.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6998f3e6
[2025-07-19T22:10:08.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4] for update
[2025-07-19T22:10:08.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.1.delta.a6924fda-d5e4-4031-8f55-57c691ff97b3.TID558.tmp
[2025-07-19T22:10:08.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.1.delta.5053b44e-f5a9-4a2b-9724-ca8fdc66f6f0.TID557.tmp
[2025-07-19T22:10:08.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.1.delta.8e7f2c8d-ae95-493b-a2f3-9bcb186cc154.TID555.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/1.delta
[2025-07-19T22:10:08.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/1.delta
[2025-07-19T22:10:08.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 555, attempt 0, stage 1.0)
[2025-07-19T22:10:08.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@103ea6af
[2025-07-19T22:10:08.523+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50] for update
[2025-07-19T22:10:08.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.1.delta.91e58d5d-57eb-48ab-9366-3ea52d4affc4.TID556.tmp
[2025-07-19T22:10:08.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.528+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 0 (task 555, attempt 0, stage 1.0)
[2025-07-19T22:10:08.528+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.1.delta.e1fad6c7-6ed6-4eb2-8abb-abb178a648b6.TID560.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/1.delta
[2025-07-19T22:10:08.528+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/1.delta
[2025-07-19T22:10:08.530+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 555). 6243 bytes result sent to driver
[2025-07-19T22:10:08.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 563) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 560, attempt 0, stage 1.0)
[2025-07-19T22:10:08.533+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 555) in 135 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T22:10:08.533+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 52.0 in stage 1.0 (TID 563)
[2025-07-19T22:10:08.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 43 (task 560, attempt 0, stage 1.0)
[2025-07-19T22:10:08.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 43.0 in stage 1.0 (TID 560). 6243 bytes result sent to driver
[2025-07-19T22:10:08.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 53.0 in stage 1.0 (TID 564) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 560) in 94 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T22:10:08.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 53.0 in stage 1.0 (TID 564)
[2025-07-19T22:10:08.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.1.delta.6f1e2b85-dd88-46c9-b0bd-486610a55677.TID562.tmp
[2025-07-19T22:10:08.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5acfc0fc
[2025-07-19T22:10:08.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52] for update
[2025-07-19T22:10:08.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:08.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.1.delta.10afb200-736e-4496-b55f-f692ec48dcdf.TID561.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/1.delta
[2025-07-19T22:10:08.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/1.delta
[2025-07-19T22:10:08.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.1.delta.4ba0904f-cb0d-4fa1-8be6-0c1981a1f466.TID559.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/1.delta
[2025-07-19T22:10:08.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/1.delta
[2025-07-19T22:10:08.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 559, attempt 0, stage 1.0)
[2025-07-19T22:10:08.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 561, attempt 0, stage 1.0)
[2025-07-19T22:10:08.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@753dded9
[2025-07-19T22:10:08.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 45 (task 561, attempt 0, stage 1.0)
[2025-07-19T22:10:08.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 45.0 in stage 1.0 (TID 561). 6243 bytes result sent to driver
[2025-07-19T22:10:08.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 38 (task 559, attempt 0, stage 1.0)
[2025-07-19T22:10:08.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 56.0 in stage 1.0 (TID 565) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 38.0 in stage 1.0 (TID 559). 6243 bytes result sent to driver
[2025-07-19T22:10:08.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53] for update
[2025-07-19T22:10:08.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 56.0 in stage 1.0 (TID 565)
[2025-07-19T22:10:08.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 59.0 in stage 1.0 (TID 566) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 559) in 125 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T22:10:08.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 59.0 in stage 1.0 (TID 566)
[2025-07-19T22:10:08.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 561) in 112 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T22:10:08.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:08.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.1.delta.b744a796-1c71-4245-b72c-5f82ad9482cc.TID563.tmp
[2025-07-19T22:10:08.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@550feb75
[2025-07-19T22:10:08.571+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.1.delta.5053b44e-f5a9-4a2b-9724-ca8fdc66f6f0.TID557.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/1.delta
[2025-07-19T22:10:08.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.1.delta.91e58d5d-57eb-48ab-9366-3ea52d4affc4.TID556.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/1.delta
[2025-07-19T22:10:08.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/1.delta
[2025-07-19T22:10:08.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/1.delta
[2025-07-19T22:10:08.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.1.delta.f27ed274-1058-4819-86f8-ae2ca2e1f3a6.TID564.tmp
[2025-07-19T22:10:08.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 557, attempt 0, stage 1.0)
[2025-07-19T22:10:08.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 556, attempt 0, stage 1.0)
[2025-07-19T22:10:08.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56] for update
[2025-07-19T22:10:08.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.1.delta.a6924fda-d5e4-4031-8f55-57c691ff97b3.TID558.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/1.delta
[2025-07-19T22:10:08.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/1.delta
[2025-07-19T22:10:08.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 558, attempt 0, stage 1.0)
[2025-07-19T22:10:08.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44c1a713
[2025-07-19T22:10:08.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 21 (task 557, attempt 0, stage 1.0)
[2025-07-19T22:10:08.579+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59] for update
[2025-07-19T22:10:08.579+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 21.0 in stage 1.0 (TID 557). 6243 bytes result sent to driver
[2025-07-19T22:10:08.580+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 61.0 in stage 1.0 (TID 567) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.580+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 557) in 163 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T22:10:08.580+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 61.0 in stage 1.0 (TID 567)
[2025-07-19T22:10:08.580+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 4 (task 556, attempt 0, stage 1.0)
[2025-07-19T22:10:08.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 4.0 in stage 1.0 (TID 556). 6243 bytes result sent to driver
[2025-07-19T22:10:08.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 37 (task 558, attempt 0, stage 1.0)
[2025-07-19T22:10:08.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 37.0 in stage 1.0 (TID 558). 6286 bytes result sent to driver
[2025-07-19T22:10:08.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 65.0 in stage 1.0 (TID 568) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 69.0 in stage 1.0 (TID 569) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 558) in 164 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T22:10:08.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 65.0 in stage 1.0 (TID 568)
[2025-07-19T22:10:08.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 556) in 189 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T22:10:08.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 69.0 in stage 1.0 (TID 569)
[2025-07-19T22:10:08.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.1.delta.83526891-129c-4be0-a15b-15eeae4bf80c.TID565.tmp
[2025-07-19T22:10:08.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a87c6fb
[2025-07-19T22:10:08.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61] for update
[2025-07-19T22:10:08.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.1.delta.6f1e2b85-dd88-46c9-b0bd-486610a55677.TID562.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/1.delta
[2025-07-19T22:10:08.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/1.delta
[2025-07-19T22:10:08.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 562, attempt 0, stage 1.0)
[2025-07-19T22:10:08.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.1.delta.95ebb8d9-717c-49d7-83b3-438e4b16ea8c.TID566.tmp
[2025-07-19T22:10:08.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 50 (task 562, attempt 0, stage 1.0)
[2025-07-19T22:10:08.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 50.0 in stage 1.0 (TID 562). 6243 bytes result sent to driver
[2025-07-19T22:10:08.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 70.0 in stage 1.0 (TID 570) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 70.0 in stage 1.0 (TID 570)
[2025-07-19T22:10:08.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 562) in 144 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T22:10:08.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.1.delta.f3bebe13-fba0-4c00-8c76-180d7ccbd895.TID567.tmp
[2025-07-19T22:10:08.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f0117d0
[2025-07-19T22:10:08.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69] for update
[2025-07-19T22:10:08.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.620+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@564ea6ef
[2025-07-19T22:10:08.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.1.delta.b744a796-1c71-4245-b72c-5f82ad9482cc.TID563.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/1.delta
[2025-07-19T22:10:08.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/1.delta
[2025-07-19T22:10:08.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 563, attempt 0, stage 1.0)
[2025-07-19T22:10:08.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70] for update
[2025-07-19T22:10:08.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.1.delta.e103ce3c-565e-43d4-91ad-4278fb379383.TID569.tmp
[2025-07-19T22:10:08.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.1.delta.f27ed274-1058-4819-86f8-ae2ca2e1f3a6.TID564.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/1.delta
[2025-07-19T22:10:08.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/1.delta
[2025-07-19T22:10:08.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 564, attempt 0, stage 1.0)
[2025-07-19T22:10:08.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 52 (task 563, attempt 0, stage 1.0)
[2025-07-19T22:10:08.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 52.0 in stage 1.0 (TID 563). 6243 bytes result sent to driver
[2025-07-19T22:10:08.638+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 53 (task 564, attempt 0, stage 1.0)
[2025-07-19T22:10:08.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 53.0 in stage 1.0 (TID 564). 6243 bytes result sent to driver
[2025-07-19T22:10:08.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28965c74
[2025-07-19T22:10:08.640+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 72.0 in stage 1.0 (TID 571) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65] for update
[2025-07-19T22:10:08.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 78.0 in stage 1.0 (TID 572) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 563) in 104 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T22:10:08.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 72.0 in stage 1.0 (TID 571)
[2025-07-19T22:10:08.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 53.0 in stage 1.0 (TID 564) in 97 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T22:10:08.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 78.0 in stage 1.0 (TID 572)
[2025-07-19T22:10:08.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:08.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:08.645+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.1.delta.166859cb-c747-42a1-aeb8-78edab03b839.TID570.tmp
[2025-07-19T22:10:08.647+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b1ee7ab
[2025-07-19T22:10:08.648+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.649+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78] for update
[2025-07-19T22:10:08.649+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.1.delta.83526891-129c-4be0-a15b-15eeae4bf80c.TID565.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/1.delta
[2025-07-19T22:10:08.652+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/1.delta
[2025-07-19T22:10:08.652+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.1.delta.8efd7357-a5d4-444f-bc10-c0264268a38e.TID568.tmp
[2025-07-19T22:10:08.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 565, attempt 0, stage 1.0)
[2025-07-19T22:10:08.655+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1806d411
[2025-07-19T22:10:08.655+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.656+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72] for update
[2025-07-19T22:10:08.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 56 (task 565, attempt 0, stage 1.0)
[2025-07-19T22:10:08.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.1.delta.77452bdf-b489-43e0-91ea-e457f12b347a.TID572.tmp
[2025-07-19T22:10:08.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 56.0 in stage 1.0 (TID 565). 6243 bytes result sent to driver
[2025-07-19T22:10:08.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.1.delta.95ebb8d9-717c-49d7-83b3-438e4b16ea8c.TID566.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/1.delta
[2025-07-19T22:10:08.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/1.delta
[2025-07-19T22:10:08.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 84.0 in stage 1.0 (TID 573) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.1.delta.f3bebe13-fba0-4c00-8c76-180d7ccbd895.TID567.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/1.delta
[2025-07-19T22:10:08.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/1.delta
[2025-07-19T22:10:08.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 566, attempt 0, stage 1.0)
[2025-07-19T22:10:08.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 56.0 in stage 1.0 (TID 565) in 107 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T22:10:08.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 567, attempt 0, stage 1.0)
[2025-07-19T22:10:08.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 84.0 in stage 1.0 (TID 573)
[2025-07-19T22:10:08.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 61 (task 567, attempt 0, stage 1.0)
[2025-07-19T22:10:08.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 59 (task 566, attempt 0, stage 1.0)
[2025-07-19T22:10:08.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 61.0 in stage 1.0 (TID 567). 6243 bytes result sent to driver
[2025-07-19T22:10:08.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 59.0 in stage 1.0 (TID 566). 6243 bytes result sent to driver
[2025-07-19T22:10:08.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 85.0 in stage 1.0 (TID 574) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 59.0 in stage 1.0 (TID 566) in 121 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T22:10:08.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 85.0 in stage 1.0 (TID 574)
[2025-07-19T22:10:08.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5347e007
[2025-07-19T22:10:08.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84] for update
[2025-07-19T22:10:08.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 94.0 in stage 1.0 (TID 575) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 94.0 in stage 1.0 (TID 575)
[2025-07-19T22:10:08.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 61.0 in stage 1.0 (TID 567) in 101 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T22:10:08.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.1.delta.bdb891f4-7508-4eb0-80a4-70a5d30ef220.TID571.tmp
[2025-07-19T22:10:08.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.1.delta.e103ce3c-565e-43d4-91ad-4278fb379383.TID569.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/1.delta
[2025-07-19T22:10:08.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/1.delta
[2025-07-19T22:10:08.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:08.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:08.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 569, attempt 0, stage 1.0)
[2025-07-19T22:10:08.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4741aaa6
[2025-07-19T22:10:08.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 69 (task 569, attempt 0, stage 1.0)
[2025-07-19T22:10:08.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 69.0 in stage 1.0 (TID 569). 6243 bytes result sent to driver
[2025-07-19T22:10:08.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94] for update
[2025-07-19T22:10:08.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 95.0 in stage 1.0 (TID 576) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 69.0 in stage 1.0 (TID 569) in 107 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T22:10:08.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.1.delta.955cdaee-d821-4ff0-8a82-95e1aecd9ddb.TID573.tmp
[2025-07-19T22:10:08.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 95.0 in stage 1.0 (TID 576)
[2025-07-19T22:10:08.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.1.delta.166859cb-c747-42a1-aeb8-78edab03b839.TID570.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/1.delta
[2025-07-19T22:10:08.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/1.delta
[2025-07-19T22:10:08.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 570, attempt 0, stage 1.0)
[2025-07-19T22:10:08.704+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:08.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c7a30fc
[2025-07-19T22:10:08.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85] for update
[2025-07-19T22:10:08.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 70 (task 570, attempt 0, stage 1.0)
[2025-07-19T22:10:08.709+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.710+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 70.0 in stage 1.0 (TID 570). 6243 bytes result sent to driver
[2025-07-19T22:10:08.711+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.1.delta.8efd7357-a5d4-444f-bc10-c0264268a38e.TID568.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/1.delta
[2025-07-19T22:10:08.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/1.delta
[2025-07-19T22:10:08.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 568, attempt 0, stage 1.0)
[2025-07-19T22:10:08.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 98.0 in stage 1.0 (TID 577) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 70.0 in stage 1.0 (TID 570) in 104 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T22:10:08.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 98.0 in stage 1.0 (TID 577)
[2025-07-19T22:10:08.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 65 (task 568, attempt 0, stage 1.0)
[2025-07-19T22:10:08.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 65.0 in stage 1.0 (TID 568). 6243 bytes result sent to driver
[2025-07-19T22:10:08.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 101.0 in stage 1.0 (TID 578) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 101.0 in stage 1.0 (TID 578)
[2025-07-19T22:10:08.719+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 65.0 in stage 1.0 (TID 568) in 134 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T22:10:08.719+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23be4ffb
[2025-07-19T22:10:08.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.1.delta.77452bdf-b489-43e0-91ea-e457f12b347a.TID572.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/1.delta
[2025-07-19T22:10:08.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/1.delta
[2025-07-19T22:10:08.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 572, attempt 0, stage 1.0)
[2025-07-19T22:10:08.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.1.delta.f1796e3b-2534-4c1c-b97b-c2fa4fb2f536.TID575.tmp
[2025-07-19T22:10:08.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95] for update
[2025-07-19T22:10:08.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 78 (task 572, attempt 0, stage 1.0)
[2025-07-19T22:10:08.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:08.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 78.0 in stage 1.0 (TID 572). 6243 bytes result sent to driver
[2025-07-19T22:10:08.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 108.0 in stage 1.0 (TID 579) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 78.0 in stage 1.0 (TID 572) in 93 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T22:10:08.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 108.0 in stage 1.0 (TID 579)
[2025-07-19T22:10:08.730+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.733+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.1.delta.137f44df-cfc0-4f24-96f3-70e07e5b8e1c.TID574.tmp
[2025-07-19T22:10:08.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ddbc89d
[2025-07-19T22:10:08.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101] for update
[2025-07-19T22:10:08.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.1.delta.89ca68cd-f91f-47c9-88dd-5cdbd0b9ebd2.TID576.tmp
[2025-07-19T22:10:08.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.743+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1534c4ff
[2025-07-19T22:10:08.743+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.744+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.1.delta.bdb891f4-7508-4eb0-80a4-70a5d30ef220.TID571.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/1.delta
[2025-07-19T22:10:08.744+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/1.delta
[2025-07-19T22:10:08.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98] for update
[2025-07-19T22:10:08.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 571, attempt 0, stage 1.0)
[2025-07-19T22:10:08.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@342e3297
[2025-07-19T22:10:08.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 72 (task 571, attempt 0, stage 1.0)
[2025-07-19T22:10:08.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.1.delta.955cdaee-d821-4ff0-8a82-95e1aecd9ddb.TID573.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/1.delta
[2025-07-19T22:10:08.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/1.delta
[2025-07-19T22:10:08.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108] for update
[2025-07-19T22:10:08.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 72.0 in stage 1.0 (TID 571). 6243 bytes result sent to driver
[2025-07-19T22:10:08.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 115.0 in stage 1.0 (TID 580) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 573, attempt 0, stage 1.0)
[2025-07-19T22:10:08.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 72.0 in stage 1.0 (TID 571) in 119 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T22:10:08.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.1.delta.7866cfe4-3fc6-4154-8538-873d3654cb3a.TID578.tmp
[2025-07-19T22:10:08.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 115.0 in stage 1.0 (TID 580)
[2025-07-19T22:10:08.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 84 (task 573, attempt 0, stage 1.0)
[2025-07-19T22:10:08.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 84.0 in stage 1.0 (TID 573). 6243 bytes result sent to driver
[2025-07-19T22:10:08.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.1.delta.9124a07c-2f4a-4969-8b55-57f7bf63ca6a.TID577.tmp
[2025-07-19T22:10:08.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 121.0 in stage 1.0 (TID 581) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 121.0 in stage 1.0 (TID 581)
[2025-07-19T22:10:08.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 84.0 in stage 1.0 (TID 573) in 100 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T22:10:08.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.1.delta.2bf86261-2d0f-4a96-b2a5-8c77bfb89672.TID579.tmp
[2025-07-19T22:10:08.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4617d0df
[2025-07-19T22:10:08.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115] for update
[2025-07-19T22:10:08.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4657a39b
[2025-07-19T22:10:08.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.1.delta.f1796e3b-2534-4c1c-b97b-c2fa4fb2f536.TID575.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/1.delta
[2025-07-19T22:10:08.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/1.delta
[2025-07-19T22:10:08.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 575, attempt 0, stage 1.0)
[2025-07-19T22:10:08.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121] for update
[2025-07-19T22:10:08.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 94 (task 575, attempt 0, stage 1.0)
[2025-07-19T22:10:08.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 94.0 in stage 1.0 (TID 575). 6243 bytes result sent to driver
[2025-07-19T22:10:08.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 122.0 in stage 1.0 (TID 582) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 94.0 in stage 1.0 (TID 575) in 109 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T22:10:08.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 122.0 in stage 1.0 (TID 582)
[2025-07-19T22:10:08.789+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.1.delta.137f44df-cfc0-4f24-96f3-70e07e5b8e1c.TID574.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/1.delta
[2025-07-19T22:10:08.789+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/1.delta
[2025-07-19T22:10:08.789+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.1.delta.f4fbe727-67a3-47ab-8b8e-c1e944be72f8.TID580.tmp
[2025-07-19T22:10:08.790+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 574, attempt 0, stage 1.0)
[2025-07-19T22:10:08.794+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.1.delta.89ca68cd-f91f-47c9-88dd-5cdbd0b9ebd2.TID576.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/1.delta
[2025-07-19T22:10:08.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/1.delta
[2025-07-19T22:10:08.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 576, attempt 0, stage 1.0)
[2025-07-19T22:10:08.796+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 85 (task 574, attempt 0, stage 1.0)
[2025-07-19T22:10:08.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 85.0 in stage 1.0 (TID 574). 6243 bytes result sent to driver
[2025-07-19T22:10:08.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 129.0 in stage 1.0 (TID 583) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 85.0 in stage 1.0 (TID 574) in 120 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T22:10:08.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 129.0 in stage 1.0 (TID 583)
[2025-07-19T22:10:08.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e5c7e4c
[2025-07-19T22:10:08.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 95 (task 576, attempt 0, stage 1.0)
[2025-07-19T22:10:08.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122] for update
[2025-07-19T22:10:08.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 95.0 in stage 1.0 (TID 576). 6243 bytes result sent to driver
[2025-07-19T22:10:08.800+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 132.0 in stage 1.0 (TID 584) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.801+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 95.0 in stage 1.0 (TID 576) in 103 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T22:10:08.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 132.0 in stage 1.0 (TID 584)
[2025-07-19T22:10:08.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.1.delta.7fb453b3-8d9a-48f5-b31d-604a66bd501d.TID581.tmp
[2025-07-19T22:10:08.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@411ea480
[2025-07-19T22:10:08.809+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.811+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132] for update
[2025-07-19T22:10:08.812+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.1.delta.7866cfe4-3fc6-4154-8538-873d3654cb3a.TID578.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/1.delta
[2025-07-19T22:10:08.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/1.delta
[2025-07-19T22:10:08.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 578, attempt 0, stage 1.0)
[2025-07-19T22:10:08.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.1.delta.0631c3a0-6511-4f68-925b-a7a5619475bb.TID582.tmp
[2025-07-19T22:10:08.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 101 (task 578, attempt 0, stage 1.0)
[2025-07-19T22:10:08.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 101.0 in stage 1.0 (TID 578). 6243 bytes result sent to driver
[2025-07-19T22:10:08.821+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2572e71f
[2025-07-19T22:10:08.821+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 133.0 in stage 1.0 (TID 585) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 101.0 in stage 1.0 (TID 578) in 104 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T22:10:08.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129] for update
[2025-07-19T22:10:08.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 133.0 in stage 1.0 (TID 585)
[2025-07-19T22:10:08.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.1.delta.2bf86261-2d0f-4a96-b2a5-8c77bfb89672.TID579.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/1.delta
[2025-07-19T22:10:08.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/1.delta
[2025-07-19T22:10:08.831+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.1.delta.9124a07c-2f4a-4969-8b55-57f7bf63ca6a.TID577.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/1.delta
[2025-07-19T22:10:08.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/1.delta
[2025-07-19T22:10:08.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 579, attempt 0, stage 1.0)
[2025-07-19T22:10:08.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 577, attempt 0, stage 1.0)
[2025-07-19T22:10:08.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 108 (task 579, attempt 0, stage 1.0)
[2025-07-19T22:10:08.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 108.0 in stage 1.0 (TID 579). 6243 bytes result sent to driver
[2025-07-19T22:10:08.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.1.delta.d1f275ab-6e14-4617-ab39-b21c46d5b558.TID584.tmp
[2025-07-19T22:10:08.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 139.0 in stage 1.0 (TID 586) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 98 (task 577, attempt 0, stage 1.0)
[2025-07-19T22:10:08.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 98.0 in stage 1.0 (TID 577). 6243 bytes result sent to driver
[2025-07-19T22:10:08.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 139.0 in stage 1.0 (TID 586)
[2025-07-19T22:10:08.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 108.0 in stage 1.0 (TID 579) in 106 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T22:10:08.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.1.delta.f4fbe727-67a3-47ab-8b8e-c1e944be72f8.TID580.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/1.delta
[2025-07-19T22:10:08.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/1.delta
[2025-07-19T22:10:08.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 580, attempt 0, stage 1.0)
[2025-07-19T22:10:08.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 146.0 in stage 1.0 (TID 587) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44bb905a
[2025-07-19T22:10:08.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 98.0 in stage 1.0 (TID 577) in 125 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T22:10:08.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 146.0 in stage 1.0 (TID 587)
[2025-07-19T22:10:08.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133] for update
[2025-07-19T22:10:08.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 115 (task 580, attempt 0, stage 1.0)
[2025-07-19T22:10:08.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 115.0 in stage 1.0 (TID 580). 6243 bytes result sent to driver
[2025-07-19T22:10:08.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 150.0 in stage 1.0 (TID 588) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.1.delta.096d5bb3-1864-40ec-a5fe-dce9d1fa1c6d.TID583.tmp
[2025-07-19T22:10:08.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 150.0 in stage 1.0 (TID 588)
[2025-07-19T22:10:08.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 115.0 in stage 1.0 (TID 580) in 90 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T22:10:08.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.1.delta.7fb453b3-8d9a-48f5-b31d-604a66bd501d.TID581.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/1.delta
[2025-07-19T22:10:08.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/1.delta
[2025-07-19T22:10:08.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 581, attempt 0, stage 1.0)
[2025-07-19T22:10:08.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@632e3c06
[2025-07-19T22:10:08.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139] for update
[2025-07-19T22:10:08.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 121 (task 581, attempt 0, stage 1.0)
[2025-07-19T22:10:08.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 121.0 in stage 1.0 (TID 581). 6286 bytes result sent to driver
[2025-07-19T22:10:08.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 154.0 in stage 1.0 (TID 589) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32c3f394
[2025-07-19T22:10:08.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 121.0 in stage 1.0 (TID 581) in 95 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T22:10:08.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 154.0 in stage 1.0 (TID 589)
[2025-07-19T22:10:08.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146] for update
[2025-07-19T22:10:08.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.863+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33379153
[2025-07-19T22:10:08.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.1.delta.937e4d3b-6532-4cb0-9ec6-011ad524e355.TID585.tmp
[2025-07-19T22:10:08.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150] for update
[2025-07-19T22:10:08.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.1.delta.0631c3a0-6511-4f68-925b-a7a5619475bb.TID582.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/1.delta
[2025-07-19T22:10:08.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/1.delta
[2025-07-19T22:10:08.873+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 582, attempt 0, stage 1.0)
[2025-07-19T22:10:08.873+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.1.delta.0a80c1d4-3f99-45d8-9512-eb7ffee426de.TID586.tmp
[2025-07-19T22:10:08.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 122 (task 582, attempt 0, stage 1.0)
[2025-07-19T22:10:08.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 122.0 in stage 1.0 (TID 582). 6243 bytes result sent to driver
[2025-07-19T22:10:08.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 158.0 in stage 1.0 (TID 590) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 158.0 in stage 1.0 (TID 590)
[2025-07-19T22:10:08.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 122.0 in stage 1.0 (TID 582) in 92 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T22:10:08.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.1.delta.067075be-5a7b-4d74-bab0-48e3a99a278f.TID588.tmp
[2025-07-19T22:10:08.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31face40
[2025-07-19T22:10:08.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.1.delta.144cbfe6-b6fe-4b45-b674-4c44999a63ca.TID587.tmp
[2025-07-19T22:10:08.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:08.885+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154] for update
[2025-07-19T22:10:08.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.1.delta.d1f275ab-6e14-4617-ab39-b21c46d5b558.TID584.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/1.delta
[2025-07-19T22:10:08.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/1.delta
[2025-07-19T22:10:08.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 584, attempt 0, stage 1.0)
[2025-07-19T22:10:08.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15e9584
[2025-07-19T22:10:08.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.896+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158] for update
[2025-07-19T22:10:08.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 132 (task 584, attempt 0, stage 1.0)
[2025-07-19T22:10:08.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.1.delta.096d5bb3-1864-40ec-a5fe-dce9d1fa1c6d.TID583.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/1.delta
[2025-07-19T22:10:08.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/1.delta
[2025-07-19T22:10:08.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 583, attempt 0, stage 1.0)
[2025-07-19T22:10:08.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 132.0 in stage 1.0 (TID 584). 6243 bytes result sent to driver
[2025-07-19T22:10:08.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 129 (task 583, attempt 0, stage 1.0)
[2025-07-19T22:10:08.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 163.0 in stage 1.0 (TID 591) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 129.0 in stage 1.0 (TID 583). 6243 bytes result sent to driver
[2025-07-19T22:10:08.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 163.0 in stage 1.0 (TID 591)
[2025-07-19T22:10:08.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 132.0 in stage 1.0 (TID 584) in 108 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T22:10:08.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 167.0 in stage 1.0 (TID 592) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 167.0 in stage 1.0 (TID 592)
[2025-07-19T22:10:08.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 129.0 in stage 1.0 (TID 583) in 110 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T22:10:08.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.917+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.1.delta.937e4d3b-6532-4cb0-9ec6-011ad524e355.TID585.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/1.delta
[2025-07-19T22:10:08.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/1.delta
[2025-07-19T22:10:08.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.1.delta.0a80c1d4-3f99-45d8-9512-eb7ffee426de.TID586.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/1.delta
[2025-07-19T22:10:08.920+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/1.delta
[2025-07-19T22:10:08.920+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 585, attempt 0, stage 1.0)
[2025-07-19T22:10:08.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 586, attempt 0, stage 1.0)
[2025-07-19T22:10:08.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54d0b1a3
[2025-07-19T22:10:08.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.1.delta.f9f1e58d-d195-4a5d-acbf-cec05608574c.TID590.tmp
[2025-07-19T22:10:08.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.1.delta.a62fda91-ee5c-450f-84a9-a1364b712082.TID589.tmp
[2025-07-19T22:10:08.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167] for update
[2025-07-19T22:10:08.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 133 (task 585, attempt 0, stage 1.0)
[2025-07-19T22:10:08.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 139 (task 586, attempt 0, stage 1.0)
[2025-07-19T22:10:08.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 139.0 in stage 1.0 (TID 586). 6243 bytes result sent to driver
[2025-07-19T22:10:08.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 133.0 in stage 1.0 (TID 585). 6243 bytes result sent to driver
[2025-07-19T22:10:08.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 170.0 in stage 1.0 (TID 593) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 170.0 in stage 1.0 (TID 593)
[2025-07-19T22:10:08.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 171.0 in stage 1.0 (TID 594) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 139.0 in stage 1.0 (TID 586) in 97 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T22:10:08.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 133.0 in stage 1.0 (TID 585) in 110 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T22:10:08.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 171.0 in stage 1.0 (TID 594)
[2025-07-19T22:10:08.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@308fec90
[2025-07-19T22:10:08.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:08.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.1.delta.067075be-5a7b-4d74-bab0-48e3a99a278f.TID588.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/1.delta
[2025-07-19T22:10:08.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/1.delta
[2025-07-19T22:10:08.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163] for update
[2025-07-19T22:10:08.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 588, attempt 0, stage 1.0)
[2025-07-19T22:10:08.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 150 (task 588, attempt 0, stage 1.0)
[2025-07-19T22:10:08.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 150.0 in stage 1.0 (TID 588). 6243 bytes result sent to driver
[2025-07-19T22:10:08.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 172.0 in stage 1.0 (TID 595) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 172.0 in stage 1.0 (TID 595)
[2025-07-19T22:10:08.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e56df74
[2025-07-19T22:10:08.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 150.0 in stage 1.0 (TID 588) in 104 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T22:10:08.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171] for update
[2025-07-19T22:10:08.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.1.delta.b0796f00-e927-4f9d-8e27-440c3f7a6a6c.TID592.tmp
[2025-07-19T22:10:08.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.1.delta.144cbfe6-b6fe-4b45-b674-4c44999a63ca.TID587.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/1.delta
[2025-07-19T22:10:08.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/1.delta
[2025-07-19T22:10:08.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 587, attempt 0, stage 1.0)
[2025-07-19T22:10:08.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.1.delta.4d3becd8-8f58-4cf1-b283-190b58101900.TID591.tmp
[2025-07-19T22:10:08.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 146 (task 587, attempt 0, stage 1.0)
[2025-07-19T22:10:08.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cd5c97a
[2025-07-19T22:10:08.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.955+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170] for update
[2025-07-19T22:10:08.960+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 146.0 in stage 1.0 (TID 587). 6286 bytes result sent to driver
[2025-07-19T22:10:08.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 180.0 in stage 1.0 (TID 596) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 146.0 in stage 1.0 (TID 587) in 127 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T22:10:08.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.1.delta.59d8505f-e209-4900-8a2c-6ddd23232684.TID594.tmp
[2025-07-19T22:10:08.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 180.0 in stage 1.0 (TID 596)
[2025-07-19T22:10:08.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c23778e
[2025-07-19T22:10:08.964+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172] for update
[2025-07-19T22:10:08.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.970+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.1.delta.a62fda91-ee5c-450f-84a9-a1364b712082.TID589.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/1.delta
[2025-07-19T22:10:08.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/1.delta
[2025-07-19T22:10:08.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 589, attempt 0, stage 1.0)
[2025-07-19T22:10:08.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.1.delta.fa542b94-93da-4ad0-8f9b-ac7dcaf74742.TID593.tmp
[2025-07-19T22:10:08.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 154 (task 589, attempt 0, stage 1.0)
[2025-07-19T22:10:08.977+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 154.0 in stage 1.0 (TID 589). 6243 bytes result sent to driver
[2025-07-19T22:10:08.977+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.1.delta.f9f1e58d-d195-4a5d-acbf-cec05608574c.TID590.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/1.delta
[2025-07-19T22:10:08.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/1.delta
[2025-07-19T22:10:08.980+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 181.0 in stage 1.0 (TID 597) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.981+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 181.0 in stage 1.0 (TID 597)
[2025-07-19T22:10:08.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 590, attempt 0, stage 1.0)
[2025-07-19T22:10:08.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 154.0 in stage 1.0 (TID 589) in 123 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T22:10:08.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32c53ff1
[2025-07-19T22:10:08.985+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:08.986+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180] for update
[2025-07-19T22:10:08.987+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.1.delta.5be79592-4b5e-4f3f-bc58-8d1b3da72cb6.TID595.tmp
[2025-07-19T22:10:08.989+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.989+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:08.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 158 (task 590, attempt 0, stage 1.0)
[2025-07-19T22:10:08.994+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 158.0 in stage 1.0 (TID 590). 6243 bytes result sent to driver
[2025-07-19T22:10:08.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 186.0 in stage 1.0 (TID 598) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:08.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 158.0 in stage 1.0 (TID 590) in 110 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T22:10:08.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 186.0 in stage 1.0 (TID 598)
[2025-07-19T22:10:08.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:08.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:08.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.1.delta.fadbfb13-0917-4738-b1f9-38e2456733c5.TID596.tmp
[2025-07-19T22:10:09.000+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19732111
[2025-07-19T22:10:09.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.1.delta.4d3becd8-8f58-4cf1-b283-190b58101900.TID591.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/1.delta
[2025-07-19T22:10:09.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/1.delta
[2025-07-19T22:10:09.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 591, attempt 0, stage 1.0)
[2025-07-19T22:10:09.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:09.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181] for update
[2025-07-19T22:10:09.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO DataWritingSparkTask: Committed partition 163 (task 591, attempt 0, stage 1.0)
[2025-07-19T22:10:09.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Finished task 163.0 in stage 1.0 (TID 591). 6243 bytes result sent to driver
[2025-07-19T22:10:09.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Starting task 189.0 in stage 1.0 (TID 599) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.004+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO Executor: Running task 189.0 in stage 1.0 (TID 599)
[2025-07-19T22:10:09.004+0000] {subprocess.py:93} INFO - 25/07/19 22:10:08 INFO TaskSetManager: Finished task 163.0 in stage 1.0 (TID 591) in 95 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T22:10:09.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.1.delta.59d8505f-e209-4900-8a2c-6ddd23232684.TID594.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/1.delta
[2025-07-19T22:10:09.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/1.delta
[2025-07-19T22:10:09.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 594, attempt 0, stage 1.0)
[2025-07-19T22:10:09.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.008+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 171 (task 594, attempt 0, stage 1.0)
[2025-07-19T22:10:09.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.1.delta.b0796f00-e927-4f9d-8e27-440c3f7a6a6c.TID592.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/1.delta
[2025-07-19T22:10:09.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/1.delta
[2025-07-19T22:10:09.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 171.0 in stage 1.0 (TID 594). 6200 bytes result sent to driver
[2025-07-19T22:10:09.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 192.0 in stage 1.0 (TID 600) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 192.0 in stage 1.0 (TID 600)
[2025-07-19T22:10:09.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32b521dd
[2025-07-19T22:10:09.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 171.0 in stage 1.0 (TID 594) in 85 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T22:10:09.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:09.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 592, attempt 0, stage 1.0)
[2025-07-19T22:10:09.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186] for update
[2025-07-19T22:10:09.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.020+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.1.delta.91c80166-17c0-4a70-8c05-b70043341203.TID597.tmp
[2025-07-19T22:10:09.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.1.delta.fa542b94-93da-4ad0-8f9b-ac7dcaf74742.TID593.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/1.delta
[2025-07-19T22:10:09.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/1.delta
[2025-07-19T22:10:09.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 593, attempt 0, stage 1.0)
[2025-07-19T22:10:09.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 167 (task 592, attempt 0, stage 1.0)
[2025-07-19T22:10:09.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1178d40f
[2025-07-19T22:10:09.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:09.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189] for update
[2025-07-19T22:10:09.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.1.delta.a80e5faa-2d29-4daf-bf4b-68e7741844b1.TID598.tmp
[2025-07-19T22:10:09.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 167.0 in stage 1.0 (TID 592). 6286 bytes result sent to driver
[2025-07-19T22:10:09.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.1.delta.5be79592-4b5e-4f3f-bc58-8d1b3da72cb6.TID595.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/1.delta
[2025-07-19T22:10:09.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/1.delta
[2025-07-19T22:10:09.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 193.0 in stage 1.0 (TID 601) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 595, attempt 0, stage 1.0)
[2025-07-19T22:10:09.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 193.0 in stage 1.0 (TID 601)
[2025-07-19T22:10:09.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 167.0 in stage 1.0 (TID 592) in 128 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T22:10:09.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 170 (task 593, attempt 0, stage 1.0)
[2025-07-19T22:10:09.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 170.0 in stage 1.0 (TID 593). 6243 bytes result sent to driver
[2025-07-19T22:10:09.043+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 195.0 in stage 1.0 (TID 602) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 195.0 in stage 1.0 (TID 602)
[2025-07-19T22:10:09.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.1.delta.8aad0513-74e0-4799-b90b-48ebf1cd7d51.TID599.tmp
[2025-07-19T22:10:09.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 170.0 in stage 1.0 (TID 593) in 116 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T22:10:09.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.1.delta.fadbfb13-0917-4738-b1f9-38e2456733c5.TID596.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/1.delta
[2025-07-19T22:10:09.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/1.delta
[2025-07-19T22:10:09.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 596, attempt 0, stage 1.0)
[2025-07-19T22:10:09.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.056+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:09.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42d8ae9b
[2025-07-19T22:10:09.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 172 (task 595, attempt 0, stage 1.0)
[2025-07-19T22:10:09.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 180 (task 596, attempt 0, stage 1.0)
[2025-07-19T22:10:09.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 180.0 in stage 1.0 (TID 596). 6200 bytes result sent to driver
[2025-07-19T22:10:09.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:09.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192] for update
[2025-07-19T22:10:09.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.116+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 603) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 0.0 in stage 7.0 (TID 603)
[2025-07-19T22:10:09.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 180.0 in stage 1.0 (TID 596) in 149 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T22:10:09.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 172.0 in stage 1.0 (TID 595). 6286 bytes result sent to driver
[2025-07-19T22:10:09.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 604) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 1.0 in stage 7.0 (TID 604)
[2025-07-19T22:10:09.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71c81a17
[2025-07-19T22:10:09.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.1.delta.91c80166-17c0-4a70-8c05-b70043341203.TID597.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/1.delta
[2025-07-19T22:10:09.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/1.delta
[2025-07-19T22:10:09.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.129+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.130+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:09.131+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193] for update
[2025-07-19T22:10:09.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 597, attempt 0, stage 1.0)
[2025-07-19T22:10:09.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 172.0 in stage 1.0 (TID 595) in 178 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T22:10:09.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 181 (task 597, attempt 0, stage 1.0)
[2025-07-19T22:10:09.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 181.0 in stage 1.0 (TID 597). 6243 bytes result sent to driver
[2025-07-19T22:10:09.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 605) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 181.0 in stage 1.0 (TID 597) in 152 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T22:10:09.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 2.0 in stage 7.0 (TID 605)
[2025-07-19T22:10:09.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.1.delta.4e52d766-6b5a-4ba4-b0ea-4edc0f53586a.TID601.tmp
[2025-07-19T22:10:09.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3919220b
[2025-07-19T22:10:09.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:09.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195] for update
[2025-07-19T22:10:09.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.1.delta.0e6ba29e-2918-4f3b-a735-bcd77c715413.TID600.tmp
[2025-07-19T22:10:09.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ff2b35f
[2025-07-19T22:10:09.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2] for update
[2025-07-19T22:10:09.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.1.delta.8aad0513-74e0-4799-b90b-48ebf1cd7d51.TID599.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/1.delta
[2025-07-19T22:10:09.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/1.delta
[2025-07-19T22:10:09.153+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 599, attempt 0, stage 1.0)
[2025-07-19T22:10:09.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bd7f60
[2025-07-19T22:10:09.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1] for update
[2025-07-19T22:10:09.160+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.1.delta.a80e5faa-2d29-4daf-bf4b-68e7741844b1.TID598.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/1.delta
[2025-07-19T22:10:09.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/1.delta
[2025-07-19T22:10:09.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 598, attempt 0, stage 1.0)
[2025-07-19T22:10:09.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodeGenerator: Code generated in 16.101291 ms
[2025-07-19T22:10:09.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 189 (task 599, attempt 0, stage 1.0)
[2025-07-19T22:10:09.165+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.166+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 186 (task 598, attempt 0, stage 1.0)
[2025-07-19T22:10:09.166+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 189.0 in stage 1.0 (TID 599). 6243 bytes result sent to driver
[2025-07-19T22:10:09.167+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 606) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.168+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 3.0 in stage 7.0 (TID 606)
[2025-07-19T22:10:09.169+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 189.0 in stage 1.0 (TID 599) in 165 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T22:10:09.171+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 186.0 in stage 1.0 (TID 598). 6243 bytes result sent to driver
[2025-07-19T22:10:09.171+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 186.0 in stage 1.0 (TID 598) in 178 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T22:10:09.171+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.171+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.172+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60e6df5b
[2025-07-19T22:10:09.173+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.1.delta.1970a490-9a8f-48dc-8bb5-2aaf5e315a33.TID602.tmp
[2025-07-19T22:10:09.174+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.175+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0] for update
[2025-07-19T22:10:09.176+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 607) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 4.0 in stage 7.0 (TID 607)
[2025-07-19T22:10:09.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42eb68bc
[2025-07-19T22:10:09.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.2.delta.4ff18b4c-a793-456c-a26e-9c18ce0d4f07.TID604.tmp
[2025-07-19T22:10:09.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3] for update
[2025-07-19T22:10:09.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b4d7448
[2025-07-19T22:10:09.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4] for update
[2025-07-19T22:10:09.185+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.2.delta.1c0ae805-ef98-4e3a-a1fc-3a5db6649f14.TID605.tmp
[2025-07-19T22:10:09.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.192+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.2.delta.68c937ae-ae51-4be6-869e-7906eb6ce267.TID603.tmp
[2025-07-19T22:10:09.194+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.2.delta.bc9c6eb1-6f80-46ea-989d-0a9aaa84d2fe.TID606.tmp
[2025-07-19T22:10:09.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.2.delta.4e029cab-3313-4c80-9ed1-3a683557e212.TID607.tmp
[2025-07-19T22:10:09.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.1.delta.4e52d766-6b5a-4ba4-b0ea-4edc0f53586a.TID601.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/1.delta
[2025-07-19T22:10:09.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/1.delta
[2025-07-19T22:10:09.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 601, attempt 0, stage 1.0)
[2025-07-19T22:10:09.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 193 (task 601, attempt 0, stage 1.0)
[2025-07-19T22:10:09.206+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 193.0 in stage 1.0 (TID 601). 6243 bytes result sent to driver
[2025-07-19T22:10:09.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 608) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 193.0 in stage 1.0 (TID 601) in 171 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T22:10:09.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 5.0 in stage 7.0 (TID 608)
[2025-07-19T22:10:09.209+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.211+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.1.delta.0e6ba29e-2918-4f3b-a735-bcd77c715413.TID600.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/1.delta
[2025-07-19T22:10:09.211+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/1.delta
[2025-07-19T22:10:09.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@988ce89
[2025-07-19T22:10:09.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 600, attempt 0, stage 1.0)
[2025-07-19T22:10:09.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5] for update
[2025-07-19T22:10:09.213+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.219+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 192 (task 600, attempt 0, stage 1.0)
[2025-07-19T22:10:09.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 192.0 in stage 1.0 (TID 600). 6243 bytes result sent to driver
[2025-07-19T22:10:09.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 609) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 6.0 in stage 7.0 (TID 609)
[2025-07-19T22:10:09.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 192.0 in stage 1.0 (TID 600) in 209 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T22:10:09.225+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.226+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ef19ffa
[2025-07-19T22:10:09.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6] for update
[2025-07-19T22:10:09.229+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.1.delta.1970a490-9a8f-48dc-8bb5-2aaf5e315a33.TID602.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/1.delta
[2025-07-19T22:10:09.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/1.delta
[2025-07-19T22:10:09.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 602, attempt 0, stage 1.0)
[2025-07-19T22:10:09.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.2.delta.f61cf468-26df-41ae-8dc5-b47486287486.TID608.tmp
[2025-07-19T22:10:09.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.2.delta.4ff18b4c-a793-456c-a26e-9c18ce0d4f07.TID604.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/2.delta
[2025-07-19T22:10:09.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/1/2.delta
[2025-07-19T22:10:09.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T22:10:09.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.2.delta.d737144b-9991-4b07-87f5-41610d17959b.TID609.tmp
[2025-07-19T22:10:09.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 195 (task 602, attempt 0, stage 1.0)
[2025-07-19T22:10:09.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.2.delta.1c0ae805-ef98-4e3a-a1fc-3a5db6649f14.TID605.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/2.delta
[2025-07-19T22:10:09.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/2/2.delta
[2025-07-19T22:10:09.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T22:10:09.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 195.0 in stage 1.0 (TID 602). 6286 bytes result sent to driver
[2025-07-19T22:10:09.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T22:10:09.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T22:10:09.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 1.0 in stage 7.0 (TID 604). 5872 bytes result sent to driver
[2025-07-19T22:10:09.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 2.0 in stage 7.0 (TID 605). 5872 bytes result sent to driver
[2025-07-19T22:10:09.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 610) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 195.0 in stage 1.0 (TID 602) in 209 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T22:10:09.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-19T22:10:09.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 611) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 612) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 8.0 in stage 7.0 (TID 611)
[2025-07-19T22:10:09.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DAGScheduler: ResultStage 1 (start at <unknown>:0) finished in 16.707 s
[2025-07-19T22:10:09.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 605) in 124 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T22:10:09.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 604) in 138 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T22:10:09.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T22:10:09.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-07-19T22:10:09.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 7.0 in stage 7.0 (TID 610)
[2025-07-19T22:10:09.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DAGScheduler: Job 2 finished: start at <unknown>:0, took 18.516942 s
[2025-07-19T22:10:09.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T22:10:09.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Committing epoch 0 for query 76699ab7-445a-4f4e-a8af-51ec24e5ea93 in append mode
[2025-07-19T22:10:09.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77f69102
[2025-07-19T22:10:09.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7] for update
[2025-07-19T22:10:09.266+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.2.delta.4e029cab-3313-4c80-9ed1-3a683557e212.TID607.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/2.delta
[2025-07-19T22:10:09.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/4/2.delta
[2025-07-19T22:10:09.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.271+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 9.0 in stage 7.0 (TID 612)
[2025-07-19T22:10:09.271+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.2.delta.bc9c6eb1-6f80-46ea-989d-0a9aaa84d2fe.TID606.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/2.delta
[2025-07-19T22:10:09.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/3/2.delta
[2025-07-19T22:10:09.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T22:10:09.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T22:10:09.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T22:10:09.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 3.0 in stage 7.0 (TID 606). 5872 bytes result sent to driver
[2025-07-19T22:10:09.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@375719b6
[2025-07-19T22:10:09.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 613) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.2.delta.68c937ae-ae51-4be6-869e-7906eb6ce267.TID603.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/2.delta
[2025-07-19T22:10:09.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/0/2.delta
[2025-07-19T22:10:09.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8] for update
[2025-07-19T22:10:09.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 10.0 in stage 7.0 (TID 613)
[2025-07-19T22:10:09.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T22:10:09.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.2.delta.39bde759-f276-4f70-bbba-a11ace3cddf7.TID610.tmp
[2025-07-19T22:10:09.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 606) in 103 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T22:10:09.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51d80f9c
[2025-07-19T22:10:09.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T22:10:09.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 4.0 in stage 7.0 (TID 607). 5872 bytes result sent to driver
[2025-07-19T22:10:09.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 614) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 607) in 101 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T22:10:09.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T22:10:09.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 11.0 in stage 7.0 (TID 614)
[2025-07-19T22:10:09.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 0.0 in stage 7.0 (TID 603). 5872 bytes result sent to driver
[2025-07-19T22:10:09.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 615) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 603) in 167 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T22:10:09.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 12.0 in stage 7.0 (TID 615)
[2025-07-19T22:10:09.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.291+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Committing streaming append with 152 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.291+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10] for update
[2025-07-19T22:10:09.293+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.295+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@200f5975
[2025-07-19T22:10:09.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.297+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12] for update
[2025-07-19T22:10:09.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.299+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6417f9da
[2025-07-19T22:10:09.300+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.300+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79e0e0ab
[2025-07-19T22:10:09.302+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11] for update
[2025-07-19T22:10:09.303+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.303+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9] for update
[2025-07-19T22:10:09.303+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.2.delta.d737144b-9991-4b07-87f5-41610d17959b.TID609.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/2.delta
[2025-07-19T22:10:09.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/6/2.delta
[2025-07-19T22:10:09.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T22:10:09.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.2.delta.933f163b-a7da-4208-9042-ca1a83811b82.TID611.tmp
[2025-07-19T22:10:09.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.2.delta.f61cf468-26df-41ae-8dc5-b47486287486.TID608.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/2.delta
[2025-07-19T22:10:09.311+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/5/2.delta
[2025-07-19T22:10:09.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T22:10:09.313+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T22:10:09.313+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 6.0 in stage 7.0 (TID 609). 5872 bytes result sent to driver
[2025-07-19T22:10:09.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 616) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 609) in 86 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T22:10:09.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 13.0 in stage 7.0 (TID 616)
[2025-07-19T22:10:09.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.316+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.317+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T22:10:09.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.2.delta.8bbe63ec-e1ee-4d49-8f20-9859baed5133.TID613.tmp
[2025-07-19T22:10:09.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36113d2
[2025-07-19T22:10:09.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.2.delta.8eca73fb-5ab2-497d-a5b0-097d4775c6f0.TID614.tmp
[2025-07-19T22:10:09.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.2.delta.acab5db9-ef41-4f45-92c9-956c272d1ae9.TID612.tmp
[2025-07-19T22:10:09.324+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 5.0 in stage 7.0 (TID 608). 5872 bytes result sent to driver
[2025-07-19T22:10:09.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13] for update
[2025-07-19T22:10:09.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.2.delta.b7ca9ca9-0ab5-4bf2-b2e7-dc12c2eeed7c.TID615.tmp
[2025-07-19T22:10:09.326+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 608) in 117 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T22:10:09.326+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 617) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.328+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 14.0 in stage 7.0 (TID 617)
[2025-07-19T22:10:09.330+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:09.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.2.delta.39bde759-f276-4f70-bbba-a11ace3cddf7.TID610.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/2.delta
[2025-07-19T22:10:09.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/7/2.delta
[2025-07-19T22:10:09.340+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T22:10:09.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c45473e
[2025-07-19T22:10:09.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T22:10:09.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14] for update
[2025-07-19T22:10:09.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 7.0 in stage 7.0 (TID 610). 5872 bytes result sent to driver
[2025-07-19T22:10:09.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 618) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 610) in 93 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T22:10:09.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 15.0 in stage 7.0 (TID 618)
[2025-07-19T22:10:09.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1eb5994
[2025-07-19T22:10:09.350+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.351+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15] for update
[2025-07-19T22:10:09.351+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.2.delta.361c7ac1-3e6d-4a9a-aa05-fb127a24e7aa.TID616.tmp
[2025-07-19T22:10:09.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.2.delta.ea39bb93-616a-4961-994d-f334939af41b.TID618.tmp
[2025-07-19T22:10:09.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.2.delta.4f323747-5925-44fa-bd40-3523b6e45225.TID617.tmp
[2025-07-19T22:10:09.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.2.delta.933f163b-a7da-4208-9042-ca1a83811b82.TID611.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/2.delta
[2025-07-19T22:10:09.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/8/2.delta
[2025-07-19T22:10:09.378+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T22:10:09.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T22:10:09.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 8.0 in stage 7.0 (TID 611). 5872 bytes result sent to driver
[2025-07-19T22:10:09.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 619) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.385+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 16.0 in stage 7.0 (TID 619)
[2025-07-19T22:10:09.386+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 611) in 135 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T22:10:09.387+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.388+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e2d3f77
[2025-07-19T22:10:09.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16] for update
[2025-07-19T22:10:09.390+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.396+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.2.delta.198bc467-d26f-424c-ae9f-25bc6e07ed92.TID619.tmp
[2025-07-19T22:10:09.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.2.delta.acab5db9-ef41-4f45-92c9-956c272d1ae9.TID612.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/2.delta
[2025-07-19T22:10:09.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/9/2.delta
[2025-07-19T22:10:09.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T22:10:09.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.2.delta.8eca73fb-5ab2-497d-a5b0-097d4775c6f0.TID614.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/2.delta
[2025-07-19T22:10:09.402+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/11/2.delta
[2025-07-19T22:10:09.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T22:10:09.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.2.delta.b7ca9ca9-0ab5-4bf2-b2e7-dc12c2eeed7c.TID615.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/2.delta
[2025-07-19T22:10:09.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/12/2.delta
[2025-07-19T22:10:09.406+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T22:10:09.409+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T22:10:09.410+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.2.delta.8bbe63ec-e1ee-4d49-8f20-9859baed5133.TID613.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/2.delta
[2025-07-19T22:10:09.411+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/10/2.delta
[2025-07-19T22:10:09.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.2.delta.361c7ac1-3e6d-4a9a-aa05-fb127a24e7aa.TID616.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/2.delta
[2025-07-19T22:10:09.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/13/2.delta
[2025-07-19T22:10:09.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 9.0 in stage 7.0 (TID 612). 5872 bytes result sent to driver
[2025-07-19T22:10:09.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 620) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T22:10:09.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T22:10:09.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T22:10:09.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 612) in 161 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T22:10:09.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 11.0 in stage 7.0 (TID 614). 5872 bytes result sent to driver
[2025-07-19T22:10:09.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 17.0 in stage 7.0 (TID 620)
[2025-07-19T22:10:09.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 621) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 614) in 142 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T22:10:09.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T22:10:09.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T22:10:09.423+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 10.0 in stage 7.0 (TID 613). 5872 bytes result sent to driver
[2025-07-19T22:10:09.424+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 18.0 in stage 7.0 (TID 621)
[2025-07-19T22:10:09.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.2.delta.ea39bb93-616a-4961-994d-f334939af41b.TID618.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/2.delta
[2025-07-19T22:10:09.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/15/2.delta
[2025-07-19T22:10:09.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 12.0 in stage 7.0 (TID 615). 5915 bytes result sent to driver
[2025-07-19T22:10:09.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 622) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T22:10:09.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T22:10:09.430+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.2.delta.4f323747-5925-44fa-bd40-3523b6e45225.TID617.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/2.delta
[2025-07-19T22:10:09.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/14/2.delta
[2025-07-19T22:10:09.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 13.0 in stage 7.0 (TID 616). 5872 bytes result sent to driver
[2025-07-19T22:10:09.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T22:10:09.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T22:10:09.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:09.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 15.0 in stage 7.0 (TID 618). 5872 bytes result sent to driver
[2025-07-19T22:10:09.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T22:10:09.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 19.0 in stage 7.0 (TID 622)
[2025-07-19T22:10:09.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 623) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 613) in 170 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T22:10:09.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 20.0 in stage 7.0 (TID 623)
[2025-07-19T22:10:09.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 615) in 160 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T22:10:09.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 616) in 129 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T22:10:09.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 624) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 625) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 618) in 94 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T22:10:09.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 22.0 in stage 7.0 (TID 625)
[2025-07-19T22:10:09.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51cc2073
[2025-07-19T22:10:09.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 21.0 in stage 7.0 (TID 624)
[2025-07-19T22:10:09.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.450+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18] for update
[2025-07-19T22:10:09.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:09.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T22:10:09.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 14.0 in stage 7.0 (TID 617). 5872 bytes result sent to driver
[2025-07-19T22:10:09.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a4213b6
[2025-07-19T22:10:09.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 626) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 617) in 118 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T22:10:09.457+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.457+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 23.0 in stage 7.0 (TID 626)
[2025-07-19T22:10:09.457+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20] for update
[2025-07-19T22:10:09.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19586626
[2025-07-19T22:10:09.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17] for update
[2025-07-19T22:10:09.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f5854b7
[2025-07-19T22:10:09.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:09.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.2.delta.ab5e97a2-ca23-427b-a085-32addcbcac54.TID621.tmp
[2025-07-19T22:10:09.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22] for update
[2025-07-19T22:10:09.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.2.delta.198bc467-d26f-424c-ae9f-25bc6e07ed92.TID619.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/2.delta
[2025-07-19T22:10:09.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/16/2.delta
[2025-07-19T22:10:09.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b9357f7
[2025-07-19T22:10:09.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19] for update
[2025-07-19T22:10:09.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T22:10:09.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.2.delta.d327a26c-c1e6-466a-aaef-728b6a4be3d8.TID623.tmp
[2025-07-19T22:10:09.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.2.delta.151731d3-d677-4d33-9741-1fd80503cb64.TID620.tmp
[2025-07-19T22:10:09.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@181551e
[2025-07-19T22:10:09.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T22:10:09.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23] for update
[2025-07-19T22:10:09.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 16.0 in stage 7.0 (TID 619). 5872 bytes result sent to driver
[2025-07-19T22:10:09.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 627) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 24.0 in stage 7.0 (TID 627)
[2025-07-19T22:10:09.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 619) in 89 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T22:10:09.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bcc1476
[2025-07-19T22:10:09.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21] for update
[2025-07-19T22:10:09.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.2.delta.c14f5d97-221a-4363-bc71-de0eb9fa7fe3.TID625.tmp
[2025-07-19T22:10:09.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a2c6bc9
[2025-07-19T22:10:09.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24] for update
[2025-07-19T22:10:09.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.484+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.2.delta.bad92fa0-8ebd-4d42-a3d2-ad3d41df3999.TID622.tmp
[2025-07-19T22:10:09.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v156.metadata.json
[2025-07-19T22:10:09.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.2.delta.4a52fb7b-c66c-4a25-8133-ea2c46213fee.TID626.tmp
[2025-07-19T22:10:09.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.2.delta.63d91c9b-b96a-4495-9dff-43ec1ef82ff3.TID624.tmp
[2025-07-19T22:10:09.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.2.delta.322219fa-bc69-4b93-85f9-97563922b7b5.TID627.tmp
[2025-07-19T22:10:09.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.2.delta.ab5e97a2-ca23-427b-a085-32addcbcac54.TID621.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/2.delta
[2025-07-19T22:10:09.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/18/2.delta
[2025-07-19T22:10:09.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T22:10:09.531+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T22:10:09.533+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 18.0 in stage 7.0 (TID 621). 5872 bytes result sent to driver
[2025-07-19T22:10:09.534+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 628) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.535+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 621) in 120 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T22:10:09.535+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.2.delta.d327a26c-c1e6-466a-aaef-728b6a4be3d8.TID623.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/2.delta
[2025-07-19T22:10:09.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/20/2.delta
[2025-07-19T22:10:09.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T22:10:09.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 25.0 in stage 7.0 (TID 628)
[2025-07-19T22:10:09.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T22:10:09.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.2.delta.c14f5d97-221a-4363-bc71-de0eb9fa7fe3.TID625.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/2.delta
[2025-07-19T22:10:09.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/22/2.delta
[2025-07-19T22:10:09.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 20.0 in stage 7.0 (TID 623). 5872 bytes result sent to driver
[2025-07-19T22:10:09.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 629) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 623) in 117 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T22:10:09.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 26.0 in stage 7.0 (TID 629)
[2025-07-19T22:10:09.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T22:10:09.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@587702e9
[2025-07-19T22:10:09.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.2.delta.151731d3-d677-4d33-9741-1fd80503cb64.TID620.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/2.delta
[2025-07-19T22:10:09.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/17/2.delta
[2025-07-19T22:10:09.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25] for update
[2025-07-19T22:10:09.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T22:10:09.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T22:10:09.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7adfdfa4
[2025-07-19T22:10:09.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 22.0 in stage 7.0 (TID 625). 5872 bytes result sent to driver
[2025-07-19T22:10:09.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 630) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26] for update
[2025-07-19T22:10:09.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 27.0 in stage 7.0 (TID 630)
[2025-07-19T22:10:09.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 625) in 116 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T22:10:09.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SnapshotProducer: Committed snapshot 8049091173762034179 (FastAppend)
[2025-07-19T22:10:09.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T22:10:09.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 17.0 in stage 7.0 (TID 620). 5872 bytes result sent to driver
[2025-07-19T22:10:09.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 620) in 143 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T22:10:09.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 631) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69e08eaf
[2025-07-19T22:10:09.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27] for update
[2025-07-19T22:10:09.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 28.0 in stage 7.0 (TID 631)
[2025-07-19T22:10:09.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.2.delta.4a52fb7b-c66c-4a25-8133-ea2c46213fee.TID626.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/2.delta
[2025-07-19T22:10:09.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/23/2.delta
[2025-07-19T22:10:09.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44144d64
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28] for update
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 23.0 in stage 7.0 (TID 626). 5872 bytes result sent to driver
[2025-07-19T22:10:09.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 632) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.2.delta.902add72-ef74-4c27-abbe-1e54d3722e66.TID628.tmp
[2025-07-19T22:10:09.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 626) in 125 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T22:10:09.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 29.0 in stage 7.0 (TID 632)
[2025-07-19T22:10:09.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.2.delta.bad92fa0-8ebd-4d42-a3d2-ad3d41df3999.TID622.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/2.delta
[2025-07-19T22:10:09.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/19/2.delta
[2025-07-19T22:10:09.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T22:10:09.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.2.delta.63d91c9b-b96a-4495-9dff-43ec1ef82ff3.TID624.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/2.delta
[2025-07-19T22:10:09.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.2.delta.b2280731-8b5f-4b30-9e04-6c5c9591ecff.TID630.tmp
[2025-07-19T22:10:09.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/21/2.delta
[2025-07-19T22:10:09.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.2.delta.87b77383-50ac-416f-81ea-ee0e6cb7a8ea.TID629.tmp
[2025-07-19T22:10:09.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T22:10:09.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.2.delta.322219fa-bc69-4b93-85f9-97563922b7b5.TID627.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/2.delta
[2025-07-19T22:10:09.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/24/2.delta
[2025-07-19T22:10:09.579+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@543f88a7
[2025-07-19T22:10:09.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T22:10:09.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.2.delta.54f2af30-3cb3-499b-8f07-2b3e7916a737.TID631.tmp
[2025-07-19T22:10:09.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T22:10:09.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 19.0 in stage 7.0 (TID 622). 5872 bytes result sent to driver
[2025-07-19T22:10:09.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29] for update
[2025-07-19T22:10:09.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T22:10:09.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 21.0 in stage 7.0 (TID 624). 5872 bytes result sent to driver
[2025-07-19T22:10:09.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 633) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 634) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T22:10:09.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 622) in 173 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T22:10:09.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 624) in 161 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T22:10:09.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 30.0 in stage 7.0 (TID 633)
[2025-07-19T22:10:09.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 24.0 in stage 7.0 (TID 627). 5872 bytes result sent to driver
[2025-07-19T22:10:09.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 31.0 in stage 7.0 (TID 634)
[2025-07-19T22:10:09.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 635) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 32.0 in stage 7.0 (TID 635)
[2025-07-19T22:10:09.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 627) in 129 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T22:10:09.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3393a701
[2025-07-19T22:10:09.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31] for update
[2025-07-19T22:10:09.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e8df55d
[2025-07-19T22:10:09.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32] for update
[2025-07-19T22:10:09.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.2.delta.b3579b89-a350-4849-a050-33a4c57b4c91.TID632.tmp
[2025-07-19T22:10:09.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=8049091173762034179, sequenceNumber=155, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.340037375S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=152}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=8258}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=276}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=12519}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=496463}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=26799088}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752962984887, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T22:10:09.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Committed in 341 ms
[2025-07-19T22:10:09.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T22:10:09.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752789180000 ms
[2025-07-19T22:10:09.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b448d6a
[2025-07-19T22:10:09.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30] for update
[2025-07-19T22:10:09.645+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.2.delta.b2280731-8b5f-4b30-9e04-6c5c9591ecff.TID630.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/2.delta
[2025-07-19T22:10:09.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/27/2.delta
[2025-07-19T22:10:09.652+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T22:10:09.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/commits/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/commits/.0.0cb9102a-7af6-4131-b823-ed7188330516.tmp
[2025-07-19T22:10:09.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.2.delta.cb51ce34-16df-4254-961d-3078ce685aa4.TID634.tmp
[2025-07-19T22:10:09.655+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.2.delta.902add72-ef74-4c27-abbe-1e54d3722e66.TID628.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/2.delta
[2025-07-19T22:10:09.656+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/25/2.delta
[2025-07-19T22:10:09.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T22:10:09.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T22:10:09.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 27.0 in stage 7.0 (TID 630). 5872 bytes result sent to driver
[2025-07-19T22:10:09.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 636) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 630) in 118 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T22:10:09.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 33.0 in stage 7.0 (TID 636)
[2025-07-19T22:10:09.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T22:10:09.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.2.delta.d88eed82-e35a-4000-adb2-0cdc7cb4be6d.TID635.tmp
[2025-07-19T22:10:09.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 25.0 in stage 7.0 (TID 628). 5915 bytes result sent to driver
[2025-07-19T22:10:09.698+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.2.delta.54f2af30-3cb3-499b-8f07-2b3e7916a737.TID631.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/2.delta
[2025-07-19T22:10:09.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/28/2.delta
[2025-07-19T22:10:09.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T22:10:09.700+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17a23f62
[2025-07-19T22:10:09.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 637) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 628) in 143 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T22:10:09.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 34.0 in stage 7.0 (TID 637)
[2025-07-19T22:10:09.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.2.delta.79342a80-a0b3-410d-a2c7-59df1b5f7854.TID633.tmp
[2025-07-19T22:10:09.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33] for update
[2025-07-19T22:10:09.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:09.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.2.delta.87b77383-50ac-416f-81ea-ee0e6cb7a8ea.TID629.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/2.delta
[2025-07-19T22:10:09.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/26/2.delta
[2025-07-19T22:10:09.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@662a4c0e
[2025-07-19T22:10:09.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T22:10:09.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34] for update
[2025-07-19T22:10:09.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T22:10:09.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 28.0 in stage 7.0 (TID 631). 5872 bytes result sent to driver
[2025-07-19T22:10:09.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 638) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.719+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 35.0 in stage 7.0 (TID 638)
[2025-07-19T22:10:09.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 631) in 151 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T22:10:09.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T22:10:09.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 26.0 in stage 7.0 (TID 629). 5915 bytes result sent to driver
[2025-07-19T22:10:09.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 639) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 629) in 181 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T22:10:09.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.2.delta.7fd371dc-7d58-43f0-9305-b70250ed7039.TID636.tmp
[2025-07-19T22:10:09.728+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 36.0 in stage 7.0 (TID 639)
[2025-07-19T22:10:09.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:09.733+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d19198
[2025-07-19T22:10:09.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35] for update
[2025-07-19T22:10:09.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6651e20d
[2025-07-19T22:10:09.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36] for update
[2025-07-19T22:10:09.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.2.delta.917c5cd1-ce98-44d9-b197-2fa1e611886a.TID637.tmp
[2025-07-19T22:10:09.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.2.delta.b3579b89-a350-4849-a050-33a4c57b4c91.TID632.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/2.delta
[2025-07-19T22:10:09.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/29/2.delta
[2025-07-19T22:10:09.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T22:10:09.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T22:10:09.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 29.0 in stage 7.0 (TID 632). 5872 bytes result sent to driver
[2025-07-19T22:10:09.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 640) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 37.0 in stage 7.0 (TID 640)
[2025-07-19T22:10:09.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 632) in 192 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T22:10:09.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/commits/.0.0cb9102a-7af6-4131-b823-ed7188330516.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/commits/0
[2025-07-19T22:10:09.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T22:10:09.765+0000] {subprocess.py:93} INFO -   "id" : "76699ab7-445a-4f4e-a8af-51ec24e5ea93",
[2025-07-19T22:10:09.765+0000] {subprocess.py:93} INFO -   "runId" : "002fa0f1-bd40-4ea7-9304-5ec9b41c6781",
[2025-07-19T22:10:09.765+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T22:10:09.766+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T22:09:48.594Z",
[2025-07-19T22:10:09.766+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T22:10:09.768+0000] {subprocess.py:93} INFO -   "numInputRows" : 276,
[2025-07-19T22:10:09.769+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:09.769+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 13.04224553444854,
[2025-07-19T22:10:09.769+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T22:10:09.769+0000] {subprocess.py:93} INFO -     "addBatch" : 19614,
[2025-07-19T22:10:09.771+0000] {subprocess.py:93} INFO -     "commitOffsets" : 138,
[2025-07-19T22:10:09.772+0000] {subprocess.py:93} INFO -     "getBatch" : 22,
[2025-07-19T22:10:09.772+0000] {subprocess.py:93} INFO -     "latestOffset" : 577,
[2025-07-19T22:10:09.772+0000] {subprocess.py:93} INFO -     "queryPlanning" : 647,
[2025-07-19T22:10:09.772+0000] {subprocess.py:93} INFO -     "triggerExecution" : 21162,
[2025-07-19T22:10:09.772+0000] {subprocess.py:93} INFO -     "walCommit" : 152
[2025-07-19T22:10:09.772+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:09.773+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T22:10:09.773+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T18:35:01.304Z",
[2025-07-19T22:10:09.773+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T21:53:00.000Z",
[2025-07-19T22:10:09.773+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T16:04:00.000Z",
[2025-07-19T22:10:09.773+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T22:10:09.773+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:09.774+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T22:10:09.774+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T22:10:09.780+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 276,
[2025-07-19T22:10:09.781+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 276,
[2025-07-19T22:10:09.782+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 3134,
[2025-07-19T22:10:09.783+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T22:10:09.783+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 123,
[2025-07-19T22:10:09.783+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 13248,
[2025-07-19T22:10:09.783+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 110944,
[2025-07-19T22:10:09.783+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T22:10:09.783+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T22:10:09.783+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T22:10:09.784+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T22:10:09.785+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T22:10:09.785+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T22:10:09.786+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T22:10:09.786+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 82144
[2025-07-19T22:10:09.786+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:09.786+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:09.786+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T22:10:09.787+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T22:10:09.788+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T22:10:09.788+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T22:10:09.789+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T22:10:09.790+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:09.790+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:09.791+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:09.791+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T22:10:09.792+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T22:10:09.793+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:09.795+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:09.796+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:09.797+0000] {subprocess.py:93} INFO -     "numInputRows" : 276,
[2025-07-19T22:10:09.798+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:09.798+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 13.04224553444854,
[2025-07-19T22:10:09.800+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T22:10:09.800+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T22:10:09.802+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T22:10:09.803+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T22:10:09.803+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:09.803+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:09.803+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T22:10:09.804+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T22:10:09.804+0000] {subprocess.py:93} INFO -     "numOutputRows" : 276
[2025-07-19T22:10:09.804+0000] {subprocess.py:93} INFO -   }
[2025-07-19T22:10:09.804+0000] {subprocess.py:93} INFO - }
[2025-07-19T22:10:09.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.2.delta.efdc74ff-0a99-4a95-b7a1-c6d3186ec935.TID639.tmp
[2025-07-19T22:10:09.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a74191d
[2025-07-19T22:10:09.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37] for update
[2025-07-19T22:10:09.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.2.delta.f7c43be7-8af5-455c-a599-a9951efd5fd6.TID638.tmp
[2025-07-19T22:10:09.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.2.delta.79342a80-a0b3-410d-a2c7-59df1b5f7854.TID633.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/2.delta
[2025-07-19T22:10:09.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/30/2.delta
[2025-07-19T22:10:09.806+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.2.delta.d88eed82-e35a-4000-adb2-0cdc7cb4be6d.TID635.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/2.delta
[2025-07-19T22:10:09.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/32/2.delta
[2025-07-19T22:10:09.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/offsets/.1.5c5b26c2-e678-49cb-91e6-efd7863454f7.tmp
[2025-07-19T22:10:09.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T22:10:09.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.2.delta.cb51ce34-16df-4254-961d-3078ce685aa4.TID634.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/2.delta
[2025-07-19T22:10:09.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T22:10:09.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/31/2.delta
[2025-07-19T22:10:09.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T22:10:09.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.2.delta.02009d68-8ece-4e94-919a-a144b64ff9ca.TID640.tmp
[2025-07-19T22:10:09.809+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T22:10:09.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T22:10:09.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 30.0 in stage 7.0 (TID 633). 5872 bytes result sent to driver
[2025-07-19T22:10:09.812+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 32.0 in stage 7.0 (TID 635). 5872 bytes result sent to driver
[2025-07-19T22:10:09.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 641) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 642) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 38.0 in stage 7.0 (TID 641)
[2025-07-19T22:10:09.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 39.0 in stage 7.0 (TID 642)
[2025-07-19T22:10:09.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 635) in 191 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T22:10:09.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 633) in 199 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T22:10:09.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T22:10:09.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 31.0 in stage 7.0 (TID 634). 5872 bytes result sent to driver
[2025-07-19T22:10:09.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 643) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 634) in 201 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T22:10:09.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 40.0 in stage 7.0 (TID 643)
[2025-07-19T22:10:09.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.2.delta.7fd371dc-7d58-43f0-9305-b70250ed7039.TID636.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/2.delta
[2025-07-19T22:10:09.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/33/2.delta
[2025-07-19T22:10:09.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T22:10:09.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51fcbbf4
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39] for update
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67111f11
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40] for update
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 33.0 in stage 7.0 (TID 636). 5872 bytes result sent to driver
[2025-07-19T22:10:09.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 644) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 636) in 139 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T22:10:09.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 41.0 in stage 7.0 (TID 644)
[2025-07-19T22:10:09.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@142f1cb4
[2025-07-19T22:10:09.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38] for update
[2025-07-19T22:10:09.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.821+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.2.delta.917c5cd1-ce98-44d9-b197-2fa1e611886a.TID637.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/2.delta
[2025-07-19T22:10:09.821+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/34/2.delta
[2025-07-19T22:10:09.821+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:09.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37335023
[2025-07-19T22:10:09.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T22:10:09.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41] for update
[2025-07-19T22:10:09.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T22:10:09.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 34.0 in stage 7.0 (TID 637). 5872 bytes result sent to driver
[2025-07-19T22:10:09.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.2.delta.a00f94f8-97bc-41df-b436-3b5eb378a230.TID642.tmp
[2025-07-19T22:10:09.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 645) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.830+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 637) in 149 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T22:10:09.830+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 42.0 in stage 7.0 (TID 645)
[2025-07-19T22:10:09.831+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bcfd02b
[2025-07-19T22:10:09.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.2.delta.7bfdd033-4b55-4552-9630-c91e3f6824a2.TID643.tmp
[2025-07-19T22:10:09.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42] for update
[2025-07-19T22:10:09.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.2.delta.efdc74ff-0a99-4a95-b7a1-c6d3186ec935.TID639.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/2.delta
[2025-07-19T22:10:09.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/36/2.delta
[2025-07-19T22:10:09.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.2.delta.f7d644d5-b4da-4b3e-9384-3a0d1494cb82.TID644.tmp
[2025-07-19T22:10:09.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T22:10:09.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.2.delta.5d3568d6-2bc9-46a5-819c-6a2ec344bde0.TID641.tmp
[2025-07-19T22:10:09.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.2.delta.f7c43be7-8af5-455c-a599-a9951efd5fd6.TID638.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/2.delta
[2025-07-19T22:10:09.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/35/2.delta
[2025-07-19T22:10:09.840+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/offsets/.1.5c5b26c2-e678-49cb-91e6-efd7863454f7.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/offsets/1
[2025-07-19T22:10:09.840+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T22:10:09.840+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T22:10:09.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 36.0 in stage 7.0 (TID 639). 5915 bytes result sent to driver
[2025-07-19T22:10:09.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752789180000,1752963009764,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T22:10:09.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.2.delta.83aacc6f-c02f-440b-90e8-374abc52c848.TID645.tmp
[2025-07-19T22:10:09.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 646) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 43.0 in stage 7.0 (TID 646)
[2025-07-19T22:10:09.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 639) in 131 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T22:10:09.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T22:10:09.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22ca27c9
[2025-07-19T22:10:09.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43] for update
[2025-07-19T22:10:09.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 35.0 in stage 7.0 (TID 638). 5915 bytes result sent to driver
[2025-07-19T22:10:09.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 647) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.2.delta.02009d68-8ece-4e94-919a-a144b64ff9ca.TID640.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/2.delta
[2025-07-19T22:10:09.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/37/2.delta
[2025-07-19T22:10:09.860+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T22:10:09.861+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.862+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 638) in 156 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T22:10:09.862+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T22:10:09.863+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 37.0 in stage 7.0 (TID 640). 5872 bytes result sent to driver
[2025-07-19T22:10:09.864+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 648) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.865+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 44.0 in stage 7.0 (TID 647)
[2025-07-19T22:10:09.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 45.0 in stage 7.0 (TID 648)
[2025-07-19T22:10:09.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 640) in 112 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T22:10:09.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.870+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.870+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.870+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@534de371
[2025-07-19T22:10:09.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.2.delta.94448b68-496a-4fd4-a3d6-4e47b6be7132.TID646.tmp
[2025-07-19T22:10:09.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44] for update
[2025-07-19T22:10:09.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.2.delta.a00f94f8-97bc-41df-b436-3b5eb378a230.TID642.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/2.delta
[2025-07-19T22:10:09.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/39/2.delta
[2025-07-19T22:10:09.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T22:10:09.885+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@de3396
[2025-07-19T22:10:09.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45] for update
[2025-07-19T22:10:09.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T22:10:09.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 39.0 in stage 7.0 (TID 642). 5872 bytes result sent to driver
[2025-07-19T22:10:09.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 649) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.2.delta.7bfdd033-4b55-4552-9630-c91e3f6824a2.TID643.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/2.delta
[2025-07-19T22:10:09.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/40/2.delta
[2025-07-19T22:10:09.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 642) in 104 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T22:10:09.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T22:10:09.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 46.0 in stage 7.0 (TID 649)
[2025-07-19T22:10:09.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@281e94b2
[2025-07-19T22:10:09.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46] for update
[2025-07-19T22:10:09.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.2.delta.83aacc6f-c02f-440b-90e8-374abc52c848.TID645.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/2.delta
[2025-07-19T22:10:09.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/42/2.delta
[2025-07-19T22:10:09.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T22:10:09.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T22:10:09.907+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 40.0 in stage 7.0 (TID 643). 5872 bytes result sent to driver
[2025-07-19T22:10:09.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 650) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.2.delta.f3240063-c458-4d29-90ba-4ded284ce72f.TID648.tmp
[2025-07-19T22:10:09.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.2.delta.368b4165-5b25-44d5-9ca3-44a91df89c61.TID647.tmp
[2025-07-19T22:10:09.915+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 47.0 in stage 7.0 (TID 650)
[2025-07-19T22:10:09.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T22:10:09.917+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.2.delta.f7d644d5-b4da-4b3e-9384-3a0d1494cb82.TID644.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/2.delta
[2025-07-19T22:10:09.917+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/41/2.delta
[2025-07-19T22:10:09.917+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 42.0 in stage 7.0 (TID 645). 5872 bytes result sent to driver
[2025-07-19T22:10:09.917+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 643) in 113 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T22:10:09.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 651) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 645) in 87 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T22:10:09.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@426cfbdf
[2025-07-19T22:10:09.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T22:10:09.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 48.0 in stage 7.0 (TID 651)
[2025-07-19T22:10:09.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47] for update
[2025-07-19T22:10:09.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T22:10:09.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47473c3b
[2025-07-19T22:10:09.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 41.0 in stage 7.0 (TID 644). 5872 bytes result sent to driver
[2025-07-19T22:10:09.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 652) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 644) in 114 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T22:10:09.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48] for update
[2025-07-19T22:10:09.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 49.0 in stage 7.0 (TID 652)
[2025-07-19T22:10:09.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73d926ab
[2025-07-19T22:10:09.949+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49] for update
[2025-07-19T22:10:09.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.2.delta.5d3568d6-2bc9-46a5-819c-6a2ec344bde0.TID641.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/2.delta
[2025-07-19T22:10:09.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/38/2.delta
[2025-07-19T22:10:09.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T22:10:09.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.2.delta.7f72588a-5903-4bb5-9b9d-2d5fd347629f.TID649.tmp
[2025-07-19T22:10:09.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T22:10:09.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 38.0 in stage 7.0 (TID 641). 5872 bytes result sent to driver
[2025-07-19T22:10:09.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.2.delta.04adb260-9183-4783-a518-d24c28bbb35d.TID651.tmp
[2025-07-19T22:10:09.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.2.delta.94448b68-496a-4fd4-a3d6-4e47b6be7132.TID646.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/2.delta
[2025-07-19T22:10:09.959+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/43/2.delta
[2025-07-19T22:10:09.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.2.delta.e6332688-2c0f-4018-bf2a-980d85425a8b.TID650.tmp
[2025-07-19T22:10:09.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T22:10:09.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 653) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 641) in 155 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T22:10:09.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 50.0 in stage 7.0 (TID 653)
[2025-07-19T22:10:09.964+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.2.delta.1f224876-b86e-4073-a412-5207e16943bd.TID652.tmp
[2025-07-19T22:10:09.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28767ea4
[2025-07-19T22:10:09.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50] for update
[2025-07-19T22:10:09.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T22:10:09.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 43.0 in stage 7.0 (TID 646). 5829 bytes result sent to driver
[2025-07-19T22:10:09.981+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:09.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 654) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:09.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 646) in 110 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T22:10:09.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 51.0 in stage 7.0 (TID 654)
[2025-07-19T22:10:09.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.2.delta.f3240063-c458-4d29-90ba-4ded284ce72f.TID648.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/2.delta
[2025-07-19T22:10:09.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/45/2.delta
[2025-07-19T22:10:09.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T22:10:09.985+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:09.986+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:09.987+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.2.delta.368b4165-5b25-44d5-9ca3-44a91df89c61.TID647.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/2.delta
[2025-07-19T22:10:09.988+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/44/2.delta
[2025-07-19T22:10:09.989+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35310f47
[2025-07-19T22:10:09.990+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:09.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51] for update
[2025-07-19T22:10:09.992+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T22:10:09.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:09.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T22:10:09.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.2.delta.dc75fc57-4aba-406c-b5d2-4112847ceebd.TID653.tmp
[2025-07-19T22:10:09.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Finished task 45.0 in stage 7.0 (TID 648). 5829 bytes result sent to driver
[2025-07-19T22:10:10.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 655) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.2.delta.7f72588a-5903-4bb5-9b9d-2d5fd347629f.TID649.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/2.delta
[2025-07-19T22:10:10.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/46/2.delta
[2025-07-19T22:10:10.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 648) in 129 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T22:10:10.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T22:10:10.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO Executor: Running task 52.0 in stage 7.0 (TID 655)
[2025-07-19T22:10:10.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8be8bd3
[2025-07-19T22:10:10.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52] for update
[2025-07-19T22:10:10.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T22:10:10.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO DataWritingSparkTask: Committed partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T22:10:10.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 209.0 KiB, free 432.8 MiB)
[2025-07-19T22:10:10.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.2.delta.04adb260-9183-4783-a518-d24c28bbb35d.TID651.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/2.delta
[2025-07-19T22:10:10.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/48/2.delta
[2025-07-19T22:10:10.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T22:10:10.016+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 44.0 in stage 7.0 (TID 647). 5915 bytes result sent to driver
[2025-07-19T22:10:10.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 656) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 53.0 in stage 7.0 (TID 656)
[2025-07-19T22:10:10.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.2.delta.e3a5fb6f-e8a0-4ad9-98d2-77dc1ddbe96c.TID654.tmp
[2025-07-19T22:10:10.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 647) in 159 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T22:10:10.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 46.0 in stage 7.0 (TID 649). 5915 bytes result sent to driver
[2025-07-19T22:10:10.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 657) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T22:10:10.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 54.0 in stage 7.0 (TID 657)
[2025-07-19T22:10:10.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 649) in 129 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T22:10:10.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 48.0 in stage 7.0 (TID 651). 5915 bytes result sent to driver
[2025-07-19T22:10:10.037+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@328c8c65
[2025-07-19T22:10:10.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53] for update
[2025-07-19T22:10:10.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 658) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 651) in 131 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T22:10:10.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.7 MiB)
[2025-07-19T22:10:10.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.2.delta.6c169fd7-f469-4b05-9a9f-f908a1ef8fad.TID655.tmp
[2025-07-19T22:10:10.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 8b44f3d35cfa:37751 (size: 35.4 KiB, free: 434.0 MiB)
[2025-07-19T22:10:10.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO SparkContext: Created broadcast 15 from start at <unknown>:0
[2025-07-19T22:10:10.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65109a8c
[2025-07-19T22:10:10.051+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 55.0 in stage 7.0 (TID 658)
[2025-07-19T22:10:10.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54] for update
[2025-07-19T22:10:10.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.0 KiB, free 432.7 MiB)
[2025-07-19T22:10:10.054+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 432.7 MiB)
[2025-07-19T22:10:10.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 8b44f3d35cfa:37751 (size: 29.6 KiB, free: 434.0 MiB)
[2025-07-19T22:10:10.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO SparkContext: Created broadcast 16 from start at <unknown>:0
[2025-07-19T22:10:10.056+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T22:10:10.056+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T22:10:10.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DAGScheduler: Registering RDD 33 (start at <unknown>:0) as input to shuffle 4
[2025-07-19T22:10:10.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DAGScheduler: Got job 4 (start at <unknown>:0) with 200 output partitions
[2025-07-19T22:10:10.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DAGScheduler: Final stage: ResultStage 9 (start at <unknown>:0)
[2025-07-19T22:10:10.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-07-19T22:10:10.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DAGScheduler: Missing parents: List()
[2025-07-19T22:10:10.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DAGScheduler: Submitting ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0), which has no missing parents
[2025-07-19T22:10:10.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.2.delta.e6332688-2c0f-4018-bf2a-980d85425a8b.TID650.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/2.delta
[2025-07-19T22:10:10.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/47/2.delta
[2025-07-19T22:10:10.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T22:10:10.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.2.delta.1f224876-b86e-4073-a412-5207e16943bd.TID652.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/2.delta
[2025-07-19T22:10:10.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/49/2.delta
[2025-07-19T22:10:10.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T22:10:10.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T22:10:10.071+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.2.delta.e49db88c-0f3c-4f63-bd21-d8bf0d7db1f1.TID656.tmp
[2025-07-19T22:10:10.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T22:10:10.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 47.0 in stage 7.0 (TID 650). 5872 bytes result sent to driver
[2025-07-19T22:10:10.077+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 659) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.080+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 650) in 171 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T22:10:10.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78f6c024
[2025-07-19T22:10:10.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 56.0 in stage 7.0 (TID 659)
[2025-07-19T22:10:10.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55] for update
[2025-07-19T22:10:10.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T22:10:10.085+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 49.0 in stage 7.0 (TID 652). 5872 bytes result sent to driver
[2025-07-19T22:10:10.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.2.delta.e8505054-facb-4a81-8315-088c24b5cbb5.TID657.tmp
[2025-07-19T22:10:10.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 660) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.092+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 652) in 174 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T22:10:10.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 57.0 in stage 7.0 (TID 660)
[2025-07-19T22:10:10.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.097+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b2eb0e8
[2025-07-19T22:10:10.097+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.098+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56] for update
[2025-07-19T22:10:10.099+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.099+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.099+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@184cd52b
[2025-07-19T22:10:10.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57] for update
[2025-07-19T22:10:10.103+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.104+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.2.delta.dc75fc57-4aba-406c-b5d2-4112847ceebd.TID653.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/2.delta
[2025-07-19T22:10:10.105+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/50/2.delta
[2025-07-19T22:10:10.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T22:10:10.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T22:10:10.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 50.0 in stage 7.0 (TID 653). 5915 bytes result sent to driver
[2025-07-19T22:10:10.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 661) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 58.0 in stage 7.0 (TID 661)
[2025-07-19T22:10:10.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 653) in 220 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T22:10:10.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 32.0 KiB, free 432.7 MiB)
[2025-07-19T22:10:10.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 432.6 MiB)
[2025-07-19T22:10:10.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c52c9e2
[2025-07-19T22:10:10.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 8b44f3d35cfa:37751 (size: 15.9 KiB, free: 434.0 MiB)
[2025-07-19T22:10:10.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.2.delta.38faf4b2-e1e6-4bfc-870e-1be94b6914ca.TID659.tmp
[2025-07-19T22:10:10.190+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.191+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58] for update
[2025-07-19T22:10:10.191+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.191+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.2.delta.4dd9fcf4-4ff1-4440-ab6e-46a98edff0e1.TID658.tmp
[2025-07-19T22:10:10.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-07-19T22:10:10.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T22:10:10.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSchedulerImpl: Adding task set 9.0 with 200 tasks resource profile 0
[2025-07-19T22:10:10.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.2.delta.e3a5fb6f-e8a0-4ad9-98d2-77dc1ddbe96c.TID654.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/2.delta
[2025-07-19T22:10:10.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/51/2.delta
[2025-07-19T22:10:10.202+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T22:10:10.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 8b44f3d35cfa:37751 in memory (size: 35.4 KiB, free: 434.0 MiB)
[2025-07-19T22:10:10.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T22:10:10.219+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.2.delta.081e49f3-5b09-4ecf-973e-f0d81ad41618.TID661.tmp
[2025-07-19T22:10:10.220+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.2.delta.12a8dcf4-abe9-4316-a506-9773fa6a07fb.TID660.tmp
[2025-07-19T22:10:10.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 51.0 in stage 7.0 (TID 654). 5872 bytes result sent to driver
[2025-07-19T22:10:10.229+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.2.delta.e49db88c-0f3c-4f63-bd21-d8bf0d7db1f1.TID656.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/2.delta
[2025-07-19T22:10:10.230+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/53/2.delta
[2025-07-19T22:10:10.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T22:10:10.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 8b44f3d35cfa:37751 in memory (size: 19.9 KiB, free: 434.0 MiB)
[2025-07-19T22:10:10.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 662) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 654) in 295 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T22:10:10.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T22:10:10.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 59.0 in stage 7.0 (TID 662)
[2025-07-19T22:10:10.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 53.0 in stage 7.0 (TID 656). 5915 bytes result sent to driver
[2025-07-19T22:10:10.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32042734
[2025-07-19T22:10:10.290+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 663) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.290+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.2.delta.6c169fd7-f469-4b05-9a9f-f908a1ef8fad.TID655.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/2.delta
[2025-07-19T22:10:10.291+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/52/2.delta
[2025-07-19T22:10:10.291+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T22:10:10.304+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 8b44f3d35cfa:37751 in memory (size: 29.5 KiB, free: 434.1 MiB)
[2025-07-19T22:10:10.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 60.0 in stage 7.0 (TID 663)
[2025-07-19T22:10:10.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.317+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 656) in 297 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T22:10:10.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59] for update
[2025-07-19T22:10:10.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f4a9eec
[2025-07-19T22:10:10.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.2.delta.081e49f3-5b09-4ecf-973e-f0d81ad41618.TID661.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/2.delta
[2025-07-19T22:10:10.324+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/58/2.delta
[2025-07-19T22:10:10.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 8b44f3d35cfa:37751 in memory (size: 19.6 KiB, free: 434.1 MiB)
[2025-07-19T22:10:10.326+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T22:10:10.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T22:10:10.328+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.2.delta.e8505054-facb-4a81-8315-088c24b5cbb5.TID657.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/2.delta
[2025-07-19T22:10:10.328+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/54/2.delta
[2025-07-19T22:10:10.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.330+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T22:10:10.331+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60] for update
[2025-07-19T22:10:10.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 8b44f3d35cfa:37751 in memory (size: 29.6 KiB, free: 434.1 MiB)
[2025-07-19T22:10:10.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T22:10:10.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 54.0 in stage 7.0 (TID 657). 5872 bytes result sent to driver
[2025-07-19T22:10:10.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 664) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 61.0 in stage 7.0 (TID 664)
[2025-07-19T22:10:10.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 657) in 314 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T22:10:10.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 58.0 in stage 7.0 (TID 661). 5872 bytes result sent to driver
[2025-07-19T22:10:10.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 665) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 62.0 in stage 7.0 (TID 665)
[2025-07-19T22:10:10.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 661) in 178 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T22:10:10.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19f0b4d9
[2025-07-19T22:10:10.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 8b44f3d35cfa:37751 in memory (size: 19.3 KiB, free: 434.1 MiB)
[2025-07-19T22:10:10.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61] for update
[2025-07-19T22:10:10.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T22:10:10.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 52.0 in stage 7.0 (TID 655). 5872 bytes result sent to driver
[2025-07-19T22:10:10.354+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 666) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.355+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 655) in 353 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T22:10:10.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 63.0 in stage 7.0 (TID 666)
[2025-07-19T22:10:10.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.361+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:10.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.2.delta.1f037d1b-fe86-4d90-baea-b40b660f1654.TID663.tmp
[2025-07-19T22:10:10.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:10.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@410805db
[2025-07-19T22:10:10.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62] for update
[2025-07-19T22:10:10.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@673296a3
[2025-07-19T22:10:10.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63] for update
[2025-07-19T22:10:10.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.371+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.2.delta.4dd9fcf4-4ff1-4440-ab6e-46a98edff0e1.TID658.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/2.delta
[2025-07-19T22:10:10.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/55/2.delta
[2025-07-19T22:10:10.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.2.delta.38faf4b2-e1e6-4bfc-870e-1be94b6914ca.TID659.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/2.delta
[2025-07-19T22:10:10.377+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/56/2.delta
[2025-07-19T22:10:10.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.2.delta.c7a123fc-9814-4510-b009-00fdc34ede94.TID662.tmp
[2025-07-19T22:10:10.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T22:10:10.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.386+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T22:10:10.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 8b44f3d35cfa:37751 in memory (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T22:10:10.392+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T22:10:10.397+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 55.0 in stage 7.0 (TID 658). 5829 bytes result sent to driver
[2025-07-19T22:10:10.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 667) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 658) in 337 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T22:10:10.402+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 64.0 in stage 7.0 (TID 667)
[2025-07-19T22:10:10.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T22:10:10.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 56.0 in stage 7.0 (TID 659). 5829 bytes result sent to driver
[2025-07-19T22:10:10.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 668) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.406+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.407+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.408+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 65.0 in stage 7.0 (TID 668)
[2025-07-19T22:10:10.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 659) in 307 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T22:10:10.414+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68140c03
[2025-07-19T22:10:10.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.2.delta.d2ca4e95-b92c-4349-afa6-a0a4b670270a.TID665.tmp
[2025-07-19T22:10:10.418+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.419+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64] for update
[2025-07-19T22:10:10.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.423+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.423+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ddd25d1
[2025-07-19T22:10:10.423+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.2.delta.12a8dcf4-abe9-4316-a506-9773fa6a07fb.TID660.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/2.delta
[2025-07-19T22:10:10.424+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/57/2.delta
[2025-07-19T22:10:10.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65] for update
[2025-07-19T22:10:10.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T22:10:10.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.2.delta.100070a1-fe3e-442b-acdb-f4e4bc3e06d1.TID664.tmp
[2025-07-19T22:10:10.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.2.delta.5eca3ea8-c182-4235-8e64-647237f2fad1.TID666.tmp
[2025-07-19T22:10:10.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.430+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 8b44f3d35cfa:37751 in memory (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T22:10:10.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T22:10:10.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 57.0 in stage 7.0 (TID 660). 5872 bytes result sent to driver
[2025-07-19T22:10:10.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 669) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 66.0 in stage 7.0 (TID 669)
[2025-07-19T22:10:10.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 660) in 318 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T22:10:10.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@629bb1a5
[2025-07-19T22:10:10.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66] for update
[2025-07-19T22:10:10.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.2.delta.cbf68eba-c3d1-4c9f-a7d9-e0ac9e588ee1.TID667.tmp
[2025-07-19T22:10:10.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 8b44f3d35cfa:37751 in memory (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T22:10:10.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.2.delta.1f037d1b-fe86-4d90-baea-b40b660f1654.TID663.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/2.delta
[2025-07-19T22:10:10.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/60/2.delta
[2025-07-19T22:10:10.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T22:10:10.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T22:10:10.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 60.0 in stage 7.0 (TID 663). 5829 bytes result sent to driver
[2025-07-19T22:10:10.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.2.delta.1e343213-7354-4f34-b37b-887eec98ddfe.TID668.tmp
[2025-07-19T22:10:10.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 670) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 67.0 in stage 7.0 (TID 670)
[2025-07-19T22:10:10.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 663) in 151 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T22:10:10.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.2.delta.eb48173a-906d-4e6d-94a9-75fac03aa157.TID669.tmp
[2025-07-19T22:10:10.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b45b49b
[2025-07-19T22:10:10.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67] for update
[2025-07-19T22:10:10.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.2.delta.c7a123fc-9814-4510-b009-00fdc34ede94.TID662.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/2.delta
[2025-07-19T22:10:10.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/59/2.delta
[2025-07-19T22:10:10.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T22:10:10.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.2.delta.d2ca4e95-b92c-4349-afa6-a0a4b670270a.TID665.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/2.delta
[2025-07-19T22:10:10.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/62/2.delta
[2025-07-19T22:10:10.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T22:10:10.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.2.delta.100070a1-fe3e-442b-acdb-f4e4bc3e06d1.TID664.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/2.delta
[2025-07-19T22:10:10.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/61/2.delta
[2025-07-19T22:10:10.462+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T22:10:10.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.2.delta.5eca3ea8-c182-4235-8e64-647237f2fad1.TID666.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/2.delta
[2025-07-19T22:10:10.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/63/2.delta
[2025-07-19T22:10:10.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T22:10:10.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 59.0 in stage 7.0 (TID 662). 5829 bytes result sent to driver
[2025-07-19T22:10:10.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 671) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T22:10:10.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 662) in 220 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T22:10:10.471+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 68.0 in stage 7.0 (TID 671)
[2025-07-19T22:10:10.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T22:10:10.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.473+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T22:10:10.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 62.0 in stage 7.0 (TID 665). 5829 bytes result sent to driver
[2025-07-19T22:10:10.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 672) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 665) in 133 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T22:10:10.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 69.0 in stage 7.0 (TID 672)
[2025-07-19T22:10:10.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 61.0 in stage 7.0 (TID 664). 5829 bytes result sent to driver
[2025-07-19T22:10:10.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21160f58
[2025-07-19T22:10:10.480+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68] for update
[2025-07-19T22:10:10.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T22:10:10.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.484+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.2.delta.f306c1e9-489b-40d5-872d-688a03ce41bd.TID670.tmp
[2025-07-19T22:10:10.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 63.0 in stage 7.0 (TID 666). 5872 bytes result sent to driver
[2025-07-19T22:10:10.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 673) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 70.0 in stage 7.0 (TID 673)
[2025-07-19T22:10:10.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 674) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 664) in 143 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T22:10:10.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.2.delta.cbf68eba-c3d1-4c9f-a7d9-e0ac9e588ee1.TID667.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/2.delta
[2025-07-19T22:10:10.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/64/2.delta
[2025-07-19T22:10:10.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 666) in 132 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T22:10:10.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T22:10:10.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 71.0 in stage 7.0 (TID 674)
[2025-07-19T22:10:10.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:10.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:10.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a823ed3
[2025-07-19T22:10:10.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T22:10:10.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69] for update
[2025-07-19T22:10:10.507+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1aab093b
[2025-07-19T22:10:10.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70] for update
[2025-07-19T22:10:10.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 64.0 in stage 7.0 (TID 667). 5829 bytes result sent to driver
[2025-07-19T22:10:10.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.510+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.2.delta.f3371c12-4da4-42df-8910-a6439f520240.TID671.tmp
[2025-07-19T22:10:10.510+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1172a901
[2025-07-19T22:10:10.511+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71] for update
[2025-07-19T22:10:10.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.2.delta.eb48173a-906d-4e6d-94a9-75fac03aa157.TID669.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/2.delta
[2025-07-19T22:10:10.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/66/2.delta
[2025-07-19T22:10:10.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 675) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T22:10:10.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 667) in 115 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T22:10:10.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 72.0 in stage 7.0 (TID 675)
[2025-07-19T22:10:10.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.2.delta.1e343213-7354-4f34-b37b-887eec98ddfe.TID668.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/2.delta
[2025-07-19T22:10:10.519+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/65/2.delta
[2025-07-19T22:10:10.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T22:10:10.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T22:10:10.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c8db44
[2025-07-19T22:10:10.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 66.0 in stage 7.0 (TID 669). 5829 bytes result sent to driver
[2025-07-19T22:10:10.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72] for update
[2025-07-19T22:10:10.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 676) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T22:10:10.528+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 669) in 92 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T22:10:10.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 73.0 in stage 7.0 (TID 676)
[2025-07-19T22:10:10.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 65.0 in stage 7.0 (TID 668). 5872 bytes result sent to driver
[2025-07-19T22:10:10.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.530+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.2.delta.0e076f31-5c63-4611-ae96-5fa2249c94f6.TID672.tmp
[2025-07-19T22:10:10.534+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.2.delta.42961b6c-c5be-4733-992e-f3a17fb59b27.TID674.tmp
[2025-07-19T22:10:10.535+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 677) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.2.delta.ee0a7745-3de8-433c-9283-7e5b24475770.TID673.tmp
[2025-07-19T22:10:10.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 668) in 130 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T22:10:10.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 74.0 in stage 7.0 (TID 677)
[2025-07-19T22:10:10.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cb7156d
[2025-07-19T22:10:10.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73] for update
[2025-07-19T22:10:10.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ab854e6
[2025-07-19T22:10:10.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74] for update
[2025-07-19T22:10:10.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.2.delta.4e88ceec-13b4-48fa-8784-4bb8e7ee9a2d.TID675.tmp
[2025-07-19T22:10:10.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.2.delta.f306c1e9-489b-40d5-872d-688a03ce41bd.TID670.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/2.delta
[2025-07-19T22:10:10.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/67/2.delta
[2025-07-19T22:10:10.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T22:10:10.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.2.delta.ce8c8498-4405-43de-a02a-bc2ee35fbe32.TID677.tmp
[2025-07-19T22:10:10.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T22:10:10.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 67.0 in stage 7.0 (TID 670). 5829 bytes result sent to driver
[2025-07-19T22:10:10.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.2.delta.29798223-1fb9-47f7-99f1-cd31e5af2b27.TID676.tmp
[2025-07-19T22:10:10.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 678) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 75.0 in stage 7.0 (TID 678)
[2025-07-19T22:10:10.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 670) in 107 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T22:10:10.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@794ec0be
[2025-07-19T22:10:10.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75] for update
[2025-07-19T22:10:10.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.2.delta.f3371c12-4da4-42df-8910-a6439f520240.TID671.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/2.delta
[2025-07-19T22:10:10.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/68/2.delta
[2025-07-19T22:10:10.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T22:10:10.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T22:10:10.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 68.0 in stage 7.0 (TID 671). 5829 bytes result sent to driver
[2025-07-19T22:10:10.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 679) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 671) in 97 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T22:10:10.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 76.0 in stage 7.0 (TID 679)
[2025-07-19T22:10:10.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.2.delta.0e076f31-5c63-4611-ae96-5fa2249c94f6.TID672.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/2.delta
[2025-07-19T22:10:10.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/69/2.delta
[2025-07-19T22:10:10.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.2.delta.77c2d98d-69df-435a-aa75-9981704b2aa1.TID678.tmp
[2025-07-19T22:10:10.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T22:10:10.572+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.2.delta.ee0a7745-3de8-433c-9283-7e5b24475770.TID673.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/2.delta
[2025-07-19T22:10:10.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/70/2.delta
[2025-07-19T22:10:10.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14e678c9
[2025-07-19T22:10:10.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76] for update
[2025-07-19T22:10:10.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T22:10:10.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.2.delta.42961b6c-c5be-4733-992e-f3a17fb59b27.TID674.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/2.delta
[2025-07-19T22:10:10.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/71/2.delta
[2025-07-19T22:10:10.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T22:10:10.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T22:10:10.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 69.0 in stage 7.0 (TID 672). 5829 bytes result sent to driver
[2025-07-19T22:10:10.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 680) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 672) in 106 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T22:10:10.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T22:10:10.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 70.0 in stage 7.0 (TID 673). 5829 bytes result sent to driver
[2025-07-19T22:10:10.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 681) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 78.0 in stage 7.0 (TID 681)
[2025-07-19T22:10:10.594+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 77.0 in stage 7.0 (TID 680)
[2025-07-19T22:10:10.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.2.delta.4e88ceec-13b4-48fa-8784-4bb8e7ee9a2d.TID675.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/2.delta
[2025-07-19T22:10:10.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/72/2.delta
[2025-07-19T22:10:10.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:10.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T22:10:10.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50ec4750
[2025-07-19T22:10:10.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T22:10:10.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 673) in 109 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T22:10:10.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78] for update
[2025-07-19T22:10:10.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.2.delta.ce8c8498-4405-43de-a02a-bc2ee35fbe32.TID677.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/2.delta
[2025-07-19T22:10:10.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 71.0 in stage 7.0 (TID 674). 5872 bytes result sent to driver
[2025-07-19T22:10:10.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/74/2.delta
[2025-07-19T22:10:10.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T22:10:10.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 682) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 72.0 in stage 7.0 (TID 675). 5829 bytes result sent to driver
[2025-07-19T22:10:10.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 79.0 in stage 7.0 (TID 682)
[2025-07-19T22:10:10.619+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 683) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.621+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 675) in 101 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T22:10:10.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T22:10:10.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 674) in 114 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T22:10:10.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 80.0 in stage 7.0 (TID 683)
[2025-07-19T22:10:10.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@339405d8
[2025-07-19T22:10:10.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.2.delta.fded04e3-7470-49f6-bdfe-afab0853f852.TID679.tmp
[2025-07-19T22:10:10.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77] for update
[2025-07-19T22:10:10.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.2.delta.29798223-1fb9-47f7-99f1-cd31e5af2b27.TID676.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/2.delta
[2025-07-19T22:10:10.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/73/2.delta
[2025-07-19T22:10:10.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:10.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T22:10:10.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T22:10:10.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T22:10:10.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 73.0 in stage 7.0 (TID 676). 5829 bytes result sent to driver
[2025-07-19T22:10:10.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@738a3d9a
[2025-07-19T22:10:10.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 74.0 in stage 7.0 (TID 677). 5829 bytes result sent to driver
[2025-07-19T22:10:10.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 684) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 81.0 in stage 7.0 (TID 684)
[2025-07-19T22:10:10.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 676) in 107 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T22:10:10.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 685) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 82.0 in stage 7.0 (TID 685)
[2025-07-19T22:10:10.645+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80] for update
[2025-07-19T22:10:10.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.647+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:10.648+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 677) in 103 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T22:10:10.648+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.649+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.650+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48064ebd
[2025-07-19T22:10:10.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.652+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81] for update
[2025-07-19T22:10:10.652+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ff7502
[2025-07-19T22:10:10.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79] for update
[2025-07-19T22:10:10.656+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dd3df73
[2025-07-19T22:10:10.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.2.delta.f3001fcb-8103-439b-b19d-3ad292d5a6f0.TID680.tmp
[2025-07-19T22:10:10.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.660+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82] for update
[2025-07-19T22:10:10.660+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.2.delta.5b26e87f-8ada-4f42-9966-85456c50ba63.TID681.tmp
[2025-07-19T22:10:10.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.2.delta.4f1ac9df-51ef-46a4-88ac-69ec202b9d4d.TID683.tmp
[2025-07-19T22:10:10.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.2.delta.77c2d98d-69df-435a-aa75-9981704b2aa1.TID678.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/2.delta
[2025-07-19T22:10:10.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/75/2.delta
[2025-07-19T22:10:10.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.2.delta.183d9196-a757-4309-b13d-f030de263f42.TID684.tmp
[2025-07-19T22:10:10.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T22:10:10.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.2.delta.bcbc8b3e-5503-40f8-b4f1-fd5726db096a.TID682.tmp
[2025-07-19T22:10:10.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.2.delta.46406e5f-629a-4cee-90fb-5545273080ed.TID685.tmp
[2025-07-19T22:10:10.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T22:10:10.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 75.0 in stage 7.0 (TID 678). 5829 bytes result sent to driver
[2025-07-19T22:10:10.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 686) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 83.0 in stage 7.0 (TID 686)
[2025-07-19T22:10:10.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 678) in 116 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T22:10:10.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b6fb5ae
[2025-07-19T22:10:10.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83] for update
[2025-07-19T22:10:10.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.2.delta.fded04e3-7470-49f6-bdfe-afab0853f852.TID679.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/2.delta
[2025-07-19T22:10:10.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/76/2.delta
[2025-07-19T22:10:10.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T22:10:10.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T22:10:10.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 76.0 in stage 7.0 (TID 679). 5829 bytes result sent to driver
[2025-07-19T22:10:10.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 687) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 84.0 in stage 7.0 (TID 687)
[2025-07-19T22:10:10.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 679) in 113 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T22:10:10.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6eeaaed8
[2025-07-19T22:10:10.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84] for update
[2025-07-19T22:10:10.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.2.delta.f3001fcb-8103-439b-b19d-3ad292d5a6f0.TID680.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/2.delta
[2025-07-19T22:10:10.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/77/2.delta
[2025-07-19T22:10:10.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T22:10:10.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.2.delta.b0fc122e-6244-4079-88cf-e28cefad4541.TID686.tmp
[2025-07-19T22:10:10.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T22:10:10.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 77.0 in stage 7.0 (TID 680). 5829 bytes result sent to driver
[2025-07-19T22:10:10.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.2.delta.5b26e87f-8ada-4f42-9966-85456c50ba63.TID681.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/2.delta
[2025-07-19T22:10:10.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/78/2.delta
[2025-07-19T22:10:10.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 680) in 118 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T22:10:10.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 688) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T22:10:10.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 85.0 in stage 7.0 (TID 688)
[2025-07-19T22:10:10.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.2.delta.183d9196-a757-4309-b13d-f030de263f42.TID684.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/2.delta
[2025-07-19T22:10:10.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/81/2.delta
[2025-07-19T22:10:10.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ac1964b
[2025-07-19T22:10:10.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T22:10:10.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85] for update
[2025-07-19T22:10:10.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T22:10:10.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 78.0 in stage 7.0 (TID 681). 5829 bytes result sent to driver
[2025-07-19T22:10:10.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 681) in 125 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T22:10:10.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.2.delta.4f1ac9df-51ef-46a4-88ac-69ec202b9d4d.TID683.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/2.delta
[2025-07-19T22:10:10.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/80/2.delta
[2025-07-19T22:10:10.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 689) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.704+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.704+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 86.0 in stage 7.0 (TID 689)
[2025-07-19T22:10:10.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.2.delta.d06f0e1d-000a-4711-a06a-8ee028ae33a8.TID687.tmp
[2025-07-19T22:10:10.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T22:10:10.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T22:10:10.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.2.delta.46406e5f-629a-4cee-90fb-5545273080ed.TID685.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/2.delta
[2025-07-19T22:10:10.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/82/2.delta
[2025-07-19T22:10:10.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.719+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 81.0 in stage 7.0 (TID 684). 5872 bytes result sent to driver
[2025-07-19T22:10:10.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T22:10:10.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.2.delta.bcbc8b3e-5503-40f8-b4f1-fd5726db096a.TID682.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/2.delta
[2025-07-19T22:10:10.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 690) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/79/2.delta
[2025-07-19T22:10:10.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 87.0 in stage 7.0 (TID 690)
[2025-07-19T22:10:10.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T22:10:10.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 80.0 in stage 7.0 (TID 683). 5872 bytes result sent to driver
[2025-07-19T22:10:10.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b86d92e
[2025-07-19T22:10:10.728+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T22:10:10.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.733+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86] for update
[2025-07-19T22:10:10.733+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:10.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 691) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 88.0 in stage 7.0 (TID 691)
[2025-07-19T22:10:10.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ab68177
[2025-07-19T22:10:10.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T22:10:10.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 684) in 113 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T22:10:10.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 683) in 131 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T22:10:10.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.743+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87] for update
[2025-07-19T22:10:10.744+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 82.0 in stage 7.0 (TID 685). 5872 bytes result sent to driver
[2025-07-19T22:10:10.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 692) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 89.0 in stage 7.0 (TID 692)
[2025-07-19T22:10:10.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T22:10:10.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 685) in 117 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T22:10:10.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 79.0 in stage 7.0 (TID 682). 5872 bytes result sent to driver
[2025-07-19T22:10:10.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ea6d863
[2025-07-19T22:10:10.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 693) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 90.0 in stage 7.0 (TID 693)
[2025-07-19T22:10:10.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89] for update
[2025-07-19T22:10:10.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 682) in 140 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T22:10:10.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5db4471d
[2025-07-19T22:10:10.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88] for update
[2025-07-19T22:10:10.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.2.delta.b45c747f-7238-4b5e-b4e9-729ea50745d3.TID688.tmp
[2025-07-19T22:10:10.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60a31a1b
[2025-07-19T22:10:10.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90] for update
[2025-07-19T22:10:10.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.2.delta.512b6352-059a-4938-a1c4-f4d478d1e4c1.TID689.tmp
[2025-07-19T22:10:10.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.2.delta.b88ec54a-deec-4aba-8a54-4a37a96426dd.TID690.tmp
[2025-07-19T22:10:10.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.2.delta.23abaeb5-c22d-42ef-bdd0-19aa5d0591c5.TID692.tmp
[2025-07-19T22:10:10.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.2.delta.9afc72ba-9d5c-4c6b-95c7-7f03f3a37cc3.TID691.tmp
[2025-07-19T22:10:10.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.2.delta.b0fc122e-6244-4079-88cf-e28cefad4541.TID686.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/2.delta
[2025-07-19T22:10:10.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/83/2.delta
[2025-07-19T22:10:10.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T22:10:10.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.2.delta.c4daffd6-e6d1-4edb-9903-4239fb27e64b.TID693.tmp
[2025-07-19T22:10:10.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T22:10:10.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 83.0 in stage 7.0 (TID 686). 5872 bytes result sent to driver
[2025-07-19T22:10:10.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 694) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 686) in 112 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T22:10:10.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 91.0 in stage 7.0 (TID 694)
[2025-07-19T22:10:10.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@127d3662
[2025-07-19T22:10:10.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.772+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91] for update
[2025-07-19T22:10:10.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.2.delta.d06f0e1d-000a-4711-a06a-8ee028ae33a8.TID687.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/2.delta
[2025-07-19T22:10:10.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/84/2.delta
[2025-07-19T22:10:10.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T22:10:10.792+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T22:10:10.793+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 84.0 in stage 7.0 (TID 687). 5872 bytes result sent to driver
[2025-07-19T22:10:10.793+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 695) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.793+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 687) in 122 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T22:10:10.794+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 92.0 in stage 7.0 (TID 695)
[2025-07-19T22:10:10.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.797+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.2.delta.b45c747f-7238-4b5e-b4e9-729ea50745d3.TID688.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/2.delta
[2025-07-19T22:10:10.798+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/85/2.delta
[2025-07-19T22:10:10.800+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75302ed6
[2025-07-19T22:10:10.801+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T22:10:10.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92] for update
[2025-07-19T22:10:10.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T22:10:10.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 85.0 in stage 7.0 (TID 688). 5872 bytes result sent to driver
[2025-07-19T22:10:10.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.2.delta.512b6352-059a-4938-a1c4-f4d478d1e4c1.TID689.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/2.delta
[2025-07-19T22:10:10.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/86/2.delta
[2025-07-19T22:10:10.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T22:10:10.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 696) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.809+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 688) in 114 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T22:10:10.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 93.0 in stage 7.0 (TID 696)
[2025-07-19T22:10:10.811+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.2.delta.23abaeb5-c22d-42ef-bdd0-19aa5d0591c5.TID692.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/2.delta
[2025-07-19T22:10:10.812+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/89/2.delta
[2025-07-19T22:10:10.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T22:10:10.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.2.delta.abadd97f-6b0a-4afc-a47b-5e7b83e4bd66.TID694.tmp
[2025-07-19T22:10:10.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T22:10:10.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T22:10:10.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 86.0 in stage 7.0 (TID 689). 5872 bytes result sent to driver
[2025-07-19T22:10:10.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 89.0 in stage 7.0 (TID 692). 5872 bytes result sent to driver
[2025-07-19T22:10:10.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54a4ba3e
[2025-07-19T22:10:10.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.2.delta.6d06f29d-ab3c-43de-bd3c-d41a5ec86552.TID695.tmp
[2025-07-19T22:10:10.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93] for update
[2025-07-19T22:10:10.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 697) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 698) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 689) in 114 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T22:10:10.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 692) in 95 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T22:10:10.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 95.0 in stage 7.0 (TID 698)
[2025-07-19T22:10:10.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 94.0 in stage 7.0 (TID 697)
[2025-07-19T22:10:10.831+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:10.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bfa0aa
[2025-07-19T22:10:10.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94] for update
[2025-07-19T22:10:10.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6896062a
[2025-07-19T22:10:10.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95] for update
[2025-07-19T22:10:10.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.2.delta.9afc72ba-9d5c-4c6b-95c7-7f03f3a37cc3.TID691.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/2.delta
[2025-07-19T22:10:10.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/88/2.delta
[2025-07-19T22:10:10.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T22:10:10.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.2.delta.b88ec54a-deec-4aba-8a54-4a37a96426dd.TID690.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/2.delta
[2025-07-19T22:10:10.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/87/2.delta
[2025-07-19T22:10:10.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T22:10:10.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.2.delta.c4daffd6-e6d1-4edb-9903-4239fb27e64b.TID693.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/2.delta
[2025-07-19T22:10:10.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/90/2.delta
[2025-07-19T22:10:10.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T22:10:10.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.2.delta.34057e92-6cb0-4dab-b7fd-7982e3d5afbb.TID696.tmp
[2025-07-19T22:10:10.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T22:10:10.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T22:10:10.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 88.0 in stage 7.0 (TID 691). 5872 bytes result sent to driver
[2025-07-19T22:10:10.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 87.0 in stage 7.0 (TID 690). 5872 bytes result sent to driver
[2025-07-19T22:10:10.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T22:10:10.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 90.0 in stage 7.0 (TID 693). 5872 bytes result sent to driver
[2025-07-19T22:10:10.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 699) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 96.0 in stage 7.0 (TID 699)
[2025-07-19T22:10:10.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 700) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.2.delta.baa94e08-8490-4909-afdd-37f7138d8054.TID698.tmp
[2025-07-19T22:10:10.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 701) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 690) in 130 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T22:10:10.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 693) in 117 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T22:10:10.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 97.0 in stage 7.0 (TID 700)
[2025-07-19T22:10:10.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 691) in 130 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T22:10:10.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.2.delta.e55d533a-b141-4337-9ff9-e1132e24c9e5.TID697.tmp
[2025-07-19T22:10:10.859+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 98.0 in stage 7.0 (TID 701)
[2025-07-19T22:10:10.861+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.862+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.865+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d6a4d5b
[2025-07-19T22:10:10.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96] for update
[2025-07-19T22:10:10.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6102244a
[2025-07-19T22:10:10.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97] for update
[2025-07-19T22:10:10.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2879f32d
[2025-07-19T22:10:10.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98] for update
[2025-07-19T22:10:10.870+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.2.delta.aee03ae9-8323-4d8d-9016-cc3fe4bc7fea.TID699.tmp
[2025-07-19T22:10:10.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.2.delta.6d06f29d-ab3c-43de-bd3c-d41a5ec86552.TID695.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/2.delta
[2025-07-19T22:10:10.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/92/2.delta
[2025-07-19T22:10:10.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.2.delta.f2bc4588-f7b8-4eee-ab02-42e5b9e04068.TID700.tmp
[2025-07-19T22:10:10.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T22:10:10.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.2.delta.4c207524-bc56-4cbf-9e51-f700b8a5ee1c.TID701.tmp
[2025-07-19T22:10:10.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T22:10:10.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 92.0 in stage 7.0 (TID 695). 5829 bytes result sent to driver
[2025-07-19T22:10:10.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 702) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 695) in 97 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T22:10:10.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 99.0 in stage 7.0 (TID 702)
[2025-07-19T22:10:10.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.2.delta.abadd97f-6b0a-4afc-a47b-5e7b83e4bd66.TID694.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/2.delta
[2025-07-19T22:10:10.895+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/91/2.delta
[2025-07-19T22:10:10.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T22:10:10.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50ecad75
[2025-07-19T22:10:10.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99] for update
[2025-07-19T22:10:10.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T22:10:10.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 91.0 in stage 7.0 (TID 694). 5915 bytes result sent to driver
[2025-07-19T22:10:10.907+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 100.0 in stage 7.0 (TID 703) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 100.0 in stage 7.0 (TID 703)
[2025-07-19T22:10:10.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 694) in 146 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T22:10:10.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.2.delta.34057e92-6cb0-4dab-b7fd-7982e3d5afbb.TID696.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/2.delta
[2025-07-19T22:10:10.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/93/2.delta
[2025-07-19T22:10:10.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T22:10:10.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.2.delta.baa94e08-8490-4909-afdd-37f7138d8054.TID698.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/2.delta
[2025-07-19T22:10:10.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/95/2.delta
[2025-07-19T22:10:10.915+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T22:10:10.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T22:10:10.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 93.0 in stage 7.0 (TID 696). 5829 bytes result sent to driver
[2025-07-19T22:10:10.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 101.0 in stage 7.0 (TID 704) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 101.0 in stage 7.0 (TID 704)
[2025-07-19T22:10:10.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 696) in 113 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T22:10:10.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69135126
[2025-07-19T22:10:10.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.2.delta.e55d533a-b141-4337-9ff9-e1132e24c9e5.TID697.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/2.delta
[2025-07-19T22:10:10.929+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/94/2.delta
[2025-07-19T22:10:10.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T22:10:10.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100] for update
[2025-07-19T22:10:10.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T22:10:10.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 95.0 in stage 7.0 (TID 698). 5829 bytes result sent to driver
[2025-07-19T22:10:10.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 102.0 in stage 7.0 (TID 705) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 102.0 in stage 7.0 (TID 705)
[2025-07-19T22:10:10.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T22:10:10.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 698) in 108 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T22:10:10.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 94.0 in stage 7.0 (TID 697). 5829 bytes result sent to driver
[2025-07-19T22:10:10.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c523f4e
[2025-07-19T22:10:10.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 103.0 in stage 7.0 (TID 706) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 103.0 in stage 7.0 (TID 706)
[2025-07-19T22:10:10.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101] for update
[2025-07-19T22:10:10.949+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 697) in 111 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T22:10:10.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4220b61a
[2025-07-19T22:10:10.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102] for update
[2025-07-19T22:10:10.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.2.delta.aee03ae9-8323-4d8d-9016-cc3fe4bc7fea.TID699.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/2.delta
[2025-07-19T22:10:10.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/96/2.delta
[2025-07-19T22:10:10.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.2.delta.5cfeae2e-ab44-4069-b317-84d4ef90d654.TID702.tmp
[2025-07-19T22:10:10.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T22:10:10.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.959+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.960+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T22:10:10.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f7e9260
[2025-07-19T22:10:10.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 96.0 in stage 7.0 (TID 699). 5829 bytes result sent to driver
[2025-07-19T22:10:10.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103] for update
[2025-07-19T22:10:10.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 104.0 in stage 7.0 (TID 707) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 699) in 97 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T22:10:10.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 104.0 in stage 7.0 (TID 707)
[2025-07-19T22:10:10.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.2.delta.357dcd29-42ae-4e42-8f73-3c9b8c872253.TID705.tmp
[2025-07-19T22:10:10.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a9c5625
[2025-07-19T22:10:10.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.2.delta.573fbf73-fa1b-4dad-8b1d-163b44c7952a.TID704.tmp
[2025-07-19T22:10:10.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.964+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104] for update
[2025-07-19T22:10:10.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.2.delta.137240be-bc5f-45eb-8252-054b37a9bf5c.TID703.tmp
[2025-07-19T22:10:10.966+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.2.delta.f2bc4588-f7b8-4eee-ab02-42e5b9e04068.TID700.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/2.delta
[2025-07-19T22:10:10.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/97/2.delta
[2025-07-19T22:10:10.971+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T22:10:10.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.2.delta.82eea034-078d-4a49-abc2-b7e3fe7ff0c1.TID706.tmp
[2025-07-19T22:10:10.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T22:10:10.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 97.0 in stage 7.0 (TID 700). 5829 bytes result sent to driver
[2025-07-19T22:10:10.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 105.0 in stage 7.0 (TID 708) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.2.delta.2e3f716c-5b51-40cb-995f-6ae946ca14bf.TID707.tmp
[2025-07-19T22:10:10.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 700) in 124 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T22:10:10.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 105.0 in stage 7.0 (TID 708)
[2025-07-19T22:10:10.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.2.delta.4c207524-bc56-4cbf-9e51-f700b8a5ee1c.TID701.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/2.delta
[2025-07-19T22:10:10.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/98/2.delta
[2025-07-19T22:10:10.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.980+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.981+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T22:10:10.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25965ba6
[2025-07-19T22:10:10.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105] for update
[2025-07-19T22:10:10.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Committed partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T22:10:10.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Finished task 98.0 in stage 7.0 (TID 701). 5829 bytes result sent to driver
[2025-07-19T22:10:10.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Starting task 106.0 in stage 7.0 (TID 709) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:10.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO Executor: Running task 106.0 in stage 7.0 (TID 709)
[2025-07-19T22:10:10.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 701) in 140 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T22:10:10.989+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:10.992+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:10.992+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a18fe13
[2025-07-19T22:10:10.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:10.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106] for update
[2025-07-19T22:10:10.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.2.delta.36979217-7402-49d2-a187-26f3c950c55f.TID708.tmp
[2025-07-19T22:10:10.994+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.2.delta.5cfeae2e-ab44-4069-b317-84d4ef90d654.TID702.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/2.delta
[2025-07-19T22:10:10.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/99/2.delta
[2025-07-19T22:10:10.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:10.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:10 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T22:10:11.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T22:10:11.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 99.0 in stage 7.0 (TID 702). 5829 bytes result sent to driver
[2025-07-19T22:10:11.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 107.0 in stage 7.0 (TID 710) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.008+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 107.0 in stage 7.0 (TID 710)
[2025-07-19T22:10:11.009+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 702) in 121 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T22:10:11.016+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.2.delta.357dcd29-42ae-4e42-8f73-3c9b8c872253.TID705.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/2.delta
[2025-07-19T22:10:11.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@559b58fc
[2025-07-19T22:10:11.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/102/2.delta
[2025-07-19T22:10:11.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.2.delta.137240be-bc5f-45eb-8252-054b37a9bf5c.TID703.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/2.delta
[2025-07-19T22:10:11.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/100/2.delta
[2025-07-19T22:10:11.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T22:10:11.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T22:10:11.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107] for update
[2025-07-19T22:10:11.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.2.delta.b7e8a7ab-1f81-4966-aebb-3f89295d42e4.TID709.tmp
[2025-07-19T22:10:11.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.2.delta.573fbf73-fa1b-4dad-8b1d-163b44c7952a.TID704.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/2.delta
[2025-07-19T22:10:11.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/101/2.delta
[2025-07-19T22:10:11.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T22:10:11.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T22:10:11.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 102.0 in stage 7.0 (TID 705). 5829 bytes result sent to driver
[2025-07-19T22:10:11.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 108.0 in stage 7.0 (TID 711) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 102.0 in stage 7.0 (TID 705) in 102 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T22:10:11.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 108.0 in stage 7.0 (TID 711)
[2025-07-19T22:10:11.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T22:10:11.030+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T22:10:11.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 100.0 in stage 7.0 (TID 703). 5829 bytes result sent to driver
[2025-07-19T22:10:11.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 101.0 in stage 7.0 (TID 704). 5829 bytes result sent to driver
[2025-07-19T22:10:11.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52fbbf43
[2025-07-19T22:10:11.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.2.delta.2e3f716c-5b51-40cb-995f-6ae946ca14bf.TID707.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/2.delta
[2025-07-19T22:10:11.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/104/2.delta
[2025-07-19T22:10:11.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 109.0 in stage 7.0 (TID 712) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T22:10:11.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108] for update
[2025-07-19T22:10:11.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 109.0 in stage 7.0 (TID 712)
[2025-07-19T22:10:11.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 110.0 in stage 7.0 (TID 713) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.051+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 101.0 in stage 7.0 (TID 704) in 119 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T22:10:11.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b0db262
[2025-07-19T22:10:11.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109] for update
[2025-07-19T22:10:11.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 110.0 in stage 7.0 (TID 713)
[2025-07-19T22:10:11.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 100.0 in stage 7.0 (TID 703) in 130 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T22:10:11.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.2.delta.82eea034-078d-4a49-abc2-b7e3fe7ff0c1.TID706.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/2.delta
[2025-07-19T22:10:11.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/103/2.delta
[2025-07-19T22:10:11.056+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T22:10:11.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.2.delta.84f22b31-f7a0-4dd3-870d-b4c58c442dc7.TID710.tmp
[2025-07-19T22:10:11.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cdafe73
[2025-07-19T22:10:11.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.2.delta.a2a2658d-645f-49e2-83ed-64331249de75.TID711.tmp
[2025-07-19T22:10:11.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110] for update
[2025-07-19T22:10:11.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T22:10:11.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T22:10:11.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.2.delta.36979217-7402-49d2-a187-26f3c950c55f.TID708.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/2.delta
[2025-07-19T22:10:11.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/105/2.delta
[2025-07-19T22:10:11.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 103.0 in stage 7.0 (TID 706). 5829 bytes result sent to driver
[2025-07-19T22:10:11.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T22:10:11.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 111.0 in stage 7.0 (TID 714) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 104.0 in stage 7.0 (TID 707). 5829 bytes result sent to driver
[2025-07-19T22:10:11.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 111.0 in stage 7.0 (TID 714)
[2025-07-19T22:10:11.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.2.delta.dc6ffa04-95d1-4151-b212-10630bc4c144.TID712.tmp
[2025-07-19T22:10:11.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 103.0 in stage 7.0 (TID 706) in 128 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T22:10:11.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T22:10:11.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 112.0 in stage 7.0 (TID 715) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.071+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 112.0 in stage 7.0 (TID 715)
[2025-07-19T22:10:11.071+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 105.0 in stage 7.0 (TID 708). 5829 bytes result sent to driver
[2025-07-19T22:10:11.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 113.0 in stage 7.0 (TID 716) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 113.0 in stage 7.0 (TID 716)
[2025-07-19T22:10:11.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 105.0 in stage 7.0 (TID 708) in 92 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T22:10:11.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 104.0 in stage 7.0 (TID 707) in 118 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T22:10:11.073+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f1d2f86
[2025-07-19T22:10:11.074+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.074+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111] for update
[2025-07-19T22:10:11.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bf9294f
[2025-07-19T22:10:11.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:11.080+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.080+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113] for update
[2025-07-19T22:10:11.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@201c701b
[2025-07-19T22:10:11.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112] for update
[2025-07-19T22:10:11.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.2.delta.d6c511eb-9346-4f6b-92f0-86dc6ea86506.TID713.tmp
[2025-07-19T22:10:11.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.2.delta.52ed674b-fc58-4d44-a492-1b4b8f88eb1b.TID716.tmp
[2025-07-19T22:10:11.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.2.delta.b7e8a7ab-1f81-4966-aebb-3f89295d42e4.TID709.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/2.delta
[2025-07-19T22:10:11.090+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/106/2.delta
[2025-07-19T22:10:11.091+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T22:10:11.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.2.delta.0c3c35a4-5700-4c34-9ce8-87b73a36ec11.TID715.tmp
[2025-07-19T22:10:11.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.2.delta.1893ac03-6e83-428f-af6c-fe19e972cd13.TID714.tmp
[2025-07-19T22:10:11.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T22:10:11.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 106.0 in stage 7.0 (TID 709). 5829 bytes result sent to driver
[2025-07-19T22:10:11.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.2.delta.84f22b31-f7a0-4dd3-870d-b4c58c442dc7.TID710.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/2.delta
[2025-07-19T22:10:11.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/107/2.delta
[2025-07-19T22:10:11.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 114.0 in stage 7.0 (TID 717) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 106.0 in stage 7.0 (TID 709) in 99 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T22:10:11.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T22:10:11.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 114.0 in stage 7.0 (TID 717)
[2025-07-19T22:10:11.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T22:10:11.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 107.0 in stage 7.0 (TID 710). 5829 bytes result sent to driver
[2025-07-19T22:10:11.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:11.097+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 115.0 in stage 7.0 (TID 718) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.098+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 107.0 in stage 7.0 (TID 710) in 82 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T22:10:11.099+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 115.0 in stage 7.0 (TID 718)
[2025-07-19T22:10:11.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16bd497d
[2025-07-19T22:10:11.101+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.101+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114] for update
[2025-07-19T22:10:11.102+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.102+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.102+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.103+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@245ab4ad
[2025-07-19T22:10:11.104+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.105+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115] for update
[2025-07-19T22:10:11.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.2.delta.dc6ffa04-95d1-4151-b212-10630bc4c144.TID712.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/2.delta
[2025-07-19T22:10:11.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/109/2.delta
[2025-07-19T22:10:11.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T22:10:11.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T22:10:11.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 109.0 in stage 7.0 (TID 712). 5829 bytes result sent to driver
[2025-07-19T22:10:11.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 116.0 in stage 7.0 (TID 719) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.109+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 116.0 in stage 7.0 (TID 719)
[2025-07-19T22:10:11.110+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 109.0 in stage 7.0 (TID 712) in 68 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T22:10:11.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@193b29d6
[2025-07-19T22:10:11.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116] for update
[2025-07-19T22:10:11.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.2.delta.fe14b708-586d-4963-b46f-b3156747b332.TID717.tmp
[2025-07-19T22:10:11.116+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.2.delta.a2a2658d-645f-49e2-83ed-64331249de75.TID711.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/2.delta
[2025-07-19T22:10:11.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/108/2.delta
[2025-07-19T22:10:11.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T22:10:11.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T22:10:11.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 108.0 in stage 7.0 (TID 711). 5829 bytes result sent to driver
[2025-07-19T22:10:11.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 117.0 in stage 7.0 (TID 720) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 117.0 in stage 7.0 (TID 720)
[2025-07-19T22:10:11.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 108.0 in stage 7.0 (TID 711) in 89 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T22:10:11.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.2.delta.967e1db3-fad3-4dfa-b31a-039688d3af4e.TID718.tmp
[2025-07-19T22:10:11.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:11.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51f63579
[2025-07-19T22:10:11.123+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.124+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117] for update
[2025-07-19T22:10:11.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.2.delta.1e119f5d-98b7-44e1-b6bf-f336f0f30f80.TID719.tmp
[2025-07-19T22:10:11.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.2.delta.1893ac03-6e83-428f-af6c-fe19e972cd13.TID714.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/2.delta
[2025-07-19T22:10:11.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.2.delta.d6c511eb-9346-4f6b-92f0-86dc6ea86506.TID713.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/2.delta
[2025-07-19T22:10:11.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/110/2.delta
[2025-07-19T22:10:11.130+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/111/2.delta
[2025-07-19T22:10:11.131+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T22:10:11.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T22:10:11.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T22:10:11.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T22:10:11.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 110.0 in stage 7.0 (TID 713). 5829 bytes result sent to driver
[2025-07-19T22:10:11.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 111.0 in stage 7.0 (TID 714). 5829 bytes result sent to driver
[2025-07-19T22:10:11.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 118.0 in stage 7.0 (TID 721) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 119.0 in stage 7.0 (TID 722) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.2.delta.0c3c35a4-5700-4c34-9ce8-87b73a36ec11.TID715.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/2.delta
[2025-07-19T22:10:11.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/112/2.delta
[2025-07-19T22:10:11.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 110.0 in stage 7.0 (TID 713) in 92 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T22:10:11.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 118.0 in stage 7.0 (TID 721)
[2025-07-19T22:10:11.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.2.delta.52ed674b-fc58-4d44-a492-1b4b8f88eb1b.TID716.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/2.delta
[2025-07-19T22:10:11.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/113/2.delta
[2025-07-19T22:10:11.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 119.0 in stage 7.0 (TID 722)
[2025-07-19T22:10:11.141+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 111.0 in stage 7.0 (TID 714) in 77 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T22:10:11.142+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T22:10:11.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@720907e7
[2025-07-19T22:10:11.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T22:10:11.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118] for update
[2025-07-19T22:10:11.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.2.delta.5b7ce60e-f672-4cce-96f1-bbebe0e4fb30.TID720.tmp
[2025-07-19T22:10:11.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35c80bac
[2025-07-19T22:10:11.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T22:10:11.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 112.0 in stage 7.0 (TID 715). 5829 bytes result sent to driver
[2025-07-19T22:10:11.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 120.0 in stage 7.0 (TID 723) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 112.0 in stage 7.0 (TID 715) in 81 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T22:10:11.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119] for update
[2025-07-19T22:10:11.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T22:10:11.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 113.0 in stage 7.0 (TID 716). 5829 bytes result sent to driver
[2025-07-19T22:10:11.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 121.0 in stage 7.0 (TID 724) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 121.0 in stage 7.0 (TID 724)
[2025-07-19T22:10:11.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 113.0 in stage 7.0 (TID 716) in 84 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T22:10:11.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 120.0 in stage 7.0 (TID 723)
[2025-07-19T22:10:11.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:11.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21440cc0
[2025-07-19T22:10:11.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120] for update
[2025-07-19T22:10:11.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.2.delta.b9686046-2ecf-4d16-98b0-dee0746a12d4.TID721.tmp
[2025-07-19T22:10:11.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f042ced
[2025-07-19T22:10:11.150+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121] for update
[2025-07-19T22:10:11.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.154+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.2.delta.1e119f5d-98b7-44e1-b6bf-f336f0f30f80.TID719.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/2.delta
[2025-07-19T22:10:11.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/116/2.delta
[2025-07-19T22:10:11.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T22:10:11.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.2.delta.1a3064d8-1f2e-4e90-8af8-c3c423e0d758.TID722.tmp
[2025-07-19T22:10:11.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.2.delta.fe14b708-586d-4963-b46f-b3156747b332.TID717.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/2.delta
[2025-07-19T22:10:11.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/114/2.delta
[2025-07-19T22:10:11.165+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.2.delta.60507645-80d0-4c6e-97d4-d1f044176694.TID724.tmp
[2025-07-19T22:10:11.167+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.2.delta.c46a17a0-9573-4b2e-872d-79ab2e3bd864.TID723.tmp
[2025-07-19T22:10:11.171+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T22:10:11.174+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T22:10:11.176+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 116.0 in stage 7.0 (TID 719). 5829 bytes result sent to driver
[2025-07-19T22:10:11.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 122.0 in stage 7.0 (TID 725) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.185+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.2.delta.967e1db3-fad3-4dfa-b31a-039688d3af4e.TID718.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/2.delta
[2025-07-19T22:10:11.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 116.0 in stage 7.0 (TID 719) in 64 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T22:10:11.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/115/2.delta
[2025-07-19T22:10:11.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T22:10:11.190+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 122.0 in stage 7.0 (TID 725)
[2025-07-19T22:10:11.192+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 114.0 in stage 7.0 (TID 717). 5829 bytes result sent to driver
[2025-07-19T22:10:11.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 123.0 in stage 7.0 (TID 726) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.2.delta.5b7ce60e-f672-4cce-96f1-bbebe0e4fb30.TID720.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/2.delta
[2025-07-19T22:10:11.225+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/117/2.delta
[2025-07-19T22:10:11.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T22:10:11.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T22:10:11.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.229+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 114.0 in stage 7.0 (TID 717) in 90 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T22:10:11.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 123.0 in stage 7.0 (TID 726)
[2025-07-19T22:10:11.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@769efe48
[2025-07-19T22:10:11.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122] for update
[2025-07-19T22:10:11.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69e03909
[2025-07-19T22:10:11.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123] for update
[2025-07-19T22:10:11.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T22:10:11.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T22:10:11.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 115.0 in stage 7.0 (TID 718). 5829 bytes result sent to driver
[2025-07-19T22:10:11.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 117.0 in stage 7.0 (TID 720). 5829 bytes result sent to driver
[2025-07-19T22:10:11.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 124.0 in stage 7.0 (TID 727) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 124.0 in stage 7.0 (TID 727)
[2025-07-19T22:10:11.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 115.0 in stage 7.0 (TID 718) in 93 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T22:10:11.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 125.0 in stage 7.0 (TID 728) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 117.0 in stage 7.0 (TID 720) in 69 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T22:10:11.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 125.0 in stage 7.0 (TID 728)
[2025-07-19T22:10:11.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b7fa61b
[2025-07-19T22:10:11.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124] for update
[2025-07-19T22:10:11.258+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75d3abab
[2025-07-19T22:10:11.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125] for update
[2025-07-19T22:10:11.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.2.delta.8ce4255c-225a-4f3d-bfbf-7e2f35cb2db6.TID726.tmp
[2025-07-19T22:10:11.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.2.delta.b9686046-2ecf-4d16-98b0-dee0746a12d4.TID721.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/2.delta
[2025-07-19T22:10:11.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/118/2.delta
[2025-07-19T22:10:11.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.2.delta.d586e8c3-f6f1-451b-a99e-9fa884c48df1.TID725.tmp
[2025-07-19T22:10:11.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T22:10:11.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T22:10:11.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 118.0 in stage 7.0 (TID 721). 5829 bytes result sent to driver
[2025-07-19T22:10:11.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 118.0 in stage 7.0 (TID 721) in 106 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T22:10:11.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 126.0 in stage 7.0 (TID 729) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 126.0 in stage 7.0 (TID 729)
[2025-07-19T22:10:11.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.2.delta.83ba18b8-f388-4e22-9cae-d45b6796d16e.TID727.tmp
[2025-07-19T22:10:11.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50ebac34
[2025-07-19T22:10:11.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126] for update
[2025-07-19T22:10:11.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.2.delta.d967943b-8c3b-4f3d-b528-c5032d809a62.TID728.tmp
[2025-07-19T22:10:11.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.2.delta.1c05f466-8f1a-40f8-b68f-f8e042cba9eb.TID729.tmp
[2025-07-19T22:10:11.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.2.delta.c46a17a0-9573-4b2e-872d-79ab2e3bd864.TID723.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/2.delta
[2025-07-19T22:10:11.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/120/2.delta
[2025-07-19T22:10:11.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T22:10:11.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.2.delta.60507645-80d0-4c6e-97d4-d1f044176694.TID724.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/2.delta
[2025-07-19T22:10:11.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/121/2.delta
[2025-07-19T22:10:11.271+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T22:10:11.272+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T22:10:11.272+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 120.0 in stage 7.0 (TID 723). 5829 bytes result sent to driver
[2025-07-19T22:10:11.272+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 127.0 in stage 7.0 (TID 730) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.272+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T22:10:11.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 127.0 in stage 7.0 (TID 730)
[2025-07-19T22:10:11.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 121.0 in stage 7.0 (TID 724). 5829 bytes result sent to driver
[2025-07-19T22:10:11.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 120.0 in stage 7.0 (TID 723) in 130 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T22:10:11.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.2.delta.1a3064d8-1f2e-4e90-8af8-c3c423e0d758.TID722.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/2.delta
[2025-07-19T22:10:11.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/119/2.delta
[2025-07-19T22:10:11.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 128.0 in stage 7.0 (TID 731) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 128.0 in stage 7.0 (TID 731)
[2025-07-19T22:10:11.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 121.0 in stage 7.0 (TID 724) in 129 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T22:10:11.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T22:10:11.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@323ed511
[2025-07-19T22:10:11.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127] for update
[2025-07-19T22:10:11.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@376b2815
[2025-07-19T22:10:11.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128] for update
[2025-07-19T22:10:11.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T22:10:11.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 119.0 in stage 7.0 (TID 722). 5915 bytes result sent to driver
[2025-07-19T22:10:11.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 129.0 in stage 7.0 (TID 732) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.287+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 119.0 in stage 7.0 (TID 722) in 162 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T22:10:11.295+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.2.delta.83ba18b8-f388-4e22-9cae-d45b6796d16e.TID727.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/2.delta
[2025-07-19T22:10:11.295+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/124/2.delta
[2025-07-19T22:10:11.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T22:10:11.297+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.2.delta.b0cc152d-ad63-4b0e-860f-43d89ca6406f.TID730.tmp
[2025-07-19T22:10:11.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 129.0 in stage 7.0 (TID 732)
[2025-07-19T22:10:11.301+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.302+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.303+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T22:10:11.306+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 124.0 in stage 7.0 (TID 727). 5872 bytes result sent to driver
[2025-07-19T22:10:11.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.2.delta.8ce4255c-225a-4f3d-bfbf-7e2f35cb2db6.TID726.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/2.delta
[2025-07-19T22:10:11.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/123/2.delta
[2025-07-19T22:10:11.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.2.delta.d967943b-8c3b-4f3d-b528-c5032d809a62.TID728.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/2.delta
[2025-07-19T22:10:11.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/125/2.delta
[2025-07-19T22:10:11.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 130.0 in stage 7.0 (TID 733) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T22:10:11.311+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T22:10:11.311+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 124.0 in stage 7.0 (TID 727) in 126 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T22:10:11.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 130.0 in stage 7.0 (TID 733)
[2025-07-19T22:10:11.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T22:10:11.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.2.delta.d586e8c3-f6f1-451b-a99e-9fa884c48df1.TID725.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/2.delta
[2025-07-19T22:10:11.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/122/2.delta
[2025-07-19T22:10:11.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T22:10:11.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.2.delta.de5b3471-9c6f-4ef9-8f4f-de93ffbace4f.TID731.tmp
[2025-07-19T22:10:11.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f5e96db
[2025-07-19T22:10:11.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 125.0 in stage 7.0 (TID 728). 5915 bytes result sent to driver
[2025-07-19T22:10:11.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 123.0 in stage 7.0 (TID 726). 5872 bytes result sent to driver
[2025-07-19T22:10:11.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 131.0 in stage 7.0 (TID 734) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 132.0 in stage 7.0 (TID 735) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.325+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 131.0 in stage 7.0 (TID 734)
[2025-07-19T22:10:11.326+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T22:10:11.328+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129] for update
[2025-07-19T22:10:11.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.2.delta.1c05f466-8f1a-40f8-b68f-f8e042cba9eb.TID729.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/2.delta
[2025-07-19T22:10:11.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/126/2.delta
[2025-07-19T22:10:11.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 132.0 in stage 7.0 (TID 735)
[2025-07-19T22:10:11.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.330+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.331+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T22:10:11.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78f13a7a
[2025-07-19T22:10:11.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131] for update
[2025-07-19T22:10:11.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 125.0 in stage 7.0 (TID 728) in 134 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T22:10:11.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 123.0 in stage 7.0 (TID 726) in 146 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T22:10:11.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T22:10:11.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 122.0 in stage 7.0 (TID 725). 5872 bytes result sent to driver
[2025-07-19T22:10:11.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:11.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 133.0 in stage 7.0 (TID 736) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 133.0 in stage 7.0 (TID 736)
[2025-07-19T22:10:11.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 122.0 in stage 7.0 (TID 725) in 153 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T22:10:11.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@712c9c92
[2025-07-19T22:10:11.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132] for update
[2025-07-19T22:10:11.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@564fe949
[2025-07-19T22:10:11.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130] for update
[2025-07-19T22:10:11.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.340+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.340+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.340+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.341+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@140b96db
[2025-07-19T22:10:11.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T22:10:11.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133] for update
[2025-07-19T22:10:11.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 126.0 in stage 7.0 (TID 729). 5872 bytes result sent to driver
[2025-07-19T22:10:11.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 126.0 in stage 7.0 (TID 729) in 98 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T22:10:11.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 134.0 in stage 7.0 (TID 737) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 134.0 in stage 7.0 (TID 737)
[2025-07-19T22:10:11.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.2.delta.b6e60b49-aa7e-4867-aef8-3d6cc330891c.TID732.tmp
[2025-07-19T22:10:11.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e1f9ac5
[2025-07-19T22:10:11.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134] for update
[2025-07-19T22:10:11.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.2.delta.1cf9ce05-ebc3-4c58-b636-53d49fee687c.TID736.tmp
[2025-07-19T22:10:11.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.2.delta.f3cf60bc-9137-4b74-80a6-5d3f1db4c070.TID735.tmp
[2025-07-19T22:10:11.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.2.delta.56533bcf-b0d4-4f06-9ef8-2c0e15435bc9.TID733.tmp
[2025-07-19T22:10:11.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.2.delta.b0cc152d-ad63-4b0e-860f-43d89ca6406f.TID730.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/2.delta
[2025-07-19T22:10:11.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/127/2.delta
[2025-07-19T22:10:11.351+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.2.delta.410d791c-a6ce-4f09-8d3b-efb55a276d76.TID734.tmp
[2025-07-19T22:10:11.351+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T22:10:11.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T22:10:11.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 127.0 in stage 7.0 (TID 730). 5872 bytes result sent to driver
[2025-07-19T22:10:11.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 135.0 in stage 7.0 (TID 738) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 135.0 in stage 7.0 (TID 738)
[2025-07-19T22:10:11.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 127.0 in stage 7.0 (TID 730) in 95 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T22:10:11.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60230ab9
[2025-07-19T22:10:11.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135] for update
[2025-07-19T22:10:11.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.2.delta.6672725b-53b8-41d5-a94e-0e6b2b42c1ed.TID737.tmp
[2025-07-19T22:10:11.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.2.delta.de5b3471-9c6f-4ef9-8f4f-de93ffbace4f.TID731.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/2.delta
[2025-07-19T22:10:11.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/128/2.delta
[2025-07-19T22:10:11.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T22:10:11.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T22:10:11.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 128.0 in stage 7.0 (TID 731). 5872 bytes result sent to driver
[2025-07-19T22:10:11.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 136.0 in stage 7.0 (TID 739) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 128.0 in stage 7.0 (TID 731) in 116 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T22:10:11.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 136.0 in stage 7.0 (TID 739)
[2025-07-19T22:10:11.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.385+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:11.386+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20763e23
[2025-07-19T22:10:11.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.391+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136] for update
[2025-07-19T22:10:11.393+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.2.delta.c6e6973a-ae9c-4b1c-a16f-285c6a9587dc.TID738.tmp
[2025-07-19T22:10:11.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.396+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.2.delta.b6e60b49-aa7e-4867-aef8-3d6cc330891c.TID732.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/2.delta
[2025-07-19T22:10:11.398+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/129/2.delta
[2025-07-19T22:10:11.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T22:10:11.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.2.delta.410d791c-a6ce-4f09-8d3b-efb55a276d76.TID734.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/2.delta
[2025-07-19T22:10:11.400+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/131/2.delta
[2025-07-19T22:10:11.401+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T22:10:11.402+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.2.delta.f3cf60bc-9137-4b74-80a6-5d3f1db4c070.TID735.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/2.delta
[2025-07-19T22:10:11.402+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/132/2.delta
[2025-07-19T22:10:11.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T22:10:11.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T22:10:11.405+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T22:10:11.406+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 129.0 in stage 7.0 (TID 732). 5829 bytes result sent to driver
[2025-07-19T22:10:11.409+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.2.delta.56533bcf-b0d4-4f06-9ef8-2c0e15435bc9.TID733.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/2.delta
[2025-07-19T22:10:11.410+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/130/2.delta
[2025-07-19T22:10:11.410+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 137.0 in stage 7.0 (TID 740) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.411+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T22:10:11.413+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 129.0 in stage 7.0 (TID 732) in 118 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T22:10:11.414+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 137.0 in stage 7.0 (TID 740)
[2025-07-19T22:10:11.415+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 131.0 in stage 7.0 (TID 734). 5829 bytes result sent to driver
[2025-07-19T22:10:11.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 138.0 in stage 7.0 (TID 741) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 138.0 in stage 7.0 (TID 741)
[2025-07-19T22:10:11.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 131.0 in stage 7.0 (TID 734) in 98 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T22:10:11.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.2.delta.36aee1a9-693e-4617-bf47-12a1a05cd4c6.TID739.tmp
[2025-07-19T22:10:11.419+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T22:10:11.421+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.2.delta.1cf9ce05-ebc3-4c58-b636-53d49fee687c.TID736.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/2.delta
[2025-07-19T22:10:11.421+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/133/2.delta
[2025-07-19T22:10:11.421+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 132.0 in stage 7.0 (TID 735). 5829 bytes result sent to driver
[2025-07-19T22:10:11.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T22:10:11.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 139.0 in stage 7.0 (TID 742) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@321a5884
[2025-07-19T22:10:11.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 132.0 in stage 7.0 (TID 735) in 100 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T22:10:11.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 139.0 in stage 7.0 (TID 742)
[2025-07-19T22:10:11.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.2.delta.6672725b-53b8-41d5-a94e-0e6b2b42c1ed.TID737.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/2.delta
[2025-07-19T22:10:11.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/134/2.delta
[2025-07-19T22:10:11.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T22:10:11.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137] for update
[2025-07-19T22:10:11.430+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 130.0 in stage 7.0 (TID 733). 5829 bytes result sent to driver
[2025-07-19T22:10:11.430+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.431+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T22:10:11.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T22:10:11.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 133.0 in stage 7.0 (TID 736). 5829 bytes result sent to driver
[2025-07-19T22:10:11.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 140.0 in stage 7.0 (TID 743) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 141.0 in stage 7.0 (TID 744) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 140.0 in stage 7.0 (TID 743)
[2025-07-19T22:10:11.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 130.0 in stage 7.0 (TID 733) in 115 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T22:10:11.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 133.0 in stage 7.0 (TID 736) in 98 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T22:10:11.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c499c2c
[2025-07-19T22:10:11.438+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138] for update
[2025-07-19T22:10:11.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T22:10:11.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 134.0 in stage 7.0 (TID 737). 5829 bytes result sent to driver
[2025-07-19T22:10:11.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 142.0 in stage 7.0 (TID 745) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 134.0 in stage 7.0 (TID 737) in 91 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T22:10:11.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f0f9671
[2025-07-19T22:10:11.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139] for update
[2025-07-19T22:10:11.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 142.0 in stage 7.0 (TID 745)
[2025-07-19T22:10:11.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 141.0 in stage 7.0 (TID 744)
[2025-07-19T22:10:11.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13231c45
[2025-07-19T22:10:11.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140] for update
[2025-07-19T22:10:11.450+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.451+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e5e1c85
[2025-07-19T22:10:11.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142] for update
[2025-07-19T22:10:11.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.2.delta.29b90b15-e529-45b4-9072-fef5237ec1e8.TID740.tmp
[2025-07-19T22:10:11.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.2.delta.afa5429b-597c-4f50-a9e3-d391244de90d.TID741.tmp
[2025-07-19T22:10:11.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@300bef50
[2025-07-19T22:10:11.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141] for update
[2025-07-19T22:10:11.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.2.delta.ee7a3930-dd73-4f30-8747-6df009883c08.TID742.tmp
[2025-07-19T22:10:11.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.2.delta.d549f278-182d-4543-8f3c-faea64a0c40e.TID745.tmp
[2025-07-19T22:10:11.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.2.delta.f136b841-d279-4665-8faa-6cd7b487a6c6.TID744.tmp
[2025-07-19T22:10:11.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.2.delta.8b87e00e-c79e-4833-ba32-1b684a75ac8f.TID743.tmp
[2025-07-19T22:10:11.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.2.delta.c6e6973a-ae9c-4b1c-a16f-285c6a9587dc.TID738.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/2.delta
[2025-07-19T22:10:11.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/135/2.delta
[2025-07-19T22:10:11.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T22:10:11.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T22:10:11.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.2.delta.36aee1a9-693e-4617-bf47-12a1a05cd4c6.TID739.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/2.delta
[2025-07-19T22:10:11.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/136/2.delta
[2025-07-19T22:10:11.471+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T22:10:11.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 135.0 in stage 7.0 (TID 738). 5829 bytes result sent to driver
[2025-07-19T22:10:11.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 143.0 in stage 7.0 (TID 746) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.473+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T22:10:11.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 143.0 in stage 7.0 (TID 746)
[2025-07-19T22:10:11.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 136.0 in stage 7.0 (TID 739). 5829 bytes result sent to driver
[2025-07-19T22:10:11.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 144.0 in stage 7.0 (TID 747) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 135.0 in stage 7.0 (TID 738) in 115 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T22:10:11.477+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 144.0 in stage 7.0 (TID 747)
[2025-07-19T22:10:11.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 136.0 in stage 7.0 (TID 739) in 91 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T22:10:11.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.480+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.484+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6988d6bd
[2025-07-19T22:10:11.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143] for update
[2025-07-19T22:10:11.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20bc8f1e
[2025-07-19T22:10:11.489+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.489+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144] for update
[2025-07-19T22:10:11.490+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.490+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.2.delta.ee7a3930-dd73-4f30-8747-6df009883c08.TID742.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/2.delta
[2025-07-19T22:10:11.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/139/2.delta
[2025-07-19T22:10:11.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T22:10:11.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.2.delta.29b90b15-e529-45b4-9072-fef5237ec1e8.TID740.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/2.delta
[2025-07-19T22:10:11.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/137/2.delta
[2025-07-19T22:10:11.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T22:10:11.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.2.delta.afa5429b-597c-4f50-a9e3-d391244de90d.TID741.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/2.delta
[2025-07-19T22:10:11.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/138/2.delta
[2025-07-19T22:10:11.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T22:10:11.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.2.delta.2b03ccd7-d0b5-4da4-9687-069ab130995e.TID746.tmp
[2025-07-19T22:10:11.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.2.delta.2abebfd9-8780-41d4-add0-a30f6ca0251f.TID747.tmp
[2025-07-19T22:10:11.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T22:10:11.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 139.0 in stage 7.0 (TID 742). 5829 bytes result sent to driver
[2025-07-19T22:10:11.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 145.0 in stage 7.0 (TID 748) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 139.0 in stage 7.0 (TID 742) in 86 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T22:10:11.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 145.0 in stage 7.0 (TID 748)
[2025-07-19T22:10:11.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T22:10:11.505+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 137.0 in stage 7.0 (TID 740). 5829 bytes result sent to driver
[2025-07-19T22:10:11.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T22:10:11.507+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 146.0 in stage 7.0 (TID 749) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.511+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.2.delta.d549f278-182d-4543-8f3c-faea64a0c40e.TID745.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/2.delta
[2025-07-19T22:10:11.512+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/142/2.delta
[2025-07-19T22:10:11.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 138.0 in stage 7.0 (TID 741). 5829 bytes result sent to driver
[2025-07-19T22:10:11.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T22:10:11.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.2.delta.f136b841-d279-4665-8faa-6cd7b487a6c6.TID744.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/2.delta
[2025-07-19T22:10:11.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/141/2.delta
[2025-07-19T22:10:11.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 147.0 in stage 7.0 (TID 750) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T22:10:11.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 147.0 in stage 7.0 (TID 750)
[2025-07-19T22:10:11.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 137.0 in stage 7.0 (TID 740) in 97 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T22:10:11.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 138.0 in stage 7.0 (TID 741) in 95 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T22:10:11.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ae89014
[2025-07-19T22:10:11.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 146.0 in stage 7.0 (TID 749)
[2025-07-19T22:10:11.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.528+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.528+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145] for update
[2025-07-19T22:10:11.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.530+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.2.delta.8b87e00e-c79e-4833-ba32-1b684a75ac8f.TID743.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/2.delta
[2025-07-19T22:10:11.530+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/140/2.delta
[2025-07-19T22:10:11.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T22:10:11.534+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 142.0 in stage 7.0 (TID 745). 5829 bytes result sent to driver
[2025-07-19T22:10:11.534+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T22:10:11.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cbce470
[2025-07-19T22:10:11.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.537+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147] for update
[2025-07-19T22:10:11.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T22:10:11.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 141.0 in stage 7.0 (TID 744). 5829 bytes result sent to driver
[2025-07-19T22:10:11.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 148.0 in stage 7.0 (TID 751) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.541+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d591bda
[2025-07-19T22:10:11.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 149.0 in stage 7.0 (TID 752) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.543+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 142.0 in stage 7.0 (TID 745) in 91 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T22:10:11.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 149.0 in stage 7.0 (TID 752)
[2025-07-19T22:10:11.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T22:10:11.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 148.0 in stage 7.0 (TID 751)
[2025-07-19T22:10:11.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 140.0 in stage 7.0 (TID 743). 5829 bytes result sent to driver
[2025-07-19T22:10:11.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146] for update
[2025-07-19T22:10:11.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 141.0 in stage 7.0 (TID 744) in 100 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T22:10:11.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.550+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 150.0 in stage 7.0 (TID 753) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3daf75a6
[2025-07-19T22:10:11.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 150.0 in stage 7.0 (TID 753)
[2025-07-19T22:10:11.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.2.delta.1ba5687e-e386-486d-ae32-71176c19e923.TID750.tmp
[2025-07-19T22:10:11.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149] for update
[2025-07-19T22:10:11.556+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.2.delta.dd1a1523-08da-4a50-b6a0-cfd35d7b994a.TID748.tmp
[2025-07-19T22:10:11.556+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.556+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 140.0 in stage 7.0 (TID 743) in 113 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T22:10:11.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@145f7cd4
[2025-07-19T22:10:11.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150] for update
[2025-07-19T22:10:11.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54e74afe
[2025-07-19T22:10:11.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.2.delta.e43f0906-63a8-45e0-a5a8-456f3b528657.TID749.tmp
[2025-07-19T22:10:11.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148] for update
[2025-07-19T22:10:11.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.2.delta.8d630226-82d9-49c7-881f-164972611433.TID753.tmp
[2025-07-19T22:10:11.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.2.delta.531c87c1-6e3d-447e-8668-6374031c92ce.TID752.tmp
[2025-07-19T22:10:11.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.2.delta.2b03ccd7-d0b5-4da4-9687-069ab130995e.TID746.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/2.delta
[2025-07-19T22:10:11.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/143/2.delta
[2025-07-19T22:10:11.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T22:10:11.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T22:10:11.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 143.0 in stage 7.0 (TID 746). 5829 bytes result sent to driver
[2025-07-19T22:10:11.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 151.0 in stage 7.0 (TID 754) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 143.0 in stage 7.0 (TID 746) in 97 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T22:10:11.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 151.0 in stage 7.0 (TID 754)
[2025-07-19T22:10:11.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.2.delta.f3393c0b-07d9-46c6-8acb-2189b63580d6.TID751.tmp
[2025-07-19T22:10:11.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.2.delta.2abebfd9-8780-41d4-add0-a30f6ca0251f.TID747.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/2.delta
[2025-07-19T22:10:11.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/144/2.delta
[2025-07-19T22:10:11.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T22:10:11.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T22:10:11.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 144.0 in stage 7.0 (TID 747). 5829 bytes result sent to driver
[2025-07-19T22:10:11.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 152.0 in stage 7.0 (TID 755) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.579+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 144.0 in stage 7.0 (TID 747) in 105 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T22:10:11.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 152.0 in stage 7.0 (TID 755)
[2025-07-19T22:10:11.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e1214bb
[2025-07-19T22:10:11.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151] for update
[2025-07-19T22:10:11.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.2.delta.1ba5687e-e386-486d-ae32-71176c19e923.TID750.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/2.delta
[2025-07-19T22:10:11.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/147/2.delta
[2025-07-19T22:10:11.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T22:10:11.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:11.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.2.delta.dd1a1523-08da-4a50-b6a0-cfd35d7b994a.TID748.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/2.delta
[2025-07-19T22:10:11.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/145/2.delta
[2025-07-19T22:10:11.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T22:10:11.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78f698a0
[2025-07-19T22:10:11.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152] for update
[2025-07-19T22:10:11.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T22:10:11.594+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 147.0 in stage 7.0 (TID 750). 5829 bytes result sent to driver
[2025-07-19T22:10:11.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 153.0 in stage 7.0 (TID 756) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 147.0 in stage 7.0 (TID 750) in 95 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T22:10:11.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.2.delta.a3ddbfd6-2050-4143-b0ce-4a8415f7d8ea.TID754.tmp
[2025-07-19T22:10:11.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 153.0 in stage 7.0 (TID 756)
[2025-07-19T22:10:11.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T22:10:11.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.2.delta.8d630226-82d9-49c7-881f-164972611433.TID753.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/2.delta
[2025-07-19T22:10:11.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/150/2.delta
[2025-07-19T22:10:11.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T22:10:11.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3136e065
[2025-07-19T22:10:11.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153] for update
[2025-07-19T22:10:11.611+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 145.0 in stage 7.0 (TID 748). 5829 bytes result sent to driver
[2025-07-19T22:10:11.612+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.2.delta.e43f0906-63a8-45e0-a5a8-456f3b528657.TID749.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/2.delta
[2025-07-19T22:10:11.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/146/2.delta
[2025-07-19T22:10:11.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T22:10:11.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 154.0 in stage 7.0 (TID 757) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 145.0 in stage 7.0 (TID 748) in 112 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T22:10:11.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T22:10:11.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 154.0 in stage 7.0 (TID 757)
[2025-07-19T22:10:11.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 150.0 in stage 7.0 (TID 753). 5829 bytes result sent to driver
[2025-07-19T22:10:11.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 155.0 in stage 7.0 (TID 758) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 150.0 in stage 7.0 (TID 753) in 90 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T22:10:11.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 155.0 in stage 7.0 (TID 758)
[2025-07-19T22:10:11.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.2.delta.531c87c1-6e3d-447e-8668-6374031c92ce.TID752.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/2.delta
[2025-07-19T22:10:11.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/149/2.delta
[2025-07-19T22:10:11.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T22:10:11.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.620+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T22:10:11.620+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 146.0 in stage 7.0 (TID 749). 5829 bytes result sent to driver
[2025-07-19T22:10:11.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2191be11
[2025-07-19T22:10:11.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 156.0 in stage 7.0 (TID 759) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155] for update
[2025-07-19T22:10:11.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 146.0 in stage 7.0 (TID 749) in 117 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T22:10:11.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 156.0 in stage 7.0 (TID 759)
[2025-07-19T22:10:11.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e5658d8
[2025-07-19T22:10:11.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.2.delta.741b671e-3ae4-4b38-92d2-482257384b1a.TID755.tmp
[2025-07-19T22:10:11.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T22:10:11.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 149.0 in stage 7.0 (TID 752). 5829 bytes result sent to driver
[2025-07-19T22:10:11.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 157.0 in stage 7.0 (TID 760) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 157.0 in stage 7.0 (TID 760)
[2025-07-19T22:10:11.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156] for update
[2025-07-19T22:10:11.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.2.delta.4af1a111-0c81-4b53-b381-10c89369e1d4.TID758.tmp
[2025-07-19T22:10:11.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.2.delta.7e046fdf-4bdf-45c9-a1c1-10f79b45bed8.TID756.tmp
[2025-07-19T22:10:11.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@771b940c
[2025-07-19T22:10:11.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 149.0 in stage 7.0 (TID 752) in 118 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T22:10:11.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154] for update
[2025-07-19T22:10:11.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.2.delta.f3393c0b-07d9-46c6-8acb-2189b63580d6.TID751.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/2.delta
[2025-07-19T22:10:11.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/148/2.delta
[2025-07-19T22:10:11.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T22:10:11.637+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.638+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.640+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T22:10:11.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 148.0 in stage 7.0 (TID 751). 5829 bytes result sent to driver
[2025-07-19T22:10:11.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 158.0 in stage 7.0 (TID 761) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13ce7a52
[2025-07-19T22:10:11.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 148.0 in stage 7.0 (TID 751) in 132 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T22:10:11.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 158.0 in stage 7.0 (TID 761)
[2025-07-19T22:10:11.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.645+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157] for update
[2025-07-19T22:10:11.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.2.delta.fb8f18ab-94db-4f3f-ae81-9bfb5a835a40.TID757.tmp
[2025-07-19T22:10:11.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.648+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.649+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54c1f725
[2025-07-19T22:10:11.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158] for update
[2025-07-19T22:10:11.652+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.2.delta.b8f414da-9eac-44f0-8f80-b17228dc4203.TID759.tmp
[2025-07-19T22:10:11.661+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.2.delta.1d44f244-8fa1-4d6f-8dfd-2f439475cd4d.TID761.tmp
[2025-07-19T22:10:11.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.2.delta.16851d85-07fc-47dd-b063-8f65a24eec27.TID760.tmp
[2025-07-19T22:10:11.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.2.delta.a3ddbfd6-2050-4143-b0ce-4a8415f7d8ea.TID754.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/2.delta
[2025-07-19T22:10:11.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/151/2.delta
[2025-07-19T22:10:11.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T22:10:11.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.2.delta.7e046fdf-4bdf-45c9-a1c1-10f79b45bed8.TID756.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/2.delta
[2025-07-19T22:10:11.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/153/2.delta
[2025-07-19T22:10:11.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T22:10:11.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T22:10:11.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 151.0 in stage 7.0 (TID 754). 5829 bytes result sent to driver
[2025-07-19T22:10:11.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 159.0 in stage 7.0 (TID 762) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 159.0 in stage 7.0 (TID 762)
[2025-07-19T22:10:11.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 151.0 in stage 7.0 (TID 754) in 106 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T22:10:11.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T22:10:11.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 153.0 in stage 7.0 (TID 756). 5829 bytes result sent to driver
[2025-07-19T22:10:11.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@835f8fe
[2025-07-19T22:10:11.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 160.0 in stage 7.0 (TID 763) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 160.0 in stage 7.0 (TID 763)
[2025-07-19T22:10:11.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159] for update
[2025-07-19T22:10:11.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 153.0 in stage 7.0 (TID 756) in 87 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T22:10:11.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.2.delta.4af1a111-0c81-4b53-b381-10c89369e1d4.TID758.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/2.delta
[2025-07-19T22:10:11.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/155/2.delta
[2025-07-19T22:10:11.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c566985
[2025-07-19T22:10:11.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T22:10:11.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160] for update
[2025-07-19T22:10:11.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.2.delta.741b671e-3ae4-4b38-92d2-482257384b1a.TID755.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/2.delta
[2025-07-19T22:10:11.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/152/2.delta
[2025-07-19T22:10:11.695+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T22:10:11.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T22:10:11.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 155.0 in stage 7.0 (TID 758). 5829 bytes result sent to driver
[2025-07-19T22:10:11.697+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T22:10:11.698+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 161.0 in stage 7.0 (TID 764) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 161.0 in stage 7.0 (TID 764)
[2025-07-19T22:10:11.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.2.delta.ecfcd6a6-f3c9-4461-9e1c-1aad489c8471.TID762.tmp
[2025-07-19T22:10:11.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 155.0 in stage 7.0 (TID 758) in 88 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T22:10:11.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 152.0 in stage 7.0 (TID 755). 5829 bytes result sent to driver
[2025-07-19T22:10:11.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.2.delta.fb8f18ab-94db-4f3f-ae81-9bfb5a835a40.TID757.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/2.delta
[2025-07-19T22:10:11.706+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/154/2.delta
[2025-07-19T22:10:11.706+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 162.0 in stage 7.0 (TID 765) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 162.0 in stage 7.0 (TID 765)
[2025-07-19T22:10:11.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T22:10:11.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 152.0 in stage 7.0 (TID 755) in 127 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T22:10:11.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.709+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:11.710+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.710+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.711+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T22:10:11.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 154.0 in stage 7.0 (TID 757). 5829 bytes result sent to driver
[2025-07-19T22:10:11.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@219073b5
[2025-07-19T22:10:11.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161] for update
[2025-07-19T22:10:11.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 163.0 in stage 7.0 (TID 766) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 154.0 in stage 7.0 (TID 757) in 102 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T22:10:11.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.2.delta.72f43c13-c0b6-4e64-b707-362c67db8982.TID763.tmp
[2025-07-19T22:10:11.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.2.delta.b8f414da-9eac-44f0-8f80-b17228dc4203.TID759.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/2.delta
[2025-07-19T22:10:11.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/156/2.delta
[2025-07-19T22:10:11.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@617c6a61
[2025-07-19T22:10:11.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 163.0 in stage 7.0 (TID 766)
[2025-07-19T22:10:11.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T22:10:11.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162] for update
[2025-07-19T22:10:11.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.2.delta.16851d85-07fc-47dd-b063-8f65a24eec27.TID760.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/2.delta
[2025-07-19T22:10:11.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/157/2.delta
[2025-07-19T22:10:11.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T22:10:11.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T22:10:11.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.719+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.720+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.2.delta.1d44f244-8fa1-4d6f-8dfd-2f439475cd4d.TID761.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/2.delta
[2025-07-19T22:10:11.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/158/2.delta
[2025-07-19T22:10:11.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T22:10:11.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 156.0 in stage 7.0 (TID 759). 5915 bytes result sent to driver
[2025-07-19T22:10:11.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f6bc37a
[2025-07-19T22:10:11.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T22:10:11.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 157.0 in stage 7.0 (TID 760). 5872 bytes result sent to driver
[2025-07-19T22:10:11.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 164.0 in stage 7.0 (TID 767) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 165.0 in stage 7.0 (TID 768) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 165.0 in stage 7.0 (TID 768)
[2025-07-19T22:10:11.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163] for update
[2025-07-19T22:10:11.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 156.0 in stage 7.0 (TID 759) in 107 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T22:10:11.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 164.0 in stage 7.0 (TID 767)
[2025-07-19T22:10:11.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 157.0 in stage 7.0 (TID 760) in 99 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T22:10:11.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T22:10:11.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 158.0 in stage 7.0 (TID 761). 5872 bytes result sent to driver
[2025-07-19T22:10:11.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.2.delta.94616189-0208-482b-bdf1-d0e52116cb8a.TID765.tmp
[2025-07-19T22:10:11.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.730+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 166.0 in stage 7.0 (TID 769) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 158.0 in stage 7.0 (TID 761) in 91 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T22:10:11.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 166.0 in stage 7.0 (TID 769)
[2025-07-19T22:10:11.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.733+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@181581ae
[2025-07-19T22:10:11.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165] for update
[2025-07-19T22:10:11.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.2.delta.dcc9717e-5826-4ae4-8572-c8e2f871aca5.TID764.tmp
[2025-07-19T22:10:11.744+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5550f39e
[2025-07-19T22:10:11.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166] for update
[2025-07-19T22:10:11.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@787381b3
[2025-07-19T22:10:11.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164] for update
[2025-07-19T22:10:11.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.2.delta.72f43c13-c0b6-4e64-b707-362c67db8982.TID763.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/2.delta
[2025-07-19T22:10:11.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/160/2.delta
[2025-07-19T22:10:11.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.2.delta.6125a96d-5c68-49d7-876f-d63c558ead52.TID766.tmp
[2025-07-19T22:10:11.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T22:10:11.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.2.delta.ecfcd6a6-f3c9-4461-9e1c-1aad489c8471.TID762.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/2.delta
[2025-07-19T22:10:11.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/159/2.delta
[2025-07-19T22:10:11.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T22:10:11.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.2.delta.b49736f5-af88-4c7f-87d3-2c143021359e.TID769.tmp
[2025-07-19T22:10:11.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.2.delta.9efdd106-96e2-4d47-a68c-d96a4fb8bd2d.TID768.tmp
[2025-07-19T22:10:11.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.2.delta.fe6e03ed-db03-4951-bf5c-cf419b9f62c7.TID767.tmp
[2025-07-19T22:10:11.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T22:10:11.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.2.delta.94616189-0208-482b-bdf1-d0e52116cb8a.TID765.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/2.delta
[2025-07-19T22:10:11.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/162/2.delta
[2025-07-19T22:10:11.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T22:10:11.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 159.0 in stage 7.0 (TID 762). 5872 bytes result sent to driver
[2025-07-19T22:10:11.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 167.0 in stage 7.0 (TID 770) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 159.0 in stage 7.0 (TID 762) in 93 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T22:10:11.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 167.0 in stage 7.0 (TID 770)
[2025-07-19T22:10:11.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T22:10:11.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 160.0 in stage 7.0 (TID 763). 5872 bytes result sent to driver
[2025-07-19T22:10:11.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T22:10:11.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 162.0 in stage 7.0 (TID 765). 5872 bytes result sent to driver
[2025-07-19T22:10:11.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 168.0 in stage 7.0 (TID 771) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 169.0 in stage 7.0 (TID 772) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 168.0 in stage 7.0 (TID 771)
[2025-07-19T22:10:11.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33832918
[2025-07-19T22:10:11.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167] for update
[2025-07-19T22:10:11.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d060be8
[2025-07-19T22:10:11.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168] for update
[2025-07-19T22:10:11.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 169.0 in stage 7.0 (TID 772)
[2025-07-19T22:10:11.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.779+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.784+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 162.0 in stage 7.0 (TID 765) in 71 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T22:10:11.784+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 160.0 in stage 7.0 (TID 763) in 103 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T22:10:11.784+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f703750
[2025-07-19T22:10:11.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169] for update
[2025-07-19T22:10:11.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.2.delta.120ffc2f-1a78-4b67-ac58-a863a8882de8.TID771.tmp
[2025-07-19T22:10:11.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.2.delta.b0ec855b-2b00-4096-9f04-10f6df05b972.TID770.tmp
[2025-07-19T22:10:11.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.2.delta.7a9bf29e-d8fc-45f1-8584-b7e01162e318.TID772.tmp
[2025-07-19T22:10:11.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.2.delta.dcc9717e-5826-4ae4-8572-c8e2f871aca5.TID764.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/2.delta
[2025-07-19T22:10:11.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/161/2.delta
[2025-07-19T22:10:11.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T22:10:11.813+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.2.delta.6125a96d-5c68-49d7-876f-d63c558ead52.TID766.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/2.delta
[2025-07-19T22:10:11.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/163/2.delta
[2025-07-19T22:10:11.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T22:10:11.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T22:10:11.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 161.0 in stage 7.0 (TID 764). 5872 bytes result sent to driver
[2025-07-19T22:10:11.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 170.0 in stage 7.0 (TID 773) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 170.0 in stage 7.0 (TID 773)
[2025-07-19T22:10:11.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 161.0 in stage 7.0 (TID 764) in 123 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T22:10:11.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T22:10:11.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 163.0 in stage 7.0 (TID 766). 5872 bytes result sent to driver
[2025-07-19T22:10:11.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 171.0 in stage 7.0 (TID 774) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.819+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 163.0 in stage 7.0 (TID 766) in 114 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T22:10:11.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 171.0 in stage 7.0 (TID 774)
[2025-07-19T22:10:11.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.2.delta.fe6e03ed-db03-4951-bf5c-cf419b9f62c7.TID767.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/2.delta
[2025-07-19T22:10:11.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/164/2.delta
[2025-07-19T22:10:11.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T22:10:11.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:11.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.2.delta.b49736f5-af88-4c7f-87d3-2c143021359e.TID769.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/2.delta
[2025-07-19T22:10:11.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/166/2.delta
[2025-07-19T22:10:11.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T22:10:11.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45b9e5af
[2025-07-19T22:10:11.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170] for update
[2025-07-19T22:10:11.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T22:10:11.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 164.0 in stage 7.0 (TID 767). 5872 bytes result sent to driver
[2025-07-19T22:10:11.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T22:10:11.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 166.0 in stage 7.0 (TID 769). 5872 bytes result sent to driver
[2025-07-19T22:10:11.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 164.0 in stage 7.0 (TID 767) in 109 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T22:10:11.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 172.0 in stage 7.0 (TID 775) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5551a517
[2025-07-19T22:10:11.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 173.0 in stage 7.0 (TID 776) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 172.0 in stage 7.0 (TID 775)
[2025-07-19T22:10:11.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 166.0 in stage 7.0 (TID 769) in 106 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T22:10:11.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 173.0 in stage 7.0 (TID 776)
[2025-07-19T22:10:11.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171] for update
[2025-07-19T22:10:11.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.2.delta.9efdd106-96e2-4d47-a68c-d96a4fb8bd2d.TID768.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/2.delta
[2025-07-19T22:10:11.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/165/2.delta
[2025-07-19T22:10:11.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a3d7d27
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c273ebb
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173] for update
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172] for update
[2025-07-19T22:10:11.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.2.delta.221345a5-81b8-41c8-ac9f-d2607bb6f506.TID773.tmp
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 165.0 in stage 7.0 (TID 768). 5915 bytes result sent to driver
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 174.0 in stage 7.0 (TID 777) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 174.0 in stage 7.0 (TID 777)
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 165.0 in stage 7.0 (TID 768) in 128 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.2.delta.c3a9c9cc-3b0d-4529-89e4-2f06b026e61c.TID774.tmp
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d9e4d68
[2025-07-19T22:10:11.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174] for update
[2025-07-19T22:10:11.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.2.delta.234d02d9-5eed-49a3-968e-65d74e38f8f4.TID775.tmp
[2025-07-19T22:10:11.861+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.2.delta.b4fa6954-1bf7-4dd4-b15b-1bb67c1e542e.TID776.tmp
[2025-07-19T22:10:11.861+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.2.delta.527e71a1-15dd-47a5-be17-d269acca261e.TID777.tmp
[2025-07-19T22:10:11.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.2.delta.b0ec855b-2b00-4096-9f04-10f6df05b972.TID770.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/2.delta
[2025-07-19T22:10:11.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/167/2.delta
[2025-07-19T22:10:11.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.2.delta.120ffc2f-1a78-4b67-ac58-a863a8882de8.TID771.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/2.delta
[2025-07-19T22:10:11.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/168/2.delta
[2025-07-19T22:10:11.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T22:10:11.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T22:10:11.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.2.delta.7a9bf29e-d8fc-45f1-8584-b7e01162e318.TID772.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/2.delta
[2025-07-19T22:10:11.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/169/2.delta
[2025-07-19T22:10:11.872+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T22:10:11.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T22:10:11.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 167.0 in stage 7.0 (TID 770). 5872 bytes result sent to driver
[2025-07-19T22:10:11.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 175.0 in stage 7.0 (TID 778) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T22:10:11.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 168.0 in stage 7.0 (TID 771). 5872 bytes result sent to driver
[2025-07-19T22:10:11.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 175.0 in stage 7.0 (TID 778)
[2025-07-19T22:10:11.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 176.0 in stage 7.0 (TID 779) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 168.0 in stage 7.0 (TID 771) in 106 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T22:10:11.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 167.0 in stage 7.0 (TID 770) in 112 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T22:10:11.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 176.0 in stage 7.0 (TID 779)
[2025-07-19T22:10:11.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@156b1012
[2025-07-19T22:10:11.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T22:10:11.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176] for update
[2025-07-19T22:10:11.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@552d1209
[2025-07-19T22:10:11.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175] for update
[2025-07-19T22:10:11.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 169.0 in stage 7.0 (TID 772). 5915 bytes result sent to driver
[2025-07-19T22:10:11.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 169.0 in stage 7.0 (TID 772) in 116 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T22:10:11.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 177.0 in stage 7.0 (TID 780) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 177.0 in stage 7.0 (TID 780)
[2025-07-19T22:10:11.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.890+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:11.890+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.2.delta.3cbc9376-a007-4d3d-b18f-244c53fbe71f.TID779.tmp
[2025-07-19T22:10:11.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.2.delta.be1e1833-6c32-442f-bed0-6cc02ab9e6d9.TID778.tmp
[2025-07-19T22:10:11.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.2.delta.221345a5-81b8-41c8-ac9f-d2607bb6f506.TID773.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/2.delta
[2025-07-19T22:10:11.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51caf34e
[2025-07-19T22:10:11.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/170/2.delta
[2025-07-19T22:10:11.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T22:10:11.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177] for update
[2025-07-19T22:10:11.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T22:10:11.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 170.0 in stage 7.0 (TID 773). 5829 bytes result sent to driver
[2025-07-19T22:10:11.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 178.0 in stage 7.0 (TID 781) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 178.0 in stage 7.0 (TID 781)
[2025-07-19T22:10:11.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 170.0 in stage 7.0 (TID 773) in 87 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T22:10:11.907+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24777a07
[2025-07-19T22:10:11.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178] for update
[2025-07-19T22:10:11.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.2.delta.4a397049-bd20-47cc-8a1d-a8620654beca.TID780.tmp
[2025-07-19T22:10:11.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.2.delta.c3a9c9cc-3b0d-4529-89e4-2f06b026e61c.TID774.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/2.delta
[2025-07-19T22:10:11.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/171/2.delta
[2025-07-19T22:10:11.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T22:10:11.916+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T22:10:11.918+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 171.0 in stage 7.0 (TID 774). 5829 bytes result sent to driver
[2025-07-19T22:10:11.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 179.0 in stage 7.0 (TID 782) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 179.0 in stage 7.0 (TID 782)
[2025-07-19T22:10:11.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 171.0 in stage 7.0 (TID 774) in 98 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T22:10:11.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.2.delta.b4fa6954-1bf7-4dd4-b15b-1bb67c1e542e.TID776.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/2.delta
[2025-07-19T22:10:11.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/173/2.delta
[2025-07-19T22:10:11.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T22:10:11.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29828fcf
[2025-07-19T22:10:11.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179] for update
[2025-07-19T22:10:11.928+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.2.delta.234d02d9-5eed-49a3-968e-65d74e38f8f4.TID775.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/2.delta
[2025-07-19T22:10:11.929+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/172/2.delta
[2025-07-19T22:10:11.930+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.2.delta.ad0b5b53-0277-4ed2-98e2-2fad93ceb686.TID781.tmp
[2025-07-19T22:10:11.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T22:10:11.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T22:10:11.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 173.0 in stage 7.0 (TID 776). 5829 bytes result sent to driver
[2025-07-19T22:10:11.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 180.0 in stage 7.0 (TID 783) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 173.0 in stage 7.0 (TID 776) in 104 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T22:10:11.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 180.0 in stage 7.0 (TID 783)
[2025-07-19T22:10:11.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T22:10:11.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 172.0 in stage 7.0 (TID 775). 5829 bytes result sent to driver
[2025-07-19T22:10:11.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f759338
[2025-07-19T22:10:11.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.2.delta.527e71a1-15dd-47a5-be17-d269acca261e.TID777.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/2.delta
[2025-07-19T22:10:11.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/174/2.delta
[2025-07-19T22:10:11.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T22:10:11.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180] for update
[2025-07-19T22:10:11.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 181.0 in stage 7.0 (TID 784) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.949+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 172.0 in stage 7.0 (TID 775) in 113 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T22:10:11.949+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.950+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 181.0 in stage 7.0 (TID 784)
[2025-07-19T22:10:11.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79029e82
[2025-07-19T22:10:11.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T22:10:11.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181] for update
[2025-07-19T22:10:11.959+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.960+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 174.0 in stage 7.0 (TID 777). 5829 bytes result sent to driver
[2025-07-19T22:10:11.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 182.0 in stage 7.0 (TID 785) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 182.0 in stage 7.0 (TID 785)
[2025-07-19T22:10:11.964+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 174.0 in stage 7.0 (TID 777) in 111 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T22:10:11.964+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.966+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.2.delta.e78f1424-3b21-4fea-bb59-add2c5f19035.TID782.tmp
[2025-07-19T22:10:11.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.2.delta.54cda434-e102-42c7-b99a-b0282b9fe7a9.TID783.tmp
[2025-07-19T22:10:11.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@274c2499
[2025-07-19T22:10:11.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.2.delta.3d036318-fa4c-4273-9bf2-6c19708ad2cd.TID784.tmp
[2025-07-19T22:10:11.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182] for update
[2025-07-19T22:10:11.970+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:11.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.2.delta.be1e1833-6c32-442f-bed0-6cc02ab9e6d9.TID778.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/2.delta
[2025-07-19T22:10:11.980+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/175/2.delta
[2025-07-19T22:10:11.981+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T22:10:11.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.2.delta.3cbc9376-a007-4d3d-b18f-244c53fbe71f.TID779.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/2.delta
[2025-07-19T22:10:11.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/176/2.delta
[2025-07-19T22:10:11.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T22:10:11.985+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T22:10:11.986+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T22:10:11.987+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 175.0 in stage 7.0 (TID 778). 5829 bytes result sent to driver
[2025-07-19T22:10:11.988+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Finished task 176.0 in stage 7.0 (TID 779). 5829 bytes result sent to driver
[2025-07-19T22:10:11.990+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 183.0 in stage 7.0 (TID 786) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Starting task 184.0 in stage 7.0 (TID 787) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:11.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 183.0 in stage 7.0 (TID 786)
[2025-07-19T22:10:11.994+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 176.0 in stage 7.0 (TID 779) in 115 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T22:10:11.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO TaskSetManager: Finished task 175.0 in stage 7.0 (TID 778) in 118 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T22:10:11.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO Executor: Running task 184.0 in stage 7.0 (TID 787)
[2025-07-19T22:10:11.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:11.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:11.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56a2175
[2025-07-19T22:10:11.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:11.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.2.delta.4a397049-bd20-47cc-8a1d-a8620654beca.TID780.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/2.delta
[2025-07-19T22:10:12.001+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/177/2.delta
[2025-07-19T22:10:12.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183] for update
[2025-07-19T22:10:12.004+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.2.delta.21b9296f-c903-4af3-b4ec-298ed566ef5e.TID785.tmp
[2025-07-19T22:10:12.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T22:10:12.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.008+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.009+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@247dfd8
[2025-07-19T22:10:12.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.2.delta.ad0b5b53-0277-4ed2-98e2-2fad93ceb686.TID781.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/2.delta
[2025-07-19T22:10:12.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/178/2.delta
[2025-07-19T22:10:12.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T22:10:12.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184] for update
[2025-07-19T22:10:12.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:11 INFO DataWritingSparkTask: Committed partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T22:10:12.015+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T22:10:12.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 178.0 in stage 7.0 (TID 781). 5829 bytes result sent to driver
[2025-07-19T22:10:12.019+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 185.0 in stage 7.0 (TID 788) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.020+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 178.0 in stage 7.0 (TID 781) in 105 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T22:10:12.020+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 185.0 in stage 7.0 (TID 788)
[2025-07-19T22:10:12.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 177.0 in stage 7.0 (TID 780). 5829 bytes result sent to driver
[2025-07-19T22:10:12.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 186.0 in stage 7.0 (TID 789) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 186.0 in stage 7.0 (TID 789)
[2025-07-19T22:10:12.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51b723b7
[2025-07-19T22:10:12.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 177.0 in stage 7.0 (TID 780) in 123 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T22:10:12.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185] for update
[2025-07-19T22:10:12.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.2.delta.1cbdb05c-1a5d-4b25-951f-caee1fa7d373.TID786.tmp
[2025-07-19T22:10:12.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cfb7ad3
[2025-07-19T22:10:12.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186] for update
[2025-07-19T22:10:12.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.2.delta.27feaf33-33a3-45b8-be26-cbe4b5b8f09c.TID787.tmp
[2025-07-19T22:10:12.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.2.delta.a6c48955-6e4e-4281-919c-e23acc9d52f1.TID789.tmp
[2025-07-19T22:10:12.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.2.delta.2300b2b9-bdaf-4ce6-ac3b-d86e274aab91.TID788.tmp
[2025-07-19T22:10:12.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.2.delta.3d036318-fa4c-4273-9bf2-6c19708ad2cd.TID784.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/2.delta
[2025-07-19T22:10:12.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/181/2.delta
[2025-07-19T22:10:12.037+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T22:10:12.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.2.delta.54cda434-e102-42c7-b99a-b0282b9fe7a9.TID783.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/2.delta
[2025-07-19T22:10:12.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/180/2.delta
[2025-07-19T22:10:12.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T22:10:12.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T22:10:12.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.2.delta.e78f1424-3b21-4fea-bb59-add2c5f19035.TID782.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/2.delta
[2025-07-19T22:10:12.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/179/2.delta
[2025-07-19T22:10:12.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T22:10:12.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 181.0 in stage 7.0 (TID 784). 5872 bytes result sent to driver
[2025-07-19T22:10:12.054+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T22:10:12.054+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 187.0 in stage 7.0 (TID 790) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 181.0 in stage 7.0 (TID 784) in 111 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T22:10:12.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 187.0 in stage 7.0 (TID 790)
[2025-07-19T22:10:12.056+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 180.0 in stage 7.0 (TID 783). 5829 bytes result sent to driver
[2025-07-19T22:10:12.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 188.0 in stage 7.0 (TID 791) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 180.0 in stage 7.0 (TID 783) in 132 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T22:10:12.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 188.0 in stage 7.0 (TID 791)
[2025-07-19T22:10:12.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.2.delta.21b9296f-c903-4af3-b4ec-298ed566ef5e.TID785.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/2.delta
[2025-07-19T22:10:12.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/182/2.delta
[2025-07-19T22:10:12.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T22:10:12.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 179.0 in stage 7.0 (TID 782). 5829 bytes result sent to driver
[2025-07-19T22:10:12.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 189.0 in stage 7.0 (TID 792) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 189.0 in stage 7.0 (TID 792)
[2025-07-19T22:10:12.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 179.0 in stage 7.0 (TID 782) in 150 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T22:10:12.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:12.071+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T22:10:12.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.2.delta.1cbdb05c-1a5d-4b25-951f-caee1fa7d373.TID786.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/2.delta
[2025-07-19T22:10:12.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/183/2.delta
[2025-07-19T22:10:12.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T22:10:12.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56b567ee
[2025-07-19T22:10:12.077+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187] for update
[2025-07-19T22:10:12.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T22:10:12.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T22:10:12.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.2.delta.27feaf33-33a3-45b8-be26-cbe4b5b8f09c.TID787.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/2.delta
[2025-07-19T22:10:12.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T22:10:12.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/184/2.delta
[2025-07-19T22:10:12.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T22:10:12.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 182.0 in stage 7.0 (TID 785). 5829 bytes result sent to driver
[2025-07-19T22:10:12.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 190.0 in stage 7.0 (TID 793) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6688e547
[2025-07-19T22:10:12.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T22:10:12.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 182.0 in stage 7.0 (TID 785) in 130 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T22:10:12.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 183.0 in stage 7.0 (TID 786). 5829 bytes result sent to driver
[2025-07-19T22:10:12.090+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 190.0 in stage 7.0 (TID 793)
[2025-07-19T22:10:12.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188] for update
[2025-07-19T22:10:12.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T22:10:12.097+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 184.0 in stage 7.0 (TID 787). 5829 bytes result sent to driver
[2025-07-19T22:10:12.098+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.2.delta.2300b2b9-bdaf-4ce6-ac3b-d86e274aab91.TID788.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/2.delta
[2025-07-19T22:10:12.099+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/185/2.delta
[2025-07-19T22:10:12.099+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.2.delta.a6c48955-6e4e-4281-919c-e23acc9d52f1.TID789.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/2.delta
[2025-07-19T22:10:12.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/186/2.delta
[2025-07-19T22:10:12.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T22:10:12.101+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T22:10:12.102+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fd70bdd
[2025-07-19T22:10:12.103+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 191.0 in stage 7.0 (TID 794) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.104+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189] for update
[2025-07-19T22:10:12.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 192.0 in stage 7.0 (TID 795) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 192.0 in stage 7.0 (TID 795)
[2025-07-19T22:10:12.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 191.0 in stage 7.0 (TID 794)
[2025-07-19T22:10:12.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 184.0 in stage 7.0 (TID 787) in 107 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T22:10:12.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 183.0 in stage 7.0 (TID 786) in 108 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T22:10:12.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T22:10:12.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a5c4aa0
[2025-07-19T22:10:12.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 185.0 in stage 7.0 (TID 788). 5829 bytes result sent to driver
[2025-07-19T22:10:12.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190] for update
[2025-07-19T22:10:12.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 193.0 in stage 7.0 (TID 796) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.110+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 185.0 in stage 7.0 (TID 788) in 95 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T22:10:12.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T22:10:12.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@384b8866
[2025-07-19T22:10:12.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:12.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 193.0 in stage 7.0 (TID 796)
[2025-07-19T22:10:12.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 186.0 in stage 7.0 (TID 789). 5829 bytes result sent to driver
[2025-07-19T22:10:12.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191] for update
[2025-07-19T22:10:12.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.2.delta.7ab098e5-196d-4205-acbd-d5a7e8f9707a.TID790.tmp
[2025-07-19T22:10:12.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 194.0 in stage 7.0 (TID 797) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 186.0 in stage 7.0 (TID 789) in 99 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T22:10:12.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@453c089a
[2025-07-19T22:10:12.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 194.0 in stage 7.0 (TID 797)
[2025-07-19T22:10:12.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192] for update
[2025-07-19T22:10:12.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:12.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bc85198
[2025-07-19T22:10:12.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.2.delta.c1e32a39-942b-41cb-a4a1-c78dc9308d20.TID792.tmp
[2025-07-19T22:10:12.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194] for update
[2025-07-19T22:10:12.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.2.delta.84090d01-12ca-4faa-9708-ec4ad906dcf9.TID794.tmp
[2025-07-19T22:10:12.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6924b5ec
[2025-07-19T22:10:12.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193] for update
[2025-07-19T22:10:12.121+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.2.delta.af3af054-98f1-4d21-8ba1-47424de5546f.TID791.tmp
[2025-07-19T22:10:12.128+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.2.delta.a7bf0140-892b-4e61-8679-b3b70b965742.TID793.tmp
[2025-07-19T22:10:12.131+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.2.delta.8b733cc6-fa15-4d6d-869b-3aaeaa1c0433.TID797.tmp
[2025-07-19T22:10:12.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.2.delta.8a1e49b8-5b0f-44c5-a276-227cddb83d9b.TID796.tmp
[2025-07-19T22:10:12.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.2.delta.de79f23c-7f18-466d-88c1-ba53abf2c04b.TID795.tmp
[2025-07-19T22:10:12.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.2.delta.7ab098e5-196d-4205-acbd-d5a7e8f9707a.TID790.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/2.delta
[2025-07-19T22:10:12.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/187/2.delta
[2025-07-19T22:10:12.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T22:10:12.160+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.2.delta.c1e32a39-942b-41cb-a4a1-c78dc9308d20.TID792.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/2.delta
[2025-07-19T22:10:12.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/189/2.delta
[2025-07-19T22:10:12.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T22:10:12.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T22:10:12.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 187.0 in stage 7.0 (TID 790). 5829 bytes result sent to driver
[2025-07-19T22:10:12.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 195.0 in stage 7.0 (TID 798) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 195.0 in stage 7.0 (TID 798)
[2025-07-19T22:10:12.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 187.0 in stage 7.0 (TID 790) in 109 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T22:10:12.165+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.2.delta.af3af054-98f1-4d21-8ba1-47424de5546f.TID791.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/2.delta
[2025-07-19T22:10:12.166+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/188/2.delta
[2025-07-19T22:10:12.169+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T22:10:12.171+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.172+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.172+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c734533
[2025-07-19T22:10:12.172+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.172+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195] for update
[2025-07-19T22:10:12.172+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T22:10:12.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T22:10:12.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 188.0 in stage 7.0 (TID 791). 5872 bytes result sent to driver
[2025-07-19T22:10:12.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 189.0 in stage 7.0 (TID 792). 5872 bytes result sent to driver
[2025-07-19T22:10:12.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 196.0 in stage 7.0 (TID 799) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 196.0 in stage 7.0 (TID 799)
[2025-07-19T22:10:12.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 188.0 in stage 7.0 (TID 791) in 117 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T22:10:12.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.2.delta.a7bf0140-892b-4e61-8679-b3b70b965742.TID793.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/2.delta
[2025-07-19T22:10:12.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/190/2.delta
[2025-07-19T22:10:12.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T22:10:12.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 197.0 in stage 7.0 (TID 800) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 189.0 in stage 7.0 (TID 792) in 112 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T22:10:12.181+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 197.0 in stage 7.0 (TID 800)
[2025-07-19T22:10:12.190+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21de882
[2025-07-19T22:10:12.190+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.191+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196] for update
[2025-07-19T22:10:12.192+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.194+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T22:10:12.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@141fef30
[2025-07-19T22:10:12.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197] for update
[2025-07-19T22:10:12.200+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 190.0 in stage 7.0 (TID 793). 5872 bytes result sent to driver
[2025-07-19T22:10:12.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 198.0 in stage 7.0 (TID 801) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.2.delta.84090d01-12ca-4faa-9708-ec4ad906dcf9.TID794.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/2.delta
[2025-07-19T22:10:12.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/191/2.delta
[2025-07-19T22:10:12.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 198.0 in stage 7.0 (TID 801)
[2025-07-19T22:10:12.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 190.0 in stage 7.0 (TID 793) in 108 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T22:10:12.204+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.204+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T22:10:12.205+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.205+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.206+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b2f5f09
[2025-07-19T22:10:12.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198] for update
[2025-07-19T22:10:12.207+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T22:10:12.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 191.0 in stage 7.0 (TID 794). 5872 bytes result sent to driver
[2025-07-19T22:10:12.211+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 199.0 in stage 7.0 (TID 802) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.211+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 199.0 in stage 7.0 (TID 802)
[2025-07-19T22:10:12.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 191.0 in stage 7.0 (TID 794) in 113 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T22:10:12.213+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.214+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:12.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6827b0e2
[2025-07-19T22:10:12.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.2.delta.5a4f533f-fa30-4a91-aea9-612f0d1cb684.TID798.tmp
[2025-07-19T22:10:12.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],9b56af61-c478-4de4-bf3d-6c85462edb9c) is active
[2025-07-19T22:10:12.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199] for update
[2025-07-19T22:10:12.219+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.2.delta.8a1e49b8-5b0f-44c5-a276-227cddb83d9b.TID796.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/2.delta
[2025-07-19T22:10:12.220+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/193/2.delta
[2025-07-19T22:10:12.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T22:10:12.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.2.delta.d3615ede-a0ec-45a4-8f57-3ab8909bf8aa.TID799.tmp
[2025-07-19T22:10:12.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.2.delta.de79f23c-7f18-466d-88c1-ba53abf2c04b.TID795.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/2.delta
[2025-07-19T22:10:12.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/192/2.delta
[2025-07-19T22:10:12.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T22:10:12.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.2.delta.642b29f7-e352-4a26-8cd7-dd03f60044ea.TID800.tmp
[2025-07-19T22:10:12.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.2.delta.e528cffe-6bce-48af-b3a0-aa1e08aa1761.TID801.tmp
[2025-07-19T22:10:12.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.2.delta.8b733cc6-fa15-4d6d-869b-3aaeaa1c0433.TID797.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/2.delta
[2025-07-19T22:10:12.230+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/194/2.delta
[2025-07-19T22:10:12.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T22:10:12.232+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T22:10:12.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 192.0 in stage 7.0 (TID 795). 5829 bytes result sent to driver
[2025-07-19T22:10:12.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 803) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 192.0 in stage 7.0 (TID 795) in 138 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T22:10:12.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 0.0 in stage 9.0 (TID 803)
[2025-07-19T22:10:12.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T22:10:12.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 193.0 in stage 7.0 (TID 796). 5829 bytes result sent to driver
[2025-07-19T22:10:12.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.2.delta.a5bbe1ea-6d7b-400e-8e02-abcae0c0ad79.TID802.tmp
[2025-07-19T22:10:12.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 804) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 1.0 in stage 9.0 (TID 804)
[2025-07-19T22:10:12.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 193.0 in stage 7.0 (TID 796) in 136 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T22:10:12.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ed3f05e
[2025-07-19T22:10:12.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T22:10:12.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:12.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0] for update
[2025-07-19T22:10:12.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 194.0 in stage 7.0 (TID 797). 5829 bytes result sent to driver
[2025-07-19T22:10:12.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@218a2fe0
[2025-07-19T22:10:12.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 805) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 194.0 in stage 7.0 (TID 797) in 137 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T22:10:12.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1] for update
[2025-07-19T22:10:12.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 2.0 in stage 9.0 (TID 805)
[2025-07-19T22:10:12.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@123fd104
[2025-07-19T22:10:12.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2] for update
[2025-07-19T22:10:12.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodeGenerator: Code generated in 9.03 ms
[2025-07-19T22:10:12.271+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.2.delta.edd20f6d-1d21-45ca-a2ec-4bfaa9110391.TID805.tmp
[2025-07-19T22:10:12.271+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.2.delta.5a4f533f-fa30-4a91-aea9-612f0d1cb684.TID798.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/2.delta
[2025-07-19T22:10:12.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/195/2.delta
[2025-07-19T22:10:12.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T22:10:12.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.2.delta.d3615ede-a0ec-45a4-8f57-3ab8909bf8aa.TID799.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/2.delta
[2025-07-19T22:10:12.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/196/2.delta
[2025-07-19T22:10:12.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.2.delta.00e05b9a-a256-4f7d-9dc5-c9cccf4d1f93.TID803.tmp
[2025-07-19T22:10:12.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T22:10:12.278+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.2.delta.fac37524-3563-49ee-8c16-28d320e20851.TID804.tmp
[2025-07-19T22:10:12.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.2.delta.e528cffe-6bce-48af-b3a0-aa1e08aa1761.TID801.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/2.delta
[2025-07-19T22:10:12.280+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/198/2.delta
[2025-07-19T22:10:12.281+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T22:10:12.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T22:10:12.282+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 195.0 in stage 7.0 (TID 798). 5829 bytes result sent to driver
[2025-07-19T22:10:12.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 806) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.283+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 3.0 in stage 9.0 (TID 806)
[2025-07-19T22:10:12.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 195.0 in stage 7.0 (TID 798) in 116 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T22:10:12.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T22:10:12.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 196.0 in stage 7.0 (TID 799). 5829 bytes result sent to driver
[2025-07-19T22:10:12.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 807) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.285+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T22:10:12.286+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:12.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 198.0 in stage 7.0 (TID 801). 5829 bytes result sent to driver
[2025-07-19T22:10:12.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12d60f82
[2025-07-19T22:10:12.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.2.delta.642b29f7-e352-4a26-8cd7-dd03f60044ea.TID800.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/2.delta
[2025-07-19T22:10:12.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 196.0 in stage 7.0 (TID 799) in 109 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T22:10:12.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 4.0 in stage 9.0 (TID 807)
[2025-07-19T22:10:12.288+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/197/2.delta
[2025-07-19T22:10:12.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3] for update
[2025-07-19T22:10:12.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T22:10:12.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 808) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.289+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T22:10:12.297+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 5.0 in stage 9.0 (TID 808)
[2025-07-19T22:10:12.298+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 197.0 in stage 7.0 (TID 800). 5915 bytes result sent to driver
[2025-07-19T22:10:12.301+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 198.0 in stage 7.0 (TID 801) in 107 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T22:10:12.304+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:12.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45b91ee3
[2025-07-19T22:10:12.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 809) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 6.0 in stage 9.0 (TID 809)
[2025-07-19T22:10:12.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5] for update
[2025-07-19T22:10:12.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 197.0 in stage 7.0 (TID 800) in 127 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T22:10:12.308+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c577f7b
[2025-07-19T22:10:12.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4] for update
[2025-07-19T22:10:12.309+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10594e28
[2025-07-19T22:10:12.313+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.315+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6] for update
[2025-07-19T22:10:12.318+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.2.delta.a5bbe1ea-6d7b-400e-8e02-abcae0c0ad79.TID802.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/2.delta
[2025-07-19T22:10:12.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/state/0/199/2.delta
[2025-07-19T22:10:12.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T22:10:12.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.324+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.2.delta.e75e5304-75a0-4997-b8bf-dfb6d2665d30.TID806.tmp
[2025-07-19T22:10:12.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.2.delta.a57bba50-b3fe-48bc-8eaf-a6f286748d87.TID808.tmp
[2025-07-19T22:10:12.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T22:10:12.331+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/.2.delta.edd20f6d-1d21-45ca-a2ec-4bfaa9110391.TID805.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/2.delta
[2025-07-19T22:10:12.331+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/2/2.delta
[2025-07-19T22:10:12.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 199.0 in stage 7.0 (TID 802). 5872 bytes result sent to driver
[2025-07-19T22:10:12.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 810) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 199.0 in stage 7.0 (TID 802) in 129 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T22:10:12.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-19T22:10:12.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T22:10:12.335+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 7.0 in stage 9.0 (TID 810)
[2025-07-19T22:10:12.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.2.delta.34e3c317-4929-4db2-990d-c8a4e4235658.TID807.tmp
[2025-07-19T22:10:12.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DAGScheduler: ResultStage 7 (start at <unknown>:0) finished in 8.765 s
[2025-07-19T22:10:12.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T22:10:12.341+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-07-19T22:10:12.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.2.delta.47852688-765f-43ab-9464-45ceae93666a.TID809.tmp
[2025-07-19T22:10:12.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DAGScheduler: Job 3 finished: start at <unknown>:0, took 8.856434 s
[2025-07-19T22:10:12.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T22:10:12.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO SparkWrite: Committing epoch 1 for query 46c08399-34b2-49a9-aadd-060519c28563 in append mode
[2025-07-19T22:10:12.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T22:10:12.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 2.0 in stage 9.0 (TID 805). 5872 bytes result sent to driver
[2025-07-19T22:10:12.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 8.0 in stage 9.0 (TID 811) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:12.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/.2.delta.fac37524-3563-49ee-8c16-28d320e20851.TID804.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/2.delta
[2025-07-19T22:10:12.350+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/1/2.delta
[2025-07-19T22:10:12.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 8.0 in stage 9.0 (TID 811)
[2025-07-19T22:10:12.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 805) in 108 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T22:10:12.354+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48a7ee5f
[2025-07-19T22:10:12.354+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.355+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7] for update
[2025-07-19T22:10:12.355+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T22:10:12.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/.2.delta.00e05b9a-a256-4f7d-9dc5-c9cccf4d1f93.TID803.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/2.delta
[2025-07-19T22:10:12.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/0/2.delta
[2025-07-19T22:10:12.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.359+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T22:10:12.359+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12a1d757
[2025-07-19T22:10:12.361+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8] for update
[2025-07-19T22:10:12.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.363+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T22:10:12.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 1.0 in stage 9.0 (TID 804). 5872 bytes result sent to driver
[2025-07-19T22:10:12.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T22:10:12.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 9.0 in stage 9.0 (TID 812) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 0.0 in stage 9.0 (TID 803). 5872 bytes result sent to driver
[2025-07-19T22:10:12.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 9.0 in stage 9.0 (TID 812)
[2025-07-19T22:10:12.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 803) in 138 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T22:10:12.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 10.0 in stage 9.0 (TID 813) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 10.0 in stage 9.0 (TID 813)
[2025-07-19T22:10:12.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 804) in 135 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T22:10:12.377+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7be12511
[2025-07-19T22:10:12.378+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9] for update
[2025-07-19T22:10:12.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T22:10:12.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7752698f
[2025-07-19T22:10:12.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10] for update
[2025-07-19T22:10:12.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.2.delta.b10816f4-fbdf-4de8-add0-b44857eb80c7.TID811.tmp
[2025-07-19T22:10:12.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.2.delta.cef937df-dc89-43c2-a90a-682cf8b72f81.TID812.tmp
[2025-07-19T22:10:12.404+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.2.delta.6418ec7d-e4c7-4d3a-bd43-a5c5cc140d43.TID810.tmp
[2025-07-19T22:10:12.412+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.2.delta.ebe437d1-7156-43e4-a9e8-0caaee23850e.TID813.tmp
[2025-07-19T22:10:12.418+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/.2.delta.a57bba50-b3fe-48bc-8eaf-a6f286748d87.TID808.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/2.delta
[2025-07-19T22:10:12.418+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/5/2.delta
[2025-07-19T22:10:12.418+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T22:10:12.422+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/.2.delta.e75e5304-75a0-4997-b8bf-dfb6d2665d30.TID806.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/2.delta
[2025-07-19T22:10:12.424+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/3/2.delta
[2025-07-19T22:10:12.425+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T22:10:12.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/.2.delta.34e3c317-4929-4db2-990d-c8a4e4235658.TID807.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/2.delta
[2025-07-19T22:10:12.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/4/2.delta
[2025-07-19T22:10:12.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T22:10:12.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T22:10:12.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T22:10:12.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 3.0 in stage 9.0 (TID 806). 5872 bytes result sent to driver
[2025-07-19T22:10:12.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 5.0 in stage 9.0 (TID 808). 5872 bytes result sent to driver
[2025-07-19T22:10:12.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 11.0 in stage 9.0 (TID 814) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 12.0 in stage 9.0 (TID 815) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 806) in 154 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T22:10:12.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T22:10:12.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 4.0 in stage 9.0 (TID 807). 5872 bytes result sent to driver
[2025-07-19T22:10:12.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 13.0 in stage 9.0 (TID 816) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 11.0 in stage 9.0 (TID 814)
[2025-07-19T22:10:12.439+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 807) in 151 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T22:10:12.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.442+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 808) in 149 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T22:10:12.444+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 13.0 in stage 9.0 (TID 816)
[2025-07-19T22:10:12.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/.2.delta.47852688-765f-43ab-9464-45ceae93666a.TID809.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/2.delta
[2025-07-19T22:10:12.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/6/2.delta
[2025-07-19T22:10:12.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T22:10:12.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 12.0 in stage 9.0 (TID 815)
[2025-07-19T22:10:12.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.456+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.457+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55e5d5c6
[2025-07-19T22:10:12.458+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11] for update
[2025-07-19T22:10:12.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b6a6c3e
[2025-07-19T22:10:12.459+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12] for update
[2025-07-19T22:10:12.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T22:10:12.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 6.0 in stage 9.0 (TID 809). 5829 bytes result sent to driver
[2025-07-19T22:10:12.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 14.0 in stage 9.0 (TID 817) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44e5840d
[2025-07-19T22:10:12.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13] for update
[2025-07-19T22:10:12.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 14.0 in stage 9.0 (TID 817)
[2025-07-19T22:10:12.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 809) in 153 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T22:10:12.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63674b51
[2025-07-19T22:10:12.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14] for update
[2025-07-19T22:10:12.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.2.delta.bf53922f-60bd-488f-bf0e-5506f77ef133.TID814.tmp
[2025-07-19T22:10:12.473+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/.2.delta.b10816f4-fbdf-4de8-add0-b44857eb80c7.TID811.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/2.delta
[2025-07-19T22:10:12.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/8/2.delta
[2025-07-19T22:10:12.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T22:10:12.478+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.2.delta.3b6f48e1-8d1e-4d34-a216-ec75093f7de8.TID815.tmp
[2025-07-19T22:10:12.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T22:10:12.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 8.0 in stage 9.0 (TID 811). 5829 bytes result sent to driver
[2025-07-19T22:10:12.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 15.0 in stage 9.0 (TID 818) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 15.0 in stage 9.0 (TID 818)
[2025-07-19T22:10:12.484+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 8.0 in stage 9.0 (TID 811) in 136 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T22:10:12.488+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/.2.delta.cef937df-dc89-43c2-a90a-682cf8b72f81.TID812.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/2.delta
[2025-07-19T22:10:12.489+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/9/2.delta
[2025-07-19T22:10:12.490+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T22:10:12.490+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/.2.delta.ebe437d1-7156-43e4-a9e8-0caaee23850e.TID813.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/2.delta
[2025-07-19T22:10:12.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:12.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11d4c1d5
[2025-07-19T22:10:12.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.2.delta.ef43df71-8d8f-44db-b6bc-bc29fa9c684a.TID816.tmp
[2025-07-19T22:10:12.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15] for update
[2025-07-19T22:10:12.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.2.delta.58be11d6-36d8-491e-a29d-d4f134673f95.TID817.tmp
[2025-07-19T22:10:12.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/.2.delta.6418ec7d-e4c7-4d3a-bd43-a5c5cc140d43.TID810.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/2.delta
[2025-07-19T22:10:12.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/7/2.delta
[2025-07-19T22:10:12.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/10/2.delta
[2025-07-19T22:10:12.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T22:10:12.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T22:10:12.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T22:10:12.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 9.0 in stage 9.0 (TID 812). 5829 bytes result sent to driver
[2025-07-19T22:10:12.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 16.0 in stage 9.0 (TID 819) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 9.0 in stage 9.0 (TID 812) in 137 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T22:10:12.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 16.0 in stage 9.0 (TID 819)
[2025-07-19T22:10:12.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T22:10:12.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 10.0 in stage 9.0 (TID 813). 5829 bytes result sent to driver
[2025-07-19T22:10:12.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 17.0 in stage 9.0 (TID 820) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.510+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 17.0 in stage 9.0 (TID 820)
[2025-07-19T22:10:12.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 10.0 in stage 9.0 (TID 813) in 138 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T22:10:12.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T22:10:12.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 7.0 in stage 9.0 (TID 810). 5829 bytes result sent to driver
[2025-07-19T22:10:12.517+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 18.0 in stage 9.0 (TID 821) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.519+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 810) in 176 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T22:10:12.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 18.0 in stage 9.0 (TID 821)
[2025-07-19T22:10:12.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a4b5174
[2025-07-19T22:10:12.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16] for update
[2025-07-19T22:10:12.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cc49ac1
[2025-07-19T22:10:12.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.523+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17] for update
[2025-07-19T22:10:12.523+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@87acce7
[2025-07-19T22:10:12.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18] for update
[2025-07-19T22:10:12.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.2.delta.089d4ed4-eba0-48b7-aabc-fb0b19da1906.TID818.tmp
[2025-07-19T22:10:12.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.2.delta.40e44a12-4671-46d4-a0dd-0584135b63b2.TID819.tmp
[2025-07-19T22:10:12.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.2.delta.844a1eb7-92bb-43a1-93f6-b9270089794c.TID820.tmp
[2025-07-19T22:10:12.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.2.delta.0a61cbb0-b486-4229-851e-d58f5d24668c.TID821.tmp
[2025-07-19T22:10:12.538+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/.2.delta.3b6f48e1-8d1e-4d34-a216-ec75093f7de8.TID815.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/2.delta
[2025-07-19T22:10:12.539+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/12/2.delta
[2025-07-19T22:10:12.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T22:10:12.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v157.metadata.json
[2025-07-19T22:10:12.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/.2.delta.bf53922f-60bd-488f-bf0e-5506f77ef133.TID814.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/2.delta
[2025-07-19T22:10:12.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T22:10:12.548+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/11/2.delta
[2025-07-19T22:10:12.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T22:10:12.550+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 12.0 in stage 9.0 (TID 815). 5829 bytes result sent to driver
[2025-07-19T22:10:12.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 12.0 in stage 9.0 (TID 815) in 117 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T22:10:12.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 19.0 in stage 9.0 (TID 822) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 19.0 in stage 9.0 (TID 822)
[2025-07-19T22:10:12.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.553+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@de8d05a
[2025-07-19T22:10:12.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.556+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19] for update
[2025-07-19T22:10:12.556+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/.2.delta.58be11d6-36d8-491e-a29d-d4f134673f95.TID817.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/2.delta
[2025-07-19T22:10:12.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/14/2.delta
[2025-07-19T22:10:12.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T22:10:12.564+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T22:10:12.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 11.0 in stage 9.0 (TID 814). 5829 bytes result sent to driver
[2025-07-19T22:10:12.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 20.0 in stage 9.0 (TID 823) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 20.0 in stage 9.0 (TID 823)
[2025-07-19T22:10:12.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 11.0 in stage 9.0 (TID 814) in 126 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T22:10:12.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b6b2970
[2025-07-19T22:10:12.572+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.572+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T22:10:12.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20] for update
[2025-07-19T22:10:12.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 14.0 in stage 9.0 (TID 817). 5829 bytes result sent to driver
[2025-07-19T22:10:12.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 21.0 in stage 9.0 (TID 824) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 21.0 in stage 9.0 (TID 824)
[2025-07-19T22:10:12.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 14.0 in stage 9.0 (TID 817) in 115 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T22:10:12.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/.2.delta.ef43df71-8d8f-44db-b6bc-bc29fa9c684a.TID816.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/2.delta
[2025-07-19T22:10:12.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/13/2.delta
[2025-07-19T22:10:12.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.2.delta.383c8cba-a472-4356-9b2f-f2b3f3b79a4d.TID822.tmp
[2025-07-19T22:10:12.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T22:10:12.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:12.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@351fb6ae
[2025-07-19T22:10:12.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21] for update
[2025-07-19T22:10:12.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/.2.delta.40e44a12-4671-46d4-a0dd-0584135b63b2.TID819.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/2.delta
[2025-07-19T22:10:12.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/16/2.delta
[2025-07-19T22:10:12.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T22:10:12.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T22:10:12.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 13.0 in stage 9.0 (TID 816). 5829 bytes result sent to driver
[2025-07-19T22:10:12.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/.2.delta.089d4ed4-eba0-48b7-aabc-fb0b19da1906.TID818.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/2.delta
[2025-07-19T22:10:12.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/15/2.delta
[2025-07-19T22:10:12.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T22:10:12.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.2.delta.4a24a74e-62eb-4173-9203-c0925e13a7aa.TID823.tmp
[2025-07-19T22:10:12.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 22.0 in stage 9.0 (TID 825) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T22:10:12.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 13.0 in stage 9.0 (TID 816) in 153 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T22:10:12.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 22.0 in stage 9.0 (TID 825)
[2025-07-19T22:10:12.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T22:10:12.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 15.0 in stage 9.0 (TID 818). 5829 bytes result sent to driver
[2025-07-19T22:10:12.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 16.0 in stage 9.0 (TID 819). 5829 bytes result sent to driver
[2025-07-19T22:10:12.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/.2.delta.844a1eb7-92bb-43a1-93f6-b9270089794c.TID820.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/2.delta
[2025-07-19T22:10:12.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/17/2.delta
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 23.0 in stage 9.0 (TID 826) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 24.0 in stage 9.0 (TID 827) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 23.0 in stage 9.0 (TID 826)
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 24.0 in stage 9.0 (TID 827)
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 15.0 in stage 9.0 (TID 818) in 108 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39c56ad5
[2025-07-19T22:10:12.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22] for update
[2025-07-19T22:10:12.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T22:10:12.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 17.0 in stage 9.0 (TID 820). 5829 bytes result sent to driver
[2025-07-19T22:10:12.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 25.0 in stage 9.0 (TID 828) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.2.delta.f2d5080d-a8ae-4e3c-853a-d774db0206ca.TID824.tmp
[2025-07-19T22:10:12.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 16.0 in stage 9.0 (TID 819) in 96 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T22:10:12.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/.2.delta.0a61cbb0-b486-4229-851e-d58f5d24668c.TID821.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/2.delta
[2025-07-19T22:10:12.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/18/2.delta
[2025-07-19T22:10:12.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 17.0 in stage 9.0 (TID 820) in 91 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T22:10:12.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 25.0 in stage 9.0 (TID 828)
[2025-07-19T22:10:12.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58a2de5
[2025-07-19T22:10:12.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T22:10:12.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24] for update
[2025-07-19T22:10:12.619+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@231b4e5e
[2025-07-19T22:10:12.620+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.620+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.621+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23] for update
[2025-07-19T22:10:12.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.2.delta.aebd6015-9a99-4019-87dc-b7a78d339829.TID825.tmp
[2025-07-19T22:10:12.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T22:10:12.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 18.0 in stage 9.0 (TID 821). 5829 bytes result sent to driver
[2025-07-19T22:10:12.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:12.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 26.0 in stage 9.0 (TID 829) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 18.0 in stage 9.0 (TID 821) in 104 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T22:10:12.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31af9074
[2025-07-19T22:10:12.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 26.0 in stage 9.0 (TID 829)
[2025-07-19T22:10:12.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25] for update
[2025-07-19T22:10:12.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO SnapshotProducer: Committed snapshot 5302802569814435778 (FastAppend)
[2025-07-19T22:10:12.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.2.delta.43fca4b9-9111-415e-a8bb-90e2034554f5.TID826.tmp
[2025-07-19T22:10:12.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.2.delta.8ac2e03e-ef0d-4719-9d2a-1df250f9221a.TID827.tmp
[2025-07-19T22:10:12.637+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.638+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:12.638+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@315bd17f
[2025-07-19T22:10:12.639+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.640+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26] for update
[2025-07-19T22:10:12.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.2.delta.9bf84555-3ece-4d14-9488-6064400a7b4d.TID828.tmp
[2025-07-19T22:10:12.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/.2.delta.383c8cba-a472-4356-9b2f-f2b3f3b79a4d.TID822.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/2.delta
[2025-07-19T22:10:12.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/19/2.delta
[2025-07-19T22:10:12.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T22:10:12.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.2.delta.f55e596d-91da-473e-8d6c-65fd37498627.TID829.tmp
[2025-07-19T22:10:12.649+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T22:10:12.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 19.0 in stage 9.0 (TID 822). 5829 bytes result sent to driver
[2025-07-19T22:10:12.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 27.0 in stage 9.0 (TID 830) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.655+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 27.0 in stage 9.0 (TID 830)
[2025-07-19T22:10:12.656+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 19.0 in stage 9.0 (TID 822) in 106 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T22:10:12.656+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/.2.delta.4a24a74e-62eb-4173-9203-c0925e13a7aa.TID823.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/2.delta
[2025-07-19T22:10:12.656+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/20/2.delta
[2025-07-19T22:10:12.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T22:10:12.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T22:10:12.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 20.0 in stage 9.0 (TID 823). 5829 bytes result sent to driver
[2025-07-19T22:10:12.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1408204f
[2025-07-19T22:10:12.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 20.0 in stage 9.0 (TID 823) in 109 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T22:10:12.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27] for update
[2025-07-19T22:10:12.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 28.0 in stage 9.0 (TID 831) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 28.0 in stage 9.0 (TID 831)
[2025-07-19T22:10:12.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/.2.delta.aebd6015-9a99-4019-87dc-b7a78d339829.TID825.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/2.delta
[2025-07-19T22:10:12.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/22/2.delta
[2025-07-19T22:10:12.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T22:10:12.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29ea1617
[2025-07-19T22:10:12.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/.2.delta.f2d5080d-a8ae-4e3c-853a-d774db0206ca.TID824.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/2.delta
[2025-07-19T22:10:12.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/21/2.delta
[2025-07-19T22:10:12.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T22:10:12.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28] for update
[2025-07-19T22:10:12.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/.2.delta.8ac2e03e-ef0d-4719-9d2a-1df250f9221a.TID827.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/2.delta
[2025-07-19T22:10:12.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/24/2.delta
[2025-07-19T22:10:12.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T22:10:12.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T22:10:12.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 21.0 in stage 9.0 (TID 824). 5829 bytes result sent to driver
[2025-07-19T22:10:12.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T22:10:12.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 29.0 in stage 9.0 (TID 832) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 21.0 in stage 9.0 (TID 824) in 121 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T22:10:12.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/.2.delta.43fca4b9-9111-415e-a8bb-90e2034554f5.TID826.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/2.delta
[2025-07-19T22:10:12.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/23/2.delta
[2025-07-19T22:10:12.696+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 29.0 in stage 9.0 (TID 832)
[2025-07-19T22:10:12.698+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 22.0 in stage 9.0 (TID 825). 5829 bytes result sent to driver
[2025-07-19T22:10:12.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.700+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T22:10:12.701+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.2.delta.e0a0d139-ab69-41e7-b875-9c21d9c201fa.TID830.tmp
[2025-07-19T22:10:12.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 30.0 in stage 9.0 (TID 833) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 22.0 in stage 9.0 (TID 825) in 105 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T22:10:12.707+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T22:10:12.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 24.0 in stage 9.0 (TID 827). 5829 bytes result sent to driver
[2025-07-19T22:10:12.709+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 30.0 in stage 9.0 (TID 833)
[2025-07-19T22:10:12.711+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T22:10:12.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 31.0 in stage 9.0 (TID 834) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 31.0 in stage 9.0 (TID 834)
[2025-07-19T22:10:12.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 24.0 in stage 9.0 (TID 827) in 104 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T22:10:12.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51640d32
[2025-07-19T22:10:12.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30] for update
[2025-07-19T22:10:12.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=5302802569814435778, sequenceNumber=156, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.320961209S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=8521}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=12519}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=24611748}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752962984887, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T22:10:12.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO SparkWrite: Committed in 321 ms
[2025-07-19T22:10:12.719+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T22:10:12.720+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 23.0 in stage 9.0 (TID 826). 5872 bytes result sent to driver
[2025-07-19T22:10:12.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 32.0 in stage 9.0 (TID 835) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.728+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 32.0 in stage 9.0 (TID 835)
[2025-07-19T22:10:12.730+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/.2.delta.9bf84555-3ece-4d14-9488-6064400a7b4d.TID828.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/2.delta
[2025-07-19T22:10:12.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/25/2.delta
[2025-07-19T22:10:12.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 23.0 in stage 9.0 (TID 826) in 111 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T22:10:12.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T22:10:12.733+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75194aa3
[2025-07-19T22:10:12.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31] for update
[2025-07-19T22:10:12.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.2.delta.180c4c2f-bdb3-4367-b707-a046ff5551ea.TID831.tmp
[2025-07-19T22:10:12.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:12.737+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T22:10:12.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45076da2
[2025-07-19T22:10:12.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.744+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29] for update
[2025-07-19T22:10:12.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 25.0 in stage 9.0 (TID 828). 5829 bytes result sent to driver
[2025-07-19T22:10:12.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 33.0 in stage 9.0 (TID 836) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 25.0 in stage 9.0 (TID 828) in 117 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T22:10:12.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 33.0 in stage 9.0 (TID 836)
[2025-07-19T22:10:12.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@556d1c26
[2025-07-19T22:10:12.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.2.delta.4608753b-bf67-4597-97bd-ae4afe217af4.TID833.tmp
[2025-07-19T22:10:12.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32] for update
[2025-07-19T22:10:12.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/commits/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/commits/.1.fdafd090-2e6d-4c2e-884e-05e9793f5078.tmp
[2025-07-19T22:10:12.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:12.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25a4a540
[2025-07-19T22:10:12.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.2.delta.d36ba3f1-cc9a-431f-a415-b841a67b06ca.TID834.tmp
[2025-07-19T22:10:12.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33] for update
[2025-07-19T22:10:12.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.2.delta.a57e828a-b527-47f7-8453-5f41810d0f3e.TID832.tmp
[2025-07-19T22:10:12.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.2.delta.df88b952-9e4e-46cc-b731-81bba5bdef0e.TID835.tmp
[2025-07-19T22:10:12.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.2.delta.4d863838-d0ec-457c-a165-af9f6d501e18.TID836.tmp
[2025-07-19T22:10:12.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/.2.delta.f55e596d-91da-473e-8d6c-65fd37498627.TID829.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/2.delta
[2025-07-19T22:10:12.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/26/2.delta
[2025-07-19T22:10:12.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T22:10:12.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/.2.delta.e0a0d139-ab69-41e7-b875-9c21d9c201fa.TID830.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/2.delta
[2025-07-19T22:10:12.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/27/2.delta
[2025-07-19T22:10:12.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T22:10:12.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T22:10:12.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 26.0 in stage 9.0 (TID 829). 5829 bytes result sent to driver
[2025-07-19T22:10:12.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 34.0 in stage 9.0 (TID 837) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 26.0 in stage 9.0 (TID 829) in 139 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T22:10:12.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T22:10:12.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 34.0 in stage 9.0 (TID 837)
[2025-07-19T22:10:12.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 27.0 in stage 9.0 (TID 830). 5829 bytes result sent to driver
[2025-07-19T22:10:12.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 35.0 in stage 9.0 (TID 838) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 35.0 in stage 9.0 (TID 838)
[2025-07-19T22:10:12.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 27.0 in stage 9.0 (TID 830) in 100 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T22:10:12.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5831ffc6
[2025-07-19T22:10:12.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35] for update
[2025-07-19T22:10:12.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9f47849
[2025-07-19T22:10:12.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34] for update
[2025-07-19T22:10:12.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.771+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/.2.delta.d36ba3f1-cc9a-431f-a415-b841a67b06ca.TID834.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/2.delta
[2025-07-19T22:10:12.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/31/2.delta
[2025-07-19T22:10:12.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T22:10:12.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/.2.delta.4608753b-bf67-4597-97bd-ae4afe217af4.TID833.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/2.delta
[2025-07-19T22:10:12.776+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/30/2.delta
[2025-07-19T22:10:12.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T22:10:12.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/.2.delta.180c4c2f-bdb3-4367-b707-a046ff5551ea.TID831.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/2.delta
[2025-07-19T22:10:12.782+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/28/2.delta
[2025-07-19T22:10:12.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T22:10:12.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/commits/.1.fdafd090-2e6d-4c2e-884e-05e9793f5078.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T22:06:00+00:00/commits/1
[2025-07-19T22:10:12.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T22:10:12.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.2.delta.fd035706-94f4-4062-9e6e-ff607d38430e.TID838.tmp
[2025-07-19T22:10:12.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 31.0 in stage 9.0 (TID 834). 5829 bytes result sent to driver
[2025-07-19T22:10:12.784+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 36.0 in stage 9.0 (TID 839) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.784+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 36.0 in stage 9.0 (TID 839)
[2025-07-19T22:10:12.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.2.delta.caad7278-2330-4dff-8af3-06d25d4815ae.TID837.tmp
[2025-07-19T22:10:12.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T22:10:12.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T22:10:12.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 31.0 in stage 9.0 (TID 834) in 91 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T22:10:12.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 28.0 in stage 9.0 (TID 831). 5829 bytes result sent to driver
[2025-07-19T22:10:12.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T22:10:12.792+0000] {subprocess.py:93} INFO -   "id" : "46c08399-34b2-49a9-aadd-060519c28563",
[2025-07-19T22:10:12.793+0000] {subprocess.py:93} INFO -   "runId" : "9b56af61-c478-4de4-bf3d-6c85462edb9c",
[2025-07-19T22:10:12.794+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T22:10:12.797+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T22:10:03.081Z",
[2025-07-19T22:10:12.797+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T22:10:12.797+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T22:10:12.797+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:12.797+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T22:10:12.798+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T22:10:12.798+0000] {subprocess.py:93} INFO -     "addBatch" : 9402,
[2025-07-19T22:10:12.798+0000] {subprocess.py:93} INFO -     "commitOffsets" : 81,
[2025-07-19T22:10:12.799+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T22:10:12.799+0000] {subprocess.py:93} INFO -     "latestOffset" : 27,
[2025-07-19T22:10:12.799+0000] {subprocess.py:93} INFO -     "queryPlanning" : 84,
[2025-07-19T22:10:12.799+0000] {subprocess.py:93} INFO -     "triggerExecution" : 9696,
[2025-07-19T22:10:12.799+0000] {subprocess.py:93} INFO -     "walCommit" : 83
[2025-07-19T22:10:12.800+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:12.800+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T22:10:12.800+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T22:09:37.000Z"
[2025-07-19T22:10:12.800+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:12.800+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T22:10:12.800+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T22:10:12.800+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 276,
[2025-07-19T22:10:12.801+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T22:10:12.801+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 332,
[2025-07-19T22:10:12.801+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T22:10:12.802+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 161,
[2025-07-19T22:10:12.802+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 18254,
[2025-07-19T22:10:12.802+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 159904,
[2025-07-19T22:10:12.802+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T22:10:12.802+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T22:10:12.802+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T22:10:12.802+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T22:10:12.803+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T22:10:12.803+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T22:10:12.803+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T22:10:12.803+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 77872
[2025-07-19T22:10:12.803+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:12.803+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:12.804+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T22:10:12.804+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T22:10:12.804+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T22:10:12.804+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T22:10:12.805+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:12.806+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:12.807+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:12.808+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T22:10:12.808+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T22:10:12.808+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:12.809+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:12.809+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:12.810+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T22:10:12.810+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T22:10:12.813+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:12.814+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:12.814+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:12.815+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T22:10:12.817+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:12.819+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T22:10:12.820+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T22:10:12.821+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T22:10:12.822+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T22:10:12.823+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T22:10:12.824+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:12.825+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:12.825+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T22:10:12.826+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T22:10:12.826+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T22:10:12.827+0000] {subprocess.py:93} INFO -   }
[2025-07-19T22:10:12.827+0000] {subprocess.py:93} INFO - }
[2025-07-19T22:10:12.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 28.0 in stage 9.0 (TID 831) in 126 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T22:10:12.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 37.0 in stage 9.0 (TID 840) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 30.0 in stage 9.0 (TID 833). 5915 bytes result sent to driver
[2025-07-19T22:10:12.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 37.0 in stage 9.0 (TID 840)
[2025-07-19T22:10:12.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 38.0 in stage 9.0 (TID 841) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 30.0 in stage 9.0 (TID 833) in 107 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T22:10:12.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 38.0 in stage 9.0 (TID 841)
[2025-07-19T22:10:12.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@98df2ef
[2025-07-19T22:10:12.829+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.830+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36] for update
[2025-07-19T22:10:12.831+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:12.832+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a2ef549
[2025-07-19T22:10:12.833+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.834+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37] for update
[2025-07-19T22:10:12.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3561d310
[2025-07-19T22:10:12.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38] for update
[2025-07-19T22:10:12.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.835+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/.2.delta.4d863838-d0ec-457c-a165-af9f6d501e18.TID836.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/2.delta
[2025-07-19T22:10:12.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/33/2.delta
[2025-07-19T22:10:12.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T22:10:12.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/.2.delta.a57e828a-b527-47f7-8453-5f41810d0f3e.TID832.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/2.delta
[2025-07-19T22:10:12.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/29/2.delta
[2025-07-19T22:10:12.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/.2.delta.df88b952-9e4e-46cc-b731-81bba5bdef0e.TID835.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/2.delta
[2025-07-19T22:10:12.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/32/2.delta
[2025-07-19T22:10:12.836+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.2.delta.831fa65d-fade-424a-899a-7116fd983e64.TID839.tmp
[2025-07-19T22:10:12.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T22:10:12.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T22:10:12.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T22:10:12.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 33.0 in stage 9.0 (TID 836). 5872 bytes result sent to driver
[2025-07-19T22:10:12.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 39.0 in stage 9.0 (TID 842) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 39.0 in stage 9.0 (TID 842)
[2025-07-19T22:10:12.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.2.delta.cd39ab52-6ba8-4552-8a4a-e7eac28e7ad3.TID841.tmp
[2025-07-19T22:10:12.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 33.0 in stage 9.0 (TID 836) in 106 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T22:10:12.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.2.delta.7ef66938-321d-4f62-9e87-9bedf009fdee.TID840.tmp
[2025-07-19T22:10:12.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T22:10:12.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 29.0 in stage 9.0 (TID 832). 5872 bytes result sent to driver
[2025-07-19T22:10:12.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T22:10:12.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 32.0 in stage 9.0 (TID 835). 5872 bytes result sent to driver
[2025-07-19T22:10:12.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27bd84cc
[2025-07-19T22:10:12.839+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 40.0 in stage 9.0 (TID 843) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.840+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 41.0 in stage 9.0 (TID 844) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.840+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 40.0 in stage 9.0 (TID 843)
[2025-07-19T22:10:12.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 29.0 in stage 9.0 (TID 832) in 139 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T22:10:12.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 32.0 in stage 9.0 (TID 835) in 127 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T22:10:12.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39] for update
[2025-07-19T22:10:12.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 41.0 in stage 9.0 (TID 844)
[2025-07-19T22:10:12.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.848+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50d18ea
[2025-07-19T22:10:12.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40] for update
[2025-07-19T22:10:12.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d236959
[2025-07-19T22:10:12.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41] for update
[2025-07-19T22:10:12.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.2.delta.63403318-8406-4d44-a078-8a2318a2d410.TID842.tmp
[2025-07-19T22:10:12.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.2.delta.baaaa7c0-47ad-4b6a-b465-4c1358fe8439.TID843.tmp
[2025-07-19T22:10:12.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/.2.delta.caad7278-2330-4dff-8af3-06d25d4815ae.TID837.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/2.delta
[2025-07-19T22:10:12.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/34/2.delta
[2025-07-19T22:10:12.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T22:10:12.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/.2.delta.fd035706-94f4-4062-9e6e-ff607d38430e.TID838.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/2.delta
[2025-07-19T22:10:12.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/35/2.delta
[2025-07-19T22:10:12.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T22:10:12.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T22:10:12.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 34.0 in stage 9.0 (TID 837). 5872 bytes result sent to driver
[2025-07-19T22:10:12.855+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 42.0 in stage 9.0 (TID 845) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 42.0 in stage 9.0 (TID 845)
[2025-07-19T22:10:12.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 34.0 in stage 9.0 (TID 837) in 101 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T22:10:12.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.2.delta.6e2b39df-5f66-4a62-8b2c-3536da068250.TID844.tmp
[2025-07-19T22:10:12.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T22:10:12.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.861+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 35.0 in stage 9.0 (TID 838). 5915 bytes result sent to driver
[2025-07-19T22:10:12.863+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 43.0 in stage 9.0 (TID 846) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.865+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 35.0 in stage 9.0 (TID 838) in 110 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T22:10:12.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 43.0 in stage 9.0 (TID 846)
[2025-07-19T22:10:12.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6836d442
[2025-07-19T22:10:12.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.867+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42] for update
[2025-07-19T22:10:12.868+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.869+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.870+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.871+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36f52bd5
[2025-07-19T22:10:12.872+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.873+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43] for update
[2025-07-19T22:10:12.874+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/.2.delta.7ef66938-321d-4f62-9e87-9bedf009fdee.TID840.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/2.delta
[2025-07-19T22:10:12.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/37/2.delta
[2025-07-19T22:10:12.876+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T22:10:12.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.878+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/.2.delta.cd39ab52-6ba8-4552-8a4a-e7eac28e7ad3.TID841.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/2.delta
[2025-07-19T22:10:12.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/38/2.delta
[2025-07-19T22:10:12.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/.2.delta.831fa65d-fade-424a-899a-7116fd983e64.TID839.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/2.delta
[2025-07-19T22:10:12.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/36/2.delta
[2025-07-19T22:10:12.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T22:10:12.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T22:10:12.880+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T22:10:12.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 37.0 in stage 9.0 (TID 840). 5872 bytes result sent to driver
[2025-07-19T22:10:12.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.2.delta.944cb2f1-c654-4d8c-a3e8-3e526965eb03.TID845.tmp
[2025-07-19T22:10:12.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T22:10:12.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 44.0 in stage 9.0 (TID 847) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T22:10:12.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 37.0 in stage 9.0 (TID 840) in 86 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T22:10:12.882+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 38.0 in stage 9.0 (TID 841). 5872 bytes result sent to driver
[2025-07-19T22:10:12.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 36.0 in stage 9.0 (TID 839). 5872 bytes result sent to driver
[2025-07-19T22:10:12.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 45.0 in stage 9.0 (TID 848) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 44.0 in stage 9.0 (TID 847)
[2025-07-19T22:10:12.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 38.0 in stage 9.0 (TID 841) in 87 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T22:10:12.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 45.0 in stage 9.0 (TID 848)
[2025-07-19T22:10:12.884+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 46.0 in stage 9.0 (TID 849) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 46.0 in stage 9.0 (TID 849)
[2025-07-19T22:10:12.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 36.0 in stage 9.0 (TID 839) in 102 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T22:10:12.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3df3849a
[2025-07-19T22:10:12.890+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.890+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44] for update
[2025-07-19T22:10:12.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.892+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.893+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dd18412
[2025-07-19T22:10:12.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.894+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45] for update
[2025-07-19T22:10:12.896+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.2.delta.ef7e3e94-f313-4ab0-9e1b-306b170ff127.TID846.tmp
[2025-07-19T22:10:12.896+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.896+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b41e45b
[2025-07-19T22:10:12.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46] for update
[2025-07-19T22:10:12.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.2.delta.0fc5d4e9-b909-4287-b106-da61de9e8e28.TID848.tmp
[2025-07-19T22:10:12.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/.2.delta.baaaa7c0-47ad-4b6a-b465-4c1358fe8439.TID843.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/2.delta
[2025-07-19T22:10:12.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/40/2.delta
[2025-07-19T22:10:12.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.2.delta.71fce1c1-0bff-4904-a239-d103f2bbe50f.TID849.tmp
[2025-07-19T22:10:12.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T22:10:12.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.2.delta.b539f877-58b7-48fc-b48d-3a865753283a.TID847.tmp
[2025-07-19T22:10:12.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/.2.delta.63403318-8406-4d44-a078-8a2318a2d410.TID842.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/2.delta
[2025-07-19T22:10:12.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/39/2.delta
[2025-07-19T22:10:12.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T22:10:12.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T22:10:12.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 40.0 in stage 9.0 (TID 843). 5872 bytes result sent to driver
[2025-07-19T22:10:12.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/.2.delta.6e2b39df-5f66-4a62-8b2c-3536da068250.TID844.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/2.delta
[2025-07-19T22:10:12.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/41/2.delta
[2025-07-19T22:10:12.910+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 47.0 in stage 9.0 (TID 850) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T22:10:12.915+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 47.0 in stage 9.0 (TID 850)
[2025-07-19T22:10:12.918+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T22:10:12.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 40.0 in stage 9.0 (TID 843) in 89 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T22:10:12.920+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T22:10:12.920+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 39.0 in stage 9.0 (TID 842). 5872 bytes result sent to driver
[2025-07-19T22:10:12.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 41.0 in stage 9.0 (TID 844). 5872 bytes result sent to driver
[2025-07-19T22:10:12.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 48.0 in stage 9.0 (TID 851) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 49.0 in stage 9.0 (TID 852) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 48.0 in stage 9.0 (TID 851)
[2025-07-19T22:10:12.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 49.0 in stage 9.0 (TID 852)
[2025-07-19T22:10:12.921+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 41.0 in stage 9.0 (TID 844) in 94 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T22:10:12.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.922+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eb0dd57
[2025-07-19T22:10:12.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47] for update
[2025-07-19T22:10:12.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 39.0 in stage 9.0 (TID 842) in 106 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T22:10:12.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@105e4292
[2025-07-19T22:10:12.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48] for update
[2025-07-19T22:10:12.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:12.926+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/.2.delta.944cb2f1-c654-4d8c-a3e8-3e526965eb03.TID845.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/2.delta
[2025-07-19T22:10:12.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/42/2.delta
[2025-07-19T22:10:12.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f7a77d0
[2025-07-19T22:10:12.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49] for update
[2025-07-19T22:10:12.928+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.928+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.928+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T22:10:12.931+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T22:10:12.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 42.0 in stage 9.0 (TID 845). 5872 bytes result sent to driver
[2025-07-19T22:10:12.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.2.delta.241df147-6a83-4793-b8da-be21800016e2.TID851.tmp
[2025-07-19T22:10:12.933+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.2.delta.a67d12da-b629-41f2-b852-b4d7084fa504.TID850.tmp
[2025-07-19T22:10:12.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 50.0 in stage 9.0 (TID 853) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 42.0 in stage 9.0 (TID 845) in 86 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T22:10:12.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 50.0 in stage 9.0 (TID 853)
[2025-07-19T22:10:12.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c73a5ce
[2025-07-19T22:10:12.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50] for update
[2025-07-19T22:10:12.938+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/.2.delta.ef7e3e94-f313-4ab0-9e1b-306b170ff127.TID846.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/2.delta
[2025-07-19T22:10:12.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/43/2.delta
[2025-07-19T22:10:12.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T22:10:12.940+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.2.delta.1eea26a9-a649-4592-b8bf-74d0af07b101.TID852.tmp
[2025-07-19T22:10:12.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T22:10:12.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 43.0 in stage 9.0 (TID 846). 5829 bytes result sent to driver
[2025-07-19T22:10:12.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 51.0 in stage 9.0 (TID 854) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 51.0 in stage 9.0 (TID 854)
[2025-07-19T22:10:12.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 43.0 in stage 9.0 (TID 846) in 86 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T22:10:12.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/.2.delta.b539f877-58b7-48fc-b48d-3a865753283a.TID847.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/2.delta
[2025-07-19T22:10:12.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/44/2.delta
[2025-07-19T22:10:12.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T22:10:12.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50516d8
[2025-07-19T22:10:12.950+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51] for update
[2025-07-19T22:10:12.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/.2.delta.71fce1c1-0bff-4904-a239-d103f2bbe50f.TID849.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/2.delta
[2025-07-19T22:10:12.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/46/2.delta
[2025-07-19T22:10:12.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T22:10:12.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.2.delta.7c25d12d-063b-4204-a879-6075a503b002.TID853.tmp
[2025-07-19T22:10:12.960+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T22:10:12.960+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 44.0 in stage 9.0 (TID 847). 5829 bytes result sent to driver
[2025-07-19T22:10:12.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T22:10:12.961+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 46.0 in stage 9.0 (TID 849). 5829 bytes result sent to driver
[2025-07-19T22:10:12.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 52.0 in stage 9.0 (TID 855) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 53.0 in stage 9.0 (TID 856) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 46.0 in stage 9.0 (TID 849) in 81 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T22:10:12.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 52.0 in stage 9.0 (TID 855)
[2025-07-19T22:10:12.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 44.0 in stage 9.0 (TID 847) in 85 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T22:10:12.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 53.0 in stage 9.0 (TID 856)
[2025-07-19T22:10:12.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.2.delta.f84596a0-7d08-4e28-93c2-fea888fd9d23.TID854.tmp
[2025-07-19T22:10:12.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70d65f0c
[2025-07-19T22:10:12.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52] for update
[2025-07-19T22:10:12.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/.2.delta.0fc5d4e9-b909-4287-b106-da61de9e8e28.TID848.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/2.delta
[2025-07-19T22:10:12.970+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/45/2.delta
[2025-07-19T22:10:12.971+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T22:10:12.971+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a348cf0
[2025-07-19T22:10:12.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53] for update
[2025-07-19T22:10:12.973+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T22:10:12.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 45.0 in stage 9.0 (TID 848). 5829 bytes result sent to driver
[2025-07-19T22:10:12.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 54.0 in stage 9.0 (TID 857) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 45.0 in stage 9.0 (TID 848) in 97 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T22:10:12.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 54.0 in stage 9.0 (TID 857)
[2025-07-19T22:10:12.980+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:12.980+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:12.980+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.2.delta.fdc7e7b0-7c3a-4220-aadf-d038845cbc93.TID855.tmp
[2025-07-19T22:10:12.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@395a91b
[2025-07-19T22:10:12.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:12.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54] for update
[2025-07-19T22:10:12.985+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:12.985+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.2.delta.8bc11fae-6a38-487b-9c86-c3dc13da5858.TID856.tmp
[2025-07-19T22:10:12.987+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/.2.delta.241df147-6a83-4793-b8da-be21800016e2.TID851.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/2.delta
[2025-07-19T22:10:12.987+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/48/2.delta
[2025-07-19T22:10:12.988+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T22:10:12.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/.2.delta.a67d12da-b629-41f2-b852-b4d7084fa504.TID850.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/2.delta
[2025-07-19T22:10:12.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/47/2.delta
[2025-07-19T22:10:12.992+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T22:10:12.993+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T22:10:12.994+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 48.0 in stage 9.0 (TID 851). 5829 bytes result sent to driver
[2025-07-19T22:10:12.995+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 55.0 in stage 9.0 (TID 858) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:12.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Running task 55.0 in stage 9.0 (TID 858)
[2025-07-19T22:10:12.996+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 48.0 in stage 9.0 (TID 851) in 79 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T22:10:12.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.2.delta.51993064-5bb0-427c-983c-9737ace509c9.TID857.tmp
[2025-07-19T22:10:12.997+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T22:10:12.998+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO Executor: Finished task 47.0 in stage 9.0 (TID 850). 5829 bytes result sent to driver
[2025-07-19T22:10:12.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/.2.delta.1eea26a9-a649-4592-b8bf-74d0af07b101.TID852.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/2.delta
[2025-07-19T22:10:12.999+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/49/2.delta
[2025-07-19T22:10:13.000+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.002+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.003+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T22:10:13.004+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f0fc5b3
[2025-07-19T22:10:13.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.005+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55] for update
[2025-07-19T22:10:13.006+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Starting task 56.0 in stage 9.0 (TID 859) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO DataWritingSparkTask: Committed partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T22:10:13.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:12 INFO TaskSetManager: Finished task 47.0 in stage 9.0 (TID 850) in 92 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T22:10:13.008+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 49.0 in stage 9.0 (TID 852). 5829 bytes result sent to driver
[2025-07-19T22:10:13.009+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 56.0 in stage 9.0 (TID 859)
[2025-07-19T22:10:13.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 57.0 in stage 9.0 (TID 860) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 57.0 in stage 9.0 (TID 860)
[2025-07-19T22:10:13.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 49.0 in stage 9.0 (TID 852) in 89 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T22:10:13.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@600e6982
[2025-07-19T22:10:13.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57] for update
[2025-07-19T22:10:13.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.014+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cd26182
[2025-07-19T22:10:13.015+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/.2.delta.7c25d12d-063b-4204-a879-6075a503b002.TID853.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/2.delta
[2025-07-19T22:10:13.015+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/50/2.delta
[2025-07-19T22:10:13.016+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56] for update
[2025-07-19T22:10:13.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T22:10:13.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.020+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T22:10:13.020+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 50.0 in stage 9.0 (TID 853). 5829 bytes result sent to driver
[2025-07-19T22:10:13.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.2.delta.7cf2ca25-7353-4f21-bd1d-f71f11fed67d.TID858.tmp
[2025-07-19T22:10:13.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 58.0 in stage 9.0 (TID 861) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 58.0 in stage 9.0 (TID 861)
[2025-07-19T22:10:13.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 50.0 in stage 9.0 (TID 853) in 88 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T22:10:13.023+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e17eb06
[2025-07-19T22:10:13.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58] for update
[2025-07-19T22:10:13.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/.2.delta.f84596a0-7d08-4e28-93c2-fea888fd9d23.TID854.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/2.delta
[2025-07-19T22:10:13.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/51/2.delta
[2025-07-19T22:10:13.030+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T22:10:13.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T22:10:13.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 51.0 in stage 9.0 (TID 854). 5829 bytes result sent to driver
[2025-07-19T22:10:13.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 59.0 in stage 9.0 (TID 862) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 59.0 in stage 9.0 (TID 862)
[2025-07-19T22:10:13.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 51.0 in stage 9.0 (TID 854) in 85 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T22:10:13.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.035+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/.2.delta.fdc7e7b0-7c3a-4220-aadf-d038845cbc93.TID855.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/2.delta
[2025-07-19T22:10:13.036+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/52/2.delta
[2025-07-19T22:10:13.037+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T22:10:13.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.2.delta.33f7066e-a34d-4cd7-b213-54d91de7788c.TID860.tmp
[2025-07-19T22:10:13.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.2.delta.e7932cf0-23ee-4906-a3d6-ad65f7c4bd1a.TID859.tmp
[2025-07-19T22:10:13.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61394c26
[2025-07-19T22:10:13.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59] for update
[2025-07-19T22:10:13.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T22:10:13.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/.2.delta.8bc11fae-6a38-487b-9c86-c3dc13da5858.TID856.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/2.delta
[2025-07-19T22:10:13.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/53/2.delta
[2025-07-19T22:10:13.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 52.0 in stage 9.0 (TID 855). 5829 bytes result sent to driver
[2025-07-19T22:10:13.048+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T22:10:13.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 60.0 in stage 9.0 (TID 863) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 60.0 in stage 9.0 (TID 863)
[2025-07-19T22:10:13.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 52.0 in stage 9.0 (TID 855) in 81 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T22:10:13.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T22:10:13.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 53.0 in stage 9.0 (TID 856). 5829 bytes result sent to driver
[2025-07-19T22:10:13.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 61.0 in stage 9.0 (TID 864) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.050+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 61.0 in stage 9.0 (TID 864)
[2025-07-19T22:10:13.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.2.delta.15474704-f1f3-40d1-880a-493caac4f8c8.TID861.tmp
[2025-07-19T22:10:13.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a110543
[2025-07-19T22:10:13.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 53.0 in stage 9.0 (TID 856) in 86 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T22:10:13.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.057+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60] for update
[2025-07-19T22:10:13.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ea1d486
[2025-07-19T22:10:13.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61] for update
[2025-07-19T22:10:13.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.2.delta.3990e8a4-5595-44f3-bb44-cc97638fa1b8.TID862.tmp
[2025-07-19T22:10:13.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/.2.delta.51993064-5bb0-427c-983c-9737ace509c9.TID857.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/2.delta
[2025-07-19T22:10:13.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/54/2.delta
[2025-07-19T22:10:13.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T22:10:13.064+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.2.delta.f425be06-5064-4a2a-9d92-06aa0e83a19a.TID863.tmp
[2025-07-19T22:10:13.068+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.2.delta.0dace187-f2a6-4da5-a2ef-d3255d4f24d6.TID864.tmp
[2025-07-19T22:10:13.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T22:10:13.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 54.0 in stage 9.0 (TID 857). 5829 bytes result sent to driver
[2025-07-19T22:10:13.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 62.0 in stage 9.0 (TID 865) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 62.0 in stage 9.0 (TID 865)
[2025-07-19T22:10:13.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 54.0 in stage 9.0 (TID 857) in 95 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T22:10:13.074+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.078+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@265e0729
[2025-07-19T22:10:13.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.086+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62] for update
[2025-07-19T22:10:13.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.094+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/.2.delta.7cf2ca25-7353-4f21-bd1d-f71f11fed67d.TID858.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/2.delta
[2025-07-19T22:10:13.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/55/2.delta
[2025-07-19T22:10:13.096+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T22:10:13.100+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.2.delta.5b4ddd04-1cb9-44c2-a25f-0d0807398d96.TID865.tmp
[2025-07-19T22:10:13.103+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T22:10:13.106+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/.2.delta.33f7066e-a34d-4cd7-b213-54d91de7788c.TID860.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/2.delta
[2025-07-19T22:10:13.107+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/57/2.delta
[2025-07-19T22:10:13.108+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T22:10:13.109+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 55.0 in stage 9.0 (TID 858). 5829 bytes result sent to driver
[2025-07-19T22:10:13.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 63.0 in stage 9.0 (TID 866) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.111+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/.2.delta.15474704-f1f3-40d1-880a-493caac4f8c8.TID861.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/2.delta
[2025-07-19T22:10:13.112+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/58/2.delta
[2025-07-19T22:10:13.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T22:10:13.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 55.0 in stage 9.0 (TID 858) in 120 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T22:10:13.115+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 63.0 in stage 9.0 (TID 866)
[2025-07-19T22:10:13.116+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/.2.delta.e7932cf0-23ee-4906-a3d6-ad65f7c4bd1a.TID859.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/2.delta
[2025-07-19T22:10:13.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/56/2.delta
[2025-07-19T22:10:13.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T22:10:13.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 58.0 in stage 9.0 (TID 861). 5829 bytes result sent to driver
[2025-07-19T22:10:13.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T22:10:13.117+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 57.0 in stage 9.0 (TID 860). 5829 bytes result sent to driver
[2025-07-19T22:10:13.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 64.0 in stage 9.0 (TID 867) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.121+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 65.0 in stage 9.0 (TID 868) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.124+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T22:10:13.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 65.0 in stage 9.0 (TID 868)
[2025-07-19T22:10:13.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@698fd913
[2025-07-19T22:10:13.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63] for update
[2025-07-19T22:10:13.126+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 64.0 in stage 9.0 (TID 867)
[2025-07-19T22:10:13.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 58.0 in stage 9.0 (TID 861) in 101 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T22:10:13.129+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/.2.delta.3990e8a4-5595-44f3-bb44-cc97638fa1b8.TID862.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/2.delta
[2025-07-19T22:10:13.130+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/59/2.delta
[2025-07-19T22:10:13.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 57.0 in stage 9.0 (TID 860) in 122 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T22:10:13.134+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T22:10:13.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.138+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T22:10:13.139+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d5c0de3
[2025-07-19T22:10:13.140+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.141+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64] for update
[2025-07-19T22:10:13.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 56.0 in stage 9.0 (TID 859). 5829 bytes result sent to driver
[2025-07-19T22:10:13.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 66.0 in stage 9.0 (TID 869) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c12b5d5
[2025-07-19T22:10:13.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 56.0 in stage 9.0 (TID 859) in 135 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T22:10:13.143+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 66.0 in stage 9.0 (TID 869)
[2025-07-19T22:10:13.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/.2.delta.f425be06-5064-4a2a-9d92-06aa0e83a19a.TID863.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/2.delta
[2025-07-19T22:10:13.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/60/2.delta
[2025-07-19T22:10:13.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T22:10:13.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T22:10:13.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65] for update
[2025-07-19T22:10:13.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 59.0 in stage 9.0 (TID 862). 5829 bytes result sent to driver
[2025-07-19T22:10:13.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T22:10:13.146+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 67.0 in stage 9.0 (TID 870) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 60.0 in stage 9.0 (TID 863). 5829 bytes result sent to driver
[2025-07-19T22:10:13.147+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 59.0 in stage 9.0 (TID 862) in 113 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T22:10:13.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.148+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/.2.delta.0dace187-f2a6-4da5-a2ef-d3255d4f24d6.TID864.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/2.delta
[2025-07-19T22:10:13.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/61/2.delta
[2025-07-19T22:10:13.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 68.0 in stage 9.0 (TID 871) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.2.delta.0a026e1d-eddf-4519-9cff-ae86bddf16f6.TID866.tmp
[2025-07-19T22:10:13.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 67.0 in stage 9.0 (TID 870)
[2025-07-19T22:10:13.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:13.151+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T22:10:13.152+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 60.0 in stage 9.0 (TID 863) in 107 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T22:10:13.152+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.152+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@241411e7
[2025-07-19T22:10:13.152+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.152+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.152+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.153+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 68.0 in stage 9.0 (TID 871)
[2025-07-19T22:10:13.154+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66] for update
[2025-07-19T22:10:13.155+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b597993
[2025-07-19T22:10:13.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67] for update
[2025-07-19T22:10:13.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78f25162
[2025-07-19T22:10:13.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T22:10:13.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68] for update
[2025-07-19T22:10:13.165+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.174+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 61.0 in stage 9.0 (TID 864). 5829 bytes result sent to driver
[2025-07-19T22:10:13.174+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 69.0 in stage 9.0 (TID 872) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.175+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 69.0 in stage 9.0 (TID 872)
[2025-07-19T22:10:13.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/.2.delta.5b4ddd04-1cb9-44c2-a25f-0d0807398d96.TID865.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/2.delta
[2025-07-19T22:10:13.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/62/2.delta
[2025-07-19T22:10:13.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.2.delta.4b93e3a8-3426-4a59-b8fb-fa3b496c79aa.TID868.tmp
[2025-07-19T22:10:13.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 61.0 in stage 9.0 (TID 864) in 120 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T22:10:13.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T22:10:13.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.2.delta.f0b9fa32-6f9f-4aed-953d-e5ab12b6bca4.TID867.tmp
[2025-07-19T22:10:13.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T22:10:13.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ec2b252
[2025-07-19T22:10:13.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 62.0 in stage 9.0 (TID 865). 5829 bytes result sent to driver
[2025-07-19T22:10:13.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.2.delta.72e3debf-f2e5-42ed-bf38-3f3adf2574b7.TID869.tmp
[2025-07-19T22:10:13.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 70.0 in stage 9.0 (TID 873) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69] for update
[2025-07-19T22:10:13.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.2.delta.ffdeb84d-0740-43ef-b15c-565fbf7e9f8c.TID870.tmp
[2025-07-19T22:10:13.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 62.0 in stage 9.0 (TID 865) in 109 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T22:10:13.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.185+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 70.0 in stage 9.0 (TID 873)
[2025-07-19T22:10:13.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c395a4
[2025-07-19T22:10:13.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.188+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70] for update
[2025-07-19T22:10:13.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.2.delta.f0c1fd40-b107-4560-9782-ba6e323d44e6.TID871.tmp
[2025-07-19T22:10:13.190+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.193+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.2.delta.745afa48-8b1b-455c-af90-9d4242fbfc11.TID872.tmp
[2025-07-19T22:10:13.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/.2.delta.0a026e1d-eddf-4519-9cff-ae86bddf16f6.TID866.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/2.delta
[2025-07-19T22:10:13.196+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/63/2.delta
[2025-07-19T22:10:13.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T22:10:13.198+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.2.delta.88968b2e-c151-429a-9aab-9a7a7adc8123.TID873.tmp
[2025-07-19T22:10:13.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T22:10:13.204+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 63.0 in stage 9.0 (TID 866). 5829 bytes result sent to driver
[2025-07-19T22:10:13.206+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/.2.delta.4b93e3a8-3426-4a59-b8fb-fa3b496c79aa.TID868.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/2.delta
[2025-07-19T22:10:13.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/65/2.delta
[2025-07-19T22:10:13.208+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 71.0 in stage 9.0 (TID 874) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.210+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T22:10:13.212+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 63.0 in stage 9.0 (TID 866) in 96 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T22:10:13.213+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 71.0 in stage 9.0 (TID 874)
[2025-07-19T22:10:13.214+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T22:10:13.214+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.215+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.215+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 65.0 in stage 9.0 (TID 868). 5829 bytes result sent to driver
[2025-07-19T22:10:13.216+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@758a1501
[2025-07-19T22:10:13.216+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 65.0 in stage 9.0 (TID 868) in 95 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T22:10:13.216+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 72.0 in stage 9.0 (TID 875) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.217+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 72.0 in stage 9.0 (TID 875)
[2025-07-19T22:10:13.217+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71] for update
[2025-07-19T22:10:13.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/.2.delta.ffdeb84d-0740-43ef-b15c-565fbf7e9f8c.TID870.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/2.delta
[2025-07-19T22:10:13.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/67/2.delta
[2025-07-19T22:10:13.218+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T22:10:13.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.223+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/.2.delta.72e3debf-f2e5-42ed-bf38-3f3adf2574b7.TID869.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/2.delta
[2025-07-19T22:10:13.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/66/2.delta
[2025-07-19T22:10:13.225+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:13.226+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T22:10:13.226+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T22:10:13.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 67.0 in stage 9.0 (TID 870). 5829 bytes result sent to driver
[2025-07-19T22:10:13.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 73.0 in stage 9.0 (TID 876) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.229+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/.2.delta.f0b9fa32-6f9f-4aed-953d-e5ab12b6bca4.TID867.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/2.delta
[2025-07-19T22:10:13.230+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/64/2.delta
[2025-07-19T22:10:13.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 67.0 in stage 9.0 (TID 870) in 84 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T22:10:13.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T22:10:13.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 73.0 in stage 9.0 (TID 876)
[2025-07-19T22:10:13.233+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T22:10:13.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 66.0 in stage 9.0 (TID 869). 5829 bytes result sent to driver
[2025-07-19T22:10:13.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 74.0 in stage 9.0 (TID 877) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 74.0 in stage 9.0 (TID 877)
[2025-07-19T22:10:13.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 66.0 in stage 9.0 (TID 869) in 94 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T22:10:13.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bee2f61
[2025-07-19T22:10:13.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T22:10:13.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72] for update
[2025-07-19T22:10:13.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ccd7ca8
[2025-07-19T22:10:13.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 64.0 in stage 9.0 (TID 867). 5829 bytes result sent to driver
[2025-07-19T22:10:13.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.243+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74] for update
[2025-07-19T22:10:13.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 75.0 in stage 9.0 (TID 878) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/.2.delta.f0c1fd40-b107-4560-9782-ba6e323d44e6.TID871.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/2.delta
[2025-07-19T22:10:13.244+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/68/2.delta
[2025-07-19T22:10:13.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T22:10:13.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16274e1c
[2025-07-19T22:10:13.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 75.0 in stage 9.0 (TID 878)
[2025-07-19T22:10:13.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73] for update
[2025-07-19T22:10:13.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.249+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 64.0 in stage 9.0 (TID 867) in 116 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T22:10:13.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19403fad
[2025-07-19T22:10:13.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75] for update
[2025-07-19T22:10:13.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T22:10:13.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 68.0 in stage 9.0 (TID 871). 5829 bytes result sent to driver
[2025-07-19T22:10:13.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 68.0 in stage 9.0 (TID 871) in 96 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T22:10:13.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 76.0 in stage 9.0 (TID 879) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 76.0 in stage 9.0 (TID 879)
[2025-07-19T22:10:13.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/.2.delta.88968b2e-c151-429a-9aab-9a7a7adc8123.TID873.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/2.delta
[2025-07-19T22:10:13.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/70/2.delta
[2025-07-19T22:10:13.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T22:10:13.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@472bb5ce
[2025-07-19T22:10:13.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76] for update
[2025-07-19T22:10:13.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.2.delta.df022d72-c6e3-41e3-a7ab-d1f9530e9ff5.TID877.tmp
[2025-07-19T22:10:13.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.2.delta.9ef336e5-c9d4-44c6-9bba-963519541958.TID874.tmp
[2025-07-19T22:10:13.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T22:10:13.258+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 70.0 in stage 9.0 (TID 873). 5829 bytes result sent to driver
[2025-07-19T22:10:13.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 77.0 in stage 9.0 (TID 880) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 77.0 in stage 9.0 (TID 880)
[2025-07-19T22:10:13.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 70.0 in stage 9.0 (TID 873) in 72 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T22:10:13.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@483958d7
[2025-07-19T22:10:13.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77] for update
[2025-07-19T22:10:13.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.2.delta.a2c83745-42e3-47a8-a7c0-d04316c901dd.TID879.tmp
[2025-07-19T22:10:13.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/.2.delta.745afa48-8b1b-455c-af90-9d4242fbfc11.TID872.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/2.delta
[2025-07-19T22:10:13.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/69/2.delta
[2025-07-19T22:10:13.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T22:10:13.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.2.delta.19db243e-b2de-4703-a0b7-8d596caa495a.TID878.tmp
[2025-07-19T22:10:13.266+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.2.delta.70a8767e-556f-4bf1-b1bf-c02fc8c4297a.TID876.tmp
[2025-07-19T22:10:13.266+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.2.delta.603e5486-d60b-480f-9dce-bb6737cf6b29.TID880.tmp
[2025-07-19T22:10:13.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T22:10:13.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 69.0 in stage 9.0 (TID 872). 5829 bytes result sent to driver
[2025-07-19T22:10:13.269+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 78.0 in stage 9.0 (TID 881) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.270+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 78.0 in stage 9.0 (TID 881)
[2025-07-19T22:10:13.271+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.2.delta.c9e00d9c-e738-40e1-aad4-f056ec2aa792.TID875.tmp
[2025-07-19T22:10:13.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 69.0 in stage 9.0 (TID 872) in 106 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T22:10:13.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bc6a444
[2025-07-19T22:10:13.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78] for update
[2025-07-19T22:10:13.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.292+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/.2.delta.9ef336e5-c9d4-44c6-9bba-963519541958.TID874.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/2.delta
[2025-07-19T22:10:13.293+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/71/2.delta
[2025-07-19T22:10:13.293+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/.2.delta.df022d72-c6e3-41e3-a7ab-d1f9530e9ff5.TID877.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/2.delta
[2025-07-19T22:10:13.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/74/2.delta
[2025-07-19T22:10:13.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T22:10:13.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T22:10:13.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T22:10:13.296+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T22:10:13.300+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.2.delta.150a9858-4ee3-479e-9bd6-085511d5f4bd.TID881.tmp
[2025-07-19T22:10:13.306+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 74.0 in stage 9.0 (TID 877). 5915 bytes result sent to driver
[2025-07-19T22:10:13.310+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 71.0 in stage 9.0 (TID 874). 5915 bytes result sent to driver
[2025-07-19T22:10:13.313+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 79.0 in stage 9.0 (TID 882) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.317+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 80.0 in stage 9.0 (TID 883) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/.2.delta.a2c83745-42e3-47a8-a7c0-d04316c901dd.TID879.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/2.delta
[2025-07-19T22:10:13.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/76/2.delta
[2025-07-19T22:10:13.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 74.0 in stage 9.0 (TID 877) in 81 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T22:10:13.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 80.0 in stage 9.0 (TID 883)
[2025-07-19T22:10:13.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 71.0 in stage 9.0 (TID 874) in 103 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T22:10:13.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 79.0 in stage 9.0 (TID 882)
[2025-07-19T22:10:13.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T22:10:13.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.324+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b919a4b
[2025-07-19T22:10:13.326+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.326+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79] for update
[2025-07-19T22:10:13.327+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T22:10:13.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 76.0 in stage 9.0 (TID 879). 5872 bytes result sent to driver
[2025-07-19T22:10:13.330+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 81.0 in stage 9.0 (TID 884) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 81.0 in stage 9.0 (TID 884)
[2025-07-19T22:10:13.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.340+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.341+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 76.0 in stage 9.0 (TID 879) in 79 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T22:10:13.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/.2.delta.70a8767e-556f-4bf1-b1bf-c02fc8c4297a.TID876.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/2.delta
[2025-07-19T22:10:13.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/73/2.delta
[2025-07-19T22:10:13.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51e1b687
[2025-07-19T22:10:13.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/.2.delta.603e5486-d60b-480f-9dce-bb6737cf6b29.TID880.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/2.delta
[2025-07-19T22:10:13.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/77/2.delta
[2025-07-19T22:10:13.346+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T22:10:13.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T22:10:13.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80] for update
[2025-07-19T22:10:13.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T22:10:13.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 77.0 in stage 9.0 (TID 880). 5872 bytes result sent to driver
[2025-07-19T22:10:13.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 82.0 in stage 9.0 (TID 885) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.2.delta.db2c34be-2d70-4d44-9a31-9e413288eb0a.TID882.tmp
[2025-07-19T22:10:13.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 77.0 in stage 9.0 (TID 880) in 87 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T22:10:13.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/.2.delta.19db243e-b2de-4703-a0b7-8d596caa495a.TID878.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/2.delta
[2025-07-19T22:10:13.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 82.0 in stage 9.0 (TID 885)
[2025-07-19T22:10:13.351+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/75/2.delta
[2025-07-19T22:10:13.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.353+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T22:10:13.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 73.0 in stage 9.0 (TID 876). 5872 bytes result sent to driver
[2025-07-19T22:10:13.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/.2.delta.c9e00d9c-e738-40e1-aad4-f056ec2aa792.TID875.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/2.delta
[2025-07-19T22:10:13.359+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/72/2.delta
[2025-07-19T22:10:13.360+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 83.0 in stage 9.0 (TID 886) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.360+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T22:10:13.362+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 83.0 in stage 9.0 (TID 886)
[2025-07-19T22:10:13.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 73.0 in stage 9.0 (TID 876) in 119 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T22:10:13.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bb65c6f
[2025-07-19T22:10:13.365+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.2.delta.c62b8c5d-264b-4f73-8df2-96554ef4d08a.TID883.tmp
[2025-07-19T22:10:13.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T22:10:13.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 72.0 in stage 9.0 (TID 875). 5872 bytes result sent to driver
[2025-07-19T22:10:13.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 84.0 in stage 9.0 (TID 887) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 72.0 in stage 9.0 (TID 875) in 135 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T22:10:13.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 84.0 in stage 9.0 (TID 887)
[2025-07-19T22:10:13.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T22:10:13.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81] for update
[2025-07-19T22:10:13.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T22:10:13.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 75.0 in stage 9.0 (TID 878). 5872 bytes result sent to driver
[2025-07-19T22:10:13.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@494ceee4
[2025-07-19T22:10:13.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 85.0 in stage 9.0 (TID 888) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.371+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84] for update
[2025-07-19T22:10:13.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 85.0 in stage 9.0 (TID 888)
[2025-07-19T22:10:13.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22c11ac9
[2025-07-19T22:10:13.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83] for update
[2025-07-19T22:10:13.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.374+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ceb8977
[2025-07-19T22:10:13.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82] for update
[2025-07-19T22:10:13.377+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 75.0 in stage 9.0 (TID 878) in 127 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T22:10:13.378+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.383+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b5c9ec4
[2025-07-19T22:10:13.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.384+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85] for update
[2025-07-19T22:10:13.386+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.386+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.2.delta.a64ba91e-4ae9-493c-831a-6367a4799763.TID884.tmp
[2025-07-19T22:10:13.391+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.2.delta.1e648acd-d7c7-4bd5-af54-989ab222599d.TID887.tmp
[2025-07-19T22:10:13.392+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/.2.delta.150a9858-4ee3-479e-9bd6-085511d5f4bd.TID881.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/2.delta
[2025-07-19T22:10:13.393+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/78/2.delta
[2025-07-19T22:10:13.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T22:10:13.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 8b44f3d35cfa:37751 in memory (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T22:10:13.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T22:10:13.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 78.0 in stage 9.0 (TID 881). 5872 bytes result sent to driver
[2025-07-19T22:10:13.396+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 86.0 in stage 9.0 (TID 889) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.397+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 78.0 in stage 9.0 (TID 881) in 125 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T22:10:13.397+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.2.delta.4f34ed93-d714-434f-80d3-6b57ead17bdd.TID886.tmp
[2025-07-19T22:10:13.397+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 86.0 in stage 9.0 (TID 889)
[2025-07-19T22:10:13.399+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.400+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.402+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.2.delta.2de17f30-a875-4aab-a610-8e0ec6b8cd70.TID888.tmp
[2025-07-19T22:10:13.403+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3942a6be
[2025-07-19T22:10:13.406+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.408+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86] for update
[2025-07-19T22:10:13.409+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.2.delta.db1db77b-e941-4f54-9203-53a29210b755.TID885.tmp
[2025-07-19T22:10:13.410+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.415+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/.2.delta.db2c34be-2d70-4d44-9a31-9e413288eb0a.TID882.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/2.delta
[2025-07-19T22:10:13.416+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/79/2.delta
[2025-07-19T22:10:13.417+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T22:10:13.421+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/.2.delta.c62b8c5d-264b-4f73-8df2-96554ef4d08a.TID883.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/2.delta
[2025-07-19T22:10:13.423+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/80/2.delta
[2025-07-19T22:10:13.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T22:10:13.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T22:10:13.429+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 79.0 in stage 9.0 (TID 882). 5829 bytes result sent to driver
[2025-07-19T22:10:13.432+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 87.0 in stage 9.0 (TID 890) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.433+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T22:10:13.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 87.0 in stage 9.0 (TID 890)
[2025-07-19T22:10:13.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 80.0 in stage 9.0 (TID 883). 5829 bytes result sent to driver
[2025-07-19T22:10:13.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 79.0 in stage 9.0 (TID 882) in 119 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T22:10:13.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 88.0 in stage 9.0 (TID 891) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.434+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 88.0 in stage 9.0 (TID 891)
[2025-07-19T22:10:13.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@264f5eae
[2025-07-19T22:10:13.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87] for update
[2025-07-19T22:10:13.435+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 80.0 in stage 9.0 (TID 883) in 122 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T22:10:13.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.436+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29e447e0
[2025-07-19T22:10:13.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88] for update
[2025-07-19T22:10:13.437+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.440+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 8b44f3d35cfa:37751 in memory (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T22:10:13.443+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.2.delta.9ce7a5fa-afc2-4363-a21e-cb211e160916.TID889.tmp
[2025-07-19T22:10:13.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.2.delta.ad664479-98c1-486b-a68c-9a72e2d3703b.TID890.tmp
[2025-07-19T22:10:13.449+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.2.delta.1723c92c-f3f5-43c5-9ad5-3af7e944ae3b.TID891.tmp
[2025-07-19T22:10:13.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 8b44f3d35cfa:37751 in memory (size: 15.8 KiB, free: 434.3 MiB)
[2025-07-19T22:10:13.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/.2.delta.a64ba91e-4ae9-493c-831a-6367a4799763.TID884.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/2.delta
[2025-07-19T22:10:13.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/81/2.delta
[2025-07-19T22:10:13.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/.2.delta.db1db77b-e941-4f54-9203-53a29210b755.TID885.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/2.delta
[2025-07-19T22:10:13.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/82/2.delta
[2025-07-19T22:10:13.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T22:10:13.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T22:10:13.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/.2.delta.4f34ed93-d714-434f-80d3-6b57ead17bdd.TID886.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/2.delta
[2025-07-19T22:10:13.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/83/2.delta
[2025-07-19T22:10:13.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T22:10:13.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/.2.delta.1e648acd-d7c7-4bd5-af54-989ab222599d.TID887.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/2.delta
[2025-07-19T22:10:13.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/84/2.delta
[2025-07-19T22:10:13.471+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T22:10:13.472+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/.2.delta.2de17f30-a875-4aab-a610-8e0ec6b8cd70.TID888.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/2.delta
[2025-07-19T22:10:13.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/85/2.delta
[2025-07-19T22:10:13.479+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T22:10:13.480+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T22:10:13.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T22:10:13.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 84.0 in stage 9.0 (TID 887). 5829 bytes result sent to driver
[2025-07-19T22:10:13.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T22:10:13.483+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 89.0 in stage 9.0 (TID 892) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 89.0 in stage 9.0 (TID 892)
[2025-07-19T22:10:13.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 81.0 in stage 9.0 (TID 884). 5829 bytes result sent to driver
[2025-07-19T22:10:13.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T22:10:13.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 82.0 in stage 9.0 (TID 885). 5829 bytes result sent to driver
[2025-07-19T22:10:13.488+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 84.0 in stage 9.0 (TID 887) in 129 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T22:10:13.489+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 83.0 in stage 9.0 (TID 886). 5829 bytes result sent to driver
[2025-07-19T22:10:13.489+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 82.0 in stage 9.0 (TID 885) in 143 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T22:10:13.490+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 90.0 in stage 9.0 (TID 893) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 91.0 in stage 9.0 (TID 894) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 91.0 in stage 9.0 (TID 894)
[2025-07-19T22:10:13.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 90.0 in stage 9.0 (TID 893)
[2025-07-19T22:10:13.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 81.0 in stage 9.0 (TID 884) in 163 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T22:10:13.497+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.498+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T22:10:13.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53c61d45
[2025-07-19T22:10:13.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 85.0 in stage 9.0 (TID 888). 5829 bytes result sent to driver
[2025-07-19T22:10:13.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 92.0 in stage 9.0 (TID 895) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89] for update
[2025-07-19T22:10:13.501+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 93.0 in stage 9.0 (TID 896) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 93.0 in stage 9.0 (TID 896)
[2025-07-19T22:10:13.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 83.0 in stage 9.0 (TID 886) in 140 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T22:10:13.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 92.0 in stage 9.0 (TID 895)
[2025-07-19T22:10:13.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 85.0 in stage 9.0 (TID 888) in 127 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T22:10:13.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69056466
[2025-07-19T22:10:13.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90] for update
[2025-07-19T22:10:13.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22f76c61
[2025-07-19T22:10:13.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91] for update
[2025-07-19T22:10:13.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/.2.delta.1723c92c-f3f5-43c5-9ad5-3af7e944ae3b.TID891.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/2.delta
[2025-07-19T22:10:13.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/88/2.delta
[2025-07-19T22:10:13.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66544647
[2025-07-19T22:10:13.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T22:10:13.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.504+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/.2.delta.9ce7a5fa-afc2-4363-a21e-cb211e160916.TID889.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/2.delta
[2025-07-19T22:10:13.505+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/86/2.delta
[2025-07-19T22:10:13.505+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T22:10:13.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93] for update
[2025-07-19T22:10:13.507+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55e8f99a
[2025-07-19T22:10:13.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92] for update
[2025-07-19T22:10:13.509+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.510+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T22:10:13.510+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.511+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 86.0 in stage 9.0 (TID 889). 5829 bytes result sent to driver
[2025-07-19T22:10:13.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T22:10:13.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 88.0 in stage 9.0 (TID 891). 5829 bytes result sent to driver
[2025-07-19T22:10:13.516+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 94.0 in stage 9.0 (TID 897) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 94.0 in stage 9.0 (TID 897)
[2025-07-19T22:10:13.518+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 95.0 in stage 9.0 (TID 898) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 95.0 in stage 9.0 (TID 898)
[2025-07-19T22:10:13.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 86.0 in stage 9.0 (TID 889) in 107 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T22:10:13.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 88.0 in stage 9.0 (TID 891) in 75 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T22:10:13.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.522+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.523+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/.2.delta.ad664479-98c1-486b-a68c-9a72e2d3703b.TID890.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/2.delta
[2025-07-19T22:10:13.523+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/87/2.delta
[2025-07-19T22:10:13.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T22:10:13.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.2.delta.5a9fdd0b-d595-488b-81be-dfa51ec24e7e.TID892.tmp
[2025-07-19T22:10:13.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72f701ac
[2025-07-19T22:10:13.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.2.delta.77cac5cb-3efa-451c-b6e6-baa55ef2448c.TID894.tmp
[2025-07-19T22:10:13.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94] for update
[2025-07-19T22:10:13.524+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.2.delta.f875d6c2-02e5-48c3-892f-34889a5bef3d.TID893.tmp
[2025-07-19T22:10:13.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T22:10:13.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 87.0 in stage 9.0 (TID 890). 5829 bytes result sent to driver
[2025-07-19T22:10:13.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 96.0 in stage 9.0 (TID 899) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.525+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 96.0 in stage 9.0 (TID 899)
[2025-07-19T22:10:13.526+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 87.0 in stage 9.0 (TID 890) in 87 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T22:10:13.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.527+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12406125
[2025-07-19T22:10:13.528+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.2.delta.10d5028e-fd84-4248-9d06-cc72a6ec6ba4.TID895.tmp
[2025-07-19T22:10:13.529+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.530+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95] for update
[2025-07-19T22:10:13.531+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.2.delta.b5d0eace-9d48-40a5-808f-749fa889748e.TID896.tmp
[2025-07-19T22:10:13.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bf2a50b
[2025-07-19T22:10:13.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.532+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96] for update
[2025-07-19T22:10:13.533+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.2.delta.20f76723-5286-47bd-8bea-553680830f84.TID898.tmp
[2025-07-19T22:10:13.533+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.533+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.2.delta.f143290b-9722-4dd3-ae72-d716d302264c.TID897.tmp
[2025-07-19T22:10:13.536+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.2.delta.ef69b9f6-1412-48f3-93b2-cc6c83b8555e.TID899.tmp
[2025-07-19T22:10:13.550+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/.2.delta.77cac5cb-3efa-451c-b6e6-baa55ef2448c.TID894.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/2.delta
[2025-07-19T22:10:13.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/91/2.delta
[2025-07-19T22:10:13.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T22:10:13.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T22:10:13.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 91.0 in stage 9.0 (TID 894). 5829 bytes result sent to driver
[2025-07-19T22:10:13.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 97.0 in stage 9.0 (TID 900) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 97.0 in stage 9.0 (TID 900)
[2025-07-19T22:10:13.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/.2.delta.b5d0eace-9d48-40a5-808f-749fa889748e.TID896.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/2.delta
[2025-07-19T22:10:13.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/93/2.delta
[2025-07-19T22:10:13.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T22:10:13.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/.2.delta.20f76723-5286-47bd-8bea-553680830f84.TID898.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/2.delta
[2025-07-19T22:10:13.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/95/2.delta
[2025-07-19T22:10:13.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T22:10:13.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/.2.delta.5a9fdd0b-d595-488b-81be-dfa51ec24e7e.TID892.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/2.delta
[2025-07-19T22:10:13.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 91.0 in stage 9.0 (TID 894) in 81 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T22:10:13.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/89/2.delta
[2025-07-19T22:10:13.559+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T22:10:13.562+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/.2.delta.10d5028e-fd84-4248-9d06-cc72a6ec6ba4.TID895.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/2.delta
[2025-07-19T22:10:13.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/92/2.delta
[2025-07-19T22:10:13.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T22:10:13.568+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T22:10:13.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T22:10:13.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 93.0 in stage 9.0 (TID 896). 5829 bytes result sent to driver
[2025-07-19T22:10:13.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/.2.delta.f875d6c2-02e5-48c3-892f-34889a5bef3d.TID893.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/2.delta
[2025-07-19T22:10:13.571+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/90/2.delta
[2025-07-19T22:10:13.572+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T22:10:13.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 98.0 in stage 9.0 (TID 901) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 89.0 in stage 9.0 (TID 892). 5829 bytes result sent to driver
[2025-07-19T22:10:13.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 95.0 in stage 9.0 (TID 898). 5829 bytes result sent to driver
[2025-07-19T22:10:13.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 98.0 in stage 9.0 (TID 901)
[2025-07-19T22:10:13.578+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 93.0 in stage 9.0 (TID 896) in 84 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T22:10:13.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 99.0 in stage 9.0 (TID 902) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 100.0 in stage 9.0 (TID 903) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T22:10:13.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 100.0 in stage 9.0 (TID 903)
[2025-07-19T22:10:13.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 95.0 in stage 9.0 (TID 898) in 66 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T22:10:13.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T22:10:13.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 99.0 in stage 9.0 (TID 902)
[2025-07-19T22:10:13.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 89.0 in stage 9.0 (TID 892) in 94 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T22:10:13.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 92.0 in stage 9.0 (TID 895). 5829 bytes result sent to driver
[2025-07-19T22:10:13.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 101.0 in stage 9.0 (TID 904) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.592+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 101.0 in stage 9.0 (TID 904)
[2025-07-19T22:10:13.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.594+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 92.0 in stage 9.0 (TID 895) in 91 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T22:10:13.595+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/.2.delta.f143290b-9722-4dd3-ae72-d716d302264c.TID897.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/2.delta
[2025-07-19T22:10:13.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/94/2.delta
[2025-07-19T22:10:13.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2694bc1f
[2025-07-19T22:10:13.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T22:10:13.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99] for update
[2025-07-19T22:10:13.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.599+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18ce1e91
[2025-07-19T22:10:13.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:13.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T22:10:13.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101] for update
[2025-07-19T22:10:13.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 90.0 in stage 9.0 (TID 893). 5829 bytes result sent to driver
[2025-07-19T22:10:13.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 102.0 in stage 9.0 (TID 905) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 102.0 in stage 9.0 (TID 905)
[2025-07-19T22:10:13.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38417bb7
[2025-07-19T22:10:13.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 90.0 in stage 9.0 (TID 893) in 100 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T22:10:13.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/.2.delta.ef69b9f6-1412-48f3-93b2-cc6c83b8555e.TID899.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/2.delta
[2025-07-19T22:10:13.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/96/2.delta
[2025-07-19T22:10:13.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.606+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T22:10:13.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98] for update
[2025-07-19T22:10:13.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 94.0 in stage 9.0 (TID 897). 5829 bytes result sent to driver
[2025-07-19T22:10:13.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a76dbb0
[2025-07-19T22:10:13.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 103.0 in stage 9.0 (TID 906) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 103.0 in stage 9.0 (TID 906)
[2025-07-19T22:10:13.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T22:10:13.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97] for update
[2025-07-19T22:10:13.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 94.0 in stage 9.0 (TID 897) in 81 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T22:10:13.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ed10d20
[2025-07-19T22:10:13.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100] for update
[2025-07-19T22:10:13.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T22:10:13.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 96.0 in stage 9.0 (TID 899). 5829 bytes result sent to driver
[2025-07-19T22:10:13.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 104.0 in stage 9.0 (TID 907) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.619+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 104.0 in stage 9.0 (TID 907)
[2025-07-19T22:10:13.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 96.0 in stage 9.0 (TID 899) in 74 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T22:10:13.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14c10c4c
[2025-07-19T22:10:13.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103] for update
[2025-07-19T22:10:13.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.2.delta.e56b994c-e1a0-4b6d-b8a4-491969627c24.TID902.tmp
[2025-07-19T22:10:13.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.2.delta.0c7ea6d9-2e93-4502-b299-246566e909d3.TID900.tmp
[2025-07-19T22:10:13.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d2c22ff
[2025-07-19T22:10:13.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102] for update
[2025-07-19T22:10:13.626+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.2.delta.096f61c0-1691-410c-9256-173e7dc7bdb7.TID901.tmp
[2025-07-19T22:10:13.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.2.delta.a2a5fed2-f43e-4597-b854-d191fd8bd1cd.TID904.tmp
[2025-07-19T22:10:13.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.2.delta.4ce382a9-0fc0-4927-a16e-2ac4cd53974e.TID903.tmp
[2025-07-19T22:10:13.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27c01055
[2025-07-19T22:10:13.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104] for update
[2025-07-19T22:10:13.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.2.delta.be335018-d5be-43ab-800a-c119325941b4.TID905.tmp
[2025-07-19T22:10:13.631+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.2.delta.277f311a-93d0-4e7d-88b5-d3d565e57895.TID906.tmp
[2025-07-19T22:10:13.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.2.delta.0adaa476-5b03-4b93-8fa6-8af6c608f8ff.TID907.tmp
[2025-07-19T22:10:13.633+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/.2.delta.a2a5fed2-f43e-4597-b854-d191fd8bd1cd.TID904.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/2.delta
[2025-07-19T22:10:13.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/101/2.delta
[2025-07-19T22:10:13.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T22:10:13.637+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T22:10:13.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/.2.delta.096f61c0-1691-410c-9256-173e7dc7bdb7.TID901.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/2.delta
[2025-07-19T22:10:13.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/98/2.delta
[2025-07-19T22:10:13.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T22:10:13.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/.2.delta.0c7ea6d9-2e93-4502-b299-246566e909d3.TID900.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/2.delta
[2025-07-19T22:10:13.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/97/2.delta
[2025-07-19T22:10:13.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 101.0 in stage 9.0 (TID 904). 5829 bytes result sent to driver
[2025-07-19T22:10:13.647+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/.2.delta.e56b994c-e1a0-4b6d-b8a4-491969627c24.TID902.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/2.delta
[2025-07-19T22:10:13.649+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/99/2.delta
[2025-07-19T22:10:13.650+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T22:10:13.651+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 105.0 in stage 9.0 (TID 908) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T22:10:13.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 101.0 in stage 9.0 (TID 904) in 68 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T22:10:13.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 105.0 in stage 9.0 (TID 908)
[2025-07-19T22:10:13.656+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T22:10:13.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 98.0 in stage 9.0 (TID 901). 5829 bytes result sent to driver
[2025-07-19T22:10:13.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 106.0 in stage 9.0 (TID 909) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 98.0 in stage 9.0 (TID 901) in 77 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T22:10:13.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T22:10:13.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 106.0 in stage 9.0 (TID 909)
[2025-07-19T22:10:13.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T22:10:13.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@368161c4
[2025-07-19T22:10:13.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 97.0 in stage 9.0 (TID 900). 5829 bytes result sent to driver
[2025-07-19T22:10:13.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105] for update
[2025-07-19T22:10:13.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 97.0 in stage 9.0 (TID 900) in 92 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T22:10:13.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 107.0 in stage 9.0 (TID 910) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 99.0 in stage 9.0 (TID 902). 5829 bytes result sent to driver
[2025-07-19T22:10:13.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/.2.delta.be335018-d5be-43ab-800a-c119325941b4.TID905.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/2.delta
[2025-07-19T22:10:13.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/102/2.delta
[2025-07-19T22:10:13.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 107.0 in stage 9.0 (TID 910)
[2025-07-19T22:10:13.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 108.0 in stage 9.0 (TID 911) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/.2.delta.4ce382a9-0fc0-4927-a16e-2ac4cd53974e.TID903.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/2.delta
[2025-07-19T22:10:13.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/100/2.delta
[2025-07-19T22:10:13.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 108.0 in stage 9.0 (TID 911)
[2025-07-19T22:10:13.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T22:10:13.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.665+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@188748ca
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/.2.delta.0adaa476-5b03-4b93-8fa6-8af6c608f8ff.TID907.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/2.delta
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/104/2.delta
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106] for update
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 99.0 in stage 9.0 (TID 902) in 83 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.666+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T22:10:13.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T22:10:13.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e9e6bd
[2025-07-19T22:10:13.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T22:10:13.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 100.0 in stage 9.0 (TID 903). 5829 bytes result sent to driver
[2025-07-19T22:10:13.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:13.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 104.0 in stage 9.0 (TID 907). 5829 bytes result sent to driver
[2025-07-19T22:10:13.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 109.0 in stage 9.0 (TID 912) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 110.0 in stage 9.0 (TID 913) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 104.0 in stage 9.0 (TID 907) in 72 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T22:10:13.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 110.0 in stage 9.0 (TID 913)
[2025-07-19T22:10:13.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 100.0 in stage 9.0 (TID 903) in 91 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T22:10:13.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 109.0 in stage 9.0 (TID 912)
[2025-07-19T22:10:13.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 102.0 in stage 9.0 (TID 905). 5829 bytes result sent to driver
[2025-07-19T22:10:13.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108] for update
[2025-07-19T22:10:13.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b907fda
[2025-07-19T22:10:13.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 111.0 in stage 9.0 (TID 914) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107] for update
[2025-07-19T22:10:13.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 111.0 in stage 9.0 (TID 914)
[2025-07-19T22:10:13.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.2.delta.03b71308-0611-4c2f-81cd-2f072adc15f4.TID908.tmp
[2025-07-19T22:10:13.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 102.0 in stage 9.0 (TID 905) in 85 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T22:10:13.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63248653
[2025-07-19T22:10:13.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109] for update
[2025-07-19T22:10:13.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@442aaa8c
[2025-07-19T22:10:13.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110] for update
[2025-07-19T22:10:13.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f298005
[2025-07-19T22:10:13.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111] for update
[2025-07-19T22:10:13.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/.2.delta.277f311a-93d0-4e7d-88b5-d3d565e57895.TID906.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/2.delta
[2025-07-19T22:10:13.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/103/2.delta
[2025-07-19T22:10:13.685+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T22:10:13.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.2.delta.61f6c5c7-012e-49d6-8f07-222e8c229101.TID910.tmp
[2025-07-19T22:10:13.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.2.delta.2d6fdba1-025e-430c-8c15-92940b0c223a.TID911.tmp
[2025-07-19T22:10:13.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.2.delta.2e218bfd-a394-4a34-8094-2f358468c5a6.TID909.tmp
[2025-07-19T22:10:13.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.2.delta.74125e5b-e9f5-495d-983a-5d9a41354fd1.TID912.tmp
[2025-07-19T22:10:13.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T22:10:13.688+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 103.0 in stage 9.0 (TID 906). 5829 bytes result sent to driver
[2025-07-19T22:10:13.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.2.delta.91f019fe-6eff-4338-af24-8c2d767c0637.TID913.tmp
[2025-07-19T22:10:13.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 112.0 in stage 9.0 (TID 915) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.689+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 112.0 in stage 9.0 (TID 915)
[2025-07-19T22:10:13.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 103.0 in stage 9.0 (TID 906) in 103 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T22:10:13.690+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.691+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71d89733
[2025-07-19T22:10:13.692+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112] for update
[2025-07-19T22:10:13.693+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.694+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.2.delta.968a55d8-f307-4f94-8a7f-6cd65f3e21f6.TID914.tmp
[2025-07-19T22:10:13.699+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.2.delta.5ab90135-500f-4551-8535-4b8fb8edcdc8.TID915.tmp
[2025-07-19T22:10:13.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/.2.delta.03b71308-0611-4c2f-81cd-2f072adc15f4.TID908.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/2.delta
[2025-07-19T22:10:13.709+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/105/2.delta
[2025-07-19T22:10:13.709+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T22:10:13.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T22:10:13.714+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 105.0 in stage 9.0 (TID 908). 5829 bytes result sent to driver
[2025-07-19T22:10:13.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 113.0 in stage 9.0 (TID 916) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 113.0 in stage 9.0 (TID 916)
[2025-07-19T22:10:13.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/.2.delta.2d6fdba1-025e-430c-8c15-92940b0c223a.TID911.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/2.delta
[2025-07-19T22:10:13.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 105.0 in stage 9.0 (TID 908) in 83 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T22:10:13.718+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/108/2.delta
[2025-07-19T22:10:13.719+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T22:10:13.720+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bab8efd
[2025-07-19T22:10:13.729+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.730+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113] for update
[2025-07-19T22:10:13.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T22:10:13.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 108.0 in stage 9.0 (TID 911). 5872 bytes result sent to driver
[2025-07-19T22:10:13.733+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/.2.delta.91f019fe-6eff-4338-af24-8c2d767c0637.TID913.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/2.delta
[2025-07-19T22:10:13.734+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/110/2.delta
[2025-07-19T22:10:13.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.736+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 114.0 in stage 9.0 (TID 917) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T22:10:13.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/.2.delta.2e218bfd-a394-4a34-8094-2f358468c5a6.TID909.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/2.delta
[2025-07-19T22:10:13.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/106/2.delta
[2025-07-19T22:10:13.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/.2.delta.74125e5b-e9f5-495d-983a-5d9a41354fd1.TID912.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/2.delta
[2025-07-19T22:10:13.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/109/2.delta
[2025-07-19T22:10:13.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T22:10:13.744+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T22:10:13.744+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 114.0 in stage 9.0 (TID 917)
[2025-07-19T22:10:13.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 108.0 in stage 9.0 (TID 911) in 86 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T22:10:13.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/.2.delta.61f6c5c7-012e-49d6-8f07-222e8c229101.TID910.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/2.delta
[2025-07-19T22:10:13.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/.2.delta.968a55d8-f307-4f94-8a7f-6cd65f3e21f6.TID914.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/2.delta
[2025-07-19T22:10:13.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/107/2.delta
[2025-07-19T22:10:13.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/111/2.delta
[2025-07-19T22:10:13.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T22:10:13.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T22:10:13.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5863556
[2025-07-19T22:10:13.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114] for update
[2025-07-19T22:10:13.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.2.delta.c9592ec1-537a-4cf0-8dc4-f3278978837f.TID916.tmp
[2025-07-19T22:10:13.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T22:10:13.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T22:10:13.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T22:10:13.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 106.0 in stage 9.0 (TID 909). 5872 bytes result sent to driver
[2025-07-19T22:10:13.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 115.0 in stage 9.0 (TID 918) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T22:10:13.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 115.0 in stage 9.0 (TID 918)
[2025-07-19T22:10:13.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 111.0 in stage 9.0 (TID 914). 5872 bytes result sent to driver
[2025-07-19T22:10:13.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 107.0 in stage 9.0 (TID 910). 5872 bytes result sent to driver
[2025-07-19T22:10:13.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 109.0 in stage 9.0 (TID 912). 5872 bytes result sent to driver
[2025-07-19T22:10:13.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 116.0 in stage 9.0 (TID 919) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 117.0 in stage 9.0 (TID 920) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T22:10:13.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 118.0 in stage 9.0 (TID 921) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 116.0 in stage 9.0 (TID 919)
[2025-07-19T22:10:13.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 117.0 in stage 9.0 (TID 920)
[2025-07-19T22:10:13.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 118.0 in stage 9.0 (TID 921)
[2025-07-19T22:10:13.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 110.0 in stage 9.0 (TID 913). 5872 bytes result sent to driver
[2025-07-19T22:10:13.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 107.0 in stage 9.0 (TID 910) in 100 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T22:10:13.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 119.0 in stage 9.0 (TID 922) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 110.0 in stage 9.0 (TID 913) in 90 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T22:10:13.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 119.0 in stage 9.0 (TID 922)
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 111.0 in stage 9.0 (TID 914) in 89 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 109.0 in stage 9.0 (TID 912) in 92 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8ea4f78
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 106.0 in stage 9.0 (TID 909) in 109 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T22:10:13.762+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115] for update
[2025-07-19T22:10:13.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.2.delta.3410eb23-4154-450c-a030-234f9a118b25.TID917.tmp
[2025-07-19T22:10:13.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/.2.delta.5ab90135-500f-4551-8535-4b8fb8edcdc8.TID915.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/2.delta
[2025-07-19T22:10:13.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/112/2.delta
[2025-07-19T22:10:13.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ee1d7f4
[2025-07-19T22:10:13.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T22:10:13.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116] for update
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1281940f
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117] for update
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 112.0 in stage 9.0 (TID 915). 5872 bytes result sent to driver
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 120.0 in stage 9.0 (TID 923) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 120.0 in stage 9.0 (TID 923)
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5943496a
[2025-07-19T22:10:13.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 112.0 in stage 9.0 (TID 915) in 79 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T22:10:13.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118] for update
[2025-07-19T22:10:13.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24b64e88
[2025-07-19T22:10:13.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.2.delta.b678d92a-d40b-45ad-b7cd-80b10d4b3181.TID920.tmp
[2025-07-19T22:10:13.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120] for update
[2025-07-19T22:10:13.772+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.2.delta.494bd2c2-daf5-4390-a824-b77f796bab8a.TID918.tmp
[2025-07-19T22:10:13.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.2.delta.76bba27c-6762-4c81-9b43-754bb74cdfb1.TID921.tmp
[2025-07-19T22:10:13.777+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a391ad4
[2025-07-19T22:10:13.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.778+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119] for update
[2025-07-19T22:10:13.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.2.delta.6276a611-7fe2-4bab-848b-2753fa2dcefc.TID919.tmp
[2025-07-19T22:10:13.798+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/.2.delta.c9592ec1-537a-4cf0-8dc4-f3278978837f.TID916.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/2.delta
[2025-07-19T22:10:13.800+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/113/2.delta
[2025-07-19T22:10:13.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.2.delta.b41497af-d4d0-4b62-b206-6c629414d079.TID923.tmp
[2025-07-19T22:10:13.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T22:10:13.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T22:10:13.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 113.0 in stage 9.0 (TID 916). 5872 bytes result sent to driver
[2025-07-19T22:10:13.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.2.delta.7c08209b-c26d-444d-ab84-a8e9b4def95a.TID922.tmp
[2025-07-19T22:10:13.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 121.0 in stage 9.0 (TID 924) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/.2.delta.3410eb23-4154-450c-a030-234f9a118b25.TID917.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/2.delta
[2025-07-19T22:10:13.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/114/2.delta
[2025-07-19T22:10:13.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T22:10:13.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 121.0 in stage 9.0 (TID 924)
[2025-07-19T22:10:13.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 113.0 in stage 9.0 (TID 916) in 90 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T22:10:13.812+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.812+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T22:10:13.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@573363b5
[2025-07-19T22:10:13.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 114.0 in stage 9.0 (TID 917). 5872 bytes result sent to driver
[2025-07-19T22:10:13.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 114.0 in stage 9.0 (TID 917) in 84 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T22:10:13.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121] for update
[2025-07-19T22:10:13.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 122.0 in stage 9.0 (TID 925) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 122.0 in stage 9.0 (TID 925)
[2025-07-19T22:10:13.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dbf778b
[2025-07-19T22:10:13.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122] for update
[2025-07-19T22:10:13.828+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.844+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.2.delta.63daf29a-29c3-43f1-a45e-6a624ba28367.TID924.tmp
[2025-07-19T22:10:13.854+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/.2.delta.494bd2c2-daf5-4390-a824-b77f796bab8a.TID918.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/2.delta
[2025-07-19T22:10:13.856+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/115/2.delta
[2025-07-19T22:10:13.857+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T22:10:13.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/.2.delta.b678d92a-d40b-45ad-b7cd-80b10d4b3181.TID920.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/2.delta
[2025-07-19T22:10:13.864+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/117/2.delta
[2025-07-19T22:10:13.866+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T22:10:13.872+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T22:10:13.872+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 115.0 in stage 9.0 (TID 918). 5872 bytes result sent to driver
[2025-07-19T22:10:13.875+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 123.0 in stage 9.0 (TID 926) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.877+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.2.delta.24c94751-0f4a-48fa-9814-6adf51957302.TID925.tmp
[2025-07-19T22:10:13.879+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 123.0 in stage 9.0 (TID 926)
[2025-07-19T22:10:13.881+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 115.0 in stage 9.0 (TID 918) in 117 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T22:10:13.883+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T22:10:13.886+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 117.0 in stage 9.0 (TID 920). 5872 bytes result sent to driver
[2025-07-19T22:10:13.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.887+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:13.888+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 124.0 in stage 9.0 (TID 927) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.889+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 117.0 in stage 9.0 (TID 920) in 136 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T22:10:13.890+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10055518
[2025-07-19T22:10:13.891+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 124.0 in stage 9.0 (TID 927)
[2025-07-19T22:10:13.896+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.897+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123] for update
[2025-07-19T22:10:13.898+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/.2.delta.6276a611-7fe2-4bab-848b-2753fa2dcefc.TID919.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/2.delta
[2025-07-19T22:10:13.900+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/116/2.delta
[2025-07-19T22:10:13.901+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/.2.delta.b41497af-d4d0-4b62-b206-6c629414d079.TID923.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/2.delta
[2025-07-19T22:10:13.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/120/2.delta
[2025-07-19T22:10:13.902+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/.2.delta.76bba27c-6762-4c81-9b43-754bb74cdfb1.TID921.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/2.delta
[2025-07-19T22:10:13.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/118/2.delta
[2025-07-19T22:10:13.903+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T22:10:13.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T22:10:13.904+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T22:10:13.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.905+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:13.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T22:10:13.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 118.0 in stage 9.0 (TID 921). 5872 bytes result sent to driver
[2025-07-19T22:10:13.906+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ce5e13
[2025-07-19T22:10:13.907+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 125.0 in stage 9.0 (TID 928) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.908+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T22:10:13.909+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T22:10:13.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 120.0 in stage 9.0 (TID 923). 5872 bytes result sent to driver
[2025-07-19T22:10:13.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.911+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124] for update
[2025-07-19T22:10:13.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 116.0 in stage 9.0 (TID 919). 5872 bytes result sent to driver
[2025-07-19T22:10:13.912+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 118.0 in stage 9.0 (TID 921) in 168 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T22:10:13.913+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 126.0 in stage 9.0 (TID 929) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 127.0 in stage 9.0 (TID 930) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 125.0 in stage 9.0 (TID 928)
[2025-07-19T22:10:13.914+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 126.0 in stage 9.0 (TID 929)
[2025-07-19T22:10:13.917+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 127.0 in stage 9.0 (TID 930)
[2025-07-19T22:10:13.918+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.919+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 116.0 in stage 9.0 (TID 919) in 176 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T22:10:13.923+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 120.0 in stage 9.0 (TID 923) in 163 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T22:10:13.924+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.925+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.927+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:13.928+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.930+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:13.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/.2.delta.7c08209b-c26d-444d-ab84-a8e9b4def95a.TID922.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/2.delta
[2025-07-19T22:10:13.932+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/119/2.delta
[2025-07-19T22:10:13.934+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T22:10:13.935+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a7c483e
[2025-07-19T22:10:13.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.936+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@788fc3c1
[2025-07-19T22:10:13.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127] for update
[2025-07-19T22:10:13.937+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.2.delta.1148192e-1ca5-4ee5-a6ae-8aa1185ebd32.TID926.tmp
[2025-07-19T22:10:13.939+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.2.delta.39cc423b-8b8a-46fa-8f3c-6c1c6ce5f0e6.TID927.tmp
[2025-07-19T22:10:13.941+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.942+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126] for update
[2025-07-19T22:10:13.943+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T22:10:13.944+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 119.0 in stage 9.0 (TID 922). 5872 bytes result sent to driver
[2025-07-19T22:10:13.945+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 128.0 in stage 9.0 (TID 931) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.946+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 119.0 in stage 9.0 (TID 922) in 189 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T22:10:13.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58e11930
[2025-07-19T22:10:13.947+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 128.0 in stage 9.0 (TID 931)
[2025-07-19T22:10:13.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/.2.delta.63daf29a-29c3-43f1-a45e-6a624ba28367.TID924.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/2.delta
[2025-07-19T22:10:13.948+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/121/2.delta
[2025-07-19T22:10:13.950+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T22:10:13.950+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125] for update
[2025-07-19T22:10:13.952+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2db402b
[2025-07-19T22:10:13.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.954+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.955+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128] for update
[2025-07-19T22:10:13.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.957+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T22:10:13.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 121.0 in stage 9.0 (TID 924). 5829 bytes result sent to driver
[2025-07-19T22:10:13.958+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 129.0 in stage 9.0 (TID 932) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.959+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 121.0 in stage 9.0 (TID 924) in 150 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T22:10:13.962+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.2.delta.4a4eda12-fd2c-4b10-b9d5-97ebaad4ee57.TID930.tmp
[2025-07-19T22:10:13.963+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 129.0 in stage 9.0 (TID 932)
[2025-07-19T22:10:13.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/.2.delta.24c94751-0f4a-48fa-9814-6adf51957302.TID925.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/2.delta
[2025-07-19T22:10:13.965+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/122/2.delta
[2025-07-19T22:10:13.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T22:10:13.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:13.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e7896ae
[2025-07-19T22:10:13.969+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.970+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129] for update
[2025-07-19T22:10:13.970+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.971+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.2.delta.c9cd0aba-79c1-466e-9f19-5a3b61849da7.TID931.tmp
[2025-07-19T22:10:13.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.2.delta.2b46fda3-7f3b-4d83-a542-da42ee209f60.TID929.tmp
[2025-07-19T22:10:13.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.2.delta.e5d6c51f-3991-475a-95de-0fefd7342a7e.TID928.tmp
[2025-07-19T22:10:13.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO DataWritingSparkTask: Committed partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T22:10:13.980+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Finished task 122.0 in stage 9.0 (TID 925). 5829 bytes result sent to driver
[2025-07-19T22:10:13.981+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Starting task 130.0 in stage 9.0 (TID 933) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:13.982+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO TaskSetManager: Finished task 122.0 in stage 9.0 (TID 925) in 161 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T22:10:13.983+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO Executor: Running task 130.0 in stage 9.0 (TID 933)
[2025-07-19T22:10:13.984+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:13.986+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T22:10:13.986+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f4966cd
[2025-07-19T22:10:13.988+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:13.991+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130] for update
[2025-07-19T22:10:13.992+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:13.992+0000] {subprocess.py:93} INFO - 25/07/19 22:10:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.2.delta.33f19b83-66e0-493e-9a9f-17e078fb5740.TID932.tmp
[2025-07-19T22:10:14.007+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.2.delta.c5797eef-c7d9-4cf3-8c72-938f7ec4226d.TID933.tmp
[2025-07-19T22:10:14.009+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/.2.delta.39cc423b-8b8a-46fa-8f3c-6c1c6ce5f0e6.TID927.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/2.delta
[2025-07-19T22:10:14.009+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/124/2.delta
[2025-07-19T22:10:14.010+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T22:10:14.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/.2.delta.1148192e-1ca5-4ee5-a6ae-8aa1185ebd32.TID926.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/2.delta
[2025-07-19T22:10:14.012+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/123/2.delta
[2025-07-19T22:10:14.015+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T22:10:14.017+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T22:10:14.018+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 124.0 in stage 9.0 (TID 927). 5829 bytes result sent to driver
[2025-07-19T22:10:14.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 131.0 in stage 9.0 (TID 934) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.024+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 124.0 in stage 9.0 (TID 927) in 144 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T22:10:14.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 131.0 in stage 9.0 (TID 934)
[2025-07-19T22:10:14.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T22:10:14.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.026+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 123.0 in stage 9.0 (TID 926). 5829 bytes result sent to driver
[2025-07-19T22:10:14.027+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@122383bf
[2025-07-19T22:10:14.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/.2.delta.4a4eda12-fd2c-4b10-b9d5-97ebaad4ee57.TID930.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/2.delta
[2025-07-19T22:10:14.028+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/127/2.delta
[2025-07-19T22:10:14.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.029+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131] for update
[2025-07-19T22:10:14.030+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T22:10:14.031+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 132.0 in stage 9.0 (TID 935) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.032+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 132.0 in stage 9.0 (TID 935)
[2025-07-19T22:10:14.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 123.0 in stage 9.0 (TID 926) in 172 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T22:10:14.034+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/.2.delta.e5d6c51f-3991-475a-95de-0fefd7342a7e.TID928.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/2.delta
[2025-07-19T22:10:14.035+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/125/2.delta
[2025-07-19T22:10:14.037+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/.2.delta.2b46fda3-7f3b-4d83-a542-da42ee209f60.TID929.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/2.delta
[2025-07-19T22:10:14.038+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/126/2.delta
[2025-07-19T22:10:14.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T22:10:14.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T22:10:14.039+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T22:10:14.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T22:10:14.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/.2.delta.c9cd0aba-79c1-466e-9f19-5a3b61849da7.TID931.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/2.delta
[2025-07-19T22:10:14.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/128/2.delta
[2025-07-19T22:10:14.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T22:10:14.040+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 125.0 in stage 9.0 (TID 928). 5829 bytes result sent to driver
[2025-07-19T22:10:14.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 126.0 in stage 9.0 (TID 929). 5829 bytes result sent to driver
[2025-07-19T22:10:14.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 127.0 in stage 9.0 (TID 930). 5829 bytes result sent to driver
[2025-07-19T22:10:14.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T22:10:14.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 133.0 in stage 9.0 (TID 936) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 127.0 in stage 9.0 (TID 930) in 123 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T22:10:14.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 133.0 in stage 9.0 (TID 936)
[2025-07-19T22:10:14.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:14.042+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 134.0 in stage 9.0 (TID 937) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.043+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 126.0 in stage 9.0 (TID 929) in 126 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T22:10:14.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 135.0 in stage 9.0 (TID 938) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@279a192d
[2025-07-19T22:10:14.044+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 125.0 in stage 9.0 (TID 928) in 134 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T22:10:14.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 134.0 in stage 9.0 (TID 937)
[2025-07-19T22:10:14.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.045+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132] for update
[2025-07-19T22:10:14.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 135.0 in stage 9.0 (TID 938)
[2025-07-19T22:10:14.046+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.049+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.051+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.052+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:14.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T22:10:14.053+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/.2.delta.33f19b83-66e0-493e-9a9f-17e078fb5740.TID932.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/2.delta
[2025-07-19T22:10:14.054+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/129/2.delta
[2025-07-19T22:10:14.055+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.056+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c54cac1
[2025-07-19T22:10:14.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T22:10:14.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 128.0 in stage 9.0 (TID 931). 5829 bytes result sent to driver
[2025-07-19T22:10:14.058+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 136.0 in stage 9.0 (TID 939) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.059+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133] for update
[2025-07-19T22:10:14.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.2.delta.873ec4f7-8437-4e43-914a-5e11b783a225.TID934.tmp
[2025-07-19T22:10:14.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67d2050e
[2025-07-19T22:10:14.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 128.0 in stage 9.0 (TID 931) in 118 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T22:10:14.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.060+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135] for update
[2025-07-19T22:10:14.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.061+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 136.0 in stage 9.0 (TID 939)
[2025-07-19T22:10:14.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fc74aa9
[2025-07-19T22:10:14.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.062+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134] for update
[2025-07-19T22:10:14.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.063+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T22:10:14.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 129.0 in stage 9.0 (TID 932). 5829 bytes result sent to driver
[2025-07-19T22:10:14.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e0a896c
[2025-07-19T22:10:14.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 137.0 in stage 9.0 (TID 940) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.066+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136] for update
[2025-07-19T22:10:14.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 137.0 in stage 9.0 (TID 940)
[2025-07-19T22:10:14.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.067+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 129.0 in stage 9.0 (TID 932) in 106 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T22:10:14.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.070+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.071+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.2.delta.18d59307-ec43-4cc8-8ec6-5f9abd66fd38.TID935.tmp
[2025-07-19T22:10:14.071+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/.2.delta.c5797eef-c7d9-4cf3-8c72-938f7ec4226d.TID933.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/2.delta
[2025-07-19T22:10:14.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/130/2.delta
[2025-07-19T22:10:14.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T22:10:14.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.2.delta.39f40fc2-9f12-4aac-8b5e-b811d136733c.TID936.tmp
[2025-07-19T22:10:14.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4dd16058
[2025-07-19T22:10:14.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137] for update
[2025-07-19T22:10:14.075+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.2.delta.68721a05-4f4f-4bd1-8b98-ac2621542dab.TID939.tmp
[2025-07-19T22:10:14.076+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.077+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T22:10:14.077+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.2.delta.7aa87998-289e-467b-9b14-3feadc326187.TID938.tmp
[2025-07-19T22:10:14.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.2.delta.5b61a37d-6ca2-4a24-87a6-c0f35c763a9a.TID937.tmp
[2025-07-19T22:10:14.080+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 130.0 in stage 9.0 (TID 933). 5829 bytes result sent to driver
[2025-07-19T22:10:14.081+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 138.0 in stage 9.0 (TID 941) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.082+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 138.0 in stage 9.0 (TID 941)
[2025-07-19T22:10:14.083+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 130.0 in stage 9.0 (TID 933) in 105 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T22:10:14.084+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.085+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21122de8
[2025-07-19T22:10:14.087+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.088+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138] for update
[2025-07-19T22:10:14.089+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.095+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.2.delta.9b479b1f-7982-4b48-920d-cd27e8281cfb.TID940.tmp
[2025-07-19T22:10:14.101+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.2.delta.c93014a4-924c-4f21-9368-5d7d8e68f4cc.TID941.tmp
[2025-07-19T22:10:14.109+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/.2.delta.873ec4f7-8437-4e43-914a-5e11b783a225.TID934.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/2.delta
[2025-07-19T22:10:14.109+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/131/2.delta
[2025-07-19T22:10:14.109+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T22:10:14.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/.2.delta.18d59307-ec43-4cc8-8ec6-5f9abd66fd38.TID935.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/2.delta
[2025-07-19T22:10:14.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/132/2.delta
[2025-07-19T22:10:14.113+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T22:10:14.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/.2.delta.39f40fc2-9f12-4aac-8b5e-b811d136733c.TID936.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/2.delta
[2025-07-19T22:10:14.114+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/133/2.delta
[2025-07-19T22:10:14.116+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T22:10:14.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T22:10:14.118+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T22:10:14.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 132.0 in stage 9.0 (TID 935). 5829 bytes result sent to driver
[2025-07-19T22:10:14.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 131.0 in stage 9.0 (TID 934). 5829 bytes result sent to driver
[2025-07-19T22:10:14.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 139.0 in stage 9.0 (TID 942) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 140.0 in stage 9.0 (TID 943) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 139.0 in stage 9.0 (TID 942)
[2025-07-19T22:10:14.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 132.0 in stage 9.0 (TID 935) in 91 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T22:10:14.121+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 131.0 in stage 9.0 (TID 934) in 97 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T22:10:14.122+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 140.0 in stage 9.0 (TID 943)
[2025-07-19T22:10:14.123+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/.2.delta.7aa87998-289e-467b-9b14-3feadc326187.TID938.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/2.delta
[2025-07-19T22:10:14.124+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/135/2.delta
[2025-07-19T22:10:14.124+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/.2.delta.68721a05-4f4f-4bd1-8b98-ac2621542dab.TID939.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/2.delta
[2025-07-19T22:10:14.125+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/136/2.delta
[2025-07-19T22:10:14.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.127+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T22:10:14.129+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.129+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.130+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.132+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T22:10:14.133+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@536f4a0d
[2025-07-19T22:10:14.135+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.136+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140] for update
[2025-07-19T22:10:14.137+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T22:10:14.144+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T22:10:14.145+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T22:10:14.149+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 135.0 in stage 9.0 (TID 938). 5829 bytes result sent to driver
[2025-07-19T22:10:14.152+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 133.0 in stage 9.0 (TID 936). 5829 bytes result sent to driver
[2025-07-19T22:10:14.153+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 136.0 in stage 9.0 (TID 939). 5829 bytes result sent to driver
[2025-07-19T22:10:14.154+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.154+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bc6fbb3
[2025-07-19T22:10:14.156+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 141.0 in stage 9.0 (TID 944) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.157+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 142.0 in stage 9.0 (TID 945) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/.2.delta.5b61a37d-6ca2-4a24-87a6-c0f35c763a9a.TID937.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/2.delta
[2025-07-19T22:10:14.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/134/2.delta
[2025-07-19T22:10:14.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 143.0 in stage 9.0 (TID 946) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.159+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T22:10:14.160+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 141.0 in stage 9.0 (TID 944)
[2025-07-19T22:10:14.160+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 135.0 in stage 9.0 (TID 938) in 87 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T22:10:14.161+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 133.0 in stage 9.0 (TID 936) in 91 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T22:10:14.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 136.0 in stage 9.0 (TID 939) in 78 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T22:10:14.162+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 143.0 in stage 9.0 (TID 946)
[2025-07-19T22:10:14.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 142.0 in stage 9.0 (TID 945)
[2025-07-19T22:10:14.163+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139] for update
[2025-07-19T22:10:14.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T22:10:14.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 134.0 in stage 9.0 (TID 937). 5829 bytes result sent to driver
[2025-07-19T22:10:14.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.164+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:14.165+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18d8f13a
[2025-07-19T22:10:14.165+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.166+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143] for update
[2025-07-19T22:10:14.166+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 144.0 in stage 9.0 (TID 947) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.168+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 144.0 in stage 9.0 (TID 947)
[2025-07-19T22:10:14.169+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 134.0 in stage 9.0 (TID 937) in 102 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T22:10:14.169+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55c6ac78
[2025-07-19T22:10:14.169+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.169+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.172+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:14.174+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/.2.delta.c93014a4-924c-4f21-9368-5d7d8e68f4cc.TID941.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/2.delta
[2025-07-19T22:10:14.174+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/138/2.delta
[2025-07-19T22:10:14.176+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.177+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T22:10:14.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141] for update
[2025-07-19T22:10:14.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.2.delta.0adb840b-e96e-4d92-aa7a-d1e666d45519.TID943.tmp
[2025-07-19T22:10:14.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/.2.delta.9b479b1f-7982-4b48-920d-cd27e8281cfb.TID940.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/2.delta
[2025-07-19T22:10:14.178+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/137/2.delta
[2025-07-19T22:10:14.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T22:10:14.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.179+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72a6c977
[2025-07-19T22:10:14.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.182+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144] for update
[2025-07-19T22:10:14.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T22:10:14.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bada611
[2025-07-19T22:10:14.184+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 138.0 in stage 9.0 (TID 941). 5829 bytes result sent to driver
[2025-07-19T22:10:14.185+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.185+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142] for update
[2025-07-19T22:10:14.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.2.delta.8ac8cfb8-217f-4b3d-864d-43b2b77cc8e3.TID942.tmp
[2025-07-19T22:10:14.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 145.0 in stage 9.0 (TID 948) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T22:10:14.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 138.0 in stage 9.0 (TID 941) in 75 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T22:10:14.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 145.0 in stage 9.0 (TID 948)
[2025-07-19T22:10:14.186+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 137.0 in stage 9.0 (TID 940). 5829 bytes result sent to driver
[2025-07-19T22:10:14.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 146.0 in stage 9.0 (TID 949) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.187+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 146.0 in stage 9.0 (TID 949)
[2025-07-19T22:10:14.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 137.0 in stage 9.0 (TID 940) in 100 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T22:10:14.189+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.2.delta.0fc38061-a25a-4e72-b9f3-c0b5670a17ef.TID946.tmp
[2025-07-19T22:10:14.191+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.2.delta.ad7fbf4a-b395-423a-ac0b-51b696ce1f78.TID944.tmp
[2025-07-19T22:10:14.194+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.194+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e22dbfe
[2025-07-19T22:10:14.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146] for update
[2025-07-19T22:10:14.195+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.197+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:14.199+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.201+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e02cb9
[2025-07-19T22:10:14.202+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.202+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145] for update
[2025-07-19T22:10:14.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.203+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.2.delta.4b7f0645-42a7-4a1d-9de2-a04db6456ebb.TID947.tmp
[2025-07-19T22:10:14.204+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.2.delta.f9fb2149-57cb-4559-aa7d-0d1d5c943671.TID945.tmp
[2025-07-19T22:10:14.204+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.2.delta.19fd04be-9740-4cb6-8ac9-b9e6d24920c6.TID949.tmp
[2025-07-19T22:10:14.205+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.2.delta.3fa642cd-fd94-4cce-a5bc-c077a6ddd0ac.TID948.tmp
[2025-07-19T22:10:14.215+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/.2.delta.8ac8cfb8-217f-4b3d-864d-43b2b77cc8e3.TID942.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/2.delta
[2025-07-19T22:10:14.217+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/139/2.delta
[2025-07-19T22:10:14.220+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T22:10:14.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/.2.delta.0adb840b-e96e-4d92-aa7a-d1e666d45519.TID943.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/2.delta
[2025-07-19T22:10:14.221+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/140/2.delta
[2025-07-19T22:10:14.222+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T22:10:14.224+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T22:10:14.227+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 139.0 in stage 9.0 (TID 942). 5829 bytes result sent to driver
[2025-07-19T22:10:14.228+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T22:10:14.231+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 140.0 in stage 9.0 (TID 943). 5829 bytes result sent to driver
[2025-07-19T22:10:14.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/.2.delta.0fc38061-a25a-4e72-b9f3-c0b5670a17ef.TID946.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/2.delta
[2025-07-19T22:10:14.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/143/2.delta
[2025-07-19T22:10:14.234+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T22:10:14.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 147.0 in stage 9.0 (TID 950) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 148.0 in stage 9.0 (TID 951) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.235+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 147.0 in stage 9.0 (TID 950)
[2025-07-19T22:10:14.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 139.0 in stage 9.0 (TID 942) in 113 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T22:10:14.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 140.0 in stage 9.0 (TID 943) in 113 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T22:10:14.236+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/.2.delta.4b7f0645-42a7-4a1d-9de2-a04db6456ebb.TID947.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/2.delta
[2025-07-19T22:10:14.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/144/2.delta
[2025-07-19T22:10:14.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 148.0 in stage 9.0 (TID 951)
[2025-07-19T22:10:14.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T22:10:14.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.237+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T22:10:14.238+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/.2.delta.ad7fbf4a-b395-423a-ac0b-51b696ce1f78.TID944.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/2.delta
[2025-07-19T22:10:14.239+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/141/2.delta
[2025-07-19T22:10:14.240+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 143.0 in stage 9.0 (TID 946). 5829 bytes result sent to driver
[2025-07-19T22:10:14.241+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26fcdd95
[2025-07-19T22:10:14.242+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T22:10:14.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.245+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148] for update
[2025-07-19T22:10:14.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 149.0 in stage 9.0 (TID 952) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/.2.delta.19fd04be-9740-4cb6-8ac9-b9e6d24920c6.TID949.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/2.delta
[2025-07-19T22:10:14.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/146/2.delta
[2025-07-19T22:10:14.246+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T22:10:14.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T22:10:14.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 144.0 in stage 9.0 (TID 947). 5829 bytes result sent to driver
[2025-07-19T22:10:14.247+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T22:10:14.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 149.0 in stage 9.0 (TID 952)
[2025-07-19T22:10:14.248+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 141.0 in stage 9.0 (TID 944). 5829 bytes result sent to driver
[2025-07-19T22:10:14.250+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/.2.delta.f9fb2149-57cb-4559-aa7d-0d1d5c943671.TID945.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/2.delta
[2025-07-19T22:10:14.251+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/142/2.delta
[2025-07-19T22:10:14.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:14.252+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 150.0 in stage 9.0 (TID 953) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T22:10:14.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T22:10:14.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 146.0 in stage 9.0 (TID 949). 5829 bytes result sent to driver
[2025-07-19T22:10:14.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.253+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 151.0 in stage 9.0 (TID 954) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 152.0 in stage 9.0 (TID 955) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 141.0 in stage 9.0 (TID 944) in 118 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T22:10:14.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 150.0 in stage 9.0 (TID 953)
[2025-07-19T22:10:14.254+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 152.0 in stage 9.0 (TID 955)
[2025-07-19T22:10:14.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 146.0 in stage 9.0 (TID 949) in 89 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T22:10:14.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 143.0 in stage 9.0 (TID 946) in 118 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T22:10:14.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 151.0 in stage 9.0 (TID 954)
[2025-07-19T22:10:14.255+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 144.0 in stage 9.0 (TID 947) in 106 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T22:10:14.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@640e11a3
[2025-07-19T22:10:14.256+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/.2.delta.3fa642cd-fd94-4cce-a5bc-c077a6ddd0ac.TID948.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/2.delta
[2025-07-19T22:10:14.257+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/145/2.delta
[2025-07-19T22:10:14.258+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147] for update
[2025-07-19T22:10:14.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.259+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T22:10:14.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@395cc075
[2025-07-19T22:10:14.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150] for update
[2025-07-19T22:10:14.260+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T22:10:14.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 142.0 in stage 9.0 (TID 945). 5829 bytes result sent to driver
[2025-07-19T22:10:14.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T22:10:14.261+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 145.0 in stage 9.0 (TID 948). 5829 bytes result sent to driver
[2025-07-19T22:10:14.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b66d4ac
[2025-07-19T22:10:14.262+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 153.0 in stage 9.0 (TID 956) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.263+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 154.0 in stage 9.0 (TID 957) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149] for update
[2025-07-19T22:10:14.264+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.265+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5da9084e
[2025-07-19T22:10:14.266+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.267+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 145.0 in stage 9.0 (TID 948) in 104 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T22:10:14.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 153.0 in stage 9.0 (TID 956)
[2025-07-19T22:10:14.268+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.272+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152] for update
[2025-07-19T22:10:14.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 142.0 in stage 9.0 (TID 945) in 131 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T22:10:14.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 154.0 in stage 9.0 (TID 957)
[2025-07-19T22:10:14.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.2.delta.ae3fbaa3-3ed0-479e-9c97-e6a225e3880f.TID952.tmp
[2025-07-19T22:10:14.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54ec1391
[2025-07-19T22:10:14.273+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151] for update
[2025-07-19T22:10:14.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cfb8d6a
[2025-07-19T22:10:14.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154] for update
[2025-07-19T22:10:14.274+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.2.delta.c1d6594e-21d2-4da2-9aa6-4bd89bca70c6.TID955.tmp
[2025-07-19T22:10:14.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13129af1
[2025-07-19T22:10:14.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.275+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153] for update
[2025-07-19T22:10:14.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.2.delta.c93651d1-453f-4094-9ad8-53d98b90f969.TID951.tmp
[2025-07-19T22:10:14.276+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.2.delta.323bfffa-4538-4540-99ad-2bf1a2f467d7.TID953.tmp
[2025-07-19T22:10:14.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.2.delta.b1edf73f-dc17-4cf6-a146-427d022e7aa0.TID950.tmp
[2025-07-19T22:10:14.277+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.2.delta.169d5a34-56dd-4afc-ab49-b53472f3334d.TID957.tmp
[2025-07-19T22:10:14.279+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.284+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.2.delta.07a60695-f4f0-45e7-9026-92cfce20ef20.TID954.tmp
[2025-07-19T22:10:14.294+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.2.delta.94bfd54c-21ec-4169-ac03-c7c55c267097.TID956.tmp
[2025-07-19T22:10:14.305+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/.2.delta.ae3fbaa3-3ed0-479e-9c97-e6a225e3880f.TID952.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/2.delta
[2025-07-19T22:10:14.306+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/149/2.delta
[2025-07-19T22:10:14.307+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T22:10:14.311+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/.2.delta.c1d6594e-21d2-4da2-9aa6-4bd89bca70c6.TID955.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/2.delta
[2025-07-19T22:10:14.312+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/152/2.delta
[2025-07-19T22:10:14.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T22:10:14.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T22:10:14.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 149.0 in stage 9.0 (TID 952). 5829 bytes result sent to driver
[2025-07-19T22:10:14.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 155.0 in stage 9.0 (TID 958) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.314+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 155.0 in stage 9.0 (TID 958)
[2025-07-19T22:10:14.319+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 149.0 in stage 9.0 (TID 952) in 78 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T22:10:14.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/.2.delta.323bfffa-4538-4540-99ad-2bf1a2f467d7.TID953.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/2.delta
[2025-07-19T22:10:14.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/150/2.delta
[2025-07-19T22:10:14.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/.2.delta.c93651d1-453f-4094-9ad8-53d98b90f969.TID951.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/2.delta
[2025-07-19T22:10:14.320+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/148/2.delta
[2025-07-19T22:10:14.321+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/.2.delta.169d5a34-56dd-4afc-ab49-b53472f3334d.TID957.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/2.delta
[2025-07-19T22:10:14.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/154/2.delta
[2025-07-19T22:10:14.322+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:14.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T22:10:14.323+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T22:10:14.326+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 152.0 in stage 9.0 (TID 955). 5915 bytes result sent to driver
[2025-07-19T22:10:14.328+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T22:10:14.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T22:10:14.329+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 156.0 in stage 9.0 (TID 959) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.331+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/.2.delta.07a60695-f4f0-45e7-9026-92cfce20ef20.TID954.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/2.delta
[2025-07-19T22:10:14.332+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/151/2.delta
[2025-07-19T22:10:14.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 152.0 in stage 9.0 (TID 955) in 82 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T22:10:14.333+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 156.0 in stage 9.0 (TID 959)
[2025-07-19T22:10:14.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/.2.delta.b1edf73f-dc17-4cf6-a146-427d022e7aa0.TID950.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/2.delta
[2025-07-19T22:10:14.334+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/147/2.delta
[2025-07-19T22:10:14.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48aa9433
[2025-07-19T22:10:14.336+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T22:10:14.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T22:10:14.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155] for update
[2025-07-19T22:10:14.337+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T22:10:14.338+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T22:10:14.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T22:10:14.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T22:10:14.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 154.0 in stage 9.0 (TID 957). 5872 bytes result sent to driver
[2025-07-19T22:10:14.339+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 148.0 in stage 9.0 (TID 951). 5872 bytes result sent to driver
[2025-07-19T22:10:14.340+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 147.0 in stage 9.0 (TID 950). 5872 bytes result sent to driver
[2025-07-19T22:10:14.340+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 151.0 in stage 9.0 (TID 954). 5872 bytes result sent to driver
[2025-07-19T22:10:14.340+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 157.0 in stage 9.0 (TID 960) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.341+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 158.0 in stage 9.0 (TID 961) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.341+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 157.0 in stage 9.0 (TID 960)
[2025-07-19T22:10:14.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 148.0 in stage 9.0 (TID 951) in 105 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T22:10:14.342+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 158.0 in stage 9.0 (TID 961)
[2025-07-19T22:10:14.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 154.0 in stage 9.0 (TID 957) in 79 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T22:10:14.343+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 159.0 in stage 9.0 (TID 962) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.344+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 160.0 in stage 9.0 (TID 963) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.345+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 147.0 in stage 9.0 (TID 950) in 106 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T22:10:14.347+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 151.0 in stage 9.0 (TID 954) in 91 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T22:10:14.348+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 159.0 in stage 9.0 (TID 962)
[2025-07-19T22:10:14.349+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.350+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.351+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T22:10:14.352+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.355+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.356+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T22:10:14.357+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 160.0 in stage 9.0 (TID 963)
[2025-07-19T22:10:14.358+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.359+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.360+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9d466a4
[2025-07-19T22:10:14.360+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 150.0 in stage 9.0 (TID 953). 5872 bytes result sent to driver
[2025-07-19T22:10:14.361+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.364+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157] for update
[2025-07-19T22:10:14.366+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 161.0 in stage 9.0 (TID 964) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.367+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 161.0 in stage 9.0 (TID 964)
[2025-07-19T22:10:14.368+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 150.0 in stage 9.0 (TID 953) in 99 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T22:10:14.369+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T22:10:14.370+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.371+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e46c6fa
[2025-07-19T22:10:14.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.372+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161] for update
[2025-07-19T22:10:14.373+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.2.delta.d4631007-ab73-424f-977a-544c75997238.TID958.tmp
[2025-07-19T22:10:14.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.375+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bb8376d
[2025-07-19T22:10:14.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.376+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160] for update
[2025-07-19T22:10:14.377+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b0c9382
[2025-07-19T22:10:14.378+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/.2.delta.94bfd54c-21ec-4169-ac03-c7c55c267097.TID956.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/2.delta
[2025-07-19T22:10:14.379+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/153/2.delta
[2025-07-19T22:10:14.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156] for update
[2025-07-19T22:10:14.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T22:10:14.380+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7eaa3d33
[2025-07-19T22:10:14.381+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.382+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158] for update
[2025-07-19T22:10:14.386+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.388+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fa36cfc
[2025-07-19T22:10:14.388+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.389+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159] for update
[2025-07-19T22:10:14.390+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.392+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T22:10:14.393+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 153.0 in stage 9.0 (TID 956). 5872 bytes result sent to driver
[2025-07-19T22:10:14.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 162.0 in stage 9.0 (TID 965) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.2.delta.77714f76-6689-4000-8366-8834431481b9.TID960.tmp
[2025-07-19T22:10:14.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 162.0 in stage 9.0 (TID 965)
[2025-07-19T22:10:14.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 153.0 in stage 9.0 (TID 956) in 110 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T22:10:14.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.2.delta.be9457e3-6566-4db8-8b7a-4832b0f47857.TID964.tmp
[2025-07-19T22:10:14.394+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@195a70e4
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.2.delta.e87d6e0b-a9e4-4ffc-8385-a2ed97ecab26.TID961.tmp
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162] for update
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.2.delta.01d78f0d-a58f-4031-91fd-07c8fbaa1d77.TID963.tmp
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.2.delta.22ff748c-ad31-4320-89b0-690a99f8c901.TID962.tmp
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.2.delta.3360fa49-973a-43e6-92ab-0805e12225db.TID959.tmp
[2025-07-19T22:10:14.395+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.2.delta.b4c8e0e0-3c6b-4629-9349-4116824a46a1.TID965.tmp
[2025-07-19T22:10:14.415+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/.2.delta.d4631007-ab73-424f-977a-544c75997238.TID958.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/2.delta
[2025-07-19T22:10:14.418+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/155/2.delta
[2025-07-19T22:10:14.419+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T22:10:14.419+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T22:10:14.419+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 155.0 in stage 9.0 (TID 958). 5872 bytes result sent to driver
[2025-07-19T22:10:14.420+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 163.0 in stage 9.0 (TID 966) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.424+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 155.0 in stage 9.0 (TID 958) in 105 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T22:10:14.426+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 163.0 in stage 9.0 (TID 966)
[2025-07-19T22:10:14.427+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d2a243d
[2025-07-19T22:10:14.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163] for update
[2025-07-19T22:10:14.428+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.441+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/.2.delta.01d78f0d-a58f-4031-91fd-07c8fbaa1d77.TID963.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/2.delta
[2025-07-19T22:10:14.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/160/2.delta
[2025-07-19T22:10:14.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T22:10:14.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/.2.delta.e87d6e0b-a9e4-4ffc-8385-a2ed97ecab26.TID961.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/2.delta
[2025-07-19T22:10:14.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/158/2.delta
[2025-07-19T22:10:14.445+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T22:10:14.446+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/.2.delta.be9457e3-6566-4db8-8b7a-4832b0f47857.TID964.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/2.delta
[2025-07-19T22:10:14.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/161/2.delta
[2025-07-19T22:10:14.447+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T22:10:14.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T22:10:14.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/.2.delta.22ff748c-ad31-4320-89b0-690a99f8c901.TID962.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/2.delta
[2025-07-19T22:10:14.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/159/2.delta
[2025-07-19T22:10:14.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T22:10:14.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 160.0 in stage 9.0 (TID 963). 5829 bytes result sent to driver
[2025-07-19T22:10:14.448+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T22:10:14.452+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/.2.delta.77714f76-6689-4000-8366-8834431481b9.TID960.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/2.delta
[2025-07-19T22:10:14.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/157/2.delta
[2025-07-19T22:10:14.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 164.0 in stage 9.0 (TID 967) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.453+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T22:10:14.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 160.0 in stage 9.0 (TID 963) in 118 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T22:10:14.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 161.0 in stage 9.0 (TID 964). 5872 bytes result sent to driver
[2025-07-19T22:10:14.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 165.0 in stage 9.0 (TID 968) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.454+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 165.0 in stage 9.0 (TID 968)
[2025-07-19T22:10:14.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.2.delta.4d0ef218-8bca-43ec-921f-0ffe0fa31c6e.TID966.tmp
[2025-07-19T22:10:14.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 161.0 in stage 9.0 (TID 964) in 115 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T22:10:14.455+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T22:10:14.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 164.0 in stage 9.0 (TID 967)
[2025-07-19T22:10:14.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T22:10:14.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 157.0 in stage 9.0 (TID 960). 5829 bytes result sent to driver
[2025-07-19T22:10:14.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/.2.delta.3360fa49-973a-43e6-92ab-0805e12225db.TID959.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/2.delta
[2025-07-19T22:10:14.460+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/156/2.delta
[2025-07-19T22:10:14.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 158.0 in stage 9.0 (TID 961). 5829 bytes result sent to driver
[2025-07-19T22:10:14.461+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T22:10:14.463+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 159.0 in stage 9.0 (TID 962). 5829 bytes result sent to driver
[2025-07-19T22:10:14.464+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 166.0 in stage 9.0 (TID 969) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 166.0 in stage 9.0 (TID 969)
[2025-07-19T22:10:14.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T22:10:14.465+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 167.0 in stage 9.0 (TID 970) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 168.0 in stage 9.0 (TID 971) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.466+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/.2.delta.b4c8e0e0-3c6b-4629-9349-4116824a46a1.TID965.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/2.delta
[2025-07-19T22:10:14.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/162/2.delta
[2025-07-19T22:10:14.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T22:10:14.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 157.0 in stage 9.0 (TID 960) in 131 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T22:10:14.467+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 159.0 in stage 9.0 (TID 962) in 131 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T22:10:14.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 158.0 in stage 9.0 (TID 961) in 132 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T22:10:14.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T22:10:14.468+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.469+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 156.0 in stage 9.0 (TID 959). 5829 bytes result sent to driver
[2025-07-19T22:10:14.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 169.0 in stage 9.0 (TID 972) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 169.0 in stage 9.0 (TID 972)
[2025-07-19T22:10:14.470+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.471+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T22:10:14.474+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 167.0 in stage 9.0 (TID 970)
[2025-07-19T22:10:14.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.475+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:14.476+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 156.0 in stage 9.0 (TID 959) in 142 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T22:10:14.480+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 168.0 in stage 9.0 (TID 971)
[2025-07-19T22:10:14.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65f75c58
[2025-07-19T22:10:14.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165] for update
[2025-07-19T22:10:14.481+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d9403f7
[2025-07-19T22:10:14.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c55c0a7
[2025-07-19T22:10:14.482+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.484+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.484+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164] for update
[2025-07-19T22:10:14.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T22:10:14.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169] for update
[2025-07-19T22:10:14.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1866804f
[2025-07-19T22:10:14.485+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167] for update
[2025-07-19T22:10:14.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2327ccfe
[2025-07-19T22:10:14.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.486+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166] for update
[2025-07-19T22:10:14.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.487+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T22:10:14.488+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.488+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.489+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@225b2273
[2025-07-19T22:10:14.490+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168] for update
[2025-07-19T22:10:14.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 162.0 in stage 9.0 (TID 965). 5829 bytes result sent to driver
[2025-07-19T22:10:14.491+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 162.0 in stage 9.0 (TID 965) in 122 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T22:10:14.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 170.0 in stage 9.0 (TID 973) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.492+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 170.0 in stage 9.0 (TID 973)
[2025-07-19T22:10:14.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.493+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.2.delta.0af9bcac-08ba-4537-819a-d773b6387abf.TID968.tmp
[2025-07-19T22:10:14.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a5bd513
[2025-07-19T22:10:14.494+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170] for update
[2025-07-19T22:10:14.495+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.496+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.2.delta.ab78d680-2b90-4559-bac2-8570c100752f.TID967.tmp
[2025-07-19T22:10:14.499+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.2.delta.994309ec-ba0f-4375-ad3e-de549f605ff2.TID971.tmp
[2025-07-19T22:10:14.500+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.2.delta.8fb0143d-f02f-4c91-83ff-f4eb80d6c94e.TID969.tmp
[2025-07-19T22:10:14.502+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.2.delta.ae30b67b-37ae-4d25-96ce-e43bb917131f.TID970.tmp
[2025-07-19T22:10:14.503+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.2.delta.9b77540c-77b4-4d77-b308-b477a24d2548.TID972.tmp
[2025-07-19T22:10:14.505+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/.2.delta.4d0ef218-8bca-43ec-921f-0ffe0fa31c6e.TID966.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/2.delta
[2025-07-19T22:10:14.506+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/163/2.delta
[2025-07-19T22:10:14.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.2.delta.4c9ed3a0-6859-4817-9a0b-49bc60775014.TID973.tmp
[2025-07-19T22:10:14.508+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T22:10:14.513+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T22:10:14.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 163.0 in stage 9.0 (TID 966). 5829 bytes result sent to driver
[2025-07-19T22:10:14.514+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 171.0 in stage 9.0 (TID 974) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.515+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 163.0 in stage 9.0 (TID 966) in 99 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T22:10:14.515+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 171.0 in stage 9.0 (TID 974)
[2025-07-19T22:10:14.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.520+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e566af0
[2025-07-19T22:10:14.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.521+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171] for update
[2025-07-19T22:10:14.523+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.534+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.2.delta.7e91450e-95fb-483b-84bb-b2122f152464.TID974.tmp
[2025-07-19T22:10:14.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/.2.delta.994309ec-ba0f-4375-ad3e-de549f605ff2.TID971.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/2.delta
[2025-07-19T22:10:14.540+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/168/2.delta
[2025-07-19T22:10:14.542+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T22:10:14.544+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/.2.delta.8fb0143d-f02f-4c91-83ff-f4eb80d6c94e.TID969.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/2.delta
[2025-07-19T22:10:14.545+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/166/2.delta
[2025-07-19T22:10:14.546+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T22:10:14.547+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/.2.delta.ab78d680-2b90-4559-bac2-8570c100752f.TID967.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/2.delta
[2025-07-19T22:10:14.549+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/164/2.delta
[2025-07-19T22:10:14.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/.2.delta.0af9bcac-08ba-4537-819a-d773b6387abf.TID968.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/2.delta
[2025-07-19T22:10:14.551+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/165/2.delta
[2025-07-19T22:10:14.552+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T22:10:14.553+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/.2.delta.4c9ed3a0-6859-4817-9a0b-49bc60775014.TID973.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/2.delta
[2025-07-19T22:10:14.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/170/2.delta
[2025-07-19T22:10:14.554+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T22:10:14.555+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T22:10:14.557+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T22:10:14.558+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T22:10:14.560+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 166.0 in stage 9.0 (TID 969). 5829 bytes result sent to driver
[2025-07-19T22:10:14.561+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 172.0 in stage 9.0 (TID 975) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.563+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 168.0 in stage 9.0 (TID 971). 5829 bytes result sent to driver
[2025-07-19T22:10:14.565+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 172.0 in stage 9.0 (TID 975)
[2025-07-19T22:10:14.566+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 168.0 in stage 9.0 (TID 971) in 84 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T22:10:14.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 173.0 in stage 9.0 (TID 976) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.567+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 166.0 in stage 9.0 (TID 969) in 88 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T22:10:14.569+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 173.0 in stage 9.0 (TID 976)
[2025-07-19T22:10:14.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.570+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.571+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.572+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.573+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d469fba
[2025-07-19T22:10:14.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T22:10:14.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.574+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172] for update
[2025-07-19T22:10:14.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 164.0 in stage 9.0 (TID 967). 5829 bytes result sent to driver
[2025-07-19T22:10:14.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 164.0 in stage 9.0 (TID 967) in 103 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T22:10:14.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 174.0 in stage 9.0 (TID 977) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.575+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T22:10:14.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 174.0 in stage 9.0 (TID 977)
[2025-07-19T22:10:14.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T22:10:14.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 165.0 in stage 9.0 (TID 968). 5829 bytes result sent to driver
[2025-07-19T22:10:14.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 170.0 in stage 9.0 (TID 973). 5829 bytes result sent to driver
[2025-07-19T22:10:14.576+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/.2.delta.9b77540c-77b4-4d77-b308-b477a24d2548.TID972.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/2.delta
[2025-07-19T22:10:14.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/169/2.delta
[2025-07-19T22:10:14.577+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.580+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5eb546ff
[2025-07-19T22:10:14.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 175.0 in stage 9.0 (TID 978) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.581+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 176.0 in stage 9.0 (TID 979) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.582+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 165.0 in stage 9.0 (TID 968) in 102 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T22:10:14.583+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T22:10:14.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.584+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173] for update
[2025-07-19T22:10:14.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 176.0 in stage 9.0 (TID 979)
[2025-07-19T22:10:14.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/.2.delta.ae30b67b-37ae-4d25-96ce-e43bb917131f.TID970.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/2.delta
[2025-07-19T22:10:14.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/167/2.delta
[2025-07-19T22:10:14.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 175.0 in stage 9.0 (TID 978)
[2025-07-19T22:10:14.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 170.0 in stage 9.0 (TID 973) in 73 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T22:10:14.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.585+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3906d1be
[2025-07-19T22:10:14.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T22:10:14.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174] for update
[2025-07-19T22:10:14.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T22:10:14.586+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 169.0 in stage 9.0 (TID 972). 5829 bytes result sent to driver
[2025-07-19T22:10:14.587+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f5eefcc
[2025-07-19T22:10:14.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 177.0 in stage 9.0 (TID 980) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 169.0 in stage 9.0 (TID 972) in 95 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T22:10:14.588+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175] for update
[2025-07-19T22:10:14.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 177.0 in stage 9.0 (TID 980)
[2025-07-19T22:10:14.589+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T22:10:14.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@183ce8dd
[2025-07-19T22:10:14.590+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176] for update
[2025-07-19T22:10:14.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 167.0 in stage 9.0 (TID 970). 5829 bytes result sent to driver
[2025-07-19T22:10:14.591+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 178.0 in stage 9.0 (TID 981) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.593+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.594+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 167.0 in stage 9.0 (TID 970) in 103 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T22:10:14.596+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 178.0 in stage 9.0 (TID 981)
[2025-07-19T22:10:14.597+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.598+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.600+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fe02a8
[2025-07-19T22:10:14.601+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.602+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177] for update
[2025-07-19T22:10:14.603+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.604+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1eca3d83
[2025-07-19T22:10:14.605+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178] for update
[2025-07-19T22:10:14.607+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.2.delta.8366f300-4a97-4f6f-a4bd-62b013d331d4.TID976.tmp
[2025-07-19T22:10:14.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.608+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.2.delta.c047f554-01d2-4768-9ca5-2e5702ee1a63.TID975.tmp
[2025-07-19T22:10:14.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.2.delta.152cd408-6885-4e91-9d83-494c362997d9.TID977.tmp
[2025-07-19T22:10:14.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.2.delta.2cc9ea08-3938-4935-8423-d01727c693c1.TID980.tmp
[2025-07-19T22:10:14.609+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.2.delta.9895ea60-7ab9-48a9-a126-68dd9f5eb515.TID979.tmp
[2025-07-19T22:10:14.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.2.delta.8da00256-1d72-4b7b-86b0-52c9af6109e9.TID978.tmp
[2025-07-19T22:10:14.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.2.delta.5ee7355a-b80b-4458-a1de-ca8613f8f642.TID981.tmp
[2025-07-19T22:10:14.610+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/.2.delta.7e91450e-95fb-483b-84bb-b2122f152464.TID974.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/2.delta
[2025-07-19T22:10:14.611+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/171/2.delta
[2025-07-19T22:10:14.611+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T22:10:14.612+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T22:10:14.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 171.0 in stage 9.0 (TID 974). 5829 bytes result sent to driver
[2025-07-19T22:10:14.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 171.0 in stage 9.0 (TID 974) in 82 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T22:10:14.613+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 179.0 in stage 9.0 (TID 982) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 179.0 in stage 9.0 (TID 982)
[2025-07-19T22:10:14.614+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.615+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35ad9152
[2025-07-19T22:10:14.616+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179] for update
[2025-07-19T22:10:14.617+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.618+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.2.delta.71452cbb-9d73-43dc-98a7-b8610e51e475.TID982.tmp
[2025-07-19T22:10:14.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/.2.delta.c047f554-01d2-4768-9ca5-2e5702ee1a63.TID975.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/2.delta
[2025-07-19T22:10:14.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/172/2.delta
[2025-07-19T22:10:14.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T22:10:14.622+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/.2.delta.2cc9ea08-3938-4935-8423-d01727c693c1.TID980.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/2.delta
[2025-07-19T22:10:14.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/177/2.delta
[2025-07-19T22:10:14.623+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T22:10:14.624+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/.2.delta.8366f300-4a97-4f6f-a4bd-62b013d331d4.TID976.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/2.delta
[2025-07-19T22:10:14.625+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/173/2.delta
[2025-07-19T22:10:14.627+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T22:10:14.628+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T22:10:14.629+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/.2.delta.5ee7355a-b80b-4458-a1de-ca8613f8f642.TID981.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/2.delta
[2025-07-19T22:10:14.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/178/2.delta
[2025-07-19T22:10:14.630+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 177.0 in stage 9.0 (TID 980). 5829 bytes result sent to driver
[2025-07-19T22:10:14.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T22:10:14.632+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T22:10:14.634+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 172.0 in stage 9.0 (TID 975). 5829 bytes result sent to driver
[2025-07-19T22:10:14.635+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 180.0 in stage 9.0 (TID 983) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 181.0 in stage 9.0 (TID 984) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.636+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 181.0 in stage 9.0 (TID 984)
[2025-07-19T22:10:14.637+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 172.0 in stage 9.0 (TID 975) in 82 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T22:10:14.637+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 180.0 in stage 9.0 (TID 983)
[2025-07-19T22:10:14.641+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/.2.delta.8da00256-1d72-4b7b-86b0-52c9af6109e9.TID978.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/2.delta
[2025-07-19T22:10:14.642+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/175/2.delta
[2025-07-19T22:10:14.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T22:10:14.643+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T22:10:14.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/.2.delta.152cd408-6885-4e91-9d83-494c362997d9.TID977.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/2.delta
[2025-07-19T22:10:14.644+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/174/2.delta
[2025-07-19T22:10:14.645+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 177.0 in stage 9.0 (TID 980) in 70 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T22:10:14.645+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 178.0 in stage 9.0 (TID 981). 5829 bytes result sent to driver
[2025-07-19T22:10:14.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T22:10:14.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T22:10:14.646+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.647+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.648+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 182.0 in stage 9.0 (TID 985) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.649+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bdce2fc
[2025-07-19T22:10:14.650+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 182.0 in stage 9.0 (TID 985)
[2025-07-19T22:10:14.652+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 178.0 in stage 9.0 (TID 981) in 71 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T22:10:14.653+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/.2.delta.9895ea60-7ab9-48a9-a126-68dd9f5eb515.TID979.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/2.delta
[2025-07-19T22:10:14.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/176/2.delta
[2025-07-19T22:10:14.654+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 173.0 in stage 9.0 (TID 976). 5829 bytes result sent to driver
[2025-07-19T22:10:14.655+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.655+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.656+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T22:10:14.657+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T22:10:14.658+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 174.0 in stage 9.0 (TID 977). 5829 bytes result sent to driver
[2025-07-19T22:10:14.659+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.660+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180] for update
[2025-07-19T22:10:14.662+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 183.0 in stage 9.0 (TID 986) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 173.0 in stage 9.0 (TID 976) in 90 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T22:10:14.663+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T22:10:14.664+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T22:10:14.667+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ea9297e
[2025-07-19T22:10:14.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 184.0 in stage 9.0 (TID 987) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 183.0 in stage 9.0 (TID 986)
[2025-07-19T22:10:14.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 175.0 in stage 9.0 (TID 978). 5829 bytes result sent to driver
[2025-07-19T22:10:14.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 185.0 in stage 9.0 (TID 988) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 185.0 in stage 9.0 (TID 988)
[2025-07-19T22:10:14.668+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 174.0 in stage 9.0 (TID 977) in 87 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T22:10:14.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 184.0 in stage 9.0 (TID 987)
[2025-07-19T22:10:14.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182] for update
[2025-07-19T22:10:14.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.669+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@759676e0
[2025-07-19T22:10:14.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 175.0 in stage 9.0 (TID 978) in 86 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T22:10:14.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T22:10:14.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181] for update
[2025-07-19T22:10:14.670+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.671+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 176.0 in stage 9.0 (TID 979). 5829 bytes result sent to driver
[2025-07-19T22:10:14.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 186.0 in stage 9.0 (TID 989) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f198766
[2025-07-19T22:10:14.672+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 186.0 in stage 9.0 (TID 989)
[2025-07-19T22:10:14.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185] for update
[2025-07-19T22:10:14.673+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 176.0 in stage 9.0 (TID 979) in 91 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T22:10:14.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@444d618e
[2025-07-19T22:10:14.674+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184] for update
[2025-07-19T22:10:14.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.675+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27537a0f
[2025-07-19T22:10:14.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.676+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183] for update
[2025-07-19T22:10:14.677+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d6c7e92
[2025-07-19T22:10:14.678+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186] for update
[2025-07-19T22:10:14.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.679+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/.2.delta.71452cbb-9d73-43dc-98a7-b8610e51e475.TID982.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/2.delta
[2025-07-19T22:10:14.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/179/2.delta
[2025-07-19T22:10:14.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T22:10:14.680+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.2.delta.3a29d75b-be3b-44a6-94f2-7e7346afb0be.TID988.tmp
[2025-07-19T22:10:14.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.2.delta.a6b98161-c857-4048-89ee-0f1af560373d.TID983.tmp
[2025-07-19T22:10:14.681+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.2.delta.1b876169-43ed-44c3-8678-9cff6c6a569c.TID987.tmp
[2025-07-19T22:10:14.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T22:10:14.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 179.0 in stage 9.0 (TID 982). 5829 bytes result sent to driver
[2025-07-19T22:10:14.682+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 187.0 in stage 9.0 (TID 990) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 179.0 in stage 9.0 (TID 982) in 68 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T22:10:14.683+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 187.0 in stage 9.0 (TID 990)
[2025-07-19T22:10:14.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.2.delta.f3a85d7c-3c63-4595-829d-6ef74b83e37d.TID989.tmp
[2025-07-19T22:10:14.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.684+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.685+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58c55ac4
[2025-07-19T22:10:14.685+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.2.delta.a4049628-9ce3-4d71-8e1b-f34a2715ba5d.TID986.tmp
[2025-07-19T22:10:14.685+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.2.delta.fb7d0c96-299f-45d1-9ef4-df560b14e262.TID985.tmp
[2025-07-19T22:10:14.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187] for update
[2025-07-19T22:10:14.686+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.2.delta.2b230cd1-b22f-43ed-b65b-24b166e0b32a.TID984.tmp
[2025-07-19T22:10:14.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.687+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.2.delta.17ae48e4-362a-45a7-b7d5-297b7e848e4e.TID990.tmp
[2025-07-19T22:10:14.702+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/.2.delta.a6b98161-c857-4048-89ee-0f1af560373d.TID983.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/2.delta
[2025-07-19T22:10:14.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/180/2.delta
[2025-07-19T22:10:14.703+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T22:10:14.705+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/.2.delta.2b230cd1-b22f-43ed-b65b-24b166e0b32a.TID984.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/2.delta
[2025-07-19T22:10:14.706+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/181/2.delta
[2025-07-19T22:10:14.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T22:10:14.708+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/.2.delta.f3a85d7c-3c63-4595-829d-6ef74b83e37d.TID989.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/2.delta
[2025-07-19T22:10:14.709+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/186/2.delta
[2025-07-19T22:10:14.711+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T22:10:14.712+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T22:10:14.713+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 180.0 in stage 9.0 (TID 983). 5829 bytes result sent to driver
[2025-07-19T22:10:14.715+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 188.0 in stage 9.0 (TID 991) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.716+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 180.0 in stage 9.0 (TID 983) in 79 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T22:10:14.717+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 188.0 in stage 9.0 (TID 991)
[2025-07-19T22:10:14.719+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T22:10:14.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/.2.delta.a4049628-9ce3-4d71-8e1b-f34a2715ba5d.TID986.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/2.delta
[2025-07-19T22:10:14.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/183/2.delta
[2025-07-19T22:10:14.721+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/.2.delta.1b876169-43ed-44c3-8678-9cff6c6a569c.TID987.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/2.delta
[2025-07-19T22:10:14.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/184/2.delta
[2025-07-19T22:10:14.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 181.0 in stage 9.0 (TID 984). 5829 bytes result sent to driver
[2025-07-19T22:10:14.722+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T22:10:14.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 181.0 in stage 9.0 (TID 984) in 81 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T22:10:14.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T22:10:14.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T22:10:14.723+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 189.0 in stage 9.0 (TID 992) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 186.0 in stage 9.0 (TID 989). 5829 bytes result sent to driver
[2025-07-19T22:10:14.724+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@155039b0
[2025-07-19T22:10:14.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 189.0 in stage 9.0 (TID 992)
[2025-07-19T22:10:14.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 190.0 in stage 9.0 (TID 993) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.725+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 186.0 in stage 9.0 (TID 989) in 69 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T22:10:14.726+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 190.0 in stage 9.0 (TID 993)
[2025-07-19T22:10:14.727+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.730+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188] for update
[2025-07-19T22:10:14.731+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.732+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/.2.delta.3a29d75b-be3b-44a6-94f2-7e7346afb0be.TID988.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/2.delta
[2025-07-19T22:10:14.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/185/2.delta
[2025-07-19T22:10:14.735+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.738+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e12d7f
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189] for update
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@640ecba6
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.739+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190] for update
[2025-07-19T22:10:14.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 183.0 in stage 9.0 (TID 986). 5829 bytes result sent to driver
[2025-07-19T22:10:14.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 184.0 in stage 9.0 (TID 987). 5829 bytes result sent to driver
[2025-07-19T22:10:14.740+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 191.0 in stage 9.0 (TID 994) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.741+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 183.0 in stage 9.0 (TID 986) in 84 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T22:10:14.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T22:10:14.742+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/.2.delta.fb7d0c96-299f-45d1-9ef4-df560b14e262.TID985.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/2.delta
[2025-07-19T22:10:14.743+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 184.0 in stage 9.0 (TID 987) in 83 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T22:10:14.745+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 191.0 in stage 9.0 (TID 994)
[2025-07-19T22:10:14.746+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/182/2.delta
[2025-07-19T22:10:14.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 185.0 in stage 9.0 (TID 988). 5915 bytes result sent to driver
[2025-07-19T22:10:14.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 192.0 in stage 9.0 (TID 995) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.2.delta.505c8e0f-12dd-423d-8c66-6ae2da0511c3.TID991.tmp
[2025-07-19T22:10:14.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 192.0 in stage 9.0 (TID 995)
[2025-07-19T22:10:14.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 185.0 in stage 9.0 (TID 988) in 89 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T22:10:14.747+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/.2.delta.17ae48e4-362a-45a7-b7d5-297b7e848e4e.TID990.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/2.delta
[2025-07-19T22:10:14.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 193.0 in stage 9.0 (TID 996) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T22:10:14.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/187/2.delta
[2025-07-19T22:10:14.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 193.0 in stage 9.0 (TID 996)
[2025-07-19T22:10:14.748+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T22:10:14.749+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d7526cb
[2025-07-19T22:10:14.750+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191] for update
[2025-07-19T22:10:14.751+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.752+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@444653c9
[2025-07-19T22:10:14.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.753+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192] for update
[2025-07-19T22:10:14.754+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.755+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T22:10:14.756+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.2.delta.dd6fc49f-98b8-4f71-90fa-ab75832098b4.TID992.tmp
[2025-07-19T22:10:14.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 187.0 in stage 9.0 (TID 990). 5872 bytes result sent to driver
[2025-07-19T22:10:14.757+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T22:10:14.758+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 194.0 in stage 9.0 (TID 997) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 182.0 in stage 9.0 (TID 985). 5872 bytes result sent to driver
[2025-07-19T22:10:14.759+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fa964bf
[2025-07-19T22:10:14.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 187.0 in stage 9.0 (TID 990) in 78 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T22:10:14.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.2.delta.4d3f51d9-0a34-48e3-a73f-77e411f8e7db.TID993.tmp
[2025-07-19T22:10:14.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 182.0 in stage 9.0 (TID 985) in 107 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T22:10:14.760+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 195.0 in stage 9.0 (TID 998) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.761+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 194.0 in stage 9.0 (TID 997)
[2025-07-19T22:10:14.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.763+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.764+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193] for update
[2025-07-19T22:10:14.765+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.2.delta.e4d92611-67c9-4ab5-8d24-318afab04243.TID995.tmp
[2025-07-19T22:10:14.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 195.0 in stage 9.0 (TID 998)
[2025-07-19T22:10:14.766+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.767+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.768+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5733b54d
[2025-07-19T22:10:14.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.769+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195] for update
[2025-07-19T22:10:14.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.770+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a2c8660
[2025-07-19T22:10:14.772+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194] for update
[2025-07-19T22:10:14.773+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.2.delta.07cc20c0-e7fc-4bd5-87f6-144c29d303d8.TID994.tmp
[2025-07-19T22:10:14.774+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.2.delta.3261b757-8840-4533-90d5-fb2c4d6e7222.TID996.tmp
[2025-07-19T22:10:14.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.2.delta.da29f641-77c2-482d-8fac-80ba647e933c.TID997.tmp
[2025-07-19T22:10:14.775+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.2.delta.055bdd59-4753-4218-8477-bac341195a4f.TID998.tmp
[2025-07-19T22:10:14.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/.2.delta.505c8e0f-12dd-423d-8c66-6ae2da0511c3.TID991.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/2.delta
[2025-07-19T22:10:14.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/188/2.delta
[2025-07-19T22:10:14.780+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T22:10:14.783+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T22:10:14.785+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 188.0 in stage 9.0 (TID 991). 5872 bytes result sent to driver
[2025-07-19T22:10:14.786+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 196.0 in stage 9.0 (TID 999) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 188.0 in stage 9.0 (TID 991) in 77 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T22:10:14.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 196.0 in stage 9.0 (TID 999)
[2025-07-19T22:10:14.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/.2.delta.dd6fc49f-98b8-4f71-90fa-ab75832098b4.TID992.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/2.delta
[2025-07-19T22:10:14.787+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/189/2.delta
[2025-07-19T22:10:14.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.788+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/.2.delta.4d3f51d9-0a34-48e3-a73f-77e411f8e7db.TID993.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/2.delta
[2025-07-19T22:10:14.789+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/190/2.delta
[2025-07-19T22:10:14.789+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T22:10:14.790+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T22:10:14.790+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/.2.delta.e4d92611-67c9-4ab5-8d24-318afab04243.TID995.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/2.delta
[2025-07-19T22:10:14.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/192/2.delta
[2025-07-19T22:10:14.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T22:10:14.792+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f66dfd1
[2025-07-19T22:10:14.792+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T22:10:14.792+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 190.0 in stage 9.0 (TID 993). 5829 bytes result sent to driver
[2025-07-19T22:10:14.793+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.794+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 197.0 in stage 9.0 (TID 1000) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196] for update
[2025-07-19T22:10:14.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 190.0 in stage 9.0 (TID 993) in 81 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T22:10:14.795+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 197.0 in stage 9.0 (TID 1000)
[2025-07-19T22:10:14.799+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.801+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T22:10:14.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.802+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 189.0 in stage 9.0 (TID 992). 5872 bytes result sent to driver
[2025-07-19T22:10:14.803+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T22:10:14.804+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 198.0 in stage 9.0 (TID 1001) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.805+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 192.0 in stage 9.0 (TID 995). 5872 bytes result sent to driver
[2025-07-19T22:10:14.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 189.0 in stage 9.0 (TID 992) in 91 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T22:10:14.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49acc0fc
[2025-07-19T22:10:14.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Starting task 199.0 in stage 9.0 (TID 1002) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T22:10:14.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 199.0 in stage 9.0 (TID 1002)
[2025-07-19T22:10:14.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197] for update
[2025-07-19T22:10:14.808+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/.2.delta.07cc20c0-e7fc-4bd5-87f6-144c29d303d8.TID994.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/2.delta
[2025-07-19T22:10:14.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/191/2.delta
[2025-07-19T22:10:14.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 192.0 in stage 9.0 (TID 995) in 78 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T22:10:14.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T22:10:14.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T22:10:14.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.810+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5be15ec5
[2025-07-19T22:10:14.811+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Running task 198.0 in stage 9.0 (TID 1001)
[2025-07-19T22:10:14.811+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.812+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199] for update
[2025-07-19T22:10:14.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/.2.delta.3261b757-8840-4533-90d5-fb2c4d6e7222.TID996.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/2.delta
[2025-07-19T22:10:14.814+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/193/2.delta
[2025-07-19T22:10:14.815+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.2.delta.a31e459f-5816-4737-bb20-0cd789f04802.TID999.tmp
[2025-07-19T22:10:14.816+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T22:10:14.817+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 191.0 in stage 9.0 (TID 994). 5872 bytes result sent to driver
[2025-07-19T22:10:14.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T22:10:14.818+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 191.0 in stage 9.0 (TID 994) in 93 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T22:10:14.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/.2.delta.da29f641-77c2-482d-8fac-80ba647e933c.TID997.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/2.delta
[2025-07-19T22:10:14.820+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/194/2.delta
[2025-07-19T22:10:14.821+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T22:10:14.822+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T22:10:14.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T22:10:14.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22dae499
[2025-07-19T22:10:14.823+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],002fa0f1-bd40-4ea7-9304-5ec9b41c6781) is active
[2025-07-19T22:10:14.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198] for update
[2025-07-19T22:10:14.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/.2.delta.055bdd59-4753-4218-8477-bac341195a4f.TID998.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/2.delta
[2025-07-19T22:10:14.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/195/2.delta
[2025-07-19T22:10:14.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T22:10:14.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T22:10:14.824+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T22:10:14.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 194.0 in stage 9.0 (TID 997). 5872 bytes result sent to driver
[2025-07-19T22:10:14.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T22:10:14.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.2.delta.f9d2c546-a790-4394-8f4a-d36d93992293.TID1000.tmp
[2025-07-19T22:10:14.825+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 195.0 in stage 9.0 (TID 998). 5872 bytes result sent to driver
[2025-07-19T22:10:14.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.2.delta.7273036f-1137-4993-846e-48bf232a4fb1.TID1002.tmp
[2025-07-19T22:10:14.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 194.0 in stage 9.0 (TID 997) in 85 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T22:10:14.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T22:10:14.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 195.0 in stage 9.0 (TID 998) in 83 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T22:10:14.826+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 193.0 in stage 9.0 (TID 996). 5872 bytes result sent to driver
[2025-07-19T22:10:14.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 193.0 in stage 9.0 (TID 996) in 98 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T22:10:14.827+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.2.delta.9c7d2040-0b09-41f3-9e1f-5192669a965a.TID1001.tmp
[2025-07-19T22:10:14.837+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/.2.delta.a31e459f-5816-4737-bb20-0cd789f04802.TID999.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/2.delta
[2025-07-19T22:10:14.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/196/2.delta
[2025-07-19T22:10:14.838+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T22:10:14.840+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T22:10:14.841+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 196.0 in stage 9.0 (TID 999). 5872 bytes result sent to driver
[2025-07-19T22:10:14.842+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 196.0 in stage 9.0 (TID 999) in 57 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T22:10:14.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/.2.delta.f9d2c546-a790-4394-8f4a-d36d93992293.TID1000.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/2.delta
[2025-07-19T22:10:14.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/197/2.delta
[2025-07-19T22:10:14.843+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T22:10:14.845+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T22:10:14.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 197.0 in stage 9.0 (TID 1000). 5872 bytes result sent to driver
[2025-07-19T22:10:14.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 197.0 in stage 9.0 (TID 1000) in 54 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T22:10:14.846+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/.2.delta.9c7d2040-0b09-41f3-9e1f-5192669a965a.TID1001.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/2.delta
[2025-07-19T22:10:14.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/198/2.delta
[2025-07-19T22:10:14.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/.2.delta.7273036f-1137-4993-846e-48bf232a4fb1.TID1002.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/2.delta
[2025-07-19T22:10:14.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/state/0/199/2.delta
[2025-07-19T22:10:14.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T22:10:14.847+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T22:10:14.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T22:10:14.849+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DataWritingSparkTask: Committed partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T22:10:14.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 198.0 in stage 9.0 (TID 1001). 5829 bytes result sent to driver
[2025-07-19T22:10:14.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO Executor: Finished task 199.0 in stage 9.0 (TID 1002). 5829 bytes result sent to driver
[2025-07-19T22:10:14.850+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 199.0 in stage 9.0 (TID 1002) in 47 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T22:10:14.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSetManager: Finished task 198.0 in stage 9.0 (TID 1001) in 49 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T22:10:14.851+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-19T22:10:14.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DAGScheduler: ResultStage 9 (start at <unknown>:0) finished in 4.690 s
[2025-07-19T22:10:14.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T22:10:14.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-07-19T22:10:14.852+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO DAGScheduler: Job 4 finished: start at <unknown>:0, took 4.794564 s
[2025-07-19T22:10:14.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T22:10:14.853+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO SparkWrite: Committing epoch 1 for query 76699ab7-445a-4f4e-a8af-51ec24e5ea93 in append mode
[2025-07-19T22:10:14.858+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T22:10:14.899+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v157.metadata.json
[2025-07-19T22:10:14.918+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO SnapshotProducer: Committed snapshot 1769037806438969308 (FastAppend)
[2025-07-19T22:10:14.951+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=1769037806438969308, sequenceNumber=156, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.084778416S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=8258}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=12519}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=26799088}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752962984887, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T22:10:14.953+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO SparkWrite: Committed in 85 ms
[2025-07-19T22:10:14.956+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T22:10:14.966+0000] {subprocess.py:93} INFO - 25/07/19 22:10:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/commits/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/commits/.1.23b9f981-9525-4fdf-b324-274f1cc3f04b.tmp
[2025-07-19T22:10:15.011+0000] {subprocess.py:93} INFO - 25/07/19 22:10:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/commits/.1.23b9f981-9525-4fdf-b324-274f1cc3f04b.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T22:06:00+00:00/commits/1
[2025-07-19T22:10:15.013+0000] {subprocess.py:93} INFO - 25/07/19 22:10:15 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T22:10:15.013+0000] {subprocess.py:93} INFO -   "id" : "76699ab7-445a-4f4e-a8af-51ec24e5ea93",
[2025-07-19T22:10:15.013+0000] {subprocess.py:93} INFO -   "runId" : "002fa0f1-bd40-4ea7-9304-5ec9b41c6781",
[2025-07-19T22:10:15.013+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T22:10:09.758Z",
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -     "addBatch" : 5057,
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -     "commitOffsets" : 67,
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T22:10:15.014+0000] {subprocess.py:93} INFO -     "latestOffset" : 5,
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -     "queryPlanning" : 38,
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -     "triggerExecution" : 5252,
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -     "walCommit" : 83
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T21:53:00.000Z"
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -   },
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T22:10:15.015+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 276,
[2025-07-19T22:10:15.016+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T22:10:15.016+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 246,
[2025-07-19T22:10:15.016+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T22:10:15.016+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 103,
[2025-07-19T22:10:15.016+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 15082,
[2025-07-19T22:10:15.016+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 159624,
[2025-07-19T22:10:15.016+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T22:10:15.016+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 77832
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T22:10:15.017+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -         "0" : 276
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -       }
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -     },
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T22:10:15.018+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T22:10:15.019+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T22:10:15.019+0000] {subprocess.py:93} INFO -     }
[2025-07-19T22:10:15.019+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T22:10:15.019+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T22:10:15.019+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T22:10:15.019+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T22:10:15.019+0000] {subprocess.py:93} INFO -   }
[2025-07-19T22:10:15.019+0000] {subprocess.py:93} INFO - }
[2025-07-19T22:10:16.165+0000] {subprocess.py:93} INFO - 25/07/19 22:10:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:22.791+0000] {subprocess.py:93} INFO - 25/07/19 22:10:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:25.021+0000] {subprocess.py:93} INFO - 25/07/19 22:10:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:26.176+0000] {subprocess.py:93} INFO - 25/07/19 22:10:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:32.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:35.022+0000] {subprocess.py:93} INFO - 25/07/19 22:10:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:36.180+0000] {subprocess.py:93} INFO - 25/07/19 22:10:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:42.807+0000] {subprocess.py:93} INFO - 25/07/19 22:10:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:45.025+0000] {subprocess.py:93} INFO - 25/07/19 22:10:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:46.183+0000] {subprocess.py:93} INFO - 25/07/19 22:10:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T22:10:48.967+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3, groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T22:10:48.968+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3, groupId=spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T22:10:48.971+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO Metrics: Metrics scheduler closed
[2025-07-19T22:10:48.971+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T22:10:48.972+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO Metrics: Metrics reporters closed
[2025-07-19T22:10:48.974+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-6f1a77d6-f578-4266-b9f6-e6fd45915c94-246029268-executor-3 unregistered
[2025-07-19T22:10:48.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2, groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T22:10:48.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2, groupId=spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T22:10:48.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO Metrics: Metrics scheduler closed
[2025-07-19T22:10:48.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T22:10:48.975+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO Metrics: Metrics reporters closed
[2025-07-19T22:10:48.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-9f1cfae4-6a53-4e2c-82f7-d8a87f82c082--301468685-executor-2 unregistered
[2025-07-19T22:10:48.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1, groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T22:10:48.976+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1, groupId=spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T22:10:48.977+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO Metrics: Metrics scheduler closed
[2025-07-19T22:10:48.977+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T22:10:48.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO Metrics: Metrics reporters closed
[2025-07-19T22:10:48.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-ac247e85-a0e1-42f3-9c67-fdcd44acade6--1279438763-executor-1 unregistered
[2025-07-19T22:10:48.978+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO SparkContext: Invoking stop() from shutdown hook
[2025-07-19T22:10:48.979+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-19T22:10:48.988+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO SparkUI: Stopped Spark web UI at http://8b44f3d35cfa:4041
[2025-07-19T22:10:49.000+0000] {subprocess.py:93} INFO - 25/07/19 22:10:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-19T22:10:49.033+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO MemoryStore: MemoryStore cleared
[2025-07-19T22:10:49.035+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO BlockManager: BlockManager stopped
[2025-07-19T22:10:49.041+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-19T22:10:49.047+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-19T22:10:49.065+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO SparkContext: Successfully stopped SparkContext
[2025-07-19T22:10:49.069+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO ShutdownHookManager: Shutdown hook called
[2025-07-19T22:10:49.072+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-a63be30f-f88f-4beb-aca8-b6fae197191e/pyspark-3bd1f743-49df-4429-b343-878d2438f29b
[2025-07-19T22:10:49.079+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-a63be30f-f88f-4beb-aca8-b6fae197191e
[2025-07-19T22:10:49.093+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-32c0af5e-3948-45d7-922b-0a761953961c
[2025-07-19T22:10:49.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2025-07-19T22:10:49.119+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2025-07-19T22:10:49.120+0000] {subprocess.py:93} INFO - 25/07/19 22:10:49 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2025-07-19T22:10:49.578+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-19T22:10:49.632+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=restaurant_pipeline, task_id=stream_to_bronze, execution_date=20250719T220600, start_date=20250719T220941, end_date=20250719T221049
[2025-07-19T22:10:49.658+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-19T22:10:49.702+0000] {taskinstance.py:2778} INFO - 1 downstream tasks scheduled from follow-on schedule check
